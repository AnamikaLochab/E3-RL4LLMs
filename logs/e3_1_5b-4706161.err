
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.5/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_covvar_kappa_0.5//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.5//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.5//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_covvar_kappa_0.5/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
[2025-11-09 18:45:05,039 W 1231689 1231689] rpc_client.h:153: Failed to connect to GCS at address 172.18.49.217:61509 within 5 seconds.
2025-11-09 18:45:12,419	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=1239844)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-09 18:45:35,654:Waiting for register center actor DCZbac_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=1243610)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1243612)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=1243612)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=1243404)[0m [rank0]:[W1109 18:45:55.136258766 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=1243610)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1243610)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1243404)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243404)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m [rank1]:[W1109 18:45:55.276925412 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243612)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1243612)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1243404)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1243610)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(WorkerDict pid=1243404)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=1243609)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:   0%|          | 1/480 [01:59<15:56:31, 119.81s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   0%|          | 2/480 [04:00<16:00:02, 120.51s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   1%|          | 3/480 [06:04<16:09:24, 121.94s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   1%|          | 4/480 [08:03<15:57:52, 120.74s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   1%|          | 5/480 [10:03<15:52:57, 120.37s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   1%|â–         | 6/480 [12:04<15:53:16, 120.67s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   1%|â–         | 7/480 [14:07<15:57:38, 121.48s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   2%|â–         | 8/480 [16:07<15:51:28, 120.95s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   2%|â–         | 9/480 [18:06<15:44:37, 120.33s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   2%|â–         | 10/480 [21:27<18:58:16, 145.31s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   2%|â–         | 11/480 [23:23<17:46:43, 136.47s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   2%|â–Ž         | 12/480 [25:22<17:00:50, 130.88s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   3%|â–Ž         | 13/480 [27:20<16:28:43, 127.03s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   3%|â–Ž         | 14/480 [29:20<16:11:51, 125.13s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   3%|â–Ž         | 15/480 [31:18<15:51:47, 122.81s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   3%|â–Ž         | 16/480 [33:17<15:40:07, 121.57s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   4%|â–Ž         | 17/480 [35:15<15:31:18, 120.69s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   4%|â–         | 18/480 [37:12<15:19:45, 119.45s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   4%|â–         | 19/480 [39:10<15:15:03, 119.10s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   4%|â–         | 20/480 [42:31<18:20:28, 143.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   4%|â–         | 21/480 [44:29<17:19:29, 135.88s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   5%|â–         | 22/480 [46:28<16:39:56, 131.00s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   5%|â–         | 23/480 [48:25<16:04:40, 126.65s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   5%|â–Œ         | 24/480 [50:18<15:32:57, 122.76s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   5%|â–Œ         | 25/480 [52:11<15:07:08, 119.62s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   5%|â–Œ         | 26/480 [54:07<14:58:01, 118.68s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   6%|â–Œ         | 27/480 [56:06<14:56:55, 118.80s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   6%|â–Œ         | 28/480 [57:58<14:37:58, 116.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   6%|â–Œ         | 29/480 [59:53<14:32:56, 116.13s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:01<17:14:00, 137.87s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   6%|â–‹         | 31/480 [1:04:48<16:02:19, 128.60s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:35<15:12:02, 122.15s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:37<15:09:45, 122.12s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:29<14:44:37, 119.01s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:20<14:24:46, 116.60s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:10<14:07:14, 114.49s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:02<13:59:36, 113.72s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   8%|â–Š         | 38/480 [1:17:58<14:04:30, 114.64s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   8%|â–Š         | 39/480 [1:19:47<13:48:18, 112.69s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   8%|â–Š         | 40/480 [1:22:53<16:28:12, 134.75s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   9%|â–Š         | 41/480 [1:24:43<15:32:57, 127.51s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   9%|â–‰         | 42/480 [1:26:35<14:56:01, 122.74s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:45<15:10:45, 125.05s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:35<14:35:05, 120.43s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:20<13:58:45, 115.69s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:10<13:45:54, 114.18s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:58<13:30:11, 112.27s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:50<13:26:31, 112.02s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:43<13:27:05, 112.36s/it]
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(TaskRunner pid=1239844)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:02<16:31:57, 138.41s/it]
[36m(WorkerDict pid=1243609)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:50<15:24:11, 129.26s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:34<14:28:41, 121.78s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:17<13:45:18, 115.97s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:06<13:29:02, 113.95s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:51:50<13:06:08, 110.98s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:39<12:59:17, 110.28s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:27<12:54:26, 109.85s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:12<12:40:44, 108.16s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:58:56<12:31:18, 107.07s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:01:51<14:50:53, 127.27s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:03:38<14:06:28, 121.21s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:21<13:27:58, 115.98s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:07:04<12:59:02, 112.09s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:09:05<13:15:38, 114.76s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:10:49<12:50:18, 111.37s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:12:38<12:44:43, 110.83s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:14:20<12:23:41, 108.04s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:16:05<12:15:01, 107.04s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:17:53<12:15:37, 107.39s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:20:51<14:39:18, 128.68s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:22:42<14:00:19, 123.28s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:24:25<13:17:21, 117.26s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:26:09<12:48:23, 113.28s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:27:55<12:32:15, 111.17s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:29:38<12:13:55, 108.73s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:31:26<12:09:05, 108.28s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:33:12<12:03:27, 107.71s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:34:58<11:58:13, 107.20s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:36:47<11:59:39, 107.68s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-09 21:26:06,590:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:39:47<14:23:03, 129.46s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:41:33<13:34:41, 122.51s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:43:19<12:59:41, 117.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:45:07<12:38:48, 114.68s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:46:54<12:21:53, 112.41s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:48:40<12:06:25, 110.34s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:50:27<11:58:12, 109.37s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:52:20<12:03:18, 110.43s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:54:09<11:57:52, 109.88s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:55:53<11:46:01, 108.34s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:58:51<13:59:01, 129.08s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:00:33<13:04:02, 120.93s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-09 21:49:49,145:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:02:19<12:34:18, 116.64s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:04:06<12:12:28, 113.56s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-09 21:53:30,981:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:06:01<12:13:14, 113.97s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:07:44<11:51:52, 110.94s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:09:34<11:47:23, 110.53s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:11:16<11:28:25, 107.85s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:12:53<11:05:41, 104.56s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:14:44<11:16:21, 106.51s/it]
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(WorkerDict pid=1243404)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1243404)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=1239844)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:18:00<14:04:56, 133.41s/it]
[36m(WorkerDict pid=1243610)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243610)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:19:40<13:00:13, 123.52s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:21:27<12:25:44, 118.37s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:23:08<11:51:00, 113.16s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:24:47<11:23:53, 109.13s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:26:32<11:13:54, 107.83s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:28:11<10:56:15, 105.28s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:29:58<10:56:29, 105.60s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:31:37<10:43:42, 103.83s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:33:31<11:00:09, 106.76s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:36:27<13:05:33, 127.39s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:38:11<12:21:40, 120.60s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:39:47<11:33:36, 113.09s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:41:30<11:13:58, 110.19s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:43:16<11:03:24, 108.76s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:44:50<10:35:58, 104.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:46:28<10:22:03, 102.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:48:09<10:17:49, 102.12s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:49:52<10:17:21, 102.32s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:51:34<10:13:43, 102.01s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:54:27<12:21:29, 123.58s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-09 22:43:42,825:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:56:10<11:40:56, 117.15s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:57:55<11:17:07, 113.48s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:59:36<10:53:13, 109.78s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:01:29<10:57:23, 110.80s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:03:10<10:37:54, 107.82s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:04:51<10:24:47, 105.90s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:06:32<10:13:29, 104.28s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:08:13<10:06:56, 103.46s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:09:54<10:01:14, 102.78s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:12:47<12:01:30, 123.69s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:14:31<11:25:39, 117.88s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:16:10<10:50:40, 112.19s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:17:52<10:31:24, 109.18s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:19:33<10:15:28, 106.73s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:21:15<10:04:25, 105.12s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:22:55<9:55:21, 103.84s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:24:33<9:42:30, 101.90s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:26:14<9:39:27, 101.66s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:27:56<9:39:21, 101.94s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:30:49<11:37:31, 123.09s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:32:32<11:00:58, 116.99s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:34:10<10:28:00, 111.48s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:35:55<10:15:22, 109.56s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:37:34<9:55:21, 106.31s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:39:13<9:41:04, 104.07s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:40:47<9:23:07, 101.16s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:42:25<9:16:20, 100.24s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:44:05<9:13:00, 99.94s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:45:51<9:21:11, 101.73s/it]
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(TaskRunner pid=1239844)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:49:00<11:44:25, 128.08s/it]
[36m(WorkerDict pid=1243609)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:50:42<10:59:24, 120.26s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:52:23<10:24:56, 114.32s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:54:02<9:58:10, 109.76s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:55:44<9:43:33, 107.40s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:57:24<9:29:51, 105.21s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:58:59<9:12:32, 102.32s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:00:35<8:59:55, 100.29s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:02:20<9:06:27, 101.82s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:04:05<9:08:42, 102.56s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:06:56<10:56:48, 123.15s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:08:43<10:28:52, 118.28s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:10:26<10:02:30, 113.68s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:12:05<9:38:31, 109.50s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:13:42<9:16:00, 105.57s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:15:20<9:02:16, 103.29s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:16:58<8:52:26, 101.74s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:18:33<8:40:54, 99.85s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:20:13<8:38:55, 99.79s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:21:48<8:30:36, 98.51s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:24:40<10:22:19, 120.45s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:26:19<9:46:58, 113.98s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:27:56<9:19:09, 108.93s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:29:34<9:00:05, 105.56s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:31:08<8:41:04, 102.17s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:32:50<8:38:55, 102.08s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:34:30<8:34:45, 101.60s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:36:09<8:29:12, 100.83s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:37:51<8:28:46, 101.08s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:39:31<8:24:40, 100.60s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 00:30:19,524:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:42:30<10:21:01, 124.20s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:44:10<9:42:38, 116.92s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:45:47<9:11:11, 110.98s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:47:27<8:53:32, 107.79s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:49:03<8:33:48, 104.15s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:50:46<8:30:54, 103.91s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:52:25<8:21:59, 102.45s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:54:00<8:09:30, 100.24s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:55:41<8:07:37, 100.20s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:57:22<8:07:32, 100.53s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 00:48:06,537:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:00:14<9:49:52, 122.04s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:01:50<9:10:47, 114.35s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:03:24<8:39:09, 108.16s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:05:02<8:22:22, 105.03s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:06:42<8:13:17, 103.49s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:08:24<8:10:24, 103.24s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:10:05<8:05:07, 102.49s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:11:40<7:52:11, 100.11s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:13:19<7:49:45, 99.95s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:14:56<7:43:38, 99.00s/it]
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(TaskRunner pid=1239844)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:18:05<9:47:19, 125.85s/it]
[36m(WorkerDict pid=1243609)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:19:44<9:08:28, 117.95s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:21:24<8:41:24, 112.53s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:23:02<8:18:42, 108.02s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:24:40<8:03:36, 105.13s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:26:19<7:53:57, 103.41s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:28:03<7:52:53, 103.55s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:29:49<7:54:23, 104.26s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:31:24<7:40:13, 101.52s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:33:03<7:34:40, 100.67s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:35:59<9:14:56, 123.32s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:37:37<8:38:34, 115.67s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:39:17<8:15:30, 110.93s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:40:59<8:02:29, 108.42s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:42:42<7:52:59, 106.69s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:44:22<7:42:31, 104.72s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:46:01<7:33:16, 103.02s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:47:42<7:28:12, 102.25s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:49:16<7:16:13, 99.90s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:51:02<7:21:57, 101.60s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:53:53<8:50:25, 122.41s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:55:31<8:17:59, 115.37s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:57:14<7:59:39, 111.55s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:58:48<7:34:37, 106.14s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:00:32<7:29:57, 105.46s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 01:49:47,792:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:02:15<7:25:10, 104.75s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:03:51<7:13:21, 102.37s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:05:36<7:15:00, 103.16s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:07:17<7:10:00, 102.38s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:08:59<7:08:09, 102.35s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:11:51<8:33:18, 123.19s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:13:29<7:59:50, 115.63s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:15:06<7:34:42, 110.01s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:16:45<7:18:57, 106.63s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:18:20<7:02:48, 103.13s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:19:57<6:53:28, 101.26s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:21:33<6:45:18, 99.66s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:23:08<6:38:39, 98.43s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:24:51<6:41:58, 99.66s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:26:28<6:37:15, 98.90s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:29:20<8:04:04, 121.02s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:31:09<7:46:53, 117.21s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:32:48<7:24:04, 111.95s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:34:28<7:07:20, 108.19s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:36:06<6:53:56, 105.24s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:37:48<6:47:55, 104.15s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:39:27<6:40:18, 102.64s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:41:06<6:34:57, 101.70s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:42:47<6:32:21, 101.47s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:44:28<6:29:23, 101.14s/it]
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(TaskRunner pid=1239844)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:47:37<8:09:01, 127.57s/it]
[36m(WorkerDict pid=1243609)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:49:13<7:31:21, 118.26s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:50:52<7:06:50, 112.33s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:52:30<6:48:21, 107.94s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:54:07<6:35:01, 104.87s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:55:43<6:23:13, 102.19s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:57:24<6:20:18, 101.87s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:59:00<6:12:09, 100.13s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:00:42<6:12:08, 100.58s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:02:16<6:03:24, 98.66s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:05:04<7:18:14, 119.52s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:06:46<6:56:00, 113.98s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:08:25<6:38:27, 109.67s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:10:06<6:26:45, 106.94s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:11:49<6:21:15, 105.90s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:13:26<6:10:08, 103.30s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:15:07<6:05:21, 102.44s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:16:45<5:59:11, 101.18s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:18:17<5:47:39, 98.40s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:19:56<5:46:31, 98.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:22:46<7:00:12, 120.06s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:24:27<6:37:57, 114.24s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:26:01<6:14:45, 108.11s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:27:38<6:01:43, 104.85s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:29:18<5:55:22, 103.51s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:30:53<5:44:21, 100.79s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:32:34<5:43:37, 101.07s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:34:15<5:41:34, 100.96s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:35:53<5:36:26, 99.93s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:37:33<5:34:49, 99.95s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:40:23<6:43:39, 121.10s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:41:55<6:12:50, 112.41s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:43:32<5:55:44, 107.80s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:45:11<5:45:15, 105.15s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:46:53<5:40:14, 104.15s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:48:34<5:35:05, 103.11s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:50:10<5:26:59, 101.13s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:51:49<5:23:25, 100.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:53:30<5:21:47, 100.56s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:55:09<5:18:42, 100.12s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:58:05<6:28:37, 122.72s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:59:43<6:03:14, 115.32s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:01:21<5:45:10, 110.16s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:02:59<5:32:38, 106.73s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:04:39<5:24:02, 104.53s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:06:19<5:17:52, 103.10s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:08:00<5:14:52, 102.68s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:09:36<5:07:00, 100.66s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:11:18<5:06:07, 100.92s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:12:55<5:00:50, 99.73s/it] 
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 04:03:42,000:Timeout during comparison
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(TaskRunner pid=1239844)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:16:09<6:24:21, 128.12s/it]
[36m(WorkerDict pid=1243609)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:17:50<5:57:49, 119.94s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:19:27<5:35:39, 113.14s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:21:08<5:22:36, 109.36s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:22:47<5:11:53, 106.33s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:24:22<4:59:51, 102.81s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:26:00<4:54:36, 101.59s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:27:34<4:46:11, 99.26s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:29:11<4:42:45, 98.64s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:30:53<4:43:54, 99.62s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:33:42<5:41:18, 120.46s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:35:20<5:19:56, 113.59s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:36:59<5:05:51, 109.23s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:38:38<4:55:13, 106.07s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:40:18<4:48:29, 104.27s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:41:58<4:43:32, 103.11s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:43:42<4:42:19, 103.29s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 04:32:54,798:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 04:32:59,817:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 04:33:06,438:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:45:32<4:46:03, 105.30s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:47:10<4:38:55, 103.31s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:48:50<4:33:45, 102.02s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 04:39:35,069:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:51:44<5:29:51, 123.70s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:53:26<5:10:34, 117.20s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 04:42:40,041:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:55:07<4:56:03, 112.42s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:56:44<4:41:50, 107.71s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:58:28<4:37:03, 106.56s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:00:08<4:30:39, 104.77s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:01:49<4:26:00, 103.64s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:03:30<4:21:42, 102.63s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:05:09<4:17:54, 101.80s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:06:45<4:11:42, 100.02s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:09:33<5:01:01, 120.41s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:11:07<4:39:21, 112.49s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:12:42<4:24:38, 107.29s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:14:25<4:19:29, 105.92s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:16:03<4:11:37, 103.40s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:17:37<4:03:18, 100.68s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:19:17<4:00:59, 100.41s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:20:56<3:58:10, 99.93s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:22:35<3:55:50, 99.65s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:24:10<3:51:10, 98.38s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:27:00<4:39:33, 119.81s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:28:37<4:21:39, 112.95s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:30:14<4:08:52, 108.21s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:31:52<3:59:48, 105.02s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:33:25<3:50:20, 101.62s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:35:06<3:48:00, 101.34s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:36:44<3:44:12, 100.39s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:38:24<3:42:28, 100.37s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:40:03<3:39:25, 99.74s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:41:36<3:33:46, 97.91s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 05:32:20,980:Timeout during comparison
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(TaskRunner pid=1239844)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:44:49<4:33:26, 126.20s/it]
[36m(WorkerDict pid=1243609)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:46:30<4:15:06, 118.65s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:48:09<4:01:03, 112.99s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:49:53<3:53:08, 110.14s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:51:35<3:46:00, 107.62s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:53:16<3:40:02, 105.62s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:54:53<3:33:30, 103.31s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:56:34<3:30:09, 102.52s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:58:11<3:24:49, 100.73s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:59:57<3:26:28, 102.39s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:02:45<4:04:23, 122.19s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:04:25<3:49:09, 115.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:06:08<3:39:22, 111.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:07:45<3:29:15, 107.31s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:09:24<3:22:31, 104.75s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:11:01<3:16:22, 102.46s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:12:37<3:11:01, 100.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:14:14<3:07:25, 99.52s/it] 
[36m(TaskRunner pid=1239844)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:15:56<3:07:08, 100.25s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 06:05:09,183:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:17:36<3:05:21, 100.20s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:20:31<3:44:47, 122.61s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:22:11<3:30:22, 115.80s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:23:54<3:21:49, 112.12s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:25:39<3:16:00, 109.91s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:27:15<3:06:46, 105.72s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:28:56<3:02:22, 104.21s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:30:36<2:58:20, 102.89s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:32:16<2:55:24, 102.18s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:33:56<2:52:24, 101.42s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:35:35<2:49:49, 100.89s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:38:27<3:23:30, 122.11s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:40:09<3:11:14, 115.90s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:41:51<3:02:37, 111.81s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:43:35<2:56:58, 109.47s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:45:22<2:53:58, 108.73s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:47:02<2:48:06, 106.17s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:48:40<2:42:39, 103.83s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:50:24<2:40:52, 103.79s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:52:04<2:37:18, 102.59s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:53:45<2:35:09, 102.30s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:56:38<3:05:06, 123.41s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:58:21<2:53:48, 117.17s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:59:58<2:43:03, 111.18s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:01:34<2:34:28, 106.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:03:15<2:30:29, 104.99s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:05:01<2:29:11, 105.31s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:06:39<2:24:07, 102.95s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:08:17<2:20:45, 101.75s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:10:03<2:20:25, 102.75s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:11:41<2:17:04, 101.54s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 07:02:33,373:Timeout during comparison
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(TaskRunner pid=1239844)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:14:58<2:53:21, 130.02s/it]
[36m(WorkerDict pid=1243609)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:16:40<2:40:11, 121.67s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:18:25<2:31:29, 116.54s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:20:09<2:24:52, 112.89s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:21:50<2:18:28, 109.32s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:23:29<2:12:39, 106.13s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:25:13<2:10:13, 105.59s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:26:58<2:08:09, 105.34s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:28:40<2:05:16, 104.39s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:30:20<2:02:12, 103.27s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 07:21:15,630:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:33:24<2:28:43, 127.47s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:35:05<2:17:27, 119.53s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:36:49<2:09:53, 114.61s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:38:31<2:03:45, 110.83s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:40:14<1:59:21, 108.51s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:41:50<1:53:32, 104.81s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:43:31<1:50:38, 103.72s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:45:15<1:48:53, 103.70s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:46:55<1:46:14, 102.81s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:48:36<1:43:49, 102.12s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:51:33<2:04:32, 124.55s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:53:14<1:55:34, 117.53s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:55:02<1:50:50, 114.67s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:56:41<1:44:22, 109.87s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:58:24<1:40:35, 107.78s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 07:47:39,514:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:00:12<1:38:52, 107.86s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:01:50<1:34:30, 105.02s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:03:32<1:32:01, 104.17s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:05:16<1:30:06, 103.97s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 07:54:31,717:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:07:01<1:28:37, 104.27s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:09:52<1:43:42, 124.46s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:11:32<1:35:33, 117.01s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:13:11<1:29:25, 111.77s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:14:58<1:26:27, 110.37s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:16:38<1:22:05, 107.07s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:18:16<1:18:22, 104.51s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:19:55<1:15:24, 102.83s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:21:36<1:13:17, 102.27s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:23:16<1:11:02, 101.49s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:24:57<1:09:15, 101.35s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:27:50<1:21:51, 122.79s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:29:31<1:15:36, 116.31s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:31:15<1:11:20, 112.63s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:32:53<1:06:41, 108.16s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:34:33<1:03:33, 105.93s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:36:17<1:01:27, 105.35s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 08:25:31,998:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 08:25:37,009:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:38:06<1:00:16, 106.35s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:39:43<56:51, 103.38s/it]  
[36m(TaskRunner pid=1239844)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:41:20<54:08, 101.52s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:43:04<52:52, 102.34s/it]
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(TaskRunner pid=1239844)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:46:15<1:04:28, 128.95s/it]
[36m(WorkerDict pid=1243609)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1239844)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:47:55<58:07, 120.27s/it]  
[36m(TaskRunner pid=1239844)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:49:32<52:49, 113.18s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:51:16<49:40, 110.37s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 08:40:30,910:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:53:01<47:11, 108.91s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:54:37<43:42, 104.89s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:56:17<41:23, 103.47s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 08:45:35,688:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:58:08<40:33, 105.80s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:59:47<38:01, 103.71s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:01:25<35:40, 101.92s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:04:27<42:02, 126.11s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:06:11<37:47, 119.36s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:07:49<33:56, 113.16s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:09:29<30:56, 109.22s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:11:08<28:18, 106.14s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:12:50<26:12, 104.81s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:14:32<24:14, 103.90s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:16:12<22:15, 102.72s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:17:53<20:27, 102.28s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:19:32<18:34, 101.30s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:22:33<20:51, 125.14s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:24:14<17:40, 117.82s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:25:56<15:04, 113.10s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:27:38<12:49, 109.93s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:29:21<10:46, 107.76s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:31:01<08:47, 105.47s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:32:44<06:58, 104.74s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:34:24<05:09, 103.22s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 09:23:45,676:Timeout during comparison
[36m(TaskRunner pid=1239844)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:36:19<03:33, 106.77s/it]
[36m(TaskRunner pid=1239844)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:38:11<01:48, 108.32s/it]
[36m(TaskRunner pid=1239844)[0m WARNING:2025-11-10 09:29:05,853:Timeout during comparison
[36m(WorkerDict pid=1243404)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1243404)[0m   warnings.warn(
[36m(TaskRunner pid=1239844)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:41:32<01:50, 110.42s/it]
[36m(WorkerDict pid=1243609)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1243609)[0m   warnings.warn([32m [repeated 3x across cluster][0m
