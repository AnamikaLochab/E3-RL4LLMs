The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a_norm/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a_norm//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a_norm//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a_norm//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a_norm/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-11 15:40:40,528	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=3384951)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 15:41:00,617:Waiting for register center actor peCxmT_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=3388683)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=3388503)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=3388503)[0m [rank0]:[W1211 15:41:18.910990768 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=3388503)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3388503)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3388503)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m [rank3]:[W1211 15:41:18.244282155 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388681)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=3388503)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3388503)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3388683)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3388683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388683)[0m   warnings.warn(
[36m(WorkerDict pid=3388684)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=3384951)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388503)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3384951)[0m Training Progress:   0%|          | 1/480 [02:01<16:12:12, 121.78s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   0%|          | 2/480 [04:02<16:06:53, 121.37s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   1%|          | 3/480 [06:05<16:11:01, 122.14s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   1%|          | 4/480 [08:04<15:58:08, 120.77s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   1%|          | 5/480 [10:04<15:53:14, 120.41s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   1%|â–         | 6/480 [12:07<15:59:33, 121.46s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   1%|â–         | 7/480 [14:09<15:58:49, 121.63s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   2%|â–         | 8/480 [16:11<15:56:56, 121.65s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   2%|â–         | 9/480 [18:13<15:54:56, 121.65s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   2%|â–         | 10/480 [21:37<19:11:42, 147.03s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   2%|â–         | 11/480 [23:34<17:59:34, 138.11s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   2%|â–Ž         | 12/480 [25:33<17:12:03, 132.32s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   3%|â–Ž         | 13/480 [27:33<16:40:38, 128.56s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   3%|â–Ž         | 14/480 [29:35<16:22:38, 126.52s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   3%|â–Ž         | 15/480 [31:33<15:59:43, 123.83s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   3%|â–Ž         | 16/480 [33:32<15:47:23, 122.51s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   4%|â–Ž         | 17/480 [35:33<15:41:00, 121.95s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   4%|â–         | 18/480 [37:30<15:28:52, 120.63s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   4%|â–         | 19/480 [39:28<15:19:24, 119.66s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 16:26:07,014:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:   4%|â–         | 20/480 [42:59<18:48:29, 147.19s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 16:27:46,774:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:   4%|â–         | 21/480 [45:11<18:10:34, 142.56s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   5%|â–         | 22/480 [47:12<17:18:26, 136.04s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   5%|â–         | 23/480 [49:10<16:34:17, 130.54s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   5%|â–Œ         | 24/480 [51:11<16:10:44, 127.73s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   5%|â–Œ         | 25/480 [53:07<15:43:30, 124.42s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   5%|â–Œ         | 26/480 [55:07<15:29:58, 122.91s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   6%|â–Œ         | 27/480 [57:08<15:24:17, 122.42s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   6%|â–Œ         | 28/480 [59:04<15:07:27, 120.46s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   6%|â–Œ         | 29/480 [1:01:08<15:14:39, 121.68s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   6%|â–‹         | 30/480 [1:04:20<17:50:38, 142.75s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   6%|â–‹         | 31/480 [1:06:10<16:32:57, 132.69s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:57<15:33:16, 124.99s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   7%|â–‹         | 33/480 [1:10:02<15:32:56, 125.23s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   7%|â–‹         | 34/480 [1:12:01<15:15:34, 123.17s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:52<14:47:28, 119.66s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:46<14:31:35, 117.78s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   8%|â–Š         | 37/480 [1:17:42<14:27:18, 117.47s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   8%|â–Š         | 38/480 [1:19:42<14:29:32, 118.04s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   8%|â–Š         | 39/480 [1:21:34<14:15:24, 116.38s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   8%|â–Š         | 40/480 [1:24:46<16:58:27, 138.88s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   9%|â–Š         | 41/480 [1:26:37<15:55:38, 130.61s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   9%|â–‰         | 42/480 [1:28:33<15:21:21, 126.21s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   9%|â–‰         | 43/480 [1:30:23<14:44:26, 121.43s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   9%|â–‰         | 44/480 [1:32:15<14:22:18, 118.67s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:   9%|â–‰         | 45/480 [1:34:03<13:57:02, 115.45s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  10%|â–‰         | 46/480 [1:35:58<13:52:47, 115.13s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  10%|â–‰         | 47/480 [1:37:54<13:53:50, 115.54s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:39:52<13:56:30, 116.18s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:41:50<13:59:24, 116.85s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 17:28:11,226:Timeout during comparison
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388503)[0m   warnings.warn(
[36m(TaskRunner pid=3384951)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:45:22<17:20:41, 145.21s/it]
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 17:30:02,525:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:47:20<16:21:25, 137.26s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:49:15<15:31:34, 130.59s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:51:06<14:47:15, 124.67s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:52:59<14:19:06, 121.00s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:54:48<13:52:05, 117.47s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:56:38<13:34:36, 115.27s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:58:31<13:27:14, 114.50s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [2:00:20<13:14:41, 112.99s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 17:44:59,874:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:02:15<13:17:17, 113.63s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 17:46:47,341:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:05:16<15:35:26, 133.63s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:07:11<14:54:35, 128.10s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:08:58<14:08:17, 121.76s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:10:44<13:34:17, 117.16s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:12:41<13:32:11, 117.14s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:14:29<13:10:27, 114.28s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:16:22<13:04:51, 113.75s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:18:14<13:01:10, 113.49s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:20:07<12:56:29, 113.08s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:21:56<12:46:30, 111.90s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:25:02<15:17:07, 134.21s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:26:54<14:29:51, 127.61s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:28:43<13:49:27, 121.98s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:30:31<13:19:21, 117.84s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:32:22<13:03:32, 115.79s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:34:07<12:39:54, 112.58s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 18:18:47,162:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:36:06<12:50:29, 114.43s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:38:00<12:47:54, 114.33s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:39:58<12:52:36, 115.31s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:41:51<12:45:52, 114.60s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:44:51<14:55:37, 134.34s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:46:41<14:05:08, 127.09s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:48:33<13:33:03, 122.57s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:50:27<13:12:52, 119.83s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:52:17<12:52:04, 116.98s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:54:08<12:37:50, 115.12s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:55:57<12:25:03, 113.46s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:57:52<12:25:10, 113.77s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:59:45<12:21:45, 113.53s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [3:01:32<12:08:13, 111.75s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:04:31<14:17:08, 131.87s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:06:19<13:27:01, 124.48s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:08:06<12:51:23, 119.29s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 18:52:45,424:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:10:04<12:47:59, 119.07s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:11:54<12:28:26, 116.34s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:13:43<12:12:16, 114.12s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:15:36<12:08:13, 113.79s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:17:22<11:51:31, 111.47s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:19:04<11:30:54, 108.52s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:21:02<11:46:57, 111.33s/it]
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388503)[0m   warnings.warn(
[36m(WorkerDict pid=3388503)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3388503)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=3384951)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:24:25<14:40:29, 139.03s/it]
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3384951)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:26:10<13:33:17, 128.75s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:28:00<12:54:50, 122.99s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:29:44<12:17:25, 117.36s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:31:29<11:52:29, 113.69s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:33:23<11:50:03, 113.61s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:35:06<11:30:05, 110.71s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:36:56<11:26:00, 110.35s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:38:39<11:09:45, 108.03s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:40:43<11:39:15, 113.09s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:43:49<13:51:11, 134.79s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:45:38<13:01:23, 127.06s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:47:20<12:12:24, 119.42s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:49:08<11:50:14, 116.12s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:50:59<11:39:34, 114.68s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:52:40<11:11:24, 110.37s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:54:25<11:00:58, 108.95s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:56:15<11:01:05, 109.27s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:58:06<11:02:12, 109.76s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:59:52<10:53:09, 108.56s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [4:02:58<13:11:05, 131.85s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:04:41<12:16:45, 123.14s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:06:31<11:50:38, 119.10s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 19:51:05,414:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 19:51:10,481:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 19:51:15,488:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:08:32<11:53:25, 119.90s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:10:40<12:04:46, 122.15s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:12:25<11:33:28, 117.21s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:14:19<11:24:34, 116.03s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:16:02<11:00:45, 112.31s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:17:47<10:45:24, 110.01s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 20:02:20,482:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:19:37<10:43:57, 110.08s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:22:36<12:42:18, 130.68s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:24:21<11:55:58, 123.09s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:26:03<11:17:16, 116.77s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:27:51<10:59:12, 113.98s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:29:34<10:38:10, 110.67s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:31:20<10:27:54, 109.20s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:33:07<10:23:06, 108.68s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:34:51<10:13:48, 107.37s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:36:38<10:10:04, 107.03s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:38:21<10:02:32, 106.02s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:41:10<11:47:26, 124.84s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:42:54<11:10:37, 118.69s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:44:34<10:36:33, 113.00s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:46:17<10:18:26, 110.11s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:47:56<9:57:24, 106.68s/it] 
[36m(TaskRunner pid=3384951)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:49:40<9:51:22, 105.92s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:51:16<9:32:34, 102.86s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:52:53<9:21:47, 101.22s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:54:35<9:20:11, 101.24s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:56:26<9:35:44, 104.36s/it]
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388503)[0m   warnings.warn(
[36m(TaskRunner pid=3384951)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [5:00:04<12:41:26, 138.44s/it]
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3384951)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [5:01:52<11:47:57, 129.11s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 20:46:25,529:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [5:03:44<11:18:46, 124.17s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [5:05:27<10:41:32, 117.71s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [5:07:09<10:14:19, 113.07s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:08:51<9:54:19, 109.72s/it] 
[36m(TaskRunner pid=3384951)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:10:28<9:31:22, 105.81s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:12:12<9:26:25, 105.22s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:13:55<9:21:14, 104.58s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:15:41<9:21:45, 105.00s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:18:36<11:12:44, 126.14s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:20:21<10:37:01, 119.82s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:22:07<10:12:11, 115.51s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:23:49<9:48:47, 111.44s/it] 
[36m(TaskRunner pid=3384951)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:25:25<9:22:58, 106.89s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:27:09<9:16:09, 105.93s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:28:51<9:09:26, 104.99s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:30:31<8:59:32, 103.43s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:32:13<8:55:28, 102.98s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:33:51<8:45:44, 101.43s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:36:42<10:32:15, 122.37s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:38:22<9:55:21, 115.60s/it] 
[36m(TaskRunner pid=3384951)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:40:02<9:29:11, 110.88s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:41:41<9:10:01, 107.50s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:43:19<8:53:33, 104.62s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:45:05<8:53:53, 105.03s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:46:49<8:50:37, 104.73s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:48:31<8:44:58, 103.96s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:50:15<8:42:24, 103.79s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:52:01<8:43:40, 104.39s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 21:36:33,852:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:55:02<10:38:06, 127.62s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 21:39:38,159:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 21:39:43,175:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:57:00<10:20:12, 124.46s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:58:42<9:45:59, 117.98s/it] 
[36m(TaskRunner pid=3384951)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [6:00:31<9:30:02, 115.16s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [6:02:12<9:07:41, 111.02s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [6:04:04<9:07:24, 111.34s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [6:05:51<8:58:22, 109.87s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:07:34<8:46:01, 107.72s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:09:19<8:41:11, 107.09s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:11:10<8:44:53, 108.23s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:14:10<10:27:11, 129.76s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:15:57<9:51:55, 122.89s/it] 
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-11 22:00:29,495:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:17:46<9:29:22, 118.62s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:19:28<9:04:11, 113.77s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:21:16<8:53:44, 111.97s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:22:59<8:40:00, 109.48s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:24:47<8:35:46, 108.97s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:26:30<8:24:41, 107.00s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:28:17<8:22:43, 106.96s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:29:59<8:15:00, 105.69s/it]
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388503)[0m   warnings.warn(
[36m(TaskRunner pid=3384951)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:33:13<10:16:17, 132.06s/it]
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3384951)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:34:58<9:36:45, 124.03s/it] 
[36m(TaskRunner pid=3384951)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:36:45<9:11:00, 118.92s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:38:29<8:47:35, 114.28s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:40:18<8:38:36, 112.74s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:42:02<8:25:16, 110.24s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:43:52<8:22:48, 110.10s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:45:47<8:27:19, 111.50s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:47:30<8:13:44, 108.92s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:49:13<8:05:00, 107.38s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:52:15<9:43:05, 129.57s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:53:58<9:05:32, 121.68s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:55:43<8:40:42, 116.58s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:57:32<8:29:37, 114.52s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:59:21<8:19:15, 112.61s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [7:01:04<8:05:19, 109.88s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [7:02:48<7:55:39, 108.10s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [7:04:34<7:50:46, 107.40s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [7:06:14<7:40:10, 105.38s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [7:08:05<7:44:55, 106.88s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:10:58<9:09:56, 126.91s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:12:44<8:39:42, 120.40s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:14:30<8:19:00, 116.05s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:16:10<7:56:36, 111.27s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:18:00<7:52:55, 110.84s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:19:44<7:42:52, 108.91s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:21:26<7:32:07, 106.80s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:23:21<7:41:12, 109.38s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:25:08<7:36:25, 108.67s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:26:54<7:31:09, 107.85s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:29:50<8:54:36, 128.31s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:31:36<8:24:32, 121.58s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:33:22<8:03:02, 116.87s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:35:09<7:48:41, 113.85s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:36:51<7:31:58, 110.24s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:38:33<7:20:54, 107.98s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:40:14<7:09:37, 105.65s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:41:54<7:01:56, 104.18s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:43:43<7:05:59, 105.62s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:45:26<7:00:43, 104.75s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:48:26<8:29:19, 127.33s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:50:26<8:18:37, 125.18s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:52:12<7:53:54, 119.47s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:53:58<7:35:27, 115.31s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:55:40<7:18:32, 111.49s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:57:29<7:13:04, 110.57s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:59:12<7:02:32, 108.34s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [8:00:57<6:57:01, 107.39s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [8:02:44<6:54:50, 107.29s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [8:04:33<6:54:48, 107.74s/it]
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388503)[0m   warnings.warn(
[36m(TaskRunner pid=3384951)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [8:07:49<8:34:08, 134.13s/it]
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3384951)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [8:09:31<7:54:55, 124.43s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:11:13<7:27:29, 117.76s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:12:56<7:08:44, 113.33s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:14:38<6:54:18, 110.00s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:16:17<6:40:32, 106.81s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:18:04<6:39:09, 106.92s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:19:46<6:31:16, 105.28s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:21:37<6:35:45, 106.96s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:23:19<6:28:16, 105.41s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:26:12<7:41:32, 125.88s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:27:58<7:17:46, 119.94s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:29:55<7:12:12, 118.96s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:31:42<6:57:32, 115.45s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:33:32<6:49:43, 113.81s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:35:16<6:36:31, 110.66s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:37:05<6:33:02, 110.20s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:38:49<6:25:20, 108.55s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:40:32<6:17:04, 106.72s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:42:18<6:14:55, 106.61s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 00:26:54,888:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 00:26:59,919:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:45:28<7:40:27, 131.56s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:47:13<7:10:08, 123.49s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:48:56<6:47:15, 117.48s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:50:39<6:30:22, 113.15s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:52:26<6:22:23, 111.38s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:54:09<6:11:52, 108.84s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:55:56<6:08:04, 108.26s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:57:46<6:08:05, 108.80s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:59:34<6:05:07, 108.45s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [9:01:22<6:03:05, 108.39s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [9:04:18<7:09:13, 128.77s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [9:05:56<6:36:29, 119.55s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [9:07:41<6:19:12, 114.91s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [9:09:26<6:08:14, 112.16s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [9:11:13<6:01:29, 110.66s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:13:02<5:57:18, 109.94s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:14:47<5:51:20, 108.66s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:16:33<5:46:58, 107.87s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:18:25<5:48:19, 108.85s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:20:08<5:41:05, 107.15s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:23:09<6:49:15, 129.24s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:24:54<6:24:22, 122.02s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:26:40<6:07:27, 117.27s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:28:26<5:55:05, 113.93s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:30:13<5:47:06, 111.97s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:32:04<5:44:01, 111.58s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:33:53<5:39:33, 110.73s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:35:40<5:34:23, 109.64s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:37:28<5:31:11, 109.19s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:39:17<5:28:41, 108.96s/it]
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388503)[0m   warnings.warn(
[36m(TaskRunner pid=3384951)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:42:35<6:47:15, 135.75s/it]
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3384951)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:44:23<6:20:13, 127.45s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:46:15<6:04:13, 122.77s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:48:04<5:49:51, 118.60s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:49:50<5:37:32, 115.07s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:51:32<5:24:12, 111.16s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:53:20<5:18:57, 109.99s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:55:04<5:12:26, 108.36s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:56:50<5:08:26, 107.60s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:58:41<5:09:51, 108.72s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [10:01:44<6:11:14, 131.03s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [10:03:31<5:48:27, 123.71s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [10:05:19<5:33:07, 118.97s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [10:07:07<5:22:12, 115.76s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [10:08:57<5:15:12, 113.93s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [10:10:47<5:10:27, 112.89s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [10:12:43<5:10:42, 113.67s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [10:14:27<5:00:42, 110.69s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [10:16:14<4:55:50, 109.57s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 02:00:49,629:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:18:08<4:58:08, 111.11s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:21:15<5:56:25, 133.66s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:23:05<5:35:34, 126.63s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:24:55<5:20:29, 121.71s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:26:40<5:05:08, 116.61s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:28:33<5:00:46, 115.68s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:30:26<4:56:26, 114.75s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:32:20<4:53:58, 114.53s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:34:12<4:50:26, 113.90s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:36:08<4:49:59, 114.47s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:37:57<4:43:45, 112.75s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:41:07<5:39:44, 135.90s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:42:55<5:16:51, 127.59s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:44:44<5:01:11, 122.11s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:46:43<4:56:58, 121.21s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:48:33<4:46:11, 117.61s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:50:20<4:37:03, 114.65s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:52:11<4:32:21, 113.48s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:54:09<4:33:44, 114.86s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:56:07<4:34:08, 115.83s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:57:59<4:29:14, 114.57s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [11:01:15<5:24:08, 138.92s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [11:03:10<5:05:46, 131.99s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [11:05:02<4:49:07, 125.70s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [11:06:54<4:38:09, 121.82s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [11:08:47<4:29:51, 119.05s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [11:10:45<4:27:00, 118.67s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [11:12:40<4:23:06, 117.81s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [11:14:34<4:18:26, 116.59s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [11:16:32<4:17:09, 116.89s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [11:18:20<4:09:31, 114.29s/it]
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388503)[0m   warnings.warn(
[36m(TaskRunner pid=3384951)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [11:21:54<5:12:44, 144.34s/it]
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3384951)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:23:49<4:51:18, 135.49s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:25:49<4:38:50, 130.71s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:27:45<4:27:42, 126.48s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:29:48<4:23:09, 125.31s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:31:47<4:16:48, 123.27s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:33:42<4:09:36, 120.78s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:35:39<4:05:50, 119.92s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:37:32<3:59:15, 117.67s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:39:35<4:00:35, 119.30s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:42:46<4:41:51, 140.93s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:44:46<4:26:59, 134.62s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:46:45<4:15:05, 129.70s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:48:44<4:07:10, 126.76s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:50:33<3:54:24, 121.25s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:52:25<3:47:19, 118.60s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:54:16<3:41:05, 116.36s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:56:07<3:36:10, 114.79s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:58:03<3:34:36, 114.97s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:59:58<3:32:36, 114.92s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [12:03:17<4:16:59, 140.18s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [12:05:11<4:00:45, 132.53s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [12:07:06<3:49:01, 127.23s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [12:09:04<3:41:31, 124.22s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [12:10:54<3:32:08, 120.08s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [12:12:51<3:28:25, 119.10s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [12:14:43<3:22:48, 117.01s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [12:16:38<3:20:05, 116.55s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [12:18:33<3:16:55, 115.83s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [12:20:27<3:14:10, 115.35s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [12:23:48<3:55:02, 141.02s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [12:25:43<3:40:12, 133.46s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 04:10:23,316:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 04:10:28,335:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 04:10:33,358:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 04:10:38,384:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 04:10:43,404:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [12:28:05<3:41:57, 135.89s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [12:30:06<3:32:18, 131.33s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [12:32:13<3:28:08, 130.08s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:34:08<3:19:02, 125.71s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:36:05<3:12:36, 122.94s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:38:03<3:08:21, 121.52s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:40:00<3:04:01, 120.02s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:42:01<3:02:28, 120.32s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:45:23<3:37:36, 145.07s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:47:22<3:23:24, 137.13s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:49:19<3:12:13, 131.07s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:51:15<3:03:38, 126.65s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:53:16<2:58:57, 124.86s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:55:18<2:55:40, 124.00s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:57:13<2:49:48, 121.29s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:59:13<2:47:24, 121.02s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [13:01:17<2:46:30, 121.83s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [13:03:17<2:43:44, 121.29s/it]
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388503)[0m   warnings.warn(
[36m(TaskRunner pid=3384951)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [13:06:59<3:21:48, 151.36s/it]
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3384951)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [13:09:04<3:08:54, 143.47s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [13:11:11<3:00:20, 138.73s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [13:13:13<2:51:30, 133.64s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [13:15:13<2:43:59, 129.46s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [13:17:13<2:38:15, 126.60s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [13:19:15<2:34:28, 125.25s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [13:21:15<2:30:32, 123.74s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [13:23:17<2:27:43, 123.11s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [13:25:23<2:26:54, 124.14s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 05:12:03,096:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [13:28:56<2:55:41, 150.60s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [13:30:57<2:42:58, 141.72s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [13:33:02<2:34:59, 136.76s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [13:35:02<2:27:18, 131.92s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [13:37:06<2:22:14, 129.30s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [13:39:05<2:16:41, 126.17s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [13:41:06<2:13:10, 124.86s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [13:43:14<2:11:50, 125.57s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:45:14<2:08:17, 124.15s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:47:18<2:06:09, 124.08s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:50:44<2:28:35, 148.58s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:52:45<2:18:04, 140.42s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:54:54<2:12:23, 136.96s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:56:59<2:06:29, 133.14s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:59:00<2:00:54, 129.54s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [14:01:06<1:57:48, 128.52s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [14:03:07<1:53:44, 126.37s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [14:05:09<1:50:26, 125.03s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [14:07:13<1:47:58, 124.59s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [14:09:12<1:44:30, 122.96s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [14:12:43<2:04:34, 149.49s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [14:14:47<1:55:40, 141.65s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [14:16:46<1:48:03, 135.08s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [14:18:52<1:43:32, 132.19s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [14:20:53<1:38:44, 128.80s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [14:22:54<1:34:54, 126.54s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [14:24:55<1:31:30, 124.79s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [14:26:59<1:29:21, 124.69s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [14:29:04<1:27:18, 124.73s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [14:31:08<1:25:01, 124.42s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [14:34:31<1:38:44, 148.12s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [14:36:30<1:30:33, 139.32s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [14:38:33<1:25:10, 134.50s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [14:40:33<1:20:12, 130.06s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [14:42:33<1:16:19, 127.20s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [14:44:35<1:13:15, 125.58s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 06:29:19,112:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [14:46:41<1:11:08, 125.55s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [14:48:38<1:07:44, 123.15s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [14:50:38<1:05:06, 122.06s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [14:52:40<1:03:07, 122.19s/it]
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388503)[0m   warnings.warn(
[36m(TaskRunner pid=3384951)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:56:23<1:16:14, 152.47s/it]
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3384951)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:58:28<1:09:37, 144.04s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [15:00:29<1:04:07, 137.40s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [15:02:31<59:45, 132.78s/it]  
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 06:47:17,532:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [15:04:41<57:03, 131.66s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [15:06:41<53:26, 128.26s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [15:08:42<50:24, 126.03s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [15:10:48<48:18, 126.00s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [15:12:51<45:57, 125.32s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [15:14:53<43:27, 124.16s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 07:01:34,312:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [15:18:27<50:21, 151.08s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [15:20:31<45:18, 143.07s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [15:22:32<40:55, 136.43s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [15:24:29<37:01, 130.69s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [15:26:33<34:15, 128.45s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [15:28:37<31:49, 127.28s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [15:30:38<29:16, 125.46s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [15:32:36<26:42, 123.24s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [15:34:35<24:22, 121.88s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [15:36:32<22:05, 120.52s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [15:39:58<24:21, 146.15s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [15:41:55<20:35, 137.26s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [15:43:52<17:29, 131.23s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [15:45:52<14:55, 127.98s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [15:47:51<12:31, 125.25s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [15:49:44<10:07, 121.49s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [15:51:40<07:59, 119.86s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [15:53:35<05:55, 118.38s/it]
[36m(TaskRunner pid=3384951)[0m WARNING:2025-12-12 07:38:18,002:Timeout during comparison
[36m(TaskRunner pid=3384951)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [15:55:39<04:00, 120.12s/it]
[36m(TaskRunner pid=3384951)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:57:44<02:01, 121.43s/it]
[36m(WorkerDict pid=3388503)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3388503)[0m   warnings.warn(
[36m(TaskRunner pid=3384951)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [16:01:26<02:00, 120.43s/it]
[36m(WorkerDict pid=3388684)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3388684)[0m   warnings.warn([32m [repeated 3x across cluster][0m
