The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a9/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a9//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a9//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a9//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a9/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-21 01:49:00,869	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=4014134)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 01:49:21,220:Waiting for register center actor kc8haL_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=4017860)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=4017859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=4017859)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=4017683)[0m [rank0]:[W1221 01:49:39.469062208 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=4017859)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=4017859)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=4017683)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017683)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m [rank1]:[W1221 01:49:39.581962008 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017683)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=4017683)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=4017683)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=4017859)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=4017859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017859)[0m   warnings.warn(
[36m(WorkerDict pid=4017860)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=4014134)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017683)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4014134)[0m /scratch/gautschi/alochab/E3-RL4LLMs/verl/verl/trainer/ppo/core_algos.py:744: RuntimeWarning: divide by zero encountered in log
[36m(TaskRunner pid=4014134)[0m   print(f"    Entropy H(q):   {Hq.item():.4f} (Max possible: {np.log(corr_mask.sum().item()):.4f})")
[36m(TaskRunner pid=4014134)[0m Training Progress:   0%|          | 1/480 [02:01<16:13:38, 121.96s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   0%|          | 2/480 [04:04<16:16:37, 122.59s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   1%|          | 3/480 [06:09<16:22:40, 123.61s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   1%|          | 4/480 [08:12<16:16:28, 123.09s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   1%|          | 5/480 [10:12<16:07:12, 122.17s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   1%|â–         | 6/480 [12:16<16:10:27, 122.84s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   1%|â–         | 7/480 [14:20<16:11:29, 123.23s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   2%|â–         | 8/480 [16:24<16:11:21, 123.48s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   2%|â–         | 9/480 [18:25<16:03:01, 122.68s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 02:13:22,222:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:   2%|â–         | 10/480 [21:55<19:32:07, 149.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   2%|â–         | 11/480 [23:56<18:20:13, 140.75s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   2%|â–Ž         | 12/480 [25:59<17:35:52, 135.37s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   3%|â–Ž         | 13/480 [27:59<16:58:44, 130.89s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   3%|â–Ž         | 14/480 [30:04<16:41:40, 128.97s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   3%|â–Ž         | 15/480 [32:03<16:15:07, 125.82s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   3%|â–Ž         | 16/480 [34:03<15:59:23, 124.06s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   4%|â–Ž         | 17/480 [36:04<15:50:16, 123.15s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   4%|â–         | 18/480 [38:02<15:36:57, 121.68s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   4%|â–         | 19/480 [40:01<15:28:49, 120.89s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   4%|â–         | 20/480 [43:29<18:46:45, 146.97s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   4%|â–         | 21/480 [45:30<17:45:01, 139.22s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   5%|â–         | 22/480 [47:29<16:57:32, 133.30s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   5%|â–         | 23/480 [49:28<16:22:53, 129.05s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   5%|â–Œ         | 24/480 [51:28<15:58:14, 126.08s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   5%|â–Œ         | 25/480 [53:22<15:28:46, 122.48s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   5%|â–Œ         | 26/480 [55:21<15:19:37, 121.54s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   6%|â–Œ         | 27/480 [57:24<15:21:38, 122.07s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   6%|â–Œ         | 28/480 [59:15<14:54:50, 118.78s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   6%|â–Œ         | 29/480 [1:01:18<15:01:50, 119.98s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   6%|â–‹         | 30/480 [1:04:27<17:35:14, 140.70s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   6%|â–‹         | 31/480 [1:06:16<16:20:16, 130.99s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   7%|â–‹         | 32/480 [1:08:04<15:27:15, 124.19s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   7%|â–‹         | 33/480 [1:10:08<15:24:04, 124.04s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   7%|â–‹         | 34/480 [1:12:04<15:04:00, 121.62s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:54<14:38:16, 118.42s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:48<14:25:51, 117.01s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   8%|â–Š         | 37/480 [1:17:45<14:22:26, 116.81s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   8%|â–Š         | 38/480 [1:19:43<14:24:39, 117.37s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   8%|â–Š         | 39/480 [1:21:32<14:04:31, 114.90s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   8%|â–Š         | 40/480 [1:24:39<16:40:57, 136.49s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   9%|â–Š         | 41/480 [1:26:29<15:39:16, 128.38s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   9%|â–‰         | 42/480 [1:28:25<15:09:49, 124.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   9%|â–‰         | 43/480 [1:30:13<14:32:29, 119.79s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   9%|â–‰         | 44/480 [1:32:02<14:06:46, 116.53s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:   9%|â–‰         | 45/480 [1:33:48<13:42:43, 113.48s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  10%|â–‰         | 46/480 [1:35:41<13:39:49, 113.34s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  10%|â–‰         | 47/480 [1:37:35<13:37:52, 113.33s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:39:29<13:37:27, 113.53s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:41:23<13:36:30, 113.67s/it]
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017683)[0m   warnings.warn(
[36m(TaskRunner pid=4014134)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:44:45<16:46:13, 140.40s/it]
[36m(WorkerDict pid=4017857)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4014134)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:46:35<15:38:13, 131.22s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:48:26<14:51:15, 124.94s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:50:11<14:07:19, 119.06s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:52:00<13:44:52, 116.18s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:53:45<13:18:52, 112.78s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:55:31<13:01:28, 110.59s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:57:21<12:59:18, 110.54s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:59:06<12:45:51, 108.89s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 03:52:05,225:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:00:58<12:50:46, 109.85s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:03:49<14:57:50, 128.26s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:05:42<14:23:30, 123.65s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:07:23<13:34:20, 116.89s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:09:06<13:02:27, 112.58s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:11:01<13:05:15, 113.26s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:12:48<12:49:51, 111.31s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:14:38<12:45:31, 110.95s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:16:23<12:32:57, 109.39s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:18:09<12:22:28, 108.13s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:19:55<12:16:09, 107.47s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:22:55<14:43:27, 129.29s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:24:41<13:54:42, 122.45s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:26:24<13:13:25, 116.68s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:28:07<12:42:36, 112.42s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:29:53<12:28:36, 110.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:31:35<12:09:11, 108.03s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:33:23<12:07:00, 107.97s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:35:13<12:07:57, 108.38s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:37:02<12:08:47, 108.77s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:38:50<12:04:46, 108.44s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:41:41<14:07:44, 127.16s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:43:28<13:24:59, 121.05s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:45:16<12:58:37, 117.38s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:47:06<12:41:37, 115.11s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:48:53<12:23:39, 112.68s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:50:42<12:13:17, 111.39s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:52:30<12:05:30, 110.48s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:54:20<12:02:23, 110.29s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:56:10<12:00:51, 110.34s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:57:56<11:49:28, 108.87s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:00:53<14:02:08, 129.56s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:02:35<13:04:42, 121.04s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 04:55:29,776:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 04:55:34,788:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 04:55:39,815:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:04:34<12:59:41, 120.57s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:06:24<12:36:48, 117.34s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:08:14<12:20:38, 115.12s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:10:00<12:00:45, 112.33s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:11:49<11:53:42, 111.52s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:13:32<11:34:18, 108.77s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:15:09<11:10:13, 105.27s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:17:00<11:20:21, 107.14s/it]
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017683)[0m   warnings.warn(
[36m(WorkerDict pid=4017683)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=4017683)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=4014134)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:20:17<14:09:41, 134.16s/it]
[36m(WorkerDict pid=4017857)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4014134)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:22:00<13:06:58, 124.59s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:23:47<12:31:24, 119.27s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:25:30<11:59:17, 114.48s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:27:11<11:31:25, 110.33s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:29:01<11:29:28, 110.32s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:30:41<11:09:06, 107.34s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:32:28<11:06:12, 107.17s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:34:08<10:50:32, 104.93s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:36:06<11:13:29, 108.92s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:39:05<13:21:12, 129.93s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:40:52<12:37:01, 123.09s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:42:30<11:49:28, 115.67s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:44:16<11:28:27, 112.55s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:46:02<11:15:32, 110.75s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:47:38<10:46:18, 106.24s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:49:17<10:31:49, 104.15s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:51:03<10:32:44, 104.58s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 05:43:59,910:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:52:54<10:42:41, 106.52s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:54:36<10:33:29, 105.29s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:57:37<12:48:12, 128.03s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:59:18<11:57:27, 119.91s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:01:05<11:31:40, 115.92s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 05:53:58,947:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:02:52<11:13:33, 113.20s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:04:50<11:21:16, 114.82s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:06:35<11:00:40, 111.66s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:08:17<10:42:59, 108.98s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:09:57<10:24:01, 106.07s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:11:39<10:15:52, 104.98s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:13:19<10:05:12, 103.45s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:16:13<12:07:28, 124.71s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:17:57<11:29:26, 118.53s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:19:35<10:50:29, 112.15s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:21:14<10:25:35, 108.17s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:22:53<10:09:03, 105.62s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:24:32<9:56:19, 103.71s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:26:14<9:50:12, 102.94s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:27:51<9:38:25, 101.18s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:29:29<9:32:01, 100.36s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:31:11<9:32:47, 100.78s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:34:00<11:26:53, 121.22s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:35:42<10:52:39, 115.51s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:37:19<10:19:31, 109.98s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:39:01<10:03:49, 107.51s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:40:37<9:43:50, 104.26s/it] 
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 06:33:29,872:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:42:20<9:39:40, 103.82s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:43:54<9:21:13, 100.82s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:45:31<9:12:36, 99.57s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:47:06<9:03:14, 98.18s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:48:54<9:17:46, 101.11s/it]
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017683)[0m   warnings.warn(
[36m(TaskRunner pid=4014134)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:52:00<11:37:02, 126.74s/it]
[36m(WorkerDict pid=4017857)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4014134)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:53:40<10:51:27, 118.81s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:55:22<10:20:37, 113.53s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:56:58<9:49:52, 108.24s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:58:34<9:28:40, 104.66s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:00:11<9:14:58, 102.46s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:01:43<8:55:33, 99.18s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:03:20<8:50:13, 98.49s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:05:01<8:53:28, 99.41s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:06:44<8:57:17, 100.43s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:09:36<10:49:31, 121.79s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:11:19<10:18:24, 116.31s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:12:58<9:48:23, 111.02s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:14:34<9:23:16, 106.61s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:16:08<9:00:51, 102.69s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:17:44<8:49:55, 100.94s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:19:24<8:45:48, 100.47s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:20:58<8:34:52, 98.70s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:22:38<8:34:04, 98.86s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:24:12<8:25:30, 97.53s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 07:18:36,160:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:27:07<10:23:56, 120.76s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:28:44<9:44:54, 113.58s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:30:18<9:13:43, 107.87s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:31:53<8:51:44, 103.92s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:33:26<8:33:36, 100.71s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:35:08<8:33:50, 101.08s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:36:47<8:29:03, 100.47s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:38:23<8:20:28, 99.11s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:40:03<8:20:30, 99.44s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:41:42<8:17:58, 99.27s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:44:36<10:08:17, 121.66s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 07:37:29,696:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:46:23<9:43:28, 117.09s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:48:00<9:12:02, 111.15s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:49:44<8:58:56, 108.88s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:51:20<8:39:08, 105.23s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:53:08<8:40:31, 105.87s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:54:47<8:29:40, 104.01s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 07:47:39,270:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:56:27<8:21:01, 102.60s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:58:12<8:23:25, 103.44s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:59:55<8:21:35, 103.42s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:02:48<10:00:10, 124.17s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:04:28<9:22:34, 116.80s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:06:06<8:53:49, 111.21s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:07:45<8:35:05, 107.68s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:09:25<8:21:33, 105.22s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:11:01<8:07:30, 102.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:12:46<8:08:44, 103.25s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:14:24<7:59:29, 101.66s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:16:04<7:55:21, 101.14s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:17:40<7:46:23, 99.59s/it] 
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017683)[0m   warnings.warn(
[36m(TaskRunner pid=4014134)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:20:50<9:51:45, 126.81s/it]
[36m(WorkerDict pid=4017857)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4014134)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:22:28<9:08:50, 118.03s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:24:09<8:43:55, 113.08s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:25:49<8:23:28, 109.06s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:27:30<8:10:53, 106.72s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:29:11<8:00:46, 104.90s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:30:53<7:55:35, 104.14s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:32:40<7:57:20, 104.91s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:34:18<7:45:57, 102.79s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:35:54<7:35:39, 100.88s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:38:50<9:15:49, 123.52s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:40:30<8:42:00, 116.43s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:42:10<8:17:22, 111.35s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:43:54<8:06:10, 109.25s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:45:34<7:52:23, 106.55s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:47:12<7:39:12, 103.97s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:48:49<7:27:46, 101.77s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:50:30<7:24:50, 101.49s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:52:07<7:17:04, 100.09s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:53:53<7:23:33, 101.97s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:56:44<8:51:09, 122.57s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:58:21<8:16:49, 115.10s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:00:05<7:59:47, 111.58s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:01:39<7:35:29, 106.34s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:03:23<7:30:55, 105.69s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 08:56:16,270:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:05:07<7:27:23, 105.27s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:06:45<7:15:26, 102.86s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:08:28<7:14:30, 103.04s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:10:09<7:09:58, 102.37s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:11:54<7:11:42, 103.20s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:14:47<8:37:50, 124.28s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:16:24<8:01:39, 116.06s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:18:04<7:38:49, 111.01s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:19:46<7:25:57, 108.33s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:21:22<7:08:58, 104.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:23:00<6:59:27, 102.72s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:24:37<6:51:19, 101.14s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:26:13<6:43:21, 99.59s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:28:02<6:52:55, 102.38s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:29:45<6:52:18, 102.65s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:32:42<8:19:46, 124.94s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:34:29<7:55:34, 119.39s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:36:09<7:30:49, 113.66s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:37:51<7:14:51, 110.09s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:39:29<6:58:55, 106.51s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:41:13<6:54:42, 105.88s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:42:53<6:45:40, 104.02s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:44:33<6:39:17, 102.82s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:46:15<6:36:11, 102.46s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:47:58<6:34:47, 102.54s/it]
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017683)[0m   warnings.warn(
[36m(TaskRunner pid=4014134)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:51:10<8:15:59, 129.39s/it]
[36m(WorkerDict pid=4017857)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4014134)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:52:48<7:38:02, 120.01s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:54:26<7:11:32, 113.56s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:56:01<6:48:05, 107.87s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:57:40<6:36:09, 105.18s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:59:16<6:24:31, 102.54s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:00:58<6:21:47, 102.27s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:02:36<6:15:11, 100.95s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:04:15<6:11:55, 100.52s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 09:57:05,731:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:05:57<6:11:16, 100.80s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:08:47<7:26:30, 121.78s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:10:29<7:02:00, 115.62s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 10:03:21,226:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:12:19<6:54:53, 114.19s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:14:00<6:38:46, 110.26s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:15:47<6:33:13, 109.23s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:17:24<6:17:33, 105.37s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:19:07<6:13:58, 104.85s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:20:46<6:05:44, 103.03s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:22:20<5:54:23, 100.30s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:23:58<5:50:08, 99.57s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:26:49<7:03:24, 120.97s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:28:28<6:39:08, 114.58s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:30:02<6:14:59, 108.17s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:31:38<6:00:40, 104.54s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:33:20<5:57:04, 104.00s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:34:55<5:45:58, 101.26s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:36:34<5:41:59, 100.59s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:38:17<5:42:18, 101.17s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:39:57<5:39:35, 100.87s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:41:36<5:36:15, 100.38s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:44:29<6:46:54, 122.07s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:46:03<6:16:31, 113.52s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:47:38<5:56:51, 108.14s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:49:17<5:46:04, 105.40s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:50:56<5:38:01, 103.48s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:52:36<5:33:04, 102.48s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:54:16<5:28:09, 101.49s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:55:55<5:24:20, 100.83s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:57:35<5:21:48, 100.56s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:59:10<5:14:57, 98.94s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:02:00<6:20:56, 120.30s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:03:38<5:57:34, 113.52s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:05:18<5:42:49, 109.41s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:06:56<5:30:58, 106.20s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:08:36<5:23:24, 104.32s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:10:15<5:16:27, 102.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:11:56<5:13:36, 102.26s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:13:35<5:08:36, 101.18s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:15:14<5:04:40, 100.44s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:16:53<5:01:50, 100.06s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:09:45,831:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:09:50,897:Timeout during comparison
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017683)[0m   warnings.warn(
[36m(TaskRunner pid=4014134)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:20:10<6:27:15, 129.09s/it]
[36m(WorkerDict pid=4017857)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4014134)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:21:51<5:59:52, 120.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:23:29<5:37:59, 113.93s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:25:09<5:23:29, 109.66s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:26:44<5:09:32, 105.53s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:28:16<4:55:58, 101.48s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:29:55<4:51:56, 100.67s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:31:28<4:43:47, 98.43s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:33:03<4:38:45, 97.24s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:34:43<4:39:59, 98.24s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:29:06,624:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:37:38<5:43:14, 121.14s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:39:15<5:20:43, 113.87s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:40:55<5:07:05, 109.68s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:42:34<4:56:18, 106.46s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:44:16<4:51:02, 105.19s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:46:02<4:49:40, 105.33s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:47:48<4:48:54, 105.70s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:40:38,924:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:40:43,964:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:40:48,981:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:49:38<4:50:40, 107.00s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:51:15<4:40:51, 104.02s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:44:07,817:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:44:12,873:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:44:18,016:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:44:23,044:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:53:17<4:52:55, 109.17s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:56:06<5:39:11, 127.20s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:57:47<5:16:24, 119.40s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 11:50:37,176:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:59:28<4:59:34, 113.77s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:01:02<4:42:51, 108.10s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:02:46<4:37:42, 106.81s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:04:27<4:30:56, 104.88s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:06:08<4:26:31, 103.84s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:07:46<4:20:19, 102.09s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:09:26<4:16:50, 101.39s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:10:58<4:08:29, 98.74s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:13:49<5:00:38, 120.26s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:15:20<4:36:50, 111.48s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:16:53<4:21:07, 105.86s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:18:34<4:16:10, 104.56s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:20:08<4:06:39, 101.37s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:21:42<3:59:21, 99.04s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:23:16<3:54:37, 97.76s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:24:56<3:54:19, 98.32s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:26:33<3:51:57, 98.01s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:28:08<3:48:01, 97.03s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:30:57<4:36:24, 118.46s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:32:39<4:23:25, 113.71s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:34:18<4:11:33, 109.37s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:35:55<4:00:45, 105.44s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:37:25<3:48:48, 100.95s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:39:05<3:46:18, 100.58s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:40:42<3:42:34, 99.66s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:42:21<3:40:27, 99.46s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:44:01<3:39:03, 99.57s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:45:34<3:32:45, 97.45s/it]
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017683)[0m   warnings.warn(
[36m(TaskRunner pid=4014134)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:48:45<4:31:52, 125.48s/it]
[36m(WorkerDict pid=4017857)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4014134)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:50:22<4:11:35, 117.02s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:52:06<4:01:05, 113.01s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:53:44<3:49:39, 108.50s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:55:28<3:45:35, 107.43s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:57:05<3:36:48, 104.07s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:58:38<3:28:40, 100.97s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:00:15<3:24:35, 99.80s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:01:51<3:20:05, 98.41s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:03:35<3:21:49, 100.08s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:06:19<3:59:01, 119.51s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:08:03<3:47:46, 114.85s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:09:44<3:37:14, 110.46s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:11:21<3:27:33, 106.44s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:12:58<3:20:44, 103.84s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 13:05:47,571:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 13:05:52,606:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:14:40<3:17:41, 103.14s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:16:14<3:10:30, 100.27s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:17:48<3:05:21, 98.42s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:19:26<3:03:53, 98.51s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 13:12:14,629:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:21:06<3:02:52, 98.85s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:23:56<3:40:07, 120.07s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:25:32<3:25:23, 113.06s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:27:13<3:16:37, 109.23s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:28:53<3:09:55, 106.50s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:30:24<3:00:18, 102.06s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:32:03<2:56:50, 101.05s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:33:38<2:51:42, 99.06s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:35:14<2:48:29, 98.15s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:36:48<2:45:00, 97.06s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:38:24<2:42:34, 96.58s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:41:12<3:16:52, 118.12s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:42:49<3:04:34, 111.86s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:44:29<2:56:48, 108.25s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:46:09<2:50:47, 105.64s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 13:39:02,730:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 13:39:08,437:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:48:04<2:53:46, 108.61s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:49:41<2:46:12, 104.98s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:51:16<2:39:49, 102.01s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:52:58<2:38:06, 102.01s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:54:31<2:32:22, 99.38s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:56:09<2:30:05, 98.96s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:59:00<3:00:49, 120.55s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:00:36<2:47:49, 113.14s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:02:11<2:38:06, 107.80s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:03:42<2:28:50, 102.65s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:05:22<2:26:11, 101.99s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:07:05<2:25:01, 102.36s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:08:40<2:20:04, 100.05s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:10:17<2:17:18, 99.26s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:11:56<2:15:12, 98.94s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:13:30<2:11:39, 97.53s/it]
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017683)[0m   warnings.warn(
[36m(TaskRunner pid=4014134)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:16:35<2:45:06, 123.83s/it]
[36m(WorkerDict pid=4017857)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4014134)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:18:13<2:32:45, 116.02s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:19:57<2:26:02, 112.34s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:21:37<2:19:36, 108.78s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:23:17<2:14:18, 106.04s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:24:49<2:07:33, 102.04s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:26:26<2:03:43, 100.32s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:28:04<2:01:25, 99.80s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:29:44<1:59:35, 99.67s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:31:23<1:57:37, 99.41s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:34:15<2:21:35, 121.36s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:35:52<2:11:07, 114.02s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:37:28<2:03:10, 108.69s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:39:04<1:57:12, 104.96s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:40:41<1:52:40, 102.43s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:42:13<1:47:25, 99.16s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:43:49<1:44:57, 98.39s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:45:30<1:44:08, 99.18s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:47:05<1:41:12, 97.94s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 14:39:57,765:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:48:48<1:40:54, 99.25s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:51:38<2:00:33, 120.56s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:53:13<1:51:03, 112.94s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:54:56<1:46:24, 110.08s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 14:47:43,915:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:56:34<1:41:01, 106.34s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:58:13<1:37:13, 104.17s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 14:51:06,041:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:59:57<1:35:18, 103.98s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:01:34<1:31:49, 102.03s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 14:54:23,894:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:03:16<1:30:03, 101.96s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:04:56<1:28:00, 101.54s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:06:32<1:24:51, 99.84s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:09:19<1:39:49, 119.79s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:10:51<1:31:06, 111.56s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:12:26<1:25:09, 106.45s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:14:12<1:23:26, 106.52s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:15:50<1:19:41, 103.95s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:17:24<1:15:34, 100.76s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:18:59<1:12:39, 99.07s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:20:36<1:10:41, 98.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:22:12<1:08:20, 97.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:23:52<1:07:14, 98.40s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:26:39<1:19:19, 118.98s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:28:14<1:12:37, 111.72s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:29:55<1:08:47, 108.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:31:30<1:04:27, 104.54s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:33:09<1:01:43, 102.88s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:34:47<59:07, 101.36s/it]  
[36m(TaskRunner pid=4014134)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:36:23<56:30, 99.71s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:37:57<53:58, 98.14s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:39:33<51:54, 97.32s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:41:10<50:20, 97.44s/it]
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017683)[0m   warnings.warn(
[36m(TaskRunner pid=4014134)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:44:13<1:01:28, 122.94s/it]
[36m(WorkerDict pid=4017857)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4014134)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:45:51<55:50, 115.55s/it]  
[36m(TaskRunner pid=4014134)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:47:25<50:51, 108.97s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:49:06<48:03, 106.79s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:50:47<45:27, 104.92s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:52:22<42:33, 102.12s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:54:02<40:29, 101.22s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:55:46<39:09, 102.14s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:57:27<37:22, 101.94s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:59:04<35:05, 100.27s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:01:58<40:52, 122.62s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:03:44<37:14, 117.63s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:05:22<33:28, 111.57s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:07:01<30:33, 107.88s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:08:40<28:01, 105.09s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:10:19<25:50, 103.38s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:11:59<23:53, 102.43s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:13:39<21:59, 101.50s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:15:16<20:04, 100.34s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:16:54<18:14, 99.48s/it] 
[36m(TaskRunner pid=4014134)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:19:54<20:36, 123.61s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:21:31<17:22, 115.87s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:23:12<14:49, 111.13s/it]
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 16:16:05,752:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 16:16:11,505:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 16:16:16,916:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m WARNING:2025-12-21 16:16:21,937:Timeout during comparison
[36m(TaskRunner pid=4014134)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:25:15<13:24, 114.96s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:26:56<11:02, 110.50s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:28:32<08:51, 106.24s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:30:14<06:59, 104.92s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:31:48<05:05, 101.81s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:33:32<03:24, 102.34s/it]
[36m(TaskRunner pid=4014134)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:35:19<01:43, 103.88s/it]
[36m(WorkerDict pid=4017683)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4017683)[0m   warnings.warn(
[36m(TaskRunner pid=4014134)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:38:36<01:50, 110.05s/it]
[36m(WorkerDict pid=4017857)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4017857)[0m   warnings.warn([32m [repeated 3x across cluster][0m
