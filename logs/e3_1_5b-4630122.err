
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_grpo/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_grpo//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_grpo//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_grpo//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=grpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_grpo/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-07 09:01:12,600	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=3623953)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 09:01:37,212:Waiting for register center actor 85sPk0_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=3627710)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3627502)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=3627502)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=3627502)[0m [rank0]:[W1107 09:01:58.716575128 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=3627710)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3627710)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3627502)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3627709)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3627709)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3627709)[0m [rank1]:[W1107 09:01:58.056245111 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3627712)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=3627502)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3627502)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3627502)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3627710)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3627502)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3627502)[0m   warnings.warn(
[36m(WorkerDict pid=3627709)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=3623953)[0m Training Progress:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 250/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=3627709)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3627709)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3623953)[0m Training Progress:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 251/480 [01:40<6:22:33, 100.24s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 252/480 [03:24<6:29:11, 102.42s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 253/480 [05:08<6:30:10, 103.13s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 254/480 [06:52<6:30:56, 103.79s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 255/480 [08:33<6:24:34, 102.55s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 256/480 [10:18<6:25:38, 103.30s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 257/480 [11:56<6:18:30, 101.84s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 258/480 [13:34<6:12:05, 100.57s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 259/480 [15:21<6:17:55, 102.60s/it]
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 09:20:36,023:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 09:20:41,840:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 09:20:48,593:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m Training Progress:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 260/480 [18:33<7:56:39, 130.00s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 261/480 [20:11<7:19:05, 120.30s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 262/480 [21:53<6:56:59, 114.77s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 263/480 [23:31<6:36:59, 109.77s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 264/480 [25:11<6:24:02, 106.68s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 265/480 [26:53<6:17:14, 105.28s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 266/480 [28:30<6:06:50, 102.85s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 267/480 [30:14<6:06:28, 103.23s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 268/480 [31:52<5:58:37, 101.50s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 269/480 [33:40<6:03:47, 103.45s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 270/480 [36:37<7:19:55, 125.69s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 271/480 [38:18<6:51:47, 118.22s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 272/480 [39:54<6:26:10, 111.40s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 273/480 [41:38<6:16:54, 109.25s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 274/480 [43:22<6:09:45, 107.70s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 275/480 [44:56<5:53:56, 103.59s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 276/480 [46:35<5:47:50, 102.31s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 277/480 [48:15<5:44:05, 101.70s/it]
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 09:53:32,980:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m Training Progress:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 278/480 [50:03<5:48:32, 103.53s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 279/480 [51:42<5:41:31, 101.95s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 280/480 [54:40<6:56:39, 125.00s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 281/480 [56:17<6:26:12, 116.44s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 282/480 [58:03<6:13:53, 113.30s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 283/480 [59:43<5:59:07, 109.38s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 284/480 [1:01:37<6:01:23, 110.63s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 285/480 [1:03:15<5:47:45, 107.00s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 286/480 [1:04:57<5:41:24, 105.59s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 287/480 [1:06:36<5:32:40, 103.42s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 288/480 [1:08:16<5:28:10, 102.56s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 289/480 [1:09:58<5:25:18, 102.19s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 290/480 [1:12:54<6:34:26, 124.56s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 291/480 [1:14:36<6:10:50, 117.73s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 292/480 [1:16:13<5:48:50, 111.33s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 293/480 [1:17:53<5:36:51, 108.08s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 294/480 [1:19:34<5:28:07, 105.85s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 295/480 [1:21:16<5:23:01, 104.76s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 296/480 [1:22:56<5:17:15, 103.45s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 297/480 [1:24:35<5:10:48, 101.90s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 298/480 [1:26:17<5:09:45, 102.12s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 299/480 [1:28:01<5:09:20, 102.55s/it]
[36m(WorkerDict pid=3627502)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3627502)[0m   warnings.warn(
[36m(TaskRunner pid=3623953)[0m Training Progress:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 300/480 [1:31:12<6:27:07, 129.04s/it]
[36m(WorkerDict pid=3627709)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3627709)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3623953)[0m Training Progress:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 301/480 [1:32:54<6:00:46, 120.93s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 302/480 [1:34:32<5:38:16, 114.02s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 303/480 [1:36:14<5:25:44, 110.42s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 304/480 [1:37:52<5:13:24, 106.84s/it]
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 10:43:07,471:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 10:43:13,418:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m Training Progress:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 305/480 [1:39:43<5:14:59, 108.00s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 306/480 [1:41:17<5:01:20, 103.91s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 307/480 [1:42:53<4:52:16, 101.36s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 308/480 [1:44:30<4:46:50, 100.06s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 309/480 [1:46:13<4:48:14, 101.14s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 310/480 [1:49:11<5:51:25, 124.03s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 311/480 [1:50:53<5:30:57, 117.50s/it]
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 10:56:09,184:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 10:56:15,235:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 10:56:20,956:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m Training Progress:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 312/480 [1:52:50<5:28:27, 117.31s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 313/480 [1:54:29<5:11:12, 111.81s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 314/480 [1:56:11<5:01:40, 109.04s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 315/480 [1:57:52<4:52:38, 106.42s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 316/480 [1:59:27<4:42:12, 103.25s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 317/480 [2:01:07<4:37:47, 102.25s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 318/480 [2:02:53<4:38:28, 103.14s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 319/480 [2:04:32<4:33:25, 101.90s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 320/480 [2:07:28<5:30:59, 124.12s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 321/480 [2:09:20<5:19:17, 120.49s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 322/480 [2:11:05<5:05:07, 115.87s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 323/480 [2:12:44<4:50:04, 110.86s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 324/480 [2:14:22<4:38:22, 107.07s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 325/480 [2:16:03<4:31:36, 105.14s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 326/480 [2:17:44<4:27:08, 104.08s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 327/480 [2:19:23<4:21:33, 102.57s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 328/480 [2:21:09<4:22:03, 103.44s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 329/480 [2:22:50<4:18:27, 102.70s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 330/480 [2:25:48<5:13:25, 125.37s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 331/480 [2:27:30<4:53:33, 118.21s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 332/480 [2:29:12<4:40:04, 113.55s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 333/480 [2:30:53<4:28:54, 109.76s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 334/480 [2:32:34<4:20:23, 107.01s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 335/480 [2:34:19<4:17:11, 106.42s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 336/480 [2:36:03<4:13:47, 105.75s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 337/480 [2:37:45<4:09:21, 104.63s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 338/480 [2:39:31<4:08:16, 104.90s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 339/480 [2:41:14<4:05:32, 104.49s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 340/480 [2:44:15<4:57:00, 127.29s/it]
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 11:49:31,443:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m Training Progress:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 341/480 [2:46:03<4:41:54, 121.69s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 342/480 [2:47:46<4:26:31, 115.88s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 343/480 [2:49:29<4:15:56, 112.09s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 344/480 [2:51:09<4:05:56, 108.50s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 345/480 [2:52:58<4:04:43, 108.77s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 346/480 [2:54:40<3:58:12, 106.66s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 347/480 [2:56:20<3:51:47, 104.57s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 348/480 [2:58:04<3:49:41, 104.41s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 349/480 [2:59:49<3:48:24, 104.61s/it]
[36m(WorkerDict pid=3627502)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3627502)[0m   warnings.warn(
[36m(WorkerDict pid=3627502)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3627502)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=3623953)[0m Training Progress:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 350/480 [3:03:00<4:42:56, 130.59s/it]
[36m(WorkerDict pid=3627709)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3627709)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3623953)[0m Training Progress:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 351/480 [3:04:38<4:19:48, 120.84s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 352/480 [3:06:18<4:04:33, 114.63s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 353/480 [3:07:58<3:53:00, 110.08s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 354/480 [3:09:42<3:47:18, 108.24s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 355/480 [3:11:19<3:38:58, 105.11s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 356/480 [3:13:03<3:36:17, 104.66s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 357/480 [3:14:41<3:30:33, 102.71s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 358/480 [3:16:26<3:30:06, 103.34s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 359/480 [3:18:04<3:24:54, 101.60s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 360/480 [3:21:00<4:07:58, 123.99s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 361/480 [3:22:42<3:52:56, 117.45s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 362/480 [3:24:24<3:41:53, 112.83s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 363/480 [3:26:04<3:32:36, 109.03s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 364/480 [3:27:46<3:26:29, 106.81s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 365/480 [3:29:27<3:21:29, 105.12s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 366/480 [3:31:11<3:19:09, 104.82s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 367/480 [3:32:57<3:18:12, 105.25s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 368/480 [3:34:34<3:11:51, 102.78s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 369/480 [3:36:14<3:08:26, 101.86s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 370/480 [3:39:16<3:50:37, 125.80s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 371/480 [3:40:58<3:35:29, 118.62s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 372/480 [3:42:41<3:25:11, 114.00s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 373/480 [3:44:25<3:18:06, 111.09s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 374/480 [3:46:09<3:12:09, 108.77s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 375/480 [3:47:48<3:05:41, 106.11s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 376/480 [3:49:30<3:01:21, 104.63s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 377/480 [3:51:10<2:57:10, 103.21s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 378/480 [3:52:47<2:52:30, 101.47s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 379/480 [3:54:36<2:54:41, 103.77s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 380/480 [3:57:34<3:29:58, 125.98s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 381/480 [3:59:13<3:14:36, 117.94s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 382/480 [4:00:57<3:05:56, 113.84s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 383/480 [4:02:31<2:54:20, 107.84s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 384/480 [4:04:15<2:50:30, 106.57s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 385/480 [4:05:55<2:45:34, 104.58s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 386/480 [4:07:32<2:40:29, 102.44s/it]
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 13:12:50,539:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m Training Progress:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 387/480 [4:09:24<2:43:09, 105.27s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 388/480 [4:11:05<2:39:35, 104.08s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 389/480 [4:12:48<2:37:16, 103.70s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 390/480 [4:15:44<3:07:55, 125.28s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 391/480 [4:17:20<2:53:02, 116.66s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 392/480 [4:19:02<2:44:17, 112.02s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 393/480 [4:20:42<2:37:12, 108.42s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 394/480 [4:22:18<2:30:14, 104.82s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 395/480 [4:23:59<2:26:44, 103.59s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 396/480 [4:25:37<2:22:48, 102.01s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 397/480 [4:27:16<2:19:46, 101.04s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 398/480 [4:29:02<2:20:14, 102.62s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 399/480 [4:30:43<2:17:48, 102.09s/it]
[36m(WorkerDict pid=3627502)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3627502)[0m   warnings.warn(
[36m(TaskRunner pid=3623953)[0m Training Progress:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 400/480 [4:33:59<2:53:53, 130.42s/it]
[36m(WorkerDict pid=3627709)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3627709)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3623953)[0m Training Progress:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 401/480 [4:35:52<2:44:33, 124.98s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 402/480 [4:37:37<2:34:38, 118.95s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 403/480 [4:39:22<2:27:24, 114.87s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 404/480 [4:41:05<2:20:52, 111.21s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 405/480 [4:42:48<2:15:52, 108.71s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 406/480 [4:44:27<2:10:32, 105.85s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 407/480 [4:46:07<2:06:38, 104.09s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 408/480 [4:47:49<2:04:22, 103.65s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 409/480 [4:49:32<2:02:26, 103.47s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 410/480 [4:52:28<2:26:07, 125.24s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 411/480 [4:54:07<2:14:53, 117.30s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 412/480 [4:55:47<2:07:01, 112.08s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 413/480 [4:57:27<2:01:02, 108.39s/it]
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 14:02:40,745:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m Training Progress:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 414/480 [4:59:09<1:57:09, 106.50s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 415/480 [5:00:46<1:52:21, 103.71s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 416/480 [5:02:29<1:50:17, 103.40s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 417/480 [5:04:06<1:46:41, 101.60s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 418/480 [5:05:47<1:44:49, 101.44s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 419/480 [5:07:25<1:41:56, 100.27s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 420/480 [5:10:16<2:01:40, 121.67s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 421/480 [5:11:59<1:53:53, 115.82s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 422/480 [5:13:40<1:47:47, 111.52s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 423/480 [5:15:22<1:43:07, 108.56s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 424/480 [5:17:07<1:40:23, 107.57s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 425/480 [5:18:45<1:36:01, 104.76s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 426/480 [5:20:26<1:33:06, 103.46s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 427/480 [5:22:05<1:30:21, 102.29s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 428/480 [5:23:40<1:26:48, 100.17s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 429/480 [5:25:20<1:24:59, 99.99s/it] 
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 14:30:35,909:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m Training Progress:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 430/480 [5:28:18<1:42:47, 123.34s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 431/480 [5:29:59<1:35:12, 116.59s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 432/480 [5:31:35<1:28:18, 110.38s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 433/480 [5:33:12<1:23:30, 106.61s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 434/480 [5:34:56<1:21:02, 105.70s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 435/480 [5:36:33<1:17:24, 103.21s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 436/480 [5:38:14<1:15:09, 102.49s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 437/480 [5:39:54<1:12:58, 101.82s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 438/480 [5:41:32<1:10:26, 100.62s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 439/480 [5:43:10<1:08:14, 99.86s/it] 
[36m(TaskRunner pid=3623953)[0m Training Progress:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 440/480 [5:46:00<1:20:31, 120.79s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 441/480 [5:47:31<1:12:42, 111.85s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 442/480 [5:49:09<1:08:16, 107.79s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 443/480 [5:50:48<1:04:52, 105.20s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 444/480 [5:52:30<1:02:29, 104.16s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 445/480 [5:54:11<1:00:12, 103.21s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 446/480 [5:55:49<57:33, 101.57s/it]  
[36m(TaskRunner pid=3623953)[0m Training Progress:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 447/480 [5:57:29<55:35, 101.06s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 448/480 [5:59:06<53:19, 99.98s/it] 
[36m(TaskRunner pid=3623953)[0m Training Progress:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 449/480 [6:00:43<51:10, 99.05s/it]
[36m(WorkerDict pid=3627502)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3627502)[0m   warnings.warn(
[36m(TaskRunner pid=3623953)[0m Training Progress:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 450/480 [6:03:57<1:03:42, 127.43s/it]
[36m(WorkerDict pid=3627709)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3627709)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3623953)[0m Training Progress:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 451/480 [6:05:33<57:06, 118.15s/it]  
[36m(TaskRunner pid=3623953)[0m Training Progress:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 452/480 [6:07:10<52:04, 111.60s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 453/480 [6:08:46<48:09, 107.02s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 454/480 [6:10:21<44:48, 103.42s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 455/480 [6:11:59<42:28, 101.95s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 456/480 [6:13:38<40:19, 100.80s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 457/480 [6:15:12<37:55, 98.93s/it] 
[36m(TaskRunner pid=3623953)[0m Training Progress:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 458/480 [6:16:51<36:18, 99.01s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 459/480 [6:18:25<34:08, 97.56s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 460/480 [6:21:13<39:29, 118.48s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 461/480 [6:22:49<35:24, 111.83s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 462/480 [6:24:25<32:07, 107.10s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 463/480 [6:26:03<29:31, 104.21s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 464/480 [6:27:41<27:19, 102.47s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 465/480 [6:29:15<24:58, 99.93s/it] 
[36m(TaskRunner pid=3623953)[0m Training Progress:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 466/480 [6:30:51<23:04, 98.91s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 467/480 [6:32:24<21:01, 97.06s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 468/480 [6:34:00<19:19, 96.65s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 469/480 [6:35:41<17:57, 97.96s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 470/480 [6:38:30<19:53, 119.34s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 471/480 [6:40:07<16:52, 112.55s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 472/480 [6:41:44<14:24, 108.05s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 473/480 [6:43:18<12:06, 103.76s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 474/480 [6:44:57<10:13, 102.21s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 475/480 [6:46:37<08:27, 101.51s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 476/480 [6:48:22<06:50, 102.59s/it]
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 15:53:29,800:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 15:53:36,553:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m Training Progress:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 477/480 [6:50:03<05:06, 102.03s/it]
[36m(TaskRunner pid=3623953)[0m Training Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 478/480 [6:51:39<03:20, 100.42s/it]
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 15:56:52,064:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 15:56:57,112:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 15:57:03,089:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 15:57:08,123:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 15:57:13,157:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 15:57:19,245:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m WARNING:2025-11-07 15:57:24,269:Timeout during comparison
[36m(TaskRunner pid=3623953)[0m Training Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 479/480 [6:53:53<01:50, 110.36s/it]
[36m(WorkerDict pid=3627502)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3627502)[0m   warnings.warn(
[36m(TaskRunner pid=3623953)[0m Training Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 479/480 [6:57:01<01:49, 109.27s/it]
[36m(WorkerDict pid=3627709)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3627709)[0m   warnings.warn([32m [repeated 3x across cluster][0m
