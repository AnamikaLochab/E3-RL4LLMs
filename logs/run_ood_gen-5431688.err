The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a10/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a10//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a10//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a10//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a10/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-21 08:48:07,833	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=52076)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 08:48:27,729:Waiting for register center actor cpvc4F_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=55881)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=55881)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=55881)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=55632)[0m [rank0]:[W1221 08:48:45.686439369 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=55881)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=55881)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=55632)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55632)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m [rank2]:[W1221 08:48:45.919141737 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55632)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=55881)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=55632)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=55878)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(WorkerDict pid=55632)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=52076)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=52076)[0m /scratch/gautschi/alochab/E3-RL4LLMs/verl/verl/trainer/ppo/core_algos.py:744: RuntimeWarning: divide by zero encountered in log
[36m(TaskRunner pid=52076)[0m   print(f"    Entropy H(q):   {Hq.item():.4f} (Max possible: {np.log(corr_mask.sum().item()):.4f})")
[36m(TaskRunner pid=52076)[0m Training Progress:   0%|          | 1/480 [02:03<16:27:58, 123.76s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   0%|          | 2/480 [04:06<16:22:28, 123.32s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   1%|          | 3/480 [06:11<16:26:28, 124.08s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   1%|          | 4/480 [08:13<16:15:30, 122.96s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   1%|          | 5/480 [10:14<16:08:43, 122.36s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   1%|â–         | 6/480 [12:18<16:11:53, 123.02s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   1%|â–         | 7/480 [14:21<16:10:10, 123.07s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   2%|â–         | 8/480 [16:28<16:16:54, 124.18s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   2%|â–         | 9/480 [18:29<16:06:52, 123.17s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   2%|â–         | 10/480 [21:54<19:22:40, 148.43s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 09:14:01,707:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:   2%|â–         | 11/480 [23:57<18:20:27, 140.78s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   2%|â–Ž         | 12/480 [25:59<17:34:03, 135.14s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   3%|â–Ž         | 13/480 [27:59<16:55:38, 130.49s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   3%|â–Ž         | 14/480 [30:04<16:39:59, 128.76s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   3%|â–Ž         | 15/480 [32:06<16:21:08, 126.60s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   3%|â–Ž         | 16/480 [34:05<16:01:26, 124.33s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   4%|â–Ž         | 17/480 [36:07<15:53:47, 123.60s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   4%|â–         | 18/480 [38:04<15:37:16, 121.72s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   4%|â–         | 19/480 [40:03<15:30:19, 121.08s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   4%|â–         | 20/480 [43:29<18:41:56, 146.34s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 09:35:42,547:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:   4%|â–         | 21/480 [45:36<17:56:10, 140.68s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   5%|â–         | 22/480 [47:37<17:09:21, 134.85s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   5%|â–         | 23/480 [49:37<16:32:28, 130.30s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   5%|â–Œ         | 24/480 [51:40<16:12:40, 127.98s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   5%|â–Œ         | 25/480 [53:38<15:48:11, 125.04s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   5%|â–Œ         | 26/480 [55:42<15:44:39, 124.85s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   6%|â–Œ         | 27/480 [57:44<15:35:29, 123.91s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   6%|â–Œ         | 28/480 [59:40<15:15:37, 121.54s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   6%|â–Œ         | 29/480 [1:01:44<15:19:37, 122.34s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   6%|â–‹         | 30/480 [1:04:56<17:53:25, 143.12s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 09:57:00,335:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:   6%|â–‹         | 31/480 [1:06:52<16:49:42, 134.93s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   7%|â–‹         | 32/480 [1:08:41<15:51:03, 127.37s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   7%|â–‹         | 33/480 [1:10:45<15:41:17, 126.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   7%|â–‹         | 34/480 [1:12:40<15:13:01, 122.83s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   7%|â–‹         | 35/480 [1:14:32<14:46:03, 119.47s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   8%|â–Š         | 36/480 [1:16:26<14:32:22, 117.89s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   8%|â–Š         | 37/480 [1:18:21<14:23:51, 117.00s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   8%|â–Š         | 38/480 [1:20:20<14:26:00, 117.56s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   8%|â–Š         | 39/480 [1:22:10<14:08:01, 115.38s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   8%|â–Š         | 40/480 [1:25:22<16:55:18, 138.45s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   9%|â–Š         | 41/480 [1:27:14<15:54:49, 130.50s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   9%|â–‰         | 42/480 [1:29:12<15:25:24, 126.77s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   9%|â–‰         | 43/480 [1:30:59<14:40:27, 120.89s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   9%|â–‰         | 44/480 [1:32:50<14:17:03, 117.94s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:   9%|â–‰         | 45/480 [1:34:39<13:55:05, 115.19s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  10%|â–‰         | 46/480 [1:36:31<13:45:40, 114.15s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  10%|â–‰         | 47/480 [1:38:27<13:47:00, 114.60s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:40:22<13:47:47, 114.97s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:42:23<13:57:56, 116.65s/it]
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(TaskRunner pid=52076)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:45:48<17:05:21, 143.07s/it]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=52076)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:47:39<15:54:19, 133.47s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:49:32<15:09:13, 127.46s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:51:17<14:19:43, 120.80s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:53:07<13:52:55, 117.31s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:54:52<13:25:49, 113.76s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:56:45<13:22:07, 113.51s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:58:39<13:21:35, 113.70s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [2:00:24<13:01:54, 111.17s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:02:11<12:49:42, 109.70s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 10:54:13,184:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:05:10<15:14:26, 130.63s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:06:59<14:26:22, 124.06s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:08:45<13:46:47, 118.68s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:10:30<13:16:56, 114.67s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:12:27<13:20:14, 115.42s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:14:14<12:59:52, 112.75s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:16:08<12:59:50, 113.02s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:17:59<12:53:53, 112.43s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:19:47<12:43:56, 111.25s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:21:36<12:37:30, 110.59s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:24:43<15:11:59, 133.46s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:26:35<14:25:48, 127.01s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:28:28<13:53:59, 122.65s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:30:14<13:18:21, 117.69s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:32:06<13:05:09, 116.03s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:33:53<12:44:44, 113.30s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:35:45<12:41:28, 113.09s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:37:39<12:39:55, 113.14s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:39:32<12:39:24, 113.34s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 11:31:39,829:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:41:31<12:48:21, 114.97s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:44:29<14:51:22, 133.71s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:46:19<14:03:08, 126.79s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:48:08<13:25:03, 121.36s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:50:04<13:11:30, 119.62s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:51:54<12:50:27, 116.74s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:53:49<12:46:53, 116.49s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:55:41<12:35:02, 114.98s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:57:33<12:28:22, 114.26s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:59:29<12:29:12, 114.68s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [3:01:16<12:11:15, 112.21s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:04:17<14:24:20, 132.98s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:06:05<13:33:41, 125.50s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 11:58:08,439:Timeout during comparison
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 11:58:13,459:Timeout during comparison
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 11:58:18,504:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:08:09<13:28:29, 125.03s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:09:57<12:53:57, 119.99s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:11:48<12:33:41, 117.15s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:13:37<12:15:53, 114.69s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:15:30<12:12:08, 114.40s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:17:16<11:53:41, 111.81s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:18:58<11:32:21, 108.75s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:20:52<11:41:14, 110.43s/it]
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(WorkerDict pid=55632)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=55632)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=52076)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:24:09<14:24:14, 136.46s/it]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=52076)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:25:54<13:20:54, 126.79s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:27:45<12:49:28, 122.14s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:29:29<12:13:08, 116.68s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:31:14<11:49:23, 113.20s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:33:05<11:43:59, 112.64s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:34:48<11:24:06, 109.75s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:36:37<11:20:47, 109.51s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:38:18<11:02:53, 106.92s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:40:20<11:28:39, 111.37s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:43:21<13:35:55, 132.31s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:45:09<12:49:09, 125.07s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:46:49<12:00:11, 117.42s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:48:36<11:39:34, 114.37s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:50:25<11:27:18, 112.67s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:52:01<10:55:46, 107.80s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:53:45<10:46:23, 106.55s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:55:32<10:46:04, 106.79s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:57:23<10:52:16, 108.11s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:59:08<10:44:25, 107.11s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 12:51:11,634:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [4:02:15<13:05:45, 130.96s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:03:57<12:12:04, 122.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:05:48<11:50:17, 119.04s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:07:35<11:26:11, 115.33s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:09:32<11:27:20, 115.84s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:11:16<11:04:40, 112.34s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:13:03<10:53:50, 110.82s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:14:48<10:40:45, 108.91s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:16:31<10:29:28, 107.30s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:18:17<10:24:12, 106.70s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:21:15<12:28:19, 128.29s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:22:58<11:41:23, 120.58s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:24:41<11:09:16, 115.39s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:26:27<10:50:15, 112.44s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:28:12<10:36:21, 110.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:29:58<10:26:03, 108.88s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:31:43<10:18:04, 107.80s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:33:28<10:12:18, 107.11s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:35:16<10:10:32, 107.11s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:36:57<9:58:39, 105.34s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:39:49<11:50:14, 125.34s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:41:34<11:13:28, 119.20s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:43:15<10:41:14, 113.83s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:44:57<10:19:50, 110.36s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:46:35<9:56:42, 106.56s/it] 
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 13:38:34,289:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:48:21<9:54:18, 106.44s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:49:58<9:37:15, 103.70s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:51:33<9:21:12, 101.12s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:53:16<9:21:37, 101.50s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:55:07<9:35:16, 104.28s/it]
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(TaskRunner pid=52076)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:58:18<11:56:32, 130.28s/it]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=52076)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [5:00:05<11:16:34, 123.39s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [5:01:47<10:39:30, 116.98s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [5:03:26<10:08:26, 111.64s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [5:05:11<9:55:19, 109.57s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:06:52<9:39:09, 106.92s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:08:27<9:18:54, 103.50s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:10:06<9:10:30, 102.26s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:11:53<9:15:04, 103.43s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:13:38<9:15:53, 103.90s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:16:34<11:09:42, 125.57s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:18:22<10:39:19, 120.25s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:20:04<10:08:38, 114.84s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:21:44<9:44:01, 110.54s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:23:19<9:17:52, 105.93s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:25:00<9:07:00, 104.19s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:26:43<9:03:15, 103.81s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 14:18:41,894:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:28:27<9:02:19, 103.96s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:30:09<8:57:02, 103.28s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:31:44<8:43:17, 100.96s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:34:37<10:33:42, 122.65s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:36:15<9:52:48, 115.11s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:37:54<9:25:40, 110.20s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:39:36<9:12:24, 107.96s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:41:15<8:56:16, 105.15s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:43:01<8:55:12, 105.29s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:44:45<8:52:15, 105.05s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:46:25<8:43:31, 103.67s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:48:08<8:39:35, 103.23s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:49:51<8:37:52, 103.23s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:52:45<10:21:47, 124.36s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:54:28<9:48:24, 118.07s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:56:07<9:18:05, 112.37s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:57:55<9:10:05, 111.13s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:59:31<8:45:32, 106.53s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [6:01:20<8:47:32, 107.30s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 14:53:20,657:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [6:03:07<8:44:47, 107.10s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:04:48<8:34:23, 105.34s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:06:37<8:37:37, 106.36s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:08:21<8:33:04, 105.79s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:11:15<10:10:09, 126.24s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:12:58<9:34:07, 119.20s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:14:38<9:04:21, 113.41s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:16:17<8:42:35, 109.25s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:18:01<8:32:27, 107.51s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:19:42<8:20:53, 105.45s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:21:27<8:18:38, 105.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:23:03<8:04:43, 102.77s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:24:47<8:04:44, 103.14s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:26:23<7:52:54, 100.98s/it]
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(TaskRunner pid=52076)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:29:34<9:57:25, 128.02s/it]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=52076)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:31:17<9:19:22, 120.30s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:32:58<8:50:21, 114.47s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:34:36<8:26:40, 109.75s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:36:18<8:14:05, 107.41s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:38:01<8:05:53, 106.01s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:39:44<7:59:27, 104.99s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 15:31:45,034:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:41:36<8:08:25, 107.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:43:13<7:51:38, 104.04s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:44:52<7:43:43, 102.67s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:47:47<9:19:00, 124.22s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:49:25<8:42:10, 116.47s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:51:06<8:19:47, 111.89s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:52:53<8:10:16, 110.17s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:54:33<7:56:12, 107.42s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:56:10<7:40:26, 104.25s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:57:51<7:33:52, 103.15s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:59:32<7:29:08, 102.47s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [7:01:07<7:18:09, 100.34s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [7:02:54<7:24:16, 102.13s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 15:56:21,254:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:05:47<8:54:43, 123.40s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:07:26<8:22:02, 116.30s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:09:13<8:07:47, 113.44s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:10:48<7:42:45, 108.04s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:12:33<7:37:00, 107.11s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:14:14<7:26:35, 105.08s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:15:51<7:15:01, 102.76s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:17:40<7:20:38, 104.50s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:19:20<7:14:04, 103.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:21:03<7:11:27, 103.14s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:23:55<8:35:17, 123.67s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:25:34<8:02:26, 116.25s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:27:13<7:39:15, 111.11s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:28:53<7:23:49, 107.81s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:30:27<7:05:48, 103.86s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:32:05<6:56:05, 101.90s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:33:41<6:47:45, 100.27s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:35:16<6:39:02, 98.53s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:36:59<6:43:29, 100.04s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:38:35<6:37:02, 98.85s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:41:32<8:08:54, 122.23s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:43:22<7:52:41, 118.67s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:45:03<7:28:45, 113.13s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:46:43<7:11:31, 109.24s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:48:22<6:57:54, 106.25s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:50:09<6:57:07, 106.50s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:51:48<6:46:31, 104.24s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:53:28<6:39:44, 102.94s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:55:11<6:38:08, 102.97s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:56:53<6:35:46, 102.80s/it]
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(TaskRunner pid=52076)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [8:00:12<8:23:57, 131.47s/it]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=52076)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [8:01:48<7:41:35, 120.94s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:03:26<7:13:07, 113.98s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:05:04<6:53:26, 109.28s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:06:42<6:38:29, 105.79s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:08:16<6:23:45, 102.34s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:09:58<6:21:36, 102.22s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:11:38<6:17:22, 101.53s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:13:23<6:19:44, 102.63s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 17:05:22,080:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:15:07<6:19:28, 103.03s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:17:56<7:30:08, 122.76s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:19:38<7:05:32, 116.59s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:21:26<6:53:43, 113.87s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:23:09<6:40:00, 110.60s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:24:53<6:31:26, 108.73s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:26:31<6:18:27, 105.62s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:28:15<6:14:20, 104.95s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:29:55<6:07:53, 103.63s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 17:21:53,185:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:31:37<6:04:02, 103.03s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:33:20<6:02:05, 102.97s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:36:11<7:11:48, 123.38s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:37:55<6:49:15, 117.49s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:39:31<6:25:16, 111.14s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:41:09<6:09:27, 107.09s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:42:51<6:03:15, 105.80s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:44:30<5:54:34, 103.78s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:46:15<5:53:28, 103.96s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:47:57<5:50:01, 103.46s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:49:37<5:44:27, 102.32s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:51:17<5:41:04, 101.81s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:54:05<6:45:31, 121.66s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:55:37<6:13:54, 112.74s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:57:15<5:56:49, 108.13s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:58:55<5:47:41, 105.90s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [9:00:41<5:45:31, 105.77s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:02:26<5:42:51, 105.50s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:04:03<5:33:33, 103.16s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:05:45<5:30:37, 102.78s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:07:28<5:29:10, 102.87s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:09:07<5:23:02, 101.48s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:12:03<6:32:39, 124.00s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:13:42<6:06:36, 116.38s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:15:18<5:46:02, 110.44s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:16:57<5:33:10, 106.90s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:18:36<5:23:54, 104.49s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:20:16<5:18:39, 103.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:21:58<5:15:30, 102.88s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 18:13:55,726:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:23:44<5:16:40, 103.83s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:25:25<5:11:49, 102.80s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:27:05<5:07:56, 102.08s/it]
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(TaskRunner pid=52076)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:30:12<6:22:31, 127.51s/it]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=52076)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:31:50<5:53:58, 118.65s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:33:30<5:35:11, 112.99s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:35:13<5:24:41, 110.06s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:36:52<5:12:53, 106.67s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:38:26<5:00:32, 103.05s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:40:08<4:57:20, 102.53s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:41:43<4:49:23, 100.37s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:43:22<4:46:13, 99.84s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:45:04<4:47:13, 100.78s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:47:54<5:43:37, 121.28s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:49:31<5:21:45, 114.23s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:51:12<5:08:42, 110.26s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:52:54<4:59:41, 107.68s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:54:34<4:51:54, 105.51s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:56:14<4:45:14, 103.73s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:57:58<4:43:51, 103.85s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 18:49:52,254:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:59:35<4:36:40, 101.84s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [10:01:11<4:29:47, 99.92s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 18:53:08,902:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:02:58<4:33:37, 101.97s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:05:47<5:25:46, 122.16s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:07:24<5:04:10, 114.78s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 18:59:20,981:Timeout during comparison
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 18:59:25,998:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:09:11<4:56:03, 112.43s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:10:45<4:39:38, 106.87s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:12:28<4:34:59, 105.77s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:14:13<4:32:06, 105.33s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:15:54<4:27:19, 104.15s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:17:33<4:21:47, 102.66s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:19:13<4:18:05, 101.88s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:20:45<4:08:26, 98.72s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:23:29<4:55:51, 118.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:25:07<4:38:36, 112.19s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:26:40<4:23:03, 106.64s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:28:25<4:19:49, 106.05s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:30:01<4:10:49, 103.08s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 19:21:56,489:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:31:40<4:06:21, 101.94s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:33:16<3:59:49, 99.93s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:34:55<3:57:45, 99.76s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:36:35<3:56:02, 99.74s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:38:09<3:50:30, 98.09s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:41:02<4:41:23, 120.60s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:42:45<4:27:10, 115.33s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:44:26<4:15:20, 111.02s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:46:05<4:04:55, 107.27s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:47:38<3:53:56, 103.21s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:49:17<3:49:11, 101.86s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:50:57<3:46:24, 101.38s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:52:38<3:44:19, 101.20s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:54:17<3:41:16, 100.58s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:55:49<3:33:45, 97.90s/it] 
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(TaskRunner pid=52076)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:59:02<4:33:52, 126.40s/it]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=52076)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:00:43<4:15:30, 118.84s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:02:27<4:03:46, 114.27s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:04:12<3:56:21, 111.66s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:06:01<3:52:44, 110.83s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:07:42<3:44:49, 107.91s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:09:18<3:35:23, 104.23s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:11:01<3:33:04, 103.94s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:12:38<3:26:50, 101.73s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:14:26<3:28:59, 103.63s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:17:13<4:05:09, 122.58s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:18:53<3:50:09, 116.05s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:20:31<3:37:10, 110.43s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:22:06<3:26:39, 105.98s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:23:42<3:18:44, 102.80s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 20:15:37,608:Timeout during comparison
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 20:15:42,642:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:25:25<3:17:07, 102.84s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:26:58<3:09:55, 99.96s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:28:33<3:05:26, 98.47s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:30:12<3:04:08, 98.64s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 20:22:04,959:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:31:49<3:01:53, 98.32s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:34:38<3:39:01, 119.47s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:36:15<3:24:29, 112.56s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:37:51<3:13:57, 107.76s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:39:35<3:10:14, 106.68s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:41:07<3:00:28, 102.16s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:42:44<2:56:03, 100.61s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:44:18<2:51:12, 98.77s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:45:55<2:48:27, 98.13s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:47:31<2:45:30, 97.36s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:49:04<2:41:58, 96.22s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:51:51<3:15:51, 117.52s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:53:28<3:03:35, 111.27s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 20:45:22,840:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:55:09<2:56:35, 108.12s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:56:51<2:51:48, 106.28s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 20:48:49,108:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:58:39<2:50:54, 106.82s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:00:17<2:44:44, 104.05s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:01:52<2:39:03, 101.53s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:03:33<2:36:57, 101.27s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:05:09<2:32:56, 99.74s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:06:46<2:30:07, 98.98s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:09:36<3:00:31, 120.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:11:16<2:49:13, 114.09s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:12:59<2:42:22, 110.71s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:14:32<2:32:55, 105.47s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:16:18<2:31:21, 105.60s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:18:05<2:30:14, 106.06s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:19:40<2:23:57, 102.82s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:21:20<2:21:03, 101.97s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:23:02<2:19:14, 101.88s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:24:40<2:15:50, 100.63s/it]
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(TaskRunner pid=52076)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:27:49<2:49:33, 127.17s/it]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=52076)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:29:31<2:37:42, 119.78s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:31:18<2:30:38, 115.88s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:33:00<2:23:22, 111.72s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:34:43<2:18:21, 109.23s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:36:20<2:11:56, 105.55s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:38:00<2:07:57, 103.74s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:39:45<2:06:35, 104.05s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:41:30<2:05:09, 104.31s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:43:09<2:01:42, 102.85s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:46:10<2:27:19, 126.27s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:47:49<2:15:39, 117.96s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:49:29<2:07:38, 112.62s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:51:12<2:02:37, 109.82s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:52:51<1:57:15, 106.60s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:54:27<1:52:07, 103.50s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:56:10<1:50:14, 103.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:57:57<1:49:36, 104.39s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:59:39<1:47:04, 103.63s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:01:20<1:44:39, 102.94s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:04:18<2:05:27, 125.46s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:05:58<1:55:52, 117.84s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:07:47<1:51:14, 115.08s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:09:29<1:45:35, 111.14s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:11:11<1:41:16, 108.52s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:12:55<1:38:08, 107.06s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:14:36<1:34:43, 105.25s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:16:18<1:31:58, 104.13s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:18:03<1:30:37, 104.57s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:19:48<1:28:57, 104.67s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:22:44<1:44:54, 125.90s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:24:24<1:36:34, 118.26s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:26:05<1:30:33, 113.20s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:27:54<1:27:38, 111.87s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:29:35<1:23:18, 108.66s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:31:16<1:19:42, 106.28s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:32:56<1:16:37, 104.49s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:34:40<1:14:37, 104.12s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:36:21<1:12:13, 103.17s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:38:06<1:10:51, 103.69s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:41:00<1:23:14, 124.87s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:42:40<1:16:20, 117.44s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:44:24<1:11:54, 113.53s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:46:03<1:07:17, 109.13s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:47:48<1:04:41, 107.82s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:49:28<1:01:33, 105.54s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 22:41:28,229:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:51:13<59:42, 105.35s/it]  
[36m(TaskRunner pid=52076)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:52:51<56:39, 103.00s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:54:28<54:00, 101.28s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:56:11<52:38, 101.88s/it]
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(TaskRunner pid=52076)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:59:18<1:03:38, 127.27s/it]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=52076)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:00:58<57:36, 119.20s/it]  
[36m(TaskRunner pid=52076)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:02:35<52:27, 112.39s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:04:19<49:29, 110.00s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:06:01<46:37, 107.60s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:07:36<43:14, 103.78s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:09:11<40:32, 101.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:10:56<39:14, 102.35s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:12:37<37:24, 102.00s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:14:13<35:04, 100.21s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:17:04<40:25, 121.27s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:18:51<37:01, 116.92s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:20:28<33:19, 111.10s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:22:06<30:19, 107.00s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:23:43<27:47, 104.21s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:25:21<25:35, 102.37s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:27:02<23:44, 101.73s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 23:18:58,573:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:28:44<22:03, 101.82s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:30:21<20:05, 100.50s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:31:58<18:14, 99.49s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:34:55<20:27, 122.78s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:36:33<17:18, 115.40s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:38:16<14:52, 111.59s/it]
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 23:30:15,774:Timeout during comparison
[36m(TaskRunner pid=52076)[0m WARNING:2025-12-21 23:30:21,686:Timeout during comparison
[36m(TaskRunner pid=52076)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:40:07<12:59, 111.39s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:41:44<10:42, 107.01s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:43:19<08:37, 103.43s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:44:58<06:48, 102.12s/it]
[36m(TaskRunner pid=52076)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:46:32<04:58, 99.60s/it] 
[36m(TaskRunner pid=52076)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:48:19<03:23, 101.87s/it]
[36m(TaskRunner pid=52076)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:50:04<01:42, 102.95s/it]
[36m(WorkerDict pid=55632)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=55632)[0m   warnings.warn(
[36m(TaskRunner pid=52076)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:53:15<01:51, 111.89s/it]
[36m(WorkerDict pid=55880)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=55880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
