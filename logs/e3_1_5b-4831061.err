
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_tw_covvar_0.0005_2/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_tw_covvar_0.0005_2//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_tw_covvar_0.0005_2//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_tw_covvar_0.0005_2//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_tw_covvar_0.0005_2/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-15 13:53:58,062	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=2450305)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 13:54:18,181:Waiting for register center actor cokuHN_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2453859)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=2453859)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=2453859)[0m [rank0]:[W1115 13:54:35.003536887 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=2453859)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2453859)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2454036)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m [rank3]:[W1115 13:54:36.341318257 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2454035)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2454034)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2454034)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2454034)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(WorkerDict pid=2453859)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=2454035)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454035)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:   0%|          | 1/480 [01:59<15:56:57, 119.87s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   0%|          | 2/480 [04:05<16:22:55, 123.38s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   1%|          | 3/480 [06:12<16:33:15, 124.94s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   1%|          | 4/480 [08:13<16:18:23, 123.33s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   1%|          | 5/480 [10:15<16:12:37, 122.86s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   1%|â–         | 6/480 [12:18<16:10:18, 122.82s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   1%|â–         | 7/480 [14:22<16:13:08, 123.44s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   2%|â–         | 8/480 [16:23<16:05:17, 122.71s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   2%|â–         | 9/480 [18:25<15:59:35, 122.24s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   2%|â–         | 10/480 [21:48<19:12:49, 147.17s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   2%|â–         | 11/480 [23:45<17:58:11, 137.93s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   2%|â–Ž         | 12/480 [25:44<17:10:45, 132.15s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   3%|â–Ž         | 13/480 [27:43<16:38:21, 128.27s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   3%|â–Ž         | 14/480 [29:45<16:21:21, 126.36s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   3%|â–Ž         | 15/480 [31:42<15:57:55, 123.60s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   3%|â–Ž         | 16/480 [33:41<15:45:12, 122.22s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   4%|â–Ž         | 17/480 [35:41<15:38:28, 121.62s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   4%|â–         | 18/480 [37:38<15:25:55, 120.25s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   4%|â–         | 19/480 [39:37<15:20:40, 119.83s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   4%|â–         | 20/480 [43:00<18:29:20, 144.70s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 14:41:02,883:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 14:41:10,504:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:   4%|â–         | 21/480 [45:11<17:55:28, 140.58s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   5%|â–         | 22/480 [47:13<17:09:45, 134.90s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   5%|â–         | 23/480 [49:11<16:29:27, 129.91s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   5%|â–Œ         | 24/480 [51:07<15:55:26, 125.72s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   5%|â–Œ         | 25/480 [53:01<15:26:10, 122.13s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   5%|â–Œ         | 26/480 [54:57<15:11:19, 120.44s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   6%|â–Œ         | 27/480 [56:59<15:13:36, 121.01s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   6%|â–Œ         | 28/480 [58:52<14:52:09, 118.43s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:49<14:48:33, 118.21s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:59<17:27:17, 139.64s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 15:01:53,003:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 15:01:58,018:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:56<16:34:19, 132.87s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:42<15:30:42, 124.65s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:39<15:12:48, 122.52s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:33<14:51:54, 119.99s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:25<14:30:27, 117.36s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:14<14:10:39, 114.95s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   8%|â–Š         | 37/480 [1:17:05<13:59:51, 113.75s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   8%|â–Š         | 38/480 [1:19:03<14:06:44, 114.94s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:51<13:51:22, 113.11s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:59<16:34:00, 135.55s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:49<15:34:29, 127.72s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:46<15:09:18, 124.56s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   9%|â–‰         | 43/480 [1:29:34<14:30:13, 119.48s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   9%|â–‰         | 44/480 [1:31:24<14:09:03, 116.84s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:   9%|â–‰         | 45/480 [1:33:08<13:38:06, 112.84s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:58<13:30:21, 112.03s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:48<13:23:52, 111.39s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:39<13:21:09, 111.27s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:33<13:25:04, 112.08s/it]
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(TaskRunner pid=2450305)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:52<16:30:38, 138.23s/it]
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:38<15:20:17, 128.71s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:47:24<14:29:04, 121.83s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:49:07<13:47:14, 116.24s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:56<13:28:21, 113.85s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:41<13:08:59, 111.39s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:28<12:57:13, 109.98s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:56:17<12:54:03, 109.80s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:58:01<12:39:29, 107.98s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 15:55:56,112:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:59:50<12:40:00, 108.31s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 15:57:43,854:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:51<15:10:00, 130.00s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:38<14:19:31, 123.08s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:06:21<13:36:19, 117.18s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:08:04<13:05:17, 112.99s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:09:55<12:59:00, 112.36s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:11:38<12:36:44, 109.41s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:13:24<12:28:21, 108.46s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:15:07<12:16:09, 106.95s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:16:50<12:05:35, 105.67s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:18:38<12:07:22, 106.19s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:21:36<14:32:51, 127.74s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:23:21<13:45:21, 121.08s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:25:05<13:08:35, 115.97s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:26:50<12:43:12, 112.51s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:28:37<12:30:21, 110.89s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 16:26:29,290:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:30:27<12:26:34, 110.60s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:32:16<12:21:43, 110.16s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:34:03<12:13:59, 109.28s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:35:49<12:05:13, 108.24s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:37:42<12:13:33, 109.76s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:40:38<14:23:34, 129.54s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:42:23<13:33:46, 122.37s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:44:08<12:56:15, 117.02s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:45:56<12:36:13, 114.29s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:47:42<12:18:16, 111.86s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:49:28<12:05:11, 110.16s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:51:15<11:56:53, 109.17s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:53:02<11:49:42, 108.35s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:54:50<11:47:59, 108.37s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:56:32<11:34:31, 106.58s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:59:30<13:50:45, 127.81s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:01:12<12:59:23, 120.22s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 16:59:02,952:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 16:59:07,970:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:03:03<12:39:16, 117.41s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:04:48<12:12:55, 113.63s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:06:36<12:00:15, 111.96s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:08:19<11:40:23, 109.15s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:10:06<11:35:27, 108.67s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:11:50<11:24:02, 107.16s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:13:26<11:00:25, 103.73s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:15:16<11:12:16, 105.87s/it]
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(WorkerDict pid=2453859)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2453859)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=2450305)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:18:29<13:55:24, 131.91s/it]
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:20:09<12:53:05, 122.39s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:21:53<12:16:16, 116.87s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:23:35<11:46:24, 112.43s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:25:15<11:21:31, 108.75s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:27:02<11:14:49, 107.97s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:28:42<10:58:21, 105.62s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:30:28<10:58:36, 105.94s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:32:07<10:43:41, 103.82s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:33:59<10:55:47, 106.06s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:36:55<13:04:52, 127.28s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:38:40<12:21:51, 120.63s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:40:16<11:33:35, 113.08s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:41:59<11:12:39, 109.97s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:43:45<11:03:23, 108.75s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:45:20<10:38:07, 104.90s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:47:00<10:25:49, 103.16s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:48:42<10:23:33, 103.07s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:50:24<10:19:52, 102.74s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:52:06<10:15:16, 102.26s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:54:59<12:21:12, 123.53s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:56:38<11:35:30, 116.24s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:58:25<11:17:12, 113.50s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:00:09<10:58:25, 110.66s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 17:58:09,955:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:02:09<11:13:55, 113.58s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:03:53<10:53:39, 110.48s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:05:36<10:38:43, 108.26s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:07:16<10:21:50, 105.70s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:08:58<10:15:07, 104.85s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:10:41<10:10:14, 104.31s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:13:33<12:06:57, 124.62s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:15:18<11:29:24, 118.52s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:16:54<10:49:16, 111.94s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:18:38<10:33:21, 109.51s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:20:22<10:21:33, 107.79s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:22:06<10:14:05, 106.80s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:23:48<10:02:41, 105.12s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:25:28<9:52:31, 103.65s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:27:11<9:49:43, 103.46s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:28:54<9:47:45, 103.42s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:31:46<11:42:43, 124.01s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:33:28<11:02:31, 117.26s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:35:05<10:26:40, 111.24s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:36:50<10:14:12, 109.35s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:38:30<9:56:24, 106.50s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:40:12<9:48:14, 105.36s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:41:48<9:30:06, 102.42s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:43:25<9:20:10, 100.93s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:45:06<9:17:38, 100.78s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:46:51<9:22:39, 101.99s/it]
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(TaskRunner pid=2450305)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:50:00<11:44:17, 128.05s/it]
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:51:41<10:58:46, 120.14s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:53:26<10:31:28, 115.51s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:55:06<10:03:35, 110.75s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:56:50<9:51:39, 108.89s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:58:32<9:38:06, 106.73s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:00:07<9:17:37, 103.26s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:01:47<9:10:35, 102.28s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:03:31<9:11:34, 102.78s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:05:13<9:08:34, 102.54s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:08:05<10:58:38, 123.49s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:09:53<10:30:45, 118.64s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:11:37<10:06:26, 114.42s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:13:17<9:41:42, 110.10s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:14:56<9:21:21, 106.59s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:16:34<9:06:33, 104.11s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:18:15<9:00:31, 103.28s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:19:53<8:50:46, 101.75s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:21:36<8:49:34, 101.84s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:23:13<8:41:39, 100.64s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:26:03<10:27:02, 121.36s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:27:40<9:47:56, 114.16s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:29:20<9:23:55, 109.85s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:30:58<9:03:32, 106.23s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:32:35<8:47:08, 103.36s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:34:16<8:42:05, 102.71s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:35:56<8:36:32, 101.95s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:37:34<8:28:57, 100.78s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:39:15<8:28:10, 100.96s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:40:55<8:24:04, 100.48s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:43:44<10:04:49, 120.97s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 19:41:33,269:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 19:41:38,289:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 19:41:44,886:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:45:40<9:55:27, 119.49s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:47:19<9:23:01, 113.36s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:48:58<9:00:38, 109.22s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:50:34<8:39:18, 105.26s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:52:21<8:39:07, 105.58s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:53:58<8:25:50, 103.23s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:55:35<8:13:44, 101.11s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:57:17<8:13:28, 101.40s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:58:58<8:11:56, 101.43s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:01:45<9:45:25, 121.12s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:03:20<9:05:39, 113.29s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:04:56<8:37:55, 107.90s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:06:34<8:23:06, 105.18s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:08:13<8:12:19, 103.29s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:09:50<8:01:39, 101.40s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:11:32<8:00:57, 101.61s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:13:08<7:51:13, 99.91s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:14:47<7:48:02, 99.58s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:16:24<7:42:27, 98.75s/it]
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(TaskRunner pid=2450305)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:19:31<9:43:56, 125.13s/it]
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:21:10<9:06:28, 117.52s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:22:51<8:40:30, 112.34s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:24:30<8:20:47, 108.47s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:26:09<8:06:24, 105.74s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:27:49<7:55:54, 103.83s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:29:32<7:53:33, 103.70s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:31:18<7:54:30, 104.29s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:32:53<7:40:57, 101.68s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:34:31<7:33:10, 100.33s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:37:24<9:10:18, 122.29s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:39:03<8:36:56, 115.30s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:40:41<8:11:49, 110.11s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:42:22<7:57:39, 107.34s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:44:01<7:44:43, 104.83s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:45:35<7:29:14, 101.72s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:47:11<7:19:06, 99.80s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:48:49<7:14:56, 99.23s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:50:21<7:04:05, 97.12s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:52:04<7:10:32, 98.97s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:54:48<8:33:34, 118.52s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:56:26<8:05:11, 112.40s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:58:04<7:44:52, 108.11s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:59:36<7:21:13, 103.01s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:01:14<7:13:56, 101.71s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:02:48<7:02:32, 99.42s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:04:22<6:53:07, 97.59s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:06:05<6:58:24, 99.23s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:07:42<6:54:25, 98.67s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:09:22<6:53:47, 98.92s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:12:07<8:15:10, 118.84s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:13:41<7:42:06, 111.35s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:15:16<7:19:48, 106.41s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:16:53<7:06:18, 103.56s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:18:26<6:52:06, 100.51s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:20:02<6:44:41, 99.11s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:21:35<6:35:53, 97.35s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:23:10<6:31:41, 96.72s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:24:52<6:35:42, 98.11s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:26:27<6:30:34, 97.24s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:29:16<7:55:21, 118.84s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 21:27:06,339:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:31:03<7:39:27, 115.35s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:32:40<7:15:37, 109.82s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:34:18<6:59:48, 106.28s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:35:54<6:45:56, 103.21s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:37:33<6:38:39, 101.79s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:39:08<6:29:48, 99.95s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:40:47<6:26:41, 99.58s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:42:26<6:24:42, 99.49s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:44:07<6:24:10, 99.78s/it]
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(TaskRunner pid=2450305)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:47:12<8:01:02, 125.49s/it]
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:48:48<7:25:05, 116.62s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 21:46:34,799:Timeout during parsing: Okay, so I need to figure out how many functions \( f \) exist from the set \(\{-1005, \ldots, 1005\}\) to \(\{-2010, \ldots, 2010\}\) that satisfy two conditions. First, if \( a < b \), then \( f(a) < f(b) \), which means the function is strictly increasing. Second, there's no \( n \) in \(\{-1005, \ldots, 1005\}\) such that \( |f(n)| = |n| \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Let me break this down step by step.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m **Understanding the domain and codomain:**
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m The domain is \(\{-1005, -1004, \ldots, 0, \ldots, 1004, 1005\}\), which has \(2011\) elements (from \(-1005\) to \(1005\) inclusive). The codomain is \(\{-2010, -2009, \ldots, 0, \ldots, 2009, 2010\}\), which has \(4021\) elements (from \(-2010\) to \(2010\) inclusive).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m **First condition: Strictly increasing function.**
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Since \( f \) is strictly increasing, each element in the domain is mapped to a unique element in the codomain, and the order is preserved. So, \( f(-1005) < f(-1004) < \ldots < f(0) < \ldots < f(1005) \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Therefore, to count such functions, I can think in terms of combinations without repetition, since each \( f(n) \) must be distinct and in increasing order. However, the codomain is larger, so not every selection will necessarily satisfy the second condition.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m **Second condition: No \( n \) such that \( |f(n)| = |n| \).**
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This means that for each \( n \) in the domain, \( f(n) \) cannot be equal to \( \pm |n| \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m So, for each \( n \), \( f(n) \) must be chosen from the set \(\{-2010, \ldots, -|n| -1, |n| + 1, \ldots, 2010\}\), except \( f(n) = -|n| \) or \( f(n) = |n| \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, actually, let's make it precise. The condition is \( |f(n)| \neq |n| \). So, for each \( n \), \( f(n) \) â‰  \( n \) and \( f(n) â‰  -n \), but wait, no: the codomain is from \(-2010\) to \(2010\), so for each \( n \), the value \( f(n) \) cannot be \( n \) or \(-n \). Wait, is that correct?
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Hold on, no. The condition is \( |f(n)| \neq |n| \), which simplifies to \( f(n) â‰  n \) and \( f(n) â‰  -n \), but since \( f(n) \) is in the codomain, not necessarily related to \( n \). Wait, actually, let's rephrase it:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m If \( |f(n)| = |n| \), then \( f(n) = n \) or \( f(n) = -n \). However, according to the second condition, this can't happen. So, for each \( n \), \( f(n) \) cannot be \( n \) unless \( n \) is in the codomain. Wait, but \( n \) can be from -1005 to 1005, while the function maps to up to 2010, so for \( n \) in the domain, \(-1005\) to \(1005\), but the images \( f(n) \) can be up to \(-2010\) to \(2010\).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Thus, for each \( n \), \( f(n) \) cannot be \( n \) or \( -n \). However, since \( n \) can also be from \(-1005\) to \(1005\), but \( f(n) \) is from \(-2010\) to \(2010\). So, the restrictions are:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m - If \( n \) is non-zero, then \( f(n) â‰  n \) and \( f(n) â‰  -n \).
[36m(TaskRunner pid=2450305)[0m - If \( n = 0 \), then \( f(0) \) can be any value except \( 0 \) (since \( |f(0)| â‰  |0| \) simplifies to \( f(0) â‰  0 \)). Wait, is that correct?
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, hold on, for \( n = 0 \), \( |f(n)| = |0| = 0 \), so \( |f(0)| â‰  0 \implies f(0) â‰  0 \). So \( f(0) \) must be something else.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Similarly, for \( n â‰  0 \), \( f(n) \) cannot be \( n \) or \( -n \), but for \( n â‰  0 \), since \( |n| â‰  0 \), the condition is simply that \( f(n) â‰  n \) and \( f(n) â‰  -n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m However, we have to be careful because some of these values \( n \) and \(-n \) might be in the codomain beyond the possible image of \( f \) given the domain size.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, for each \( n \) in the domain, the forbidden images are \( n \) and \( -n \). However, \( n \) and \(-n \) might not necessarily be in the codomain. Wait, no. The domain includes both positive and negative numbers and zero, but the codomain includes both negative and positive numbers beyond that. So, for example, for \( n = 1005 \), \( -1005 \) is in the codomain, but \( 1005 \) is in the domain. Wait, no: the function maps from domain to codomain, but \( n \) is in the domain, while \( f(n) \) must not equal \( n \) or \(-n \). But \( f(n) \) can be equal to \( -n \) if that's in the codomain.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, this is getting a bit tangled.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Maybe it's better to structure this problem.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m First, think of this as a strict increasing function from a 2011-element set to a 4021-element set. So normally, the number of strictly increasing functions (i.e., strictly increasing functions without any restrictions) is equal to the number of combinations of 4021 elements taken 2011 at a time, since each function is uniquely determined by choosing 2011 distinct elements from the codomain in increasing order.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But with the additional restrictions, we need to subtract the functions where for some \( n \), \( f(n) = \pm n \), but we need to do it carefully since some choices violate the restrictions for multiple \( n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This seems similar to inclusion-exclusion, but since the forbidden assignments are maybe independent or overlapping, it's tricky.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But before getting bogged down in inclusion-exclusion, perhaps we can think of the problem more combinatorially.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m First, the total number of strictly increasing functions without any restrictions is \( \dbinom{4021}{2011} \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Now, we have to subtract the number of strictly increasing functions where for some \( n \), either \( f(n) = n \) or \( f(n) = -n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But we have to be cautious about overlapping cases where multiple restrictions can be violated at the same time, so inclusion-exclusion might be necessary. But inclusion-exclusion can get complicated because each forbidden assignment might interact in non-trivial ways.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Alternatively, perhaps a bijection can help.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, but given the domain is from -1005 to 1005 and the codomain is from -2010 to 2010, we can think of the domain as a subset of the codomain? Or not necessarily.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, but maybe not. The function is from a subset.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Alternatively, since the maps are from a 2011-element set to a 4021-element set, the function must pick 2011 elements in increasing order.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But to count the number where no element \( f(n) = \pm n \). Hmm.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, perhaps it's helpful to split this problem into two parts:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m 1. Assign each element \( n \) in the domain a value in the codomain, ensuring that the assignments are strictly increasing, and for each \( n \), if \( |f(n)| â‰  |n| \), i.e., \( f(n) â‰  n \) and \( f(n) â‰  -n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But perhaps it's easier to model this as choosing images for each \( n \) such that \( f(n) \) is not in \( \{ -|n|, |n| \} \) (except possibly when \( n = 0 \), but actually, for \( n = 0 \), \( |f(n)| â‰  0 \), meaning \( f(0) \) can be anything except 0.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, perhaps the forbidden mappings are:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m - For each \( n \neq 0 \), \( f(n) \) cannot be \( n \) or \( -n \).
[36m(TaskRunner pid=2450305)[0m - Specifically, for \( n = 0 \), \( f(0) \) cannot be 0.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Therefore, the problem reduces to counting the number of increasing functions from the domain \(\{-1005, ..., 1005\}\) to the codomain \(\{-2010, ..., 2010\}\), with the constraint that for each \( n \neq 0 \), \( f(n) \) is not in \( \{n, -n\} \), and for \( n = 0 \), \( f(0) \neq 0 \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Therefore, we can model this as selecting a subset of the codomain of size 2011, with the first element \( f(-1005) \) being the smallest, and each subsequent \( f(n) \) being larger than the previous, and avoiding the forbidden values for each \( n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This problem is similar to counting the number of injective functions with forbidden positions, which is a standard inclusion-exclusion problem.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But considering the domain is from -1005 to 1005 (size 2011), and codomain is from -2010 to 2010 (size 4021), the number will be high. However, the forbidden assignments are for each \( n \neq 0 \) (there are 1005 such n: -1005 to -1 and 1 to 1005), and for \( n = 0 \), there is one forbidden value (0).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m So perhaps we can model this as a permutation problem with forbidden positions.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But since the codomain is much larger, perhaps hypergeometric distribution.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, let me think differently.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m To count the number of strictly increasing functions, we can model it as choosing a strictly increasing sequence of length 2011 from the codomain. So normally, the count is \( \dbinom{4021}{2011} \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m However, we need to exclude those functions where for some \( n \in \{-1005, ..., 1005\} \setminus \{0\} \), \( f(n) = n \) or \( f(n) = -n \). But each forbidden assignment is for a specific \( n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m For \( n \neq 0 \), the number of choices for \( f(n) \) is:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m If \( |n| \) is within the codomain, which it is since \( \{-2010, ..., 2010\} \) includes all possible \( |n| \) except that \( f(n) â‰  |n| \) and \( f(n) â‰  -|n| \). Wait, or does it?
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, actually, for each \( n \) in the domain, \( f(n) \) cannot be \( n \) or \( -n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But \( f(n) \) maps to codomain \(\{-2010, ..., 2010\}\), so \( n \) and \(-n \) are elements of the codomain, so yes, we need to exclude them.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Therefore, for each \( n \neq 0 \), two values are forbidden. But wait, hold on: For each \( n \neq 0 \), \( f(n) \) cannot be \( n \) or \( -n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Thus, for each \( n \neq 0 \), we have 4021 - 2 = 4019 allowed choices for \( f(n) \). But no, because the function is strictly increasing, the choices for different \( n \) are not independent, so this doesn't hold.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Therefore, perhaps inclusion-exclusion is necessary.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Alternatively, perhaps this can be transformed into a problem about choosing positions with forbidden elements. Since each forbidden element depends on the index \( n \), which is also the position in the sequence.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This complicates things, because the forbidden assignments are not uniform across the sequence. Thus, it's a bit of a trick question, and I think the solution is related to choosing a subset of the domain where certain positions are forbidden, which is similar to permutation counting with forbidden positions.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But since the forbidden assignments vary with \( n \), it's tricky.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, perhaps the following approach: model the problem as choosing a sequence \( a_1, a_2, \ldots, a_{2011} \) where \( a_1 < a_2 < \ldots < a_{2011} \), and each \( a_i \in \{-2010, \ldots, 2010\} \), such that for each \( j \) in the original domain (excluding 0), \( a_j \neq j \) and \( a_j \neq -j \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But this is equivalent to counting the number of such sequences where certain positions are forbidden.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m However, since \( j \) is the index in the domain, and \( a_j \in \{-2010, ..., 2010\} \), the forbidden values for each position are \( j \) and \(-j \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Therefore, the problem reduces to counting the number of strictly increasing sequences of length 2011, where each element is in \{-2010, ..., 2010\}, and for each position \( k \) (which corresponds to the value \( j = -k \) or something? Wait, no, perhaps better to think in terms of injection.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, perhaps we can model this as a matching problem where each "origin" \( n \) has some forbidden values in the codomain, and we have to choose injective mappings.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Alternatively, perhaps consider the set of forbidden numbers on the codomain: for each \( n \) in the domain \(\{-1005, ..., 1005\}\), the values \( n \) and \(-n \) are forbidden from being images of \( f(n) \). So, in other words, we are trying to map 2011 elements \( n \) to 2011 elements of the codomain, avoiding the two forbidden values per position.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This seems similar to a permutation with forbidden positions, which can be counted using inclusion-exclusion.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m In such cases, the formula is:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Total = \(\dbinom{M}{K}\) where \( M \) is the codomain size, \( K \) is the domain size.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But with forbidden positions, it gets more complex.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m In our case, for each \( n \), there is a forbidden number \( f(n) = n \) and \( f(n) = -n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But these forbidden assignments are tied to the position in the sequence, so each choice affects the next choices.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This complicates things, and perhaps a better way is to transform the problem.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, note that the mapping \( f \) must have \( f(n) \neq n \) and \( f(n) \neq -n \) for each \( n \neq 0 \). Also, \( f(0) \neq 0 \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Therefore, perhaps we can map each element \( n \) in the domain to a codomain element \( m \) such that \( m \neq n \) and \( m \neq -n \), except for 0.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But in the codomain, the possible images are from -2010 to 2010, so for each \( n \in \{-1005, ..., 1005\} \setminus \{0\} \), \( f(n) \) must be chosen from 4021 - 2 = 4019 options (since two are forbidden: \( n \) and \(-n \)).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But because the function is strictly increasing, the choices are dependent across different \( n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This is too vague. Maybe instead, think of the problem as matching the domain to the codomain with specific forbidden assignments, so it's equivalent to derangements but in higher dimensions.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m However, thinking more clearly, each forbidden assignment is a specific mapping. For each \( n \neq 0 \), \( f(n) \neq n \), \( f(n) \neq -n \). So, for each \( n \neq 0 \), it's forbidden to map to the two specific values in the codomain.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, but the crucial point is that 0 in the domain cannot map to 0 in the codomain, but 0 in the codomain could be mapped from multiple domain values because the forbidden assignments per domain value are different.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This doesn't directly translate into a simple derangement problem.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Perhaps inclusion-exclusion is the way to go. The idea is that we're trying to count the number of injective sequences with certain forbidden positions.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Let me try to model it as a generalized derangement.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m In combinatorics, the number of injective functions from a set \( A \) to a set \( B \) where certain elements are forbidden from certain positions is given by inclusion-exclusion.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m In our problem:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m - The domain \( A \) has 2011 elements: \(-1005, ..., 1005\).
[36m(TaskRunner pid=2450305)[0m - The codomain \( B \) has 4021 elements.
[36m(TaskRunner pid=2450305)[0m - We are choosing a strictly increasing function \( f: A \rightarrow B \), meaning it's a bijection if size is preserved.
[36m(TaskRunner pid=2450305)[0m - However, for each \( n \in A \), \( f(n) \) cannot be \( n \) or \(-n \), except for \( n = 0 \), where \( f(0) \neq 0 \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Therefore, the total number of such functions is equal to the number of injective functions from \( A \) to \( B \) with constraints on their images.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This can be calculated using inclusion-exclusion where we exclude mappings that map \( n \) to \( n \) or \(-n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m The formula for such a count is:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m \[
[36m(TaskRunner pid=2450305)[0m \sum_{k=0}^{2011} (-1)^k \dbinom{C}{k} \dbinom{4021 - 2k}{2011 - k}
[36m(TaskRunner pid=2450305)[0m \]
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Where \( C \) is the number of forbidden assignments. Wait, actually, the inclusion-exclusion formula is a bit different.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Typically, the inclusion-exclusion formula for this is:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m \[
[36m(TaskRunner pid=2450305)[0m \sum_{S \subseteq A} (-1)^{|S|} \prod_{n \in S} \dbinom{4021 - 2}{1} \dbinom{4021 - 2 - (2011 - |S|)}{2011 - |S|}
[36m(TaskRunner pid=2450305)[0m \]
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, maybe not. Actually, each forbidden condition for a single \( n \) (i.e., \( f(n) \neq n \) and \( f(n) \neq -n \)) reduces the available choices.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But maybe it's overcomplicating.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Alternatively, perhaps consider the problem as a permutation with restricted positions.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Each element in the domain needs to be mapped to a codomain element, avoiding certain positions. Since each \( n \neq 0 \) is forbidden from being mapped to \( n \) or \(-n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Therefore, for each \( n \neq 0 \), there are two forbidden images, but since the codomain is larger, we can consider the forbidden assignments as constraints that need to be respected.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Therefore, using inclusion-exclusion, the number of such functions is:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m First, count the total number of injective functions: \(\dbinom{4021}{2011}\).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Then, subtract the number of functions where at least one forbidden mapping occurs, add back those where at least two forbidden mappings occur, and so on.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m However, due to the overlapping forbidden mappings, inclusion-exclusion is needed. But due to the large size of the codomain and the small size of the forbidden set, the computation becomes complex.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m However, noticing that the forbidden choices are symmetric and limited, maybe there's a combinatorial structure or symmetry that can be exploited.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, another approach: Since for each \( n \neq 0 \), \( f(n) \) must not be \( n \) or \( -n \), which is equivalent to \( f(n) \neq \pm n \). But because the domain has 2011 elements and the codomain has 4021 elements, the forbidden positions for each \( n \) are specific. Therefore, by the principle of inclusion-exclusion, the desired count is:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m \[
[36m(TaskRunner pid=2450305)[0m \sum_{k=0}^{2011} (-1)^k \dbinom{2011}{k} \dbinom{4021 - 2k}{2011 - k}
[36m(TaskRunner pid=2450305)[0m \]
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But wait, this is similar to arranging forbidden positions.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Each forbidden assignment reduces the available pool.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But considering that each forbidden condition is independent, the inclusion-exclusion formula would be as follows:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Total = \(\sum_{k=0}^{2011} (-1)^k \dbinom{2011}{k} \times \dbinom{4021 - 2k}{2011 - k}\)
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Where each term is subtracting the cases where \( k \) specific domain elements are mapped to specific forbidden codomain elements.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m However, I'm not sure about the exact computation here because it's intricate.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But actually, upon reflection, this problem is equivalent to counting the number of strictly increasing functions from a linearly ordered set (the domain) to another ordered set (the codomain), with some elements (the forbidden mappings) forbidden.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This is a standard problem in combinatorics, often tackled using the inclusion-exclusion principle or by transforming it into a known counting problem.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But another observation: Each forbidden mapping \( f(n) = \pm n \) can be thought of as two forbidden assignments for each \( n \neq 0 \). However, since each such \( f(n) \) must map to a unique codomain element, it complicates the exact count.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m However, perhaps the total number of such functions is simply \(\dbinom{4021 - 2010}{2011} \times 2011!\). Wait, no. Alternatively, it could be zero if the forbidden positions are more restrictive, but in this case, since the forbidden mappings don't interfere with the strictly increasing nature, the count can be expressed as:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m For each strictly increasing sequence, we need to subtract the cases where at least one forbidden image is used. But as forbidden images are unique and spread across the codomain, it's a bit messy.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m However, considering that each forbidden assignment is symmetric, and each n â‰  0 has exactly two forbidden elements, perhaps the total number is \(\dbinom{4021 - 4020}{2011}\), which would be zero, but I think that's the wrong way.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, perhaps a better way is to note that each forbidden mapping for a domain element \( n \) removes up to 2 codomain elements, but since it's allowed to have multiple forbidden mappings, inclusion-exclusion is unavoidable.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, I think the correct approach is that each forbidden image is a unique element in the codomain, so essentially, the problem is equivalent to choosing a strictly increasing sequence where each term is not equal to Â±the index.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But given the strictness, since for each domain element \( n \), two elements are prohibited from being mapped to, perhaps it's similar to arranging the images such that for each \( n \), \( f(n) \neq n \) and \( f(n) \neq -n \).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m This is analogous to derangements but on a larger set.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m However, without a clear formula, maybe a better approach is to recognize that the number of injective functions from a set of size \( m \) to another set of size \( n \) with forbidden assignments is given by a certain inclusion-exclusion formula, but in our case, each forbidden assignment is based on the domain element's value.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Another angle: Since the forbidden assignments are of the form \( f(n) = n \) and \( f(n) = -n \), and since each of these forbidden mappings is a specific element in the codomain, perhaps we can model this problem as choosing 2011 elements out of 4021, with some conditions, and then arranging them in increasing order.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But I think I'm going in circles here.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, perhaps the answer is \(\dbinom{4021 - 2 \times 2011}{2011}\), but that would be negative, so that can't be.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Alternatively, since each forbidden mapping is a unique element, perhaps the number of such functions is \(\dbinom{4021 - 2 \times 2011 +1}{2011}\) or something else.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But honestly, I'm stuck here.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, let me consider a simpler case.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Suppose the domain is \(\{-1, 1\}\) and codomain is \(\{-2, 0, 2\}\}. Wait, okay, not sure.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But given that for each \( n \in \{-1005, ..., 1005\} \), two numbers are forbidden, I think the number of functions satisfying the two conditions is \(\dbinom{4021 - 2 \times 2011}{2011}\).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m But 4021 - 2*2011 = 4021 - 4022 = -1. Then, \(\dbinom{-1}{2011}\) is zero. Hmm, that can't be.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Alternatively, maybe it's \(\dbinom{4020}{2011}\).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Because each forbidden mapping removes two choices, so from 4020 to 2011.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Thus, \(\dbinom{4020}{2011}\) is the number, considering we remove two elements for each domain element. But that reasoning is shaky.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Wait, another way: The domain has size 2011, and for each of them, we remove two elements from the codomain. However, since each forbidden assignment is tied to the domain element, it's actually equivalent to choosing 2011 elements from the codomain with 2 restrictions per element, but these are unique.
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Thus, perhaps:
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Total number without restrictions: \(\dbinom{4021}{2011}\).
[36m(TaskRunner pid=2450305)[0m 
[36m(TaskRunner pid=2450305)[0m Minus the number of functions where at least one domain element is mapped to forbidden values. Each
[36m(TaskRunner pid=2450305)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:50:31<7:06:57, 112.36s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:52:06<6:46:07, 107.34s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 21:49:52,189:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 21:50:00,225:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:53:53<6:43:26, 107.11s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:55:29<6:28:48, 103.68s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:57:09<6:23:45, 102.79s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:58:45<6:14:09, 100.67s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:00:27<6:13:43, 101.01s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 21:58:11,809:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:02:06<6:09:55, 100.43s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:04:51<7:19:11, 119.78s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:06:30<6:54:54, 113.67s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:08:13<6:41:29, 110.50s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:09:54<6:29:22, 107.66s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:11:36<6:21:18, 105.92s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:13:13<6:09:39, 103.16s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:14:53<6:04:30, 102.20s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:16:30<5:57:25, 100.68s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:18:03<5:47:10, 98.26s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:19:40<5:44:32, 97.98s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 22:17:29,384:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:22:33<7:01:44, 120.50s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:24:14<6:38:55, 114.52s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:25:48<6:16:29, 108.60s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:27:26<6:03:06, 105.25s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:29:08<5:57:43, 104.19s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:30:42<5:46:31, 101.42s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:32:23<5:43:45, 101.11s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 22:30:11,452:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:34:10<5:48:22, 102.97s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:35:48<5:41:18, 101.38s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:37:27<5:37:08, 100.64s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:40:15<6:42:41, 120.81s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:41:47<6:12:45, 112.39s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:43:25<5:56:36, 108.06s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:45:03<5:44:13, 104.84s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:46:46<5:41:27, 104.53s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:48:29<5:37:48, 103.94s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:50:06<5:29:22, 101.87s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:51:45<5:24:35, 100.91s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:53:23<5:20:25, 100.13s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:55:00<5:15:51, 99.22s/it] 
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 22:54:24,453:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:57:59<6:29:45, 123.08s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:59:37<6:03:43, 115.47s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:01:13<5:44:04, 109.81s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:02:51<5:31:05, 106.23s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:04:27<5:19:52, 103.18s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:06:06<5:13:56, 101.82s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:07:48<5:12:27, 101.89s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:09:23<5:04:52, 99.96s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:11:03<5:02:50, 99.84s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:12:40<4:58:50, 99.06s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 23:11:56,843:Timeout during comparison
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(TaskRunner pid=2450305)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:15:48<6:17:12, 125.73s/it]
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:17:25<5:49:37, 117.19s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:19:01<5:28:42, 110.80s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:20:38<5:14:47, 106.71s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:22:16<5:05:22, 104.10s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:23:51<4:55:01, 101.15s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:25:28<4:49:37, 99.87s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:27:00<4:41:50, 97.75s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:28:36<4:38:22, 97.10s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:30:17<4:40:00, 98.25s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:33:02<5:34:52, 118.19s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:34:37<5:13:21, 111.25s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:36:11<4:57:40, 106.31s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:37:45<4:45:14, 102.48s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:39:21<4:38:25, 100.64s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:41:00<4:35:11, 100.07s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:42:43<4:35:44, 100.88s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 23:40:27,074:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 23:40:32,096:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 23:40:37,627:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 23:40:44,181:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:44:35<4:43:10, 104.23s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:46:11<4:34:52, 101.80s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:47:49<4:30:15, 100.71s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 23:47:07,194:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:50:42<5:26:00, 122.25s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:52:18<5:03:34, 114.56s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-15 23:50:02,847:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:54:04<4:54:59, 112.02s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:55:40<4:40:01, 107.01s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:57:20<4:33:17, 105.11s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [9:58:58<4:25:48, 102.89s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:00:35<4:19:21, 101.05s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:02:15<4:17:03, 100.81s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:03:53<4:13:19, 100.00s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:05:28<4:07:50, 98.48s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:08:13<4:55:47, 118.32s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:09:41<4:31:26, 109.31s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:11:14<4:17:23, 104.35s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:12:53<4:11:44, 102.75s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:14:27<4:04:02, 100.29s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:16:02<3:58:18, 98.61s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:17:38<3:54:58, 97.90s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:19:16<3:53:17, 97.89s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:20:52<3:50:03, 97.20s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:22:25<3:45:47, 96.08s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:25:11<4:32:44, 116.89s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:26:49<4:17:54, 111.32s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:28:27<4:06:49, 107.31s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:30:03<3:57:36, 104.06s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:31:35<3:47:02, 100.17s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:33:13<3:44:05, 99.59s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:34:51<3:41:10, 99.03s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:36:29<3:39:09, 98.87s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:38:08<3:37:33, 98.89s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:39:41<3:32:15, 97.22s/it]
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(TaskRunner pid=2450305)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:42:45<4:27:00, 123.24s/it]
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:44:25<4:09:57, 116.26s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:46:07<3:58:33, 111.83s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:47:48<3:49:58, 108.65s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:49:28<3:42:28, 105.94s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:51:05<3:35:28, 103.43s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:52:40<3:28:34, 100.92s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:54:19<3:25:32, 100.27s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:55:55<3:21:13, 98.96s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:57:41<3:23:44, 101.03s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:00:27<4:01:09, 120.58s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:02:07<3:46:53, 114.40s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:03:47<3:36:42, 110.19s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:05:25<3:27:19, 106.32s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:07:02<3:20:26, 103.68s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-16 01:04:47,508:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:08:42<3:16:37, 102.58s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:10:16<3:09:51, 99.92s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:11:49<3:04:13, 97.82s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:13:28<3:03:38, 98.38s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:15:02<2:59:33, 97.06s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:17:51<3:37:23, 118.57s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:19:29<3:24:19, 112.47s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:21:10<3:15:55, 108.85s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:22:49<3:08:46, 105.85s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:24:23<3:00:54, 102.40s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:26:00<2:56:08, 100.65s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:27:35<2:51:46, 99.11s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:29:12<2:49:14, 98.59s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:30:48<2:45:59, 97.65s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:32:22<2:42:24, 96.48s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:35:08<3:15:31, 117.31s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:36:44<3:03:18, 111.10s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:38:22<2:55:01, 107.16s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:40:01<2:49:25, 104.80s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:41:51<2:49:46, 106.11s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:43:26<2:42:52, 102.87s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:45:01<2:37:36, 100.60s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:46:42<2:35:59, 100.64s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-16 01:44:29,315:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:48:23<2:34:17, 100.62s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:50:02<2:32:13, 100.37s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:52:50<3:00:42, 120.47s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:54:27<2:48:35, 113.66s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:56:01<2:37:42, 107.53s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [11:57:33<2:29:07, 102.85s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [11:59:06<2:23:19, 99.99s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:00:47<2:22:07, 100.32s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:02:18<2:16:44, 97.68s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:03:53<2:13:56, 96.83s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:05:30<2:12:16, 96.79s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:07:06<2:10:16, 96.50s/it]
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(TaskRunner pid=2450305)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:10:06<2:42:08, 121.61s/it]
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:11:44<2:30:37, 114.40s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:13:24<2:23:07, 110.10s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:15:03<2:17:07, 106.86s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:16:39<2:11:16, 103.64s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:18:12<2:05:31, 100.42s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:19:50<2:03:04, 99.79s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:21:31<2:01:34, 99.92s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:23:10<1:59:39, 99.71s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:24:45<1:56:28, 98.42s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:27:34<2:19:28, 119.55s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:29:11<2:09:49, 112.90s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:30:47<2:01:58, 107.63s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:32:22<1:56:10, 104.04s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:34:01<1:52:31, 102.29s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:35:33<1:47:41, 99.41s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:37:09<1:44:46, 98.22s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:38:48<1:43:33, 98.63s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:40:24<1:41:08, 97.87s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:42:01<1:39:01, 97.41s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-16 02:41:20,031:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:44:55<2:00:18, 120.31s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:46:31<1:51:24, 113.30s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:48:16<1:46:55, 110.61s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:49:52<1:41:04, 106.39s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:51:31<1:37:09, 104.10s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:53:10<1:34:01, 102.57s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:54:47<1:30:40, 100.76s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [12:56:25<1:28:25, 100.10s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [12:58:08<1:27:25, 100.88s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [12:59:50<1:26:07, 101.32s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-16 02:57:35,090:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-16 02:57:41,129:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:02:46<1:42:59, 123.59s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:04:21<1:34:02, 115.15s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:05:55<1:27:05, 108.86s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:07:40<1:24:19, 107.65s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:09:17<1:20:06, 104.50s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:10:55<1:16:47, 102.38s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:12:31<1:13:44, 100.57s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:14:06<1:10:45, 98.74s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:15:41<1:08:28, 97.83s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:17:20<1:07:00, 98.05s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:20:03<1:18:25, 117.64s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:21:41<1:12:29, 111.53s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:23:22<1:08:40, 108.43s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:24:59<1:04:52, 105.19s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:26:36<1:01:29, 102.48s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:28:14<59:07, 101.36s/it]  
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-16 03:25:59,911:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:29:54<57:05, 100.75s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:31:28<54:22, 98.87s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:33:00<51:41, 96.91s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:34:40<50:31, 97.78s/it]
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(TaskRunner pid=2450305)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:37:42<1:01:32, 123.09s/it]
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2450305)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:39:22<56:05, 116.05s/it]  
[36m(TaskRunner pid=2450305)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:40:57<51:08, 109.59s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:42:35<47:52, 106.37s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:44:13<44:54, 103.65s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:45:46<41:53, 100.54s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:47:23<39:45, 99.40s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:49:05<38:28, 100.39s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:50:44<36:36, 99.86s/it] 
[36m(TaskRunner pid=2450305)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:52:20<34:32, 98.71s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [13:55:12<40:15, 120.77s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [13:56:53<36:20, 114.76s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [13:58:31<32:53, 109.64s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-16 03:56:20,118:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:00:13<30:27, 107.49s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:01:53<28:01, 105.07s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:03:34<25:58, 103.88s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:05:15<24:02, 103.05s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:06:54<22:05, 101.97s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:08:35<20:18, 101.51s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:10:12<18:22, 100.27s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-16 04:09:37,258:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:13:12<20:42, 124.23s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:14:52<17:31, 116.78s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:16:33<14:57, 112.17s/it]
[36m(TaskRunner pid=2450305)[0m WARNING:2025-11-16 04:14:21,229:Timeout during comparison
[36m(TaskRunner pid=2450305)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:18:18<12:49, 109.91s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:19:57<10:40, 106.69s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:21:31<08:34, 102.84s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:23:10<06:46, 101.72s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:24:48<05:01, 100.50s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:26:31<03:23, 101.50s/it]
[36m(TaskRunner pid=2450305)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:28:18<01:43, 103.08s/it]
[36m(WorkerDict pid=2453859)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2453859)[0m   warnings.warn(
[36m(TaskRunner pid=2450305)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:31:27<01:49, 109.16s/it]
[36m(WorkerDict pid=2454036)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2454036)[0m   warnings.warn([32m [repeated 3x across cluster][0m
