The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a1/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a1//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a1//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a1//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a1/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-19 15:44:43,538	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=3130250)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 15:45:02,498:Waiting for register center actor aP3YIs_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=3134088)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3134088)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=3134088)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=3133874)[0m [rank0]:[W1219 15:45:19.316920467 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=3133874)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3133874)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3133874)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3133874)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m [rank2]:[W1219 15:45:20.552449108 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134088)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=3133874)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3134088)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3134088)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3134088)[0m   warnings.warn(
[36m(WorkerDict pid=3134090)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=3130250)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3130250)[0m /scratch/gautschi/alochab/E3-RL4LLMs/verl/verl/trainer/ppo/core_algos.py:744: RuntimeWarning: divide by zero encountered in log
[36m(TaskRunner pid=3130250)[0m   print(f"    Entropy H(q):   {Hq.item():.4f} (Max possible: {np.log(corr_mask.sum().item()):.4f})")
[36m(TaskRunner pid=3130250)[0m Training Progress:   0%|          | 1/480 [02:04<16:37:18, 124.92s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   0%|          | 2/480 [04:07<16:24:05, 123.53s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   1%|          | 3/480 [06:15<16:39:15, 125.69s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   1%|          | 4/480 [08:22<16:41:39, 126.26s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   1%|          | 5/480 [10:28<16:38:31, 126.13s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   1%|â–         | 6/480 [12:35<16:36:51, 126.19s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   1%|â–         | 7/480 [14:42<16:38:54, 126.71s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   2%|â–         | 8/480 [16:49<16:35:28, 126.54s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   2%|â–         | 9/480 [18:54<16:30:47, 126.22s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   2%|â–         | 10/480 [22:18<19:36:59, 150.25s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   2%|â–         | 11/480 [24:18<18:21:47, 140.95s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   2%|â–Ž         | 12/480 [26:19<17:32:26, 134.93s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   3%|â–Ž         | 13/480 [28:18<16:51:55, 130.01s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   3%|â–Ž         | 14/480 [30:22<16:35:28, 128.17s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   3%|â–Ž         | 15/480 [32:23<16:17:36, 126.14s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   3%|â–Ž         | 16/480 [34:27<16:09:30, 125.37s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   4%|â–Ž         | 17/480 [36:30<16:02:14, 124.70s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   4%|â–         | 18/480 [38:31<15:50:50, 123.49s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   4%|â–         | 19/480 [40:31<15:42:32, 122.67s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   4%|â–         | 20/480 [43:58<18:54:25, 147.97s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   4%|â–         | 21/480 [46:02<17:56:07, 140.67s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   5%|â–         | 22/480 [48:02<17:05:45, 134.38s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   5%|â–         | 23/480 [50:03<16:33:10, 130.40s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   5%|â–Œ         | 24/480 [52:07<16:17:00, 128.55s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   5%|â–Œ         | 25/480 [54:04<15:49:03, 125.15s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   5%|â–Œ         | 26/480 [56:04<15:34:38, 123.52s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   6%|â–Œ         | 27/480 [58:05<15:28:05, 122.93s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   6%|â–Œ         | 28/480 [1:00:02<15:11:03, 120.94s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   6%|â–Œ         | 29/480 [1:02:07<15:19:25, 122.32s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   6%|â–‹         | 30/480 [1:05:17<17:48:50, 142.51s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   6%|â–‹         | 31/480 [1:07:06<16:30:53, 132.41s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   7%|â–‹         | 32/480 [1:08:57<15:41:04, 126.04s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   7%|â–‹         | 33/480 [1:11:02<15:36:40, 125.73s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   7%|â–‹         | 34/480 [1:13:02<15:22:30, 124.10s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   7%|â–‹         | 35/480 [1:14:58<15:02:44, 121.72s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   8%|â–Š         | 36/480 [1:16:52<14:42:14, 119.22s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   8%|â–Š         | 37/480 [1:18:51<14:40:01, 119.19s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   8%|â–Š         | 38/480 [1:20:51<14:39:39, 119.41s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   8%|â–Š         | 39/480 [1:22:41<14:17:51, 116.72s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   8%|â–Š         | 40/480 [1:25:54<17:03:33, 139.58s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   9%|â–Š         | 41/480 [1:27:47<16:02:58, 131.61s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   9%|â–‰         | 42/480 [1:29:42<15:22:48, 126.41s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   9%|â–‰         | 43/480 [1:31:29<14:39:10, 120.71s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   9%|â–‰         | 44/480 [1:33:20<14:15:44, 117.76s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:   9%|â–‰         | 45/480 [1:35:09<13:55:59, 115.31s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  10%|â–‰         | 46/480 [1:37:04<13:51:57, 115.02s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  10%|â–‰         | 47/480 [1:38:57<13:46:17, 114.50s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:40:54<13:49:53, 115.26s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:42:51<13:51:17, 115.73s/it]
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3133874)[0m   warnings.warn(
[36m(TaskRunner pid=3130250)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:46:09<16:47:20, 140.56s/it]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3130250)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:47:57<15:34:56, 130.76s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:49:55<15:05:03, 126.88s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:51:40<14:15:43, 120.24s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:53:29<13:50:18, 116.94s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:55:19<13:32:41, 114.73s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:57:05<13:13:35, 112.30s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:58:56<13:09:26, 111.98s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [2:00:44<12:57:45, 110.58s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 17:49:22,250:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 17:49:27,350:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:02:43<13:15:02, 113.31s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:05:37<15:18:57, 131.28s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:07:30<14:39:01, 125.87s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:09:15<13:52:26, 119.49s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:11:00<13:20:44, 115.21s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:12:56<13:21:45, 115.64s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:14:46<13:06:25, 113.70s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:16:39<13:04:12, 113.65s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:18:31<12:58:58, 113.17s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:20:22<12:52:24, 112.49s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:22:10<12:41:29, 111.17s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:25:10<14:59:58, 131.70s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:27:02<14:17:38, 125.82s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:28:51<13:41:32, 120.81s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:30:39<13:14:13, 117.09s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:32:32<13:03:02, 115.72s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:34:17<12:39:46, 112.56s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:36:11<12:41:28, 113.09s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:38:00<12:30:11, 111.69s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 18:26:39,112:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:40:00<12:45:14, 114.21s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:41:57<12:49:03, 115.07s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:44:54<14:51:31, 133.73s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:46:45<14:03:56, 126.91s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:48:40<13:38:00, 123.32s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:50:33<13:14:03, 120.01s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:52:24<12:54:47, 117.39s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:54:12<12:34:37, 114.63s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:55:59<12:18:39, 112.49s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:57:55<12:22:51, 113.41s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:59:49<12:22:45, 113.69s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [3:01:35<12:04:20, 111.15s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:04:32<14:12:18, 131.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:06:17<13:19:32, 123.32s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:08:02<12:40:06, 117.54s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:09:54<12:27:50, 115.95s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 18:58:30,536:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:11:53<12:32:51, 117.02s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:13:40<12:10:56, 113.91s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:15:34<12:08:58, 113.90s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:17:14<11:40:03, 109.67s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:18:55<11:22:10, 107.15s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:20:48<11:32:14, 109.01s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 19:09:21,690:Timeout during comparison
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3133874)[0m   warnings.warn(
[36m(WorkerDict pid=3133874)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3133874)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=3130250)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:24:07<14:20:12, 135.82s/it]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3130250)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:25:53<13:23:02, 127.13s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 19:14:30,949:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:27:47<12:54:44, 122.98s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:29:33<12:20:58, 117.93s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:31:15<11:49:38, 113.24s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:33:02<11:35:27, 111.27s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:34:40<11:09:00, 107.33s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:36:28<11:09:10, 107.64s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:38:11<10:57:30, 106.05s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:40:05<11:11:30, 108.60s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:43:03<13:17:56, 129.40s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:44:51<12:35:49, 122.90s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:46:27<11:45:11, 114.98s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 19:35:01,586:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:48:20<11:38:17, 114.16s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 19:36:55,499:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:50:13<11:35:39, 114.04s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:51:51<11:02:46, 108.95s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:53:28<10:40:02, 105.50s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:55:13<10:36:34, 105.22s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:57:03<10:44:07, 106.76s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:58:43<10:30:27, 104.78s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 19:47:17,997:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [4:01:47<12:51:48, 128.63s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:03:29<12:01:16, 120.55s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:05:18<11:38:45, 117.11s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 19:53:54,530:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:07:10<11:27:49, 115.60s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:09:11<11:34:32, 117.06s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:10:57<11:13:57, 113.91s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:12:43<10:58:13, 111.56s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:14:27<10:43:12, 109.33s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:16:10<10:30:25, 107.46s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:17:54<10:21:37, 106.26s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:20:48<12:19:11, 126.72s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:22:33<11:39:12, 120.21s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 20:11:04,079:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:24:20<11:12:58, 116.03s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:26:03<10:48:40, 112.16s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:27:44<10:27:45, 108.86s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:29:27<10:15:56, 107.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:31:10<10:07:44, 106.00s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:32:48<9:51:56, 103.55s/it] 
[36m(TaskRunner pid=3130250)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:34:34<9:53:26, 104.11s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:36:18<9:51:20, 104.05s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:39:07<11:40:04, 123.54s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:40:47<10:59:08, 116.66s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:42:23<10:22:27, 110.50s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:44:07<10:08:28, 108.33s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:45:42<9:44:56, 104.45s/it] 
[36m(TaskRunner pid=3130250)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:47:26<9:42:49, 104.39s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:49:02<9:26:40, 101.80s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:50:38<9:15:18, 100.06s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:52:16<9:10:46, 99.54s/it] 
[36m(TaskRunner pid=3130250)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:54:05<9:24:59, 102.42s/it]
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3133874)[0m   warnings.warn(
[36m(TaskRunner pid=3130250)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:57:14<11:46:06, 128.38s/it]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3130250)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:58:59<11:04:02, 121.10s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [5:00:44<10:36:50, 116.49s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [5:02:21<10:01:52, 110.43s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [5:04:04<9:49:06, 108.43s/it] 
[36m(TaskRunner pid=3130250)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:05:47<9:37:24, 106.60s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:07:21<9:16:22, 103.03s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:09:02<9:11:13, 102.39s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:10:46<9:12:25, 102.94s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:12:27<9:06:04, 102.07s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:15:17<10:54:10, 122.66s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:17:04<10:26:34, 117.85s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:18:49<10:04:48, 114.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:20:26<9:35:31, 108.93s/it] 
[36m(TaskRunner pid=3130250)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:22:03<9:14:19, 105.25s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:23:39<8:58:02, 102.49s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:25:23<8:59:04, 103.01s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:27:03<8:52:49, 102.14s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:28:47<8:53:14, 102.55s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:30:24<8:43:50, 101.06s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:33:15<10:30:16, 121.99s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:34:52<9:49:30, 114.47s/it] 
[36m(TaskRunner pid=3130250)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:36:33<9:26:24, 110.34s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:38:11<9:05:51, 106.68s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:39:51<8:54:37, 104.83s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:41:40<8:58:04, 105.85s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:43:21<8:49:38, 104.54s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:44:59<8:38:20, 102.64s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:46:45<8:40:50, 103.48s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:48:28<8:39:14, 103.50s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:51:22<10:23:08, 124.63s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:53:07<9:51:16, 118.65s/it] 
[36m(TaskRunner pid=3130250)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:54:46<9:19:38, 112.68s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:56:31<9:07:04, 110.52s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:58:13<8:52:08, 107.87s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [6:00:06<8:58:22, 109.50s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [6:01:49<8:46:54, 107.53s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 21:50:22,559:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:03:34<8:40:50, 106.66s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:05:18<8:35:01, 105.83s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:07:02<8:31:02, 105.37s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:09:54<10:05:43, 125.32s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:11:34<9:26:57, 117.71s/it] 
[36m(TaskRunner pid=3130250)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:13:18<9:05:03, 113.55s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:15:00<8:47:54, 110.36s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:16:43<8:35:03, 108.05s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:18:23<8:21:11, 105.51s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:20:08<8:19:39, 105.56s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:21:46<8:06:04, 103.05s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:23:27<8:01:50, 102.52s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:25:06<7:56:01, 101.64s/it]
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3133874)[0m   warnings.warn(
[36m(TaskRunner pid=3130250)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:28:17<9:58:51, 128.33s/it]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3130250)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:29:57<9:17:37, 119.92s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:31:38<8:48:52, 114.15s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:33:19<8:28:23, 110.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:35:04<8:20:28, 108.80s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:36:44<8:06:02, 106.04s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:38:31<8:06:00, 106.42s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:40:25<8:13:25, 108.44s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:42:07<8:02:51, 106.51s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:43:45<7:49:47, 104.01s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:46:49<9:35:47, 127.95s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:48:31<8:58:42, 120.16s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:50:13<8:32:55, 114.84s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:52:01<8:22:35, 112.94s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:53:45<8:08:25, 110.17s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:55:24<7:52:13, 106.92s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:57:04<7:41:14, 104.83s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:58:46<7:34:48, 103.76s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [7:00:26<7:28:02, 102.60s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [7:02:17<7:37:42, 105.22s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:05:11<9:05:31, 125.89s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:06:50<8:28:33, 117.81s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:08:35<8:10:22, 114.04s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:10:12<7:46:17, 108.86s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:12:01<7:44:10, 108.79s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:13:45<7:36:09, 107.33s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:15:25<7:25:19, 105.19s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-19 23:03:57,153:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:17:13<7:27:58, 106.24s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:18:57<7:23:12, 105.53s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:20:40<7:17:51, 104.67s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:23:30<8:38:15, 124.38s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:25:11<8:06:58, 117.34s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:26:55<7:47:58, 113.22s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:28:35<7:29:47, 109.26s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:30:11<7:12:08, 105.40s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:31:49<7:01:05, 103.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:33:27<6:52:51, 101.52s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:35:08<6:50:53, 101.46s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:37:00<7:01:55, 104.61s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:38:41<6:56:11, 103.61s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:41:39<8:23:02, 125.76s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:43:35<8:08:51, 122.72s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:45:19<7:45:07, 117.26s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:47:03<7:27:33, 113.31s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:48:44<7:11:34, 109.72s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:50:29<7:03:51, 108.22s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:52:10<6:53:43, 106.08s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:53:54<6:49:17, 105.40s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:55:38<6:45:55, 104.98s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:57:25<6:46:16, 105.52s/it]
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3133874)[0m   warnings.warn(
[36m(TaskRunner pid=3130250)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [8:00:39<8:26:29, 132.13s/it]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3130250)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [8:02:17<7:45:36, 121.99s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:03:59<7:20:12, 115.84s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:05:39<7:00:46, 111.22s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:07:19<6:46:22, 107.89s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:08:59<6:34:44, 105.26s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:10:44<6:33:30, 105.40s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:12:27<6:28:27, 104.52s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:14:13<6:28:05, 104.89s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:15:52<6:20:15, 103.24s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:18:47<7:38:02, 124.92s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:20:32<7:13:16, 118.71s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:22:23<7:03:30, 116.56s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:24:09<6:49:36, 113.26s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:26:01<6:47:00, 113.06s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:27:41<6:30:23, 108.95s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:29:28<6:26:33, 108.38s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:31:10<6:18:11, 106.53s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:32:50<6:09:30, 104.58s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:34:33<6:06:31, 104.23s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 00:23:05,582:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 00:23:10,607:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:37:38<7:29:05, 128.31s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:39:19<6:58:22, 120.11s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:40:59<6:35:18, 114.03s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:42:37<6:17:13, 109.34s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:44:22<6:11:15, 108.13s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:46:04<6:02:35, 106.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:47:45<5:56:01, 104.71s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:49:31<5:55:38, 105.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:51:13<5:49:54, 103.93s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:52:56<5:47:42, 103.79s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:55:51<6:57:03, 125.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:57:24<6:23:14, 115.55s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:59:03<6:05:06, 110.64s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [9:00:45<5:54:31, 107.97s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [9:02:30<5:49:45, 107.07s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:04:15<5:46:14, 106.53s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:05:58<5:40:25, 105.28s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:07:39<5:34:27, 103.98s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:09:21<5:31:21, 103.55s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:10:59<5:24:11, 101.84s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:13:56<6:33:44, 124.34s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:15:36<6:08:57, 117.13s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:17:14<5:49:04, 111.41s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:18:56<5:38:38, 108.65s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:20:41<5:32:36, 107.30s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:22:24<5:27:39, 106.27s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:24:11<5:25:53, 106.27s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:25:52<5:19:46, 104.85s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:27:38<5:18:39, 105.05s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:29:19<5:13:29, 103.92s/it]
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3133874)[0m   warnings.warn(
[36m(TaskRunner pid=3130250)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:32:30<6:29:46, 129.92s/it]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3130250)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:34:12<6:03:14, 121.76s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:35:51<5:40:48, 114.88s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:37:34<5:27:59, 111.18s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:39:15<5:17:38, 108.29s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:40:52<5:05:21, 104.70s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:42:33<5:00:45, 103.71s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:44:08<4:51:22, 101.05s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:45:46<4:47:33, 100.31s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:47:32<4:50:19, 101.87s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:50:29<5:52:09, 124.29s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:52:06<5:27:27, 116.26s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:53:49<5:14:34, 112.35s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:55:27<5:00:28, 107.95s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:57:11<4:55:07, 106.67s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:58:59<4:54:40, 107.16s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [10:00:52<4:58:02, 109.04s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 01:49:20,221:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [10:02:32<4:48:16, 106.11s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [10:04:12<4:41:59, 104.44s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 01:52:42,810:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 01:52:49,131:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:06:06<4:47:37, 107.19s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:09:02<5:41:13, 127.96s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:10:44<5:18:16, 120.10s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 01:59:14,631:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 01:59:19,666:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 01:59:24,680:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:12:39<5:12:01, 118.49s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:14:16<4:53:07, 112.02s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:16:01<4:46:24, 110.15s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:17:41<4:36:13, 106.93s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:19:24<4:31:42, 105.86s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:21:06<4:26:36, 104.56s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:22:52<4:26:25, 105.17s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:24:29<4:17:54, 102.48s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:27:23<5:10:20, 124.14s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:29:02<4:49:20, 116.51s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:30:39<4:32:51, 110.62s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:32:25<4:27:47, 109.30s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:34:03<4:17:33, 105.85s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:35:44<4:12:30, 104.49s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:37:25<4:08:01, 103.35s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:39:04<4:03:22, 102.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:40:43<3:59:28, 101.19s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:42:22<3:56:29, 100.63s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:45:16<4:45:44, 122.46s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:47:06<4:35:11, 118.79s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:48:47<4:20:38, 113.32s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:50:28<4:10:27, 109.69s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:52:03<3:58:36, 105.27s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:53:46<3:55:16, 104.56s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:55:28<3:52:03, 103.91s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:57:11<3:49:29, 103.53s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:58:51<3:45:26, 102.47s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [11:00:29<3:41:03, 101.25s/it]
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3133874)[0m   warnings.warn(
[36m(TaskRunner pid=3130250)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [11:03:48<4:42:54, 130.58s/it]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3130250)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:05:34<4:24:55, 123.22s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:07:21<4:12:19, 118.28s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:09:02<3:59:11, 113.01s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:10:53<3:56:08, 112.45s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:12:34<3:47:15, 109.08s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:14:09<3:36:55, 104.96s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:15:54<3:34:44, 104.75s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:17:35<3:31:03, 103.80s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:19:22<3:31:09, 104.71s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:22:10<4:07:14, 123.62s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:23:59<3:56:55, 119.46s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:25:44<3:45:59, 114.91s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:27:29<3:38:09, 111.87s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:29:06<3:27:46, 107.47s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:30:41<3:18:52, 103.76s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:32:19<3:13:54, 102.05s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:33:53<3:07:27, 99.54s/it] 
[36m(TaskRunner pid=3130250)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:35:32<3:05:55, 99.60s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 03:23:58,939:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 03:24:04,025:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:37:18<3:07:52, 101.55s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:40:11<3:45:05, 122.78s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:41:54<3:32:17, 116.86s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:43:35<3:21:48, 112.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:45:21<3:16:39, 110.28s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:46:55<3:06:13, 105.41s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:48:38<3:03:06, 104.64s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:50:16<2:57:58, 102.68s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:51:57<2:55:21, 102.15s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:53:34<2:51:16, 100.75s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:55:15<2:49:30, 100.70s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:58:07<3:23:44, 122.25s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:59:50<3:12:02, 116.38s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 03:48:21,661:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 03:48:26,694:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [12:01:44<3:08:54, 115.66s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [12:03:29<3:01:51, 112.49s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 03:52:04,963:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [12:05:27<3:02:29, 114.06s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:07:08<2:54:21, 110.12s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:08:51<2:49:28, 108.18s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:10:36<2:45:53, 107.03s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:12:17<2:41:38, 105.42s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:14:04<2:40:28, 105.81s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:17:01<3:10:30, 127.00s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:18:44<2:57:49, 119.88s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:20:23<2:46:41, 113.65s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:22:03<2:38:45, 109.49s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:23:47<2:34:49, 108.02s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:25:39<2:34:26, 109.02s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:27:18<2:28:21, 105.97s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:29:01<2:25:20, 105.06s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:30:43<2:22:35, 104.34s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:32:27<2:20:30, 104.08s/it]
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3133874)[0m   warnings.warn(
[36m(TaskRunner pid=3130250)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:35:42<2:55:23, 131.54s/it]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3130250)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:37:29<2:43:27, 124.15s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:39:19<2:35:42, 119.78s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:41:02<2:27:27, 114.90s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:42:43<2:19:59, 110.52s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:44:24<2:14:55, 107.94s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:46:12<2:12:50, 107.71s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:48:01<2:11:28, 108.06s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:49:45<2:08:31, 107.11s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:51:30<2:05:47, 106.30s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:54:29<2:29:29, 128.14s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:56:13<2:19:13, 121.06s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:57:55<2:10:38, 115.27s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:59:37<2:04:15, 111.28s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [13:01:24<2:00:46, 109.79s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [13:02:59<1:54:23, 105.60s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [13:04:41<1:51:21, 104.40s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [13:06:29<1:50:39, 105.39s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:08:10<1:47:37, 104.15s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 04:56:44,441:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:10:00<1:47:37, 105.87s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:12:59<2:07:58, 127.98s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:14:41<1:57:57, 119.96s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:16:31<1:53:08, 117.04s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:18:12<1:46:39, 112.27s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:19:55<1:42:18, 109.61s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 05:08:30,047:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:21:46<1:40:38, 109.80s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:23:30<1:37:19, 108.14s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:25:14<1:34:35, 107.08s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:27:02<1:32:53, 107.18s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:28:45<1:30:06, 106.01s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:31:38<1:45:04, 126.09s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:33:18<1:36:30, 118.18s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:34:59<1:30:33, 113.19s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:36:52<1:28:34, 113.08s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:38:35<1:24:24, 110.09s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:40:20<1:21:17, 108.38s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:42:07<1:19:11, 108.00s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:43:49<1:16:10, 106.29s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:45:35<1:14:24, 106.29s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:47:19<1:12:03, 105.46s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 05:35:52,833:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:50:21<1:25:35, 128.39s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:52:03<1:18:25, 120.65s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:53:48<1:13:21, 115.83s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:55:30<1:08:49, 111.60s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:57:14<1:05:38, 109.39s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:58:57<1:02:37, 107.36s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [14:00:41<1:00:19, 106.47s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [14:02:20<57:15, 104.10s/it]  
[36m(TaskRunner pid=3130250)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [14:04:00<54:56, 103.01s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [14:05:46<53:41, 103.91s/it]
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3133874)[0m   warnings.warn(
[36m(TaskRunner pid=3130250)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:08:56<1:04:53, 129.77s/it]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3130250)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:10:39<58:47, 121.65s/it]  
[36m(TaskRunner pid=3130250)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:12:15<53:09, 113.92s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:13:59<49:58, 111.07s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:15:42<47:06, 108.70s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:17:19<43:49, 105.17s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:19:00<41:29, 103.72s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:20:49<40:25, 105.47s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:22:34<38:38, 105.40s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:24:17<36:38, 104.68s/it]
[36m(TaskRunner pid=3130250)[0m WARNING:2025-12-20 06:14:26,575:Timeout during comparison
[36m(TaskRunner pid=3130250)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:27:19<42:37, 127.88s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:29:07<38:34, 121.81s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:30:46<34:28, 114.91s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:32:25<31:12, 110.16s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:34:07<28:45, 107.82s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:35:51<26:38, 106.54s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:37:36<24:47, 106.28s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:39:18<22:41, 104.72s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:40:58<20:40, 103.36s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:42:39<18:49, 102.64s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:45:40<21:02, 126.21s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:47:23<17:52, 119.17s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:49:07<15:18, 114.75s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:50:55<13:09, 112.76s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:52:37<10:56, 109.36s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:54:13<08:47, 105.45s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:55:58<07:00, 105.20s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:57:36<05:09, 103.07s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:59:21<03:27, 103.73s/it]
[36m(TaskRunner pid=3130250)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:01:13<01:46, 106.07s/it]
[36m(WorkerDict pid=3133874)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3133874)[0m   warnings.warn(
[36m(TaskRunner pid=3130250)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:04:28<01:53, 113.29s/it]
[36m(WorkerDict pid=3134090)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3134090)[0m   warnings.warn([32m [repeated 3x across cluster][0m
