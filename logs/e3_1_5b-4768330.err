
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_0.00005/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_0.00005//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.00005//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.00005//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_0.00005/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-13 16:04:14,784	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=3919966)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 16:04:35,284:Waiting for register center actor tZhsCa_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=3923721)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=3923518)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=3923518)[0m [rank0]:[W1113 16:04:52.708776351 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=3923721)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3923721)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3923518)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m [rank3]:[W1113 16:04:53.941246796 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923518)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=3923722)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3923518)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3923518)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(WorkerDict pid=3923721)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=3923720)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923720)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:   0%|          | 1/480 [01:57<15:39:43, 117.71s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   0%|          | 2/480 [03:57<15:45:27, 118.68s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   1%|          | 3/480 [05:58<15:54:58, 120.12s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   1%|          | 4/480 [07:54<15:39:48, 118.46s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   1%|          | 5/480 [09:53<15:38:02, 118.49s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   1%|â–         | 6/480 [11:53<15:41:43, 119.21s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   1%|â–         | 7/480 [13:55<15:45:55, 119.99s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 16:22:16,327:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:   2%|â–         | 8/480 [16:00<15:55:48, 121.50s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   2%|â–         | 9/480 [17:58<15:46:43, 120.60s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   2%|â–         | 10/480 [21:20<19:01:18, 145.70s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   2%|â–         | 11/480 [23:17<17:49:46, 136.86s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   2%|â–Ž         | 12/480 [25:15<17:01:50, 131.01s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   3%|â–Ž         | 13/480 [27:13<16:29:19, 127.11s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   3%|â–Ž         | 14/480 [29:13<16:11:35, 125.10s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   3%|â–Ž         | 15/480 [31:09<15:46:50, 122.17s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   3%|â–Ž         | 16/480 [33:06<15:32:32, 120.59s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   4%|â–Ž         | 17/480 [35:05<15:27:18, 120.17s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   4%|â–         | 18/480 [37:08<15:31:53, 121.03s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   4%|â–         | 19/480 [39:14<15:40:46, 122.44s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   4%|â–         | 20/480 [42:41<18:53:58, 147.91s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   4%|â–         | 21/480 [44:41<17:48:24, 139.66s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   5%|â–         | 22/480 [46:41<17:01:24, 133.81s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   5%|â–         | 23/480 [48:39<16:22:16, 128.96s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   5%|â–Œ         | 24/480 [50:35<15:49:48, 124.98s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   5%|â–Œ         | 25/480 [52:29<15:23:22, 121.76s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   5%|â–Œ         | 26/480 [54:32<15:23:42, 122.08s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   6%|â–Œ         | 27/480 [56:37<15:28:19, 122.96s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   6%|â–Œ         | 28/480 [58:28<15:00:07, 119.49s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:25<14:51:50, 118.65s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:34<17:28:32, 139.81s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:19<16:08:41, 129.45s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:05<15:12:39, 122.23s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:00<14:55:44, 120.23s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:52<14:35:15, 117.75s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:43<14:17:52, 115.67s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:33<14:02:27, 113.85s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:24<13:53:45, 112.92s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:19<13:57:56, 113.75s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:07<13:43:32, 112.05s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:15<16:27:12, 134.62s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:03<15:28:29, 126.90s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   9%|â–‰         | 42/480 [1:26:56<14:55:35, 122.68s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:44<14:21:21, 118.27s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:32<13:57:32, 115.26s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:15<13:28:21, 111.50s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:06<13:25:18, 111.33s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:54<13:14:54, 110.15s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:43<13:11:43, 109.96s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:36<13:17:03, 110.96s/it]
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(TaskRunner pid=3919966)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:42:53<16:20:16, 136.78s/it]
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:40<15:13:50, 127.81s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:28<14:29:24, 121.88s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:13<13:51:00, 116.77s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:02<13:31:35, 114.31s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:51:46<13:07:23, 111.16s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:32<12:55:14, 109.70s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:19<12:47:21, 108.84s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:02<12:32:50, 107.04s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 18:05:11,227:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 18:05:18,002:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:58:55<12:44:35, 108.97s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:01:48<14:57:22, 128.20s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:03:36<14:12:19, 122.05s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:20<13:32:23, 116.61s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:07:03<13:02:49, 112.64s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:08:53<12:55:53, 111.91s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:10:34<12:31:51, 108.70s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:12:22<12:27:45, 108.37s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:14:04<12:13:27, 106.55s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:15:47<12:02:57, 105.28s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:17:32<12:00:26, 105.17s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 18:27:14,776:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:20:34<14:37:59, 128.49s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:22:17<13:43:43, 120.84s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:23:59<13:02:01, 115.00s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:25:42<12:35:55, 111.44s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:27:28<12:22:35, 109.74s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 18:35:36,607:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:29:14<12:13:26, 108.66s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:31:01<12:08:24, 108.18s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:32:45<11:59:11, 107.08s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:34:29<11:50:19, 106.02s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:36:14<11:45:40, 105.59s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:39:06<13:58:07, 125.72s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:40:49<13:10:24, 118.86s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:42:33<12:39:31, 114.50s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:44:19<12:19:27, 111.76s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:46:02<12:00:47, 109.21s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:47:47<11:49:29, 107.77s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:49:30<11:38:52, 106.43s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:51:14<11:33:19, 105.85s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:53:00<11:32:04, 105.93s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:54:41<11:20:29, 104.42s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:57:35<13:34:41, 125.34s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [2:59:15<12:42:10, 117.56s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 19:07:19,031:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 19:07:24,821:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:01:03<12:20:56, 114.58s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:02:44<11:53:51, 110.68s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 19:10:58,722:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 19:11:03,749:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:04:44<12:09:02, 113.32s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:06:24<11:42:25, 109.47s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:08:09<11:31:15, 108.01s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:09:47<11:10:23, 105.02s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:11:19<10:44:54, 101.29s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:13:06<10:53:56, 102.98s/it]
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(WorkerDict pid=3923518)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3923518)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=3919966)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:16:18<13:41:20, 129.69s/it]
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:17:56<12:39:23, 120.22s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:19:35<11:57:26, 113.88s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:21:15<11:29:22, 109.72s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:22:55<11:08:32, 106.68s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:24:38<10:59:59, 105.60s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:26:15<10:42:08, 103.02s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:28:00<10:43:49, 103.56s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:29:42<10:39:55, 103.21s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:31:33<10:52:35, 105.54s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:34:33<13:08:11, 127.81s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:36:17<12:21:30, 120.57s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:37:52<11:32:42, 112.94s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:39:33<11:09:33, 109.47s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:41:18<10:59:00, 108.03s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:42:49<10:26:46, 103.03s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:44:26<10:13:49, 101.18s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:46:08<10:13:28, 101.40s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:47:48<10:09:05, 100.96s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:49:26<10:01:10, 99.92s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:52:17<12:08:15, 121.38s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:53:52<11:18:47, 113.45s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:55:34<10:57:20, 110.17s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 20:03:39,802:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 20:03:44,837:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:57:22<10:50:20, 109.30s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 20:05:36,487:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [3:59:16<10:57:34, 110.83s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:00:56<10:35:41, 107.44s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:02:33<10:16:03, 104.42s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:04:07<9:56:08, 101.33s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:05:47<9:52:12, 100.95s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:07:25<9:44:39, 99.94s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:10:15<11:45:43, 120.98s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:11:57<11:10:56, 115.35s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:13:31<10:31:31, 108.88s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:15:11<10:14:03, 106.18s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:16:51<10:01:44, 104.35s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:18:33<9:56:00, 103.65s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:20:13<9:48:47, 102.70s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:21:49<9:35:16, 100.63s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:23:29<9:31:45, 100.31s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:25:12<9:34:37, 101.11s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:28:03<11:32:08, 122.14s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:29:43<10:52:40, 115.52s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:31:21<10:21:40, 110.36s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:33:04<10:06:46, 108.03s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:34:43<9:49:38, 105.29s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:36:21<9:36:25, 103.24s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:37:54<9:16:44, 100.01s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:39:28<9:05:32, 98.30s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:41:05<9:02:02, 97.96s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:42:49<9:10:54, 99.86s/it]
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(TaskRunner pid=3919966)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:45:56<11:31:32, 125.73s/it]
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:47:37<10:49:02, 118.37s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:49:17<10:17:59, 113.05s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:51:02<10:02:10, 110.49s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:52:41<9:42:22, 107.19s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:54:19<9:25:46, 104.45s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:55:52<9:04:49, 100.89s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [4:57:28<8:54:59, 99.38s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [4:59:11<8:58:46, 100.39s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:00:53<9:00:17, 100.99s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:03:43<10:48:35, 121.61s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:05:27<10:18:36, 116.35s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:07:08<9:52:46, 111.85s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:08:44<9:25:42, 107.07s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:10:19<9:04:35, 103.40s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:11:55<8:51:20, 101.21s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:13:36<8:50:05, 101.29s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:15:13<8:40:28, 99.77s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:16:49<8:33:22, 98.73s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:18:24<8:25:57, 97.61s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:21:15<10:17:21, 119.49s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:22:51<9:40:21, 112.69s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:24:26<9:11:15, 107.39s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:26:02<8:50:47, 103.74s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:27:34<8:32:25, 100.48s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:29:12<8:26:12, 99.58s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:30:50<8:21:31, 98.99s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:32:24<8:13:30, 97.72s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:34:02<8:12:01, 97.75s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:35:39<8:09:02, 97.48s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:38:31<9:59:43, 119.95s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 21:46:36,694:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 21:46:41,743:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 21:46:47,499:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:40:24<9:47:20, 117.86s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:42:00<9:12:00, 111.14s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:43:37<8:48:58, 106.86s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:45:09<8:25:57, 102.56s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:46:56<8:31:09, 103.96s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:48:33<8:18:52, 101.81s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:50:07<8:05:35, 99.44s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:51:46<8:02:58, 99.24s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:53:25<8:01:18, 99.24s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [5:56:12<9:38:15, 119.64s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [5:57:48<9:01:32, 112.43s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [5:59:22<8:32:27, 106.76s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:00:58<8:15:58, 103.69s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:02:34<8:02:54, 101.31s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:04:10<7:53:47, 99.74s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:05:52<7:54:43, 100.30s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:07:25<7:43:47, 98.33s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:09:04<7:42:27, 98.40s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:10:38<7:35:03, 97.16s/it]
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(TaskRunner pid=3919966)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:13:45<9:39:07, 124.10s/it]
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:15:22<8:59:01, 115.92s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:17:00<8:32:21, 110.58s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:18:39<8:13:48, 106.96s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:20:22<8:07:02, 105.88s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:21:58<7:52:23, 103.07s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:23:40<7:48:53, 102.68s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:25:24<7:48:43, 103.02s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:26:58<7:35:19, 100.44s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:28:35<7:28:01, 99.19s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:31:27<9:05:43, 121.27s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:33:04<8:30:06, 113.78s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:34:42<8:07:41, 109.18s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:36:22<7:53:57, 106.51s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:38:00<7:40:13, 103.81s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:39:35<7:26:49, 101.17s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:41:11<7:17:47, 99.50s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:42:48<7:13:22, 98.87s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:44:23<7:06:08, 97.59s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:46:08<7:14:34, 99.90s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:48:54<8:39:14, 119.83s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:50:29<8:04:52, 112.33s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:52:11<7:49:24, 109.16s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:53:41<7:23:09, 103.46s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [6:55:17<7:12:16, 101.31s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [6:56:53<7:03:51, 99.73s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [6:58:27<6:54:02, 97.80s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:00:08<6:56:45, 98.84s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:01:43<6:51:03, 97.87s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:03:24<6:52:38, 98.64s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:06:07<8:12:04, 118.10s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:07:41<7:38:59, 110.60s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:09:17<7:19:04, 106.23s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:10:51<7:03:01, 102.76s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:12:24<6:49:36, 99.90s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:13:59<6:41:33, 98.34s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:15:32<6:33:22, 96.73s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:17:06<6:28:05, 95.83s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:18:48<6:34:08, 97.72s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:20:24<6:30:08, 97.13s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-13 23:30:01,256:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:23:21<8:05:04, 121.27s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:25:08<7:46:11, 117.04s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:26:46<7:20:52, 111.15s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:28:27<7:06:34, 108.00s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:30:04<6:52:56, 104.98s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:31:43<6:43:38, 103.06s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:33:21<6:35:56, 101.52s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:34:58<6:28:43, 100.10s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:36:35<6:24:11, 99.36s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:38:14<6:21:58, 99.21s/it]
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(TaskRunner pid=3919966)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:41:23<8:03:15, 126.07s/it]
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:42:59<7:27:16, 117.19s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:44:38<7:03:55, 111.56s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:46:14<6:44:52, 107.01s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:47:49<6:29:32, 103.42s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:49:26<6:19:43, 101.26s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:51:06<6:17:03, 101.00s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:52:44<6:12:10, 100.14s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:54:25<6:11:03, 100.29s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [7:55:57<6:00:20, 97.83s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [7:58:44<7:15:10, 118.68s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:00:25<6:53:11, 113.20s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:02:04<6:36:27, 109.12s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:03:47<6:27:30, 107.14s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:05:34<6:25:50, 107.18s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:07:11<6:12:55, 104.07s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:08:49<6:05:10, 102.38s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:10:25<5:56:57, 100.55s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:12:00<5:48:45, 98.70s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:13:38<5:46:38, 98.57s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:16:30<7:02:20, 120.67s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:18:10<6:38:22, 114.36s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:19:45<6:16:38, 108.65s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:21:22<6:02:02, 104.94s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:23:06<5:59:22, 104.67s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:24:44<5:50:53, 102.70s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:26:25<5:47:28, 102.20s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:28:08<5:47:13, 102.63s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:29:47<5:41:42, 101.50s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:31:29<5:39:50, 101.45s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:34:20<6:48:19, 122.50s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:35:52<6:15:28, 113.21s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:37:29<5:57:47, 108.42s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:39:08<5:47:08, 105.73s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:40:49<5:39:50, 104.03s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:42:31<5:36:13, 103.45s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:44:07<5:28:03, 101.46s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:45:45<5:22:26, 100.24s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:47:23<5:18:37, 99.57s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:49:01<5:15:20, 99.06s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:51:57<6:27:21, 122.33s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:53:35<6:01:57, 114.91s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [8:55:13<5:44:16, 109.87s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [8:56:49<5:29:16, 105.65s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [8:58:30<5:23:12, 104.26s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:00:09<5:16:59, 102.81s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:01:53<5:15:55, 103.02s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:03:28<5:06:42, 100.56s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:05:08<5:04:27, 100.37s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:06:43<4:58:43, 99.02s/it] 
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 01:14:53,264:Timeout during comparison
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(TaskRunner pid=3919966)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:09:58<6:23:21, 127.79s/it]
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:11:37<5:55:16, 119.09s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:13:13<5:32:38, 112.12s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:14:51<5:17:59, 107.79s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:16:32<5:10:33, 105.87s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:18:07<4:59:06, 102.55s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:19:45<4:53:40, 101.26s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:21:20<4:46:01, 99.20s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:22:56<4:41:55, 98.35s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:24:35<4:40:52, 98.56s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 01:34:07,452:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:27:27<5:41:38, 120.58s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:29:04<5:19:35, 113.46s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:30:42<5:04:30, 108.75s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:32:18<4:52:50, 105.21s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:33:56<4:45:00, 103.01s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:35:38<4:42:04, 102.57s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:37:22<4:41:22, 102.94s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 01:45:23,767:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 01:45:29,419:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 01:45:35,596:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:39:09<4:43:28, 104.34s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:40:47<4:36:23, 102.37s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:42:24<4:30:27, 100.79s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:45:12<5:22:41, 121.01s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:46:50<5:02:08, 114.02s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:48:24<4:44:02, 107.86s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:49:56<4:30:11, 103.26s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:51:38<4:27:21, 102.83s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [9:53:15<4:21:08, 101.08s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [9:54:52<4:16:01, 99.75s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [9:56:29<4:12:50, 99.16s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [9:58:05<4:08:12, 97.98s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [9:59:37<4:02:27, 96.34s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:02:22<4:52:33, 117.02s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:03:54<4:31:49, 109.46s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:05:26<4:16:40, 104.05s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:07:02<4:09:36, 101.88s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:08:38<4:03:15, 99.97s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:10:10<3:56:08, 97.71s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:11:45<3:51:57, 96.65s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:13:20<3:49:20, 96.22s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:14:57<3:48:30, 96.55s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:16:30<3:44:04, 95.35s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:19:13<4:30:07, 115.77s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:20:51<4:16:00, 110.51s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:22:27<4:04:02, 106.10s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:24:04<3:55:53, 103.31s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:25:34<3:45:15, 99.38s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:27:13<3:43:30, 99.33s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:28:49<3:39:24, 98.24s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:30:26<3:36:54, 97.85s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:32:04<3:35:11, 97.81s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:33:39<3:32:10, 97.18s/it]
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(TaskRunner pid=3919966)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:36:44<4:27:36, 123.51s/it]
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:38:30<4:13:42, 118.00s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:40:15<4:03:49, 114.30s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:42:01<3:56:14, 111.61s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:43:42<3:47:54, 108.53s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:45:24<3:42:14, 106.68s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:47:07<3:38:15, 105.61s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:48:49<3:33:54, 104.35s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:50:36<3:33:51, 105.17s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:52:22<3:32:48, 105.52s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [10:55:19<4:13:52, 126.94s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [10:56:59<3:55:57, 118.97s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [10:58:44<3:45:45, 114.79s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:00:29<3:38:04, 111.83s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:02:10<3:29:45, 108.49s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 03:10:20,702:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:03:57<3:27:14, 108.12s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:05:37<3:20:27, 105.50s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:07:15<3:14:47, 103.43s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:08:59<3:13:05, 103.44s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 03:17:05,304:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:10:41<3:10:42, 103.09s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:13:40<3:50:34, 125.77s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:15:22<3:35:39, 118.71s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:17:06<3:25:51, 114.36s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:18:52<3:19:05, 111.64s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:20:26<3:08:16, 106.57s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:22:07<3:03:19, 104.76s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:23:45<2:58:00, 102.70s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 03:31:51,726:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:25:28<2:56:22, 102.74s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:27:05<2:51:59, 101.17s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:28:42<2:48:10, 99.90s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:31:45<3:27:52, 124.72s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:33:27<3:14:49, 118.07s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:35:12<3:06:11, 114.00s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:36:53<2:58:16, 110.27s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:38:45<2:57:23, 110.87s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:40:24<2:49:54, 107.31s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:42:05<2:44:53, 105.25s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:43:56<2:46:01, 107.11s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:45:42<2:43:37, 106.71s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:47:29<2:41:45, 106.66s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:50:32<3:14:24, 129.61s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:52:17<3:01:23, 122.29s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:53:58<2:49:48, 115.78s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [11:55:46<2:44:46, 113.63s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [11:57:25<2:36:30, 109.19s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [11:59:16<2:35:27, 109.73s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:00:56<2:29:21, 106.69s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:02:35<2:24:32, 104.49s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:04:15<2:20:59, 103.17s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:05:57<2:18:42, 102.75s/it]
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(TaskRunner pid=3919966)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:09:27<2:59:51, 134.89s/it]
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:11:19<2:48:39, 128.10s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:13:07<2:38:35, 121.99s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:14:54<2:30:47, 117.50s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:16:39<2:24:20, 113.95s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:18:19<2:17:08, 109.71s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:20:05<2:13:51, 108.53s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:21:51<2:11:15, 107.89s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:23:46<2:12:00, 110.01s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:25:30<2:07:53, 108.08s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:28:42<2:35:19, 133.14s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:30:26<2:23:06, 124.44s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:32:07<2:13:08, 117.48s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:33:52<2:07:03, 113.78s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:35:40<2:03:08, 111.95s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:37:27<1:59:38, 110.44s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:39:11<1:55:42, 108.48s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:41:02<1:54:55, 109.45s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:42:51<1:52:45, 109.12s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:44:44<1:52:07, 110.29s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:47:58<2:15:26, 135.45s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:49:45<2:04:52, 126.99s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 04:58:02,550:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:51:44<2:00:26, 124.60s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:53:31<1:53:21, 119.33s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:55:20<1:48:32, 116.30s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:57:10<1:44:53, 114.42s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:58:56<1:40:31, 111.69s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:00:56<1:40:49, 114.13s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:02:49<1:38:42, 113.89s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:04:35<1:34:51, 111.60s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:07:46<1:52:50, 135.41s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:09:36<1:44:13, 127.62s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:11:23<1:37:08, 121.43s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:13:20<1:34:09, 120.21s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:15:17<1:31:22, 119.18s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:17:04<1:26:48, 115.75s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:18:53<1:23:15, 113.52s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:20:39<1:19:52, 111.45s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:22:28<1:17:27, 110.66s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:24:17<1:15:17, 110.18s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:27:37<1:31:17, 136.94s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 05:35:46,065:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:29:26<1:23:36, 128.63s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:31:09<1:16:34, 120.92s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:32:50<1:10:51, 114.91s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:34:30<1:06:16, 110.45s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:36:11<1:02:48, 107.67s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:37:47<59:05, 104.27s/it]  
[36m(TaskRunner pid=3919966)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:39:23<55:58, 101.77s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:40:59<53:17, 99.92s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:42:41<51:55, 100.51s/it]
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(TaskRunner pid=3919966)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:45:51<1:03:45, 127.51s/it]
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3919966)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:47:31<57:36, 119.17s/it]  
[36m(TaskRunner pid=3919966)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:49:07<52:18, 112.09s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:50:46<48:47, 108.44s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:52:25<45:40, 105.41s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:53:59<42:29, 101.99s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:55:37<40:18, 100.78s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:57:21<39:02, 101.83s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:59:01<37:07, 101.24s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:00:40<35:12, 100.59s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:03:31<40:32, 121.63s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:05:11<36:28, 115.18s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:06:47<32:48, 109.35s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:08:24<29:59, 105.86s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:10:01<27:31, 103.21s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:11:41<25:31, 102.08s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:13:19<23:34, 101.06s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 06:21:22,907:Timeout during parsing: Alright, so I have this problem here: I need to find the number of functions \( f \) from the set \( \{-1005, \ldots, 1005\} \) to \( \{-2010, \ldots, 2010\} \) that satisfy two conditions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m The first condition is that if \( a < b \) then \( f(a) < f(b) \). So, this means that the function is strictly increasing. That's straightforward enoughâ€”every time the input increases, the output also increases.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m The second condition is trickier: there's no \( n \) in \( \{-1005, \ldots, 1005\} \) such that \( |f(n)| = |n| \). So, for each \( n \), the function value \( |f(n)| \) doesn't equal the absolute value of \( n \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Alright, let's break this down.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m First, let's consider the domains and codomains.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m The function is defined on \( \{-1005, -1004, \ldots, 1004, 1005\} \). That's a total of \( 2011 \) elements because from -1005 to 1005 inclusive is \( (1005 - (-1005)) + 1 = 2011 \) numbers.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m The codomain is \( \{-2010, -2009, \ldots, 0, \ldots, 2009, 2010\} \). The size of this set is \( 2010 - (-2010) + 1 = 4021 \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, that might not be accurate. Let's compute the size correctly.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m From -2010 to 2010 inclusive, the number of integers is \( 2010 - (-2010) + 1 = 4021 \). Yeah, that's correct.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Now, the function \( f \) is strictly increasing, so it's a bijection (one-to-one and onto) onto its image, but the image has to be a subset of the codomain of size at least as big as the domain. Since the domain is 2011 elements, the image needs to have at least 2011 elements.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But the codomain is 4021 elements, which is quite large.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Now, condition two: for no \( n \) is \( |f(n)| = |n| \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, for each \( n \) in the domain, \( |f(n)| \ne |n| \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, for each \( n \), \( f(n) \) cannot be equal to \( n \) or \( -n \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, since \( |f(n)| \ne |n| \), that implies \( f(n) \ne n \) and \( f(n) \ne -n \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But \( n \) is negative or zero or positive.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, but \( f \) is defined on \( \{-1005, ..., 1005\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, for each \( n \) from -1005 to 1005, \( f(n) \) must not equal \( n \) or \( -n \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, \( f(n) \in \{-2010, ..., 2010\} \setminus \{n, -n\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But also, \( f \) is strictly increasing. So, the function is injective (since it's strictly increasing).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Thus, the image of \( f \) is a subset of the codomain of size equal to the domain, which is 2011.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Furthermore, for each \( n \), \( f(n) \) cannot be \( n \) or \( -n \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Therefore, we need to choose a strictly increasing function from the domain to the codomain, avoiding the points \( n \) and \( -n \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hmm.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Perhaps we can model this as a combinatorial problem where we have to choose a strictly increasing sequence with certain restrictions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m First, note that the domain is size 2011. The codomain is size 4021.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But the function needs to be strictly increasing, so the function is determined by choosing 2011 distinct values in increasing order.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Additionally, for each position \( i \) (from 1 to 2011), the value \( f(i) \) is chosen from the codomain such that \( f(i) \ne i \) and \( f(i) \ne -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, but the codomain elements are from -2010 to 2010, so it's a set that includes all integers from -2010 to 2010.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hence, for each \( n \) in the domain, there are \( | \{-2010, ..., 2010\} | - 2 \) choices for \( f(n) \), because we exclude \( n \) and \( -n \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, but for \( n = 0 \), \( |f(0)| \ne |0| \) implies \( |f(0)| \ne 0 \), so \( f(0) \ne 0 \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, for \( n = 0 \), we have to choose from all elements except 0.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m For other \( n \) (non-zero), \( f(n) \) cannot be \( n \) or \( -n \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Is that correct?
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Yes.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, for each \( n \), except when \( n = 0 \), \( f(n) \ne n \) and \( f(n) \ne -n \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But \( f \) is strictly increasing, so it's injective.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, to count the number of such functions, perhaps we can think of this as a permutation with forbidden positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But since it's strictly increasing, it's similar to choosing 2011 elements from the codomain, arranged in order, with the given restrictions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This seems analogous to choosing a subset of size 2011 from a universe of size 4021, avoiding certain elements at specific positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps inclusion-exclusion can be used here.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Alternatively, perhaps model each position as being restricted in some way.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Alternatively, think of the function \( f \) as a strictly increasing sequence \( a_1 < a_2 < \ldots < a_{2011} \) where each \( a_i \ne i \) and \( a_i \ne -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But wait, noâ€”the variables \( a_i \) are values in the codomain.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But each \( a_i \) must satisfy \( a_i \ne i \) and \( a_i \ne -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, but \( a_i \) is in \( \{-2010, \ldots, 2010\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But \( i \) ranges from -1005 to 1005.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, \( a_i \) is being assigned a value, but \( i \) itself is an index.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hence, for each index \( i \), \( f(i) \) must not equal \( i \) or \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, in terms of assignments, each position \( i \) in the domain has the constraint that \( f(i) \notin \{i, -i\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But since \( f \) is strictly increasing, all \( f(i) \) are distinct.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Therefore, it's equivalent to counting the number of 2011-element strictly increasing sequences from \( \{-2010, \ldots, 2010\} \) such that for each \( i \), \( f(i) \ne i \) and \( f(i) \ne -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, perhaps this is similar to arranging the numbers with certain forbidden positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This seems similar to the problem of counting permutations with forbidden positions, but here it's a sequence not a permutation.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hmm.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, maybe think of it as a string of 2011 elements selected from \( \{-2010, \ldots, 2010\} \), arranged in increasing order, such that for each position \( i \), the element is not \( i \) or \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, but for some \( i \), \( i \) is within the codomain.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, \( i \) is from -1005 to 1005.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, in the codomain, from -2010 to 2010.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, the forbidden assignments for position \( i \) are \( f(i) = i \) and \( f(i) = -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m These are specific values within the codomain.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Thus, it's like avoiding certain positions at each step.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This seems similar to arranging a permutation where certain elements are excluded from certain positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hmm.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, another approach.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Since \( f \) is strictly increasing, we can model the function as a monotonic sequence.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Moreover, in the restricted codomain, excluding \( i \) and \( -i \) for each \( i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps inclusion-exclusion can be used.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m We can compute the total number of strictly increasing functions without restrictions, and subtract those that violate the condition.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But the number of strictly increasing functions without restrictions would just be the combination \( C(4021, 2011) \), but here the codomain is large.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps another angle: each \( f(i) \) must be in the set \( S = \{-2010, \ldots, 2010\} \setminus \{n, -n | n \in \{-1005, \ldots, 1005\}\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, actually, \( |f(n)| \ne |n| \). So, \( f(n) \ne n \) and \( f(n) \ne -n \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, for each \( n \), \( f(n) \) can be any element in \( S \setminus \{n, -n\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But \( S \) is the codomain: \( \{-2010, \ldots, 2010\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Thus, excluding \( n \) and \( -n \) from \( S \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, for each \( n \), we need to exclude two elements: \( n \) and \( -n \) from the codomain.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Therefore, the number of available elements at each position is \( 4021 - 2 = 4019 \), but this can't be because \( n \) and \( -n \) are different elements.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, no: for each \( n \), excluding \( n \) and \( -n \) would remove two elements, but \( n \) and \( -n \) are different.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hence, for each position \( i \), the number of available choices is \( 4021 - 2 = 4019 \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But wait, the function is strictly increasing, so the choices are interdependent.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Thus, maybe use a recursive approach or stars and bars.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, maybe modeling the problem as arranging the numbers.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Since the function is strictly increasing, it is equivalent to choosing 2011 numbers from the codomain \( \{-2010, \ldots, 2010\} \) (size 4021) such that each chosen number \( a_i \) satisfies \( a_i \ne i \) and \( a_i \ne -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, the problem reduces to counting the number of increasing sequences \( a_1 < a_2 < \ldots < a_{2011} \) with \( a_i \ne i \) and \( a_i \ne -i \) for each \( i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This seems similar to counting the number of injective sequences.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But the condition is on each term.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Perhaps use inclusion-exclusion.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m We can think of forbidden positions as \( a_i = i \) and \( a_i = -i \) for each \( i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Therefore, we have 2011 forbidden values for each position.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But the problem is that these forbidden values vary per position.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, perhaps model it as a permutation where certain elements are forbidden at certain positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m In such cases, inclusion-exclusion can be applied by considering forbidden assignments.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m In this case, for each \( i \) in 1 to 2011, position \( i \) is forbidden to have the values \( i \) and \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This is similar to derangements, but with multiple forbidden positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hmm.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Alternatively, perhaps model the problem as arranging the numbers such that for each \( i \), the number \( a_i \) is not \( i \) or \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This seems like assigning each \( a_i \) with specific restrictions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Another approach: bijective correspondence.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Let me consider that the set \( \{-2010, \ldots, 2010\} \) can be thought of as \( \{-2010, -2009, \ldots, 0, \ldots, 2009, 2010\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Thus, the codomain has 4021 elements.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m We have to choose 2011 elements, strictly increasing, so essentially a combination.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m However, some of these combinations have \( a_i = i \) or \( a_i = -i \), which are forbidden.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Therefore, perhaps subtract the number of combinations where at least one \( a_i = i \) or \( a_i = -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But with overlapping, inclusion-exclusion would be needed.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m However, inclusion-exclusion for 2011 events is quite intensive, but perhaps manageable due to symmetrical properties.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, let me try.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Let me denote:
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m For each position \( i \) (from 1 to 2011), define \( A_i \) as the set of combinations where \( a_i = i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Similarly, \( B_i \) as the set of combinations where \( a_i = -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m We need to count the total number of combinations minus the number of combinations where at least one \( a_i = i \) or \( a_i = -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Thus, the desired count is:
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m \( C = \binom{4021}{2011} - \sum |A_i| - \sum |B_i| + \sum |A_i \cap A_j| + \sum |A_i \cap B_j| + \dots - \dots + (-1)^{k+1} |A_1 \cap A_2 \cap \dots \cap A_{2011}| + \dots \)
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This seems quite involved, but let's see if we can find a pattern or a simpler way.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps transforming the problem.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Suppose we make a substitution: Let \( b_i = a_i - i \). Then, the condition becomes \( b_i + i \ne i \) and \( b_i + i \ne -i \), which implies \( b_i \ne 0 \) and \( b_i \ne -2i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But I'm not sure if this helps.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Alternatively, perhaps consider shifting the codomain.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, maybe another way.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Suppose we fix the positions where \( a_i = i \) and \( a_i = -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Each such forbidden assignment must be avoided.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m However, the overlapping of these forbidden assignments complicates things.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps approximate using inclusion-exclusion but focusing on the forbidden positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, given the problem is symmetrical for positive and negative, perhaps it's appropriate to compute the total number without restrictions, subtract those which have \( a_i = i \) or \( a_i = -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But inclusion-exclusion is still complicated.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps use the principle similar to derangements.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, in derangements, we count permutations with no fixed points.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Similarly, perhaps here we want functions where the image is not in certain positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, but the forbidden positions depend on \( i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps another angle.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Since \( f \) is strictly increasing, it's equivalent to choosing 2011 elements from the codomain in increasing order.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Thus, the problem is equivalent to counting the number of subsets of size 2011 from \( \{-2010, \ldots, 2010\} \) such that none of the elements are equal to \( i \) or \( -i \) for any element in the subset.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, but the codomain is large, and the forbidden elements are specific.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps another substitution.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Let me denote \( c_i = a_i - i \). Then, \( a_i = c_i + i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m The condition \( a_i \ne i \) is equivalent to \( c_i \ne 0 \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m The condition \( a_i \ne -i \) is equivalent to \( c_i \ne -2i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, \( c_i \) cannot be 0 or \( -2i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hmm, but variables \( c_i \) are arbitrary.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Not sure if this helps.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps think of it as a permutation from 1 to 2011 with certain forbidden positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, seems like overcomplicating.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Perhaps think of it as a stars and bars problem.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, given that for each position \( i \), \( a_i \) can't be \( i \) or \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This is similar to choosing a sequence where each term is restricted.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m In combinatorics, such problems are often solved using inclusion-exclusion.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m The formula would be:
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Number of sequences \( = \) Total number of strictly increasing sequences \( - \) sequences with at least one forbidden \( a_i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But to compute exactly this, we need to use inclusion-exclusion.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m The inclusion-exclusion formula would be:
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Number of valid sequences = \( \sum_{k=0}^{2011} (-1)^k \sum_{1 \leq i_1 < i_2 < \ldots < i_k \leq 2011} N(i_1, i_2, \ldots, i_k) } \),
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m where \( N(i_1, i_2, \ldots, i_k) \) is the number of strictly increasing sequences where \( a_{i_m} = i_m \) for each \( m \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But in this case, the forbidden values are \( i \) and \( -i \), so for each \( i_m \), \( a_{i_m} \ne i_m \) and \( a_{i_m} \ne -i_m \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, this is getting too complicated.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Another idea: Maybe consider swapping variables.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Let me model the function \( f \) as a bijection from the domain to the codomain with certain forbidden assignments.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, mapping \( i \) to \( f(i) \), which can't be \( i \) or \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hence, the problem is to count the number of bijections \( f: \{-1005, \ldots, 1005\} \to \{-2010, \ldots, 2010\} \), strictly increasing, such that \( f(i) \ne i \) and \( f(i) \ne -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hmm.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps transform the problem into matching.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Since the function is strictly increasing, it's order-preserving.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, imagine placing 2011 elements from the codomain into increasing order, avoiding \( i \) and \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Perhaps we can model this as a permutation matrix with forbidden positions, but again, not sure.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, another approach.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Suppose we fix the function \( f \) as strictly increasing, which is equivalent to choosing a subset of size 2011 from the codomain and listing them in increasing order.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m We need to count such subsets where for each i in the domain, \( f(i) = a_i \ne i \) and \( a_i \ne -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, as previously thought.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Perhaps denote this as a bijection problem.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps the answer is \( \binom{4021 - 2 \times 2011}{2011} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But 4021 - 2*2011 = 4021 - 4022 = -1, which is not feasible.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, maybe that approach is wrong.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps model it as injective functions with restrictions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, and another approach.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Suppose that for each \( i \), we exclude two values: \( i \) and \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Then, when choosing a subset of size 2011, each chosen element must not be equal to any \( i \) or \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But the forbidden values vary per position.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, an alternative idea:
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Assume that the forbidden assignments are that \( f(i) \notin \{i, -i\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This is equivalent to \( f(i) \in \{ -2010, \ldots, 2010 \} \setminus \{i, -i\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Since \( f \) is strictly increasing, the choices are dependent.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Maybe, using the principle similar to derangements:
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m The number of such functions is equal to the number of strictly increasing sequences where each term is not equal to its position or the negative of its position.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This is similar to derangements but in a larger set.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Alternatively, notice that this problem is similar to counting the number of permutations with forbidden positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m In our case, for each position \( i \), we have two forbidden elements: \( i \) and \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, the total number of forbidden assignments is \( 2 \times 2011 \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, applying inclusion-exclusion.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m The formula is:
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Total sequences without restrictions: \( \binom{4021}{2011} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Subtract sequences where at least one \( a_i = i \) or \( a_i = -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But since some sequences may have multiple forbidden assignments overlapping (e.g., \( a_i = i \) and \( a_j = j \)), inclusion-exclusion is needed.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m However, inclusion-exclusion is complicated here because the forbidden sets overlap, especially given that \( i \) and \( -i \) can coincide for different \( i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Alternatively, maybe this is a problem that can be approached with recursion.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Let me define \( C(n, k) \) as the number of strictly increasing sequences of length \( k \) chosen from \( \{-n, \ldots, n\} \setminus \{ -i, i \} \) for each \( i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, not sure.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Alternatively, in the problem, the function is from a smaller set (2011 elements) to a larger set (4021 elements), strictly increasing.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Each position has two forbidden elements. Perhaps approximate using inclusion-exclusion.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But since each forbidden element depends on the position, inclusion-exclusion is necessary.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m It might be complicated, but let me attempt.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m First, compute the total number of strictly increasing functions without restrictions:
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m \( T = \binom{4021}{2011} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Now, for each position \( i \), define \( A_i \) as the set of sequences where \( a_i = i \), and \( B_i \) as the set where \( a_i = -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m We need to compute the size of the intersection of all these \( A_i \) and \( B_i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, using inclusion-exclusion:
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m \( |A_1 \cup A_2 \cup \ldots \cup A_{2011} \cup B_1 \cup \ldots \cup B_{2011}| = \sum |A_i| + \sum |B_i| - \sum |A_i \cap A_j| - \sum |A_i \cap B_j| - \ldots + \ldots - |A_1 \cap A_2 \cap \ldots \cap A_{2011} \cap B_1 \cap \ldots \cap B_{2011}| \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This is quite involved.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But perhaps exploit symmetry.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Notice that each \( A_i \) and \( B_i \) are symmetric for each \( i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Compute the number of sequences where \( a_i = i \) and none of the other constraints.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Similarly for \( a_i = -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Given that, maybe compute \( |A_i| \) and \( |B_i| \), then the intersections.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m First, compute \( |A_i| \): Number of sequences where \( a_i = i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m If \( a_i = i \), then since the sequence is strictly increasing, \( i \) must be somewhere in the middle.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, fix \( a_i = i \), then the remaining 2010 elements must be chosen from the remaining 4020 elements, excluding \( i \) and ensuring the sequence remains strictly increasing.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, no.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m After fixing \( a_i = i \), the sequence is composed of 2011 elements, one of which is \( i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Thus, the rest 2010 elements must be chosen from \( \{-2010, \ldots, 2010\} \setminus \{i\} \), maintaining the strictly increasing order.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hence, \( |A_i| = \binom{4020}{2010} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Similarly, \( |B_i| = \binom{4020}{2010} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Because, if we fix \( a_i = -i \), then the remaining 2010 elements are from the remaining 4020 elements.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Similarly, \( |A_i \cap B_j| \) is the number of sequences where \( a_i = i \) and \( a_j = -j \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m So, fix \( a_i = i \) and \( a_j = -j \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Now, since \( i \neq j \), we have two specific elements fixed.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Thus, the remaining 2009 elements must be chosen from \( \{-2010, \ldots, 2010\} \setminus \{i, -j\} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Hence, \( |A_i \cap B_j| = \binom{4019}{2009} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Similarly, the intersection of multiple \( A_i \) and \( B_j \) is tricky.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m In general, computing these terms requires combinatorial formulas.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Given the complexity, perhaps refer to a known result.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, this seems like a known problem.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Upon further reflection, perhaps use the principle similar to derangements.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But another approach: incrementally build the sequence.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m We can think of the function as an injective map from the domain to the codomain with specific restrictions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Each element \( i \) in the domain cannot map to \( i \) or \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Perhaps for each position \( i \), two choices are forbidden.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, perhaps model this as a permutation with restricted positions.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m In permutation terms, for each position \( i \), there are two elements forbidden: \( i \) and \( -i \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m This is similar to a permutation matrix where certain positions are forbidden.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Then, the number of such permutations is given by the permanent of a matrix where entries indicate allowed placements.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But computing the permanent is difficult.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Alternatively, maybe model it as the product over (number of available choices at each step).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Starting with the largest element, we have 4021 choices.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Once we choose a_i, the remaining choices are reduced.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But it's not straightforward because choices are dependent on previous choices.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Given the complexity, perhaps refer to an approximate answer or recognize a pattern.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Wait, an alternative idea: in such problems where each element has forbidden assignments, the answer often involves the inclusion-exclusion formula.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Given the problem's time constraints, perhaps the answer is \( \binom{4021 - 2*2011}{2011} \).
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m But 4021 - 2*2011 = 4021 - 4022 = -1.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Not feasible.
[36m(TaskRunner pid=3919966)[0m 
[36m(TaskRunner pid=3919966)[0m Alternatively, since each forbidden pair takes away two elements, perhaps the total
[36m(TaskRunner pid=3919966)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:15:02<21:58, 101.41s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:16:41<20:08, 100.71s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:18:16<18:09, 99.09s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:21:10<20:16, 121.65s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:22:48<17:09, 114.37s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:24:29<14:42, 110.35s/it]
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 06:32:34,171:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 06:32:39,922:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m WARNING:2025-11-14 06:32:45,779:Timeout during comparison
[36m(TaskRunner pid=3919966)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:26:23<13:00, 111.44s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:27:59<10:42, 107.05s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:29:33<08:34, 102.88s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:31:11<06:46, 101.56s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:32:45<04:57, 99.31s/it] 
[36m(TaskRunner pid=3919966)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:34:30<03:21, 100.88s/it]
[36m(TaskRunner pid=3919966)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:36:15<01:42, 102.16s/it]
[36m(WorkerDict pid=3923518)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3923518)[0m   warnings.warn(
[36m(TaskRunner pid=3919966)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:39:26<01:50, 110.16s/it]
[36m(WorkerDict pid=3923722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3923722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
