The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_0.00001_3/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_0.00001_3//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.00001_3//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.00001_3//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_0.00001_3/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-09 18:54:38,169	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=1168185)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 18:54:58,708:Waiting for register center actor eVMwpB_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=1172107)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1172107)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=1172107)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=1172107)[0m [rank3]:[W1209 18:55:16.760038259 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=1171846)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1171846)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1171846)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172106)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172106)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172106)[0m [rank2]:[W1209 18:55:20.473434078 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1171846)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1172107)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1172107)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1172106)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(WorkerDict pid=1172107)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=1168185)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1168185)[0m Training Progress:   0%|          | 1/480 [01:58<15:44:14, 118.28s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   0%|          | 2/480 [03:58<15:49:52, 119.23s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   1%|          | 3/480 [06:00<15:59:22, 120.68s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   1%|          | 4/480 [07:58<15:49:34, 119.69s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   1%|          | 5/480 [09:58<15:48:29, 119.81s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   1%|â–         | 6/480 [12:00<15:51:03, 120.39s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   1%|â–         | 7/480 [14:03<15:57:07, 121.41s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   2%|â–         | 8/480 [16:04<15:53:27, 121.20s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   2%|â–         | 9/480 [18:00<15:39:42, 119.71s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   2%|â–         | 10/480 [21:22<18:56:25, 145.08s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   2%|â–         | 11/480 [23:19<17:46:11, 136.40s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   2%|â–Ž         | 12/480 [25:18<17:01:22, 130.95s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   3%|â–Ž         | 13/480 [27:16<16:28:49, 127.04s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   3%|â–Ž         | 14/480 [29:16<16:12:01, 125.15s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   3%|â–Ž         | 15/480 [31:13<15:49:53, 122.57s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   3%|â–Ž         | 16/480 [33:12<15:38:53, 121.41s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   4%|â–Ž         | 17/480 [35:11<15:31:50, 120.76s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   4%|â–         | 18/480 [37:07<15:18:19, 119.26s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 19:35:51,820:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:   4%|â–         | 19/480 [39:10<15:25:47, 120.49s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   4%|â–         | 20/480 [42:31<18:28:34, 144.60s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   4%|â–         | 21/480 [44:29<17:25:29, 136.67s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   5%|â–         | 22/480 [46:28<16:42:20, 131.31s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   5%|â–         | 23/480 [48:25<16:08:49, 127.20s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   5%|â–Œ         | 24/480 [50:20<15:36:58, 123.29s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   5%|â–Œ         | 25/480 [52:13<15:12:55, 120.39s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   5%|â–Œ         | 26/480 [54:09<15:00:21, 118.99s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   6%|â–Œ         | 27/480 [56:08<14:58:15, 118.97s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   6%|â–Œ         | 28/480 [57:59<14:38:07, 116.57s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   6%|â–Œ         | 29/480 [59:56<14:36:51, 116.66s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:04<17:15:15, 138.03s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 20:01:40,778:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:   6%|â–‹         | 31/480 [1:04:55<16:13:30, 130.09s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:41<15:16:01, 122.68s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:36<14:57:07, 120.42s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:28<14:36:31, 117.92s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:18<14:16:50, 115.53s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:06<13:58:18, 113.28s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   8%|â–Š         | 37/480 [1:15:55<13:48:25, 112.20s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   8%|â–Š         | 38/480 [1:17:49<13:49:07, 112.55s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   8%|â–Š         | 39/480 [1:19:33<13:29:01, 110.07s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   8%|â–Š         | 40/480 [1:22:38<16:12:30, 132.61s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   9%|â–Š         | 41/480 [1:24:24<15:11:25, 124.57s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   9%|â–‰         | 42/480 [1:26:16<14:41:43, 120.78s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:03<14:09:29, 116.63s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   9%|â–‰         | 44/480 [1:29:50<13:46:54, 113.79s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:   9%|â–‰         | 45/480 [1:31:31<13:17:35, 110.01s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  10%|â–‰         | 46/480 [1:33:20<13:13:01, 109.63s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:08<13:08:10, 109.22s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:36:58<13:07:07, 109.32s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:38:50<13:12:10, 110.28s/it]
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(TaskRunner pid=1168185)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:42:09<16:20:55, 136.87s/it]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1168185)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:43:54<15:10:01, 127.28s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:45:38<14:18:14, 120.32s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:47:19<13:33:45, 114.35s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:49:06<13:16:44, 112.22s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:50:49<12:55:47, 109.52s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:52:37<12:49:16, 108.86s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:54:27<12:49:55, 109.21s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:56:09<12:33:30, 107.13s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:57:53<12:24:20, 106.08s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 20:58:00,319:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:00:51<14:53:59, 127.71s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:02:37<14:05:59, 121.14s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:04:21<13:28:22, 116.03s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:06:03<12:58:17, 111.98s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:07:54<12:53:23, 111.55s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:09:35<12:30:32, 108.51s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:11:23<12:27:21, 108.31s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:13:07<12:15:42, 106.88s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:14:50<12:07:04, 105.89s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:16:36<12:05:58, 105.98s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:19:36<14:35:38, 128.14s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:21:22<13:47:26, 121.39s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:23:05<13:08:51, 116.01s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:24:49<12:42:25, 112.40s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:26:37<12:31:25, 111.05s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:28:22<12:18:01, 109.34s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:30:09<12:10:38, 108.51s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:31:56<12:06:06, 108.11s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:33:42<11:59:35, 107.40s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:35:32<12:02:13, 108.06s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:38:29<14:19:13, 128.88s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 21:37:04,154:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:40:18<13:37:22, 122.91s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:42:02<12:56:59, 117.13s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:43:46<12:29:06, 113.22s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:45:31<12:11:46, 110.87s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:47:15<11:55:44, 108.72s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:49:01<11:49:30, 108.05s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:50:50<11:48:03, 108.10s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:52:36<11:43:43, 107.71s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:54:20<11:34:06, 106.51s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:57:18<13:51:45, 127.96s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [2:58:59<12:57:20, 119.90s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:00:45<12:27:54, 115.66s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:02:28<12:01:21, 111.84s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 22:01:03,800:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 22:01:11,493:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 22:01:16,565:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:04:28<12:15:03, 114.26s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:06:10<11:50:31, 110.73s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 22:04:48,896:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:08:04<11:54:34, 111.65s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 22:06:38,020:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:09:52<11:45:49, 110.57s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:11:27<11:13:26, 105.78s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:13:15<11:16:06, 106.47s/it]
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(WorkerDict pid=1171846)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1171846)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=1168185)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:16:28<13:58:48, 132.44s/it]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1168185)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:18:06<12:51:22, 122.12s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:19:49<12:13:49, 116.48s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:21:27<11:36:34, 110.86s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:23:02<11:05:32, 106.20s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:24:47<11:00:21, 105.66s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:26:25<10:45:03, 103.49s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:28:09<10:43:36, 103.53s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 22:26:41,140:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:29:50<10:37:54, 102.89s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:31:41<10:50:44, 105.24s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:34:36<12:58:05, 126.18s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:36:19<12:13:19, 119.24s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:37:54<11:27:37, 112.11s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:39:35<11:05:29, 108.80s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:41:17<10:50:34, 106.65s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:42:50<10:24:26, 102.65s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:44:29<10:15:47, 101.50s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:46:10<10:13:07, 101.34s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:47:50<10:08:33, 100.87s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:49:29<10:03:51, 100.36s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:52:21<12:11:42, 121.95s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:53:56<11:21:16, 113.86s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:55:41<11:02:37, 111.05s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:57:20<10:39:13, 107.43s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-09 22:56:00,869:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [3:59:14<10:49:41, 109.50s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:00:53<10:28:53, 106.29s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:02:31<10:12:31, 103.82s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:04:07<9:56:00, 101.30s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:05:45<9:49:17, 100.45s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:07:24<9:45:26, 100.07s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:10:14<11:45:03, 120.87s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:11:54<11:06:32, 114.59s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:13:30<10:32:19, 109.02s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:15:09<10:14:34, 106.27s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:16:48<9:59:02, 103.88s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:18:28<9:51:35, 102.89s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:20:07<9:43:05, 101.70s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:21:44<9:33:03, 100.24s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:23:25<9:32:56, 100.52s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:25:05<9:30:08, 100.32s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:27:53<11:23:06, 120.55s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:29:32<10:44:52, 114.14s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:31:07<10:09:48, 108.25s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:32:44<9:50:33, 105.14s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:34:21<9:34:08, 102.53s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:35:57<9:22:34, 100.76s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:37:29<9:05:12, 97.94s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:39:01<8:54:12, 96.26s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:40:37<8:51:08, 95.99s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:42:17<8:57:26, 97.42s/it]
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(TaskRunner pid=1168185)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:45:20<11:16:19, 122.97s/it]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1168185)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:46:59<10:34:32, 115.72s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:48:38<10:05:57, 110.85s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:50:13<9:38:38, 106.17s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:51:53<9:25:21, 104.05s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:53:29<9:12:07, 101.93s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:55:02<8:55:21, 99.14s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [4:56:39<8:49:32, 98.37s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [4:58:20<8:52:26, 99.21s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [4:59:59<8:49:59, 99.07s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:02:47<10:39:03, 119.82s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:04:30<10:10:09, 114.76s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:06:11<9:45:54, 110.55s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:07:46<9:20:11, 106.03s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:09:20<8:59:33, 102.45s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:10:57<8:48:50, 100.73s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:12:35<8:43:13, 99.98s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:14:09<8:31:30, 98.05s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:15:47<8:30:40, 98.21s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:17:22<8:24:09, 97.26s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:20:09<10:10:25, 118.15s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:21:45<9:34:26, 111.54s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:23:19<9:05:51, 106.34s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:24:55<8:48:12, 103.23s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:26:28<8:30:10, 100.03s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:28:06<8:24:44, 99.29s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:29:44<8:21:45, 99.03s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:31:21<8:17:17, 98.47s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:33:01<8:17:49, 98.90s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:34:39<8:15:23, 98.75s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:37:33<10:05:12, 121.04s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 00:36:05,825:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:39:17<9:38:19, 116.05s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:40:56<9:11:00, 110.94s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:42:36<8:53:36, 107.80s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:44:09<8:29:41, 103.32s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:45:52<8:27:05, 103.14s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:47:30<8:18:22, 101.71s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:49:05<8:06:59, 99.73s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:50:46<8:05:50, 99.83s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:52:26<8:04:45, 99.95s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [5:55:14<9:42:03, 120.43s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [5:56:49<9:03:53, 112.92s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [5:58:25<8:37:37, 107.84s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:00:05<8:24:29, 105.47s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:01:44<8:13:43, 103.58s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:03:20<8:01:15, 101.32s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:05:03<8:01:40, 101.76s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:06:41<7:53:44, 100.44s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:08:22<7:53:33, 100.76s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:09:59<7:46:48, 99.68s/it] 
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(TaskRunner pid=1168185)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:13:11<9:54:05, 127.31s/it]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1168185)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:14:49<9:11:00, 118.50s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:16:30<8:44:14, 113.15s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:18:08<8:21:45, 108.68s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:19:45<8:03:43, 105.16s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:21:25<7:55:39, 103.78s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:23:07<7:51:00, 103.14s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:24:53<7:52:26, 103.83s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:26:27<7:37:55, 101.01s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:28:07<7:34:31, 100.63s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:31:03<9:14:42, 123.27s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:32:42<8:39:57, 115.98s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:34:21<8:15:08, 110.85s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:36:04<8:02:57, 108.53s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:37:45<7:51:49, 106.43s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:39:22<7:36:59, 103.47s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:40:59<7:26:30, 101.48s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:42:38<7:22:08, 100.87s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:44:14<7:14:16, 99.45s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:45:59<7:19:59, 101.15s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:48:51<8:49:50, 122.27s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:50:30<8:17:34, 115.27s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:52:10<7:56:34, 110.83s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:53:42<7:30:38, 105.21s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [6:55:22<7:21:11, 103.41s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [6:56:59<7:12:11, 101.69s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [6:58:33<7:00:23, 99.31s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:00:15<7:02:15, 100.14s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:01:53<6:57:07, 99.32s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:03:34<6:57:58, 99.92s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:06:26<8:26:29, 121.56s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:08:02<7:52:06, 113.76s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:09:37<7:26:57, 108.14s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:11:15<7:13:27, 105.30s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:12:49<6:57:02, 101.72s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:14:24<6:48:01, 99.93s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:15:58<6:38:32, 98.00s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:17:32<6:32:16, 96.86s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:19:12<6:34:30, 97.81s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:20:47<6:28:56, 96.83s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:23:40<7:59:46, 119.94s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:25:27<7:41:59, 115.98s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:27:04<7:17:28, 110.29s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:28:42<7:01:17, 106.66s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:30:19<6:47:24, 103.58s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:31:55<6:36:58, 101.36s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:33:30<6:28:25, 99.60s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:35:06<6:21:53, 98.34s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:36:43<6:18:52, 97.98s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:38:21<6:17:42, 98.11s/it]
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(TaskRunner pid=1168185)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:41:30<8:00:06, 125.24s/it]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1168185)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:43:03<7:21:02, 115.56s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:44:39<6:56:26, 109.59s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:46:14<6:38:16, 105.27s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:47:49<6:25:35, 102.37s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 02:46:19,959:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:49:28<6:20:04, 101.35s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:51:04<6:12:26, 99.76s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:52:36<6:02:03, 97.42s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:54:14<6:00:19, 97.38s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [7:55:44<5:51:17, 95.37s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [7:58:32<7:09:27, 117.13s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:00:13<6:49:50, 112.29s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:01:54<6:35:44, 108.92s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:03:32<6:21:32, 105.49s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:05:10<6:11:33, 103.21s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:06:42<5:58:07, 99.94s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:08:17<5:51:21, 98.51s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:09:51<5:44:53, 97.15s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:11:21<5:35:17, 94.89s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:12:56<5:34:00, 94.98s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 03:11:27,343:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 03:11:33,949:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 03:11:38,967:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:16:01<7:06:51, 121.96s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:17:37<6:38:18, 114.35s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:19:08<6:11:59, 107.30s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:20:44<5:57:48, 103.71s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:22:22<5:50:05, 101.97s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:23:54<5:38:22, 99.04s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:25:30<5:33:53, 98.21s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 03:24:04,149:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:27:14<5:37:59, 99.90s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:28:49<5:31:44, 98.54s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:30:24<5:26:18, 97.41s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:33:12<6:34:57, 118.49s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:34:41<6:03:52, 109.71s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:36:14<5:45:51, 104.81s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:37:50<5:34:47, 101.97s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:39:30<5:31:42, 101.54s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:41:09<5:27:20, 100.72s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:42:43<5:18:50, 98.61s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:44:17<5:13:31, 97.47s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:45:52<5:09:00, 96.57s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:47:26<5:05:07, 95.85s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:50:19<6:17:12, 119.12s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:51:55<5:53:12, 112.13s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [8:53:30<5:35:10, 106.97s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [8:55:04<5:21:27, 103.14s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [8:56:39<5:11:46, 100.57s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [8:58:17<5:07:15, 99.65s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [8:59:56<5:05:24, 99.59s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:01:29<4:57:34, 97.56s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:03:06<4:56:00, 97.59s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:04:42<4:52:55, 97.10s/it]
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(TaskRunner pid=1168185)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:07:46<6:09:22, 123.13s/it]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 04:06:18,971:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:09:29<5:49:13, 117.06s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:11:04<5:27:04, 110.25s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:12:39<5:11:48, 105.70s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:14:16<5:02:41, 103.19s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:15:50<4:52:49, 100.40s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:17:26<4:47:07, 99.01s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:18:58<4:39:52, 97.06s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:20:33<4:36:08, 96.33s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:22:11<4:36:30, 97.02s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:24:58<5:34:17, 117.98s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:26:33<5:12:36, 110.99s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:28:09<4:58:08, 106.48s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:29:44<4:46:42, 103.01s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:31:22<4:41:18, 101.68s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:33:02<4:37:45, 101.00s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:34:48<4:40:12, 102.52s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 04:33:17,796:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:36:25<4:34:29, 101.04s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:38:02<4:29:08, 99.68s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:39:40<4:25:54, 99.09s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 04:39:43,492:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:42:36<5:25:58, 122.24s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:44:15<5:05:10, 115.16s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 04:42:43,782:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:45:52<4:49:26, 109.91s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:47:25<4:34:16, 104.82s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:49:05<4:28:43, 103.35s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [9:50:42<4:21:49, 101.35s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [9:52:18<4:16:05, 99.78s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [9:53:56<4:13:13, 99.31s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [9:55:34<4:10:14, 98.78s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [9:57:06<4:03:27, 96.74s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [9:59:54<4:55:33, 118.22s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:01:23<4:31:46, 109.44s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:02:55<4:16:44, 104.08s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:04:31<4:09:05, 101.67s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:06:04<4:01:45, 99.35s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:07:35<3:53:45, 96.73s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:09:08<3:49:03, 95.44s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:10:42<3:47:07, 95.30s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:12:15<3:43:50, 94.58s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:13:50<3:42:19, 94.60s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:16:39<4:33:06, 117.05s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:18:15<4:16:07, 110.56s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:19:53<4:05:25, 106.71s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:21:27<3:55:24, 103.10s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:22:57<3:44:39, 99.12s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:24:32<3:40:14, 97.88s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:26:05<3:35:10, 96.35s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:27:40<3:32:38, 95.93s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:29:17<3:31:31, 96.15s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:30:47<3:26:15, 94.47s/it]
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(TaskRunner pid=1168185)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:33:54<4:24:38, 122.15s/it]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1168185)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:35:32<4:06:59, 114.88s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:37:10<3:54:29, 109.92s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:38:48<3:45:13, 106.41s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:40:28<3:39:14, 104.40s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:42:04<3:32:09, 101.83s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:43:37<3:25:06, 99.24s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:45:12<3:20:49, 97.96s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:46:45<3:16:07, 96.45s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:48:27<3:17:43, 98.05s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [10:51:16<3:59:05, 119.55s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [10:52:52<3:42:59, 112.44s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [10:54:31<3:32:59, 108.30s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [10:56:06<3:23:41, 104.46s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [10:57:41<3:16:19, 101.55s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 05:56:10,640:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [10:59:20<3:13:14, 100.82s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:00:53<3:07:10, 98.52s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:02:28<3:03:08, 97.25s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:04:05<3:01:33, 97.27s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 06:02:38,244:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:05:47<3:02:35, 98.70s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:08:46<3:45:06, 122.79s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:10:23<3:28:47, 114.93s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:12:03<3:19:12, 110.67s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:13:41<3:10:37, 106.89s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:15:15<3:01:54, 102.97s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:16:53<2:57:40, 101.53s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:18:28<2:52:15, 99.38s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:20:05<2:49:14, 98.59s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:21:42<2:47:00, 98.24s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:23:19<2:44:37, 97.79s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:26:10<3:19:36, 119.76s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:27:48<3:07:09, 113.43s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:29:27<2:58:01, 109.00s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:31:06<2:51:18, 105.96s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:32:53<2:50:18, 106.44s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:34:32<2:44:34, 103.94s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:36:10<2:40:19, 102.34s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:37:52<2:38:19, 102.15s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:39:29<2:34:15, 100.61s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:41:10<2:32:39, 100.65s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:44:04<3:04:03, 122.71s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:45:42<2:51:17, 115.48s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:47:17<2:40:07, 109.17s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [11:48:49<2:30:48, 104.01s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [11:50:25<2:25:33, 101.56s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [11:52:08<2:24:32, 102.03s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [11:53:41<2:19:00, 99.29s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [11:55:17<2:16:12, 98.46s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [11:56:55<2:14:09, 98.16s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [11:58:31<2:11:41, 97.55s/it]
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(TaskRunner pid=1168185)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:01:39<2:46:24, 124.81s/it]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1168185)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:03:17<2:33:29, 116.58s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:04:58<2:25:34, 111.98s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:06:38<2:19:18, 108.56s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 07:05:11,775:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:08:21<2:15:03, 106.62s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:09:55<2:08:36, 102.89s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:11:32<2:04:59, 101.35s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:13:12<2:02:44, 100.88s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:14:51<2:00:13, 100.19s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:16:26<1:56:46, 98.68s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:19:17<2:20:23, 120.34s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:20:54<2:10:21, 113.35s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:22:29<2:02:16, 107.90s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:24:04<1:56:07, 103.99s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:25:43<1:52:36, 102.37s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:27:13<1:47:00, 98.78s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:28:49<1:44:20, 97.82s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:30:28<1:43:13, 98.31s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:32:07<1:41:43, 98.45s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:33:44<1:39:47, 98.16s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:36:38<2:00:41, 120.69s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:38:13<1:51:11, 113.07s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:39:56<1:46:31, 110.19s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:41:32<1:40:37, 105.92s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:43:11<1:36:49, 103.75s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:44:51<1:34:05, 102.65s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:46:28<1:30:51, 100.96s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [12:48:07<1:28:40, 100.40s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [12:49:50<1:27:36, 101.08s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [12:51:26<1:24:46, 99.73s/it] 
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 07:49:58,768:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [12:54:24<1:42:39, 123.18s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [12:56:03<1:34:32, 115.76s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [12:57:39<1:27:55, 109.91s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [12:59:22<1:24:35, 107.98s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:00:59<1:20:07, 104.51s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:02:35<1:16:33, 102.08s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:04:14<1:14:08, 101.09s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:05:52<1:11:43, 100.09s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:07:31<1:09:47, 99.69s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:09:11<1:08:15, 99.88s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:12:01<1:20:42, 121.06s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:13:39<1:14:07, 114.03s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:15:20<1:09:46, 110.18s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:16:57<1:05:26, 106.13s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:18:37<1:02:32, 104.23s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:20:15<59:51, 102.61s/it]  
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 08:18:48,609:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:21:57<57:53, 102.16s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:23:31<54:57, 99.94s/it] 
[36m(TaskRunner pid=1168185)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:25:06<52:27, 98.35s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:26:47<51:16, 99.23s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 08:25:19,196:Timeout during comparison
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(TaskRunner pid=1168185)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:30:00<1:03:34, 127.16s/it]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1168185)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:31:38<57:13, 118.39s/it]  
[36m(TaskRunner pid=1168185)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:33:13<51:59, 111.42s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:34:54<48:48, 108.46s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:36:32<45:37, 105.27s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:38:04<42:10, 101.21s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:39:42<40:09, 100.39s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:41:29<39:15, 102.41s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:43:08<37:10, 101.38s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:44:46<35:05, 100.27s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [13:47:42<41:01, 123.05s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [13:49:22<36:47, 116.18s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [13:51:02<33:19, 111.08s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 08:49:36,836:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 08:49:41,847:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [13:52:51<31:20, 110.63s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [13:54:29<28:29, 106.85s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [13:56:11<26:21, 105.44s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [13:57:52<24:14, 103.92s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 08:56:26,635:Timeout during parsing: Okay, so we need to find the number of functions \( f \) from the set \( \{-1005, -1004, \ldots, 1004, 1005\} \) to the set \( \{-2010, -2009, \ldots, 2009, 2010\} \) that satisfy two conditions.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m First condition: If \( a < b \), then \( f(a) < f(b) \). So, \( f \) is strictly increasing.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Second condition: There is no \( n \) in \( \{-1005, \ldots, 1005\} \) such that \( |f(n)| = |n| \). So, for every \( n \), \( |f(n)| \neq |n| \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alright, let's break this down step by step.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m First, condition 1 says that \( f \) is strictly increasing. Since it's a function from a set of 2100 elements (from -1005 to 1005, inclusive) to the set of 4021 elements (from -2010 to 2010, inclusive), we need to select an increasing sequence of 2101 numbers (since from -1005 to 1005, that's 2100 + 1? Wait, actually from -1005 to 1005 it's (1005 - (-1005)) + 1 = 2011 numbers. Oh, right.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, the domain has 2011 elements, and the codomain has 4021 elements. So, we need to choose a strictly increasing function, which is equivalent to choosing an injective increasing function. So, in terms of combinations, it's choosing 2011 elements from the codomain such that they can be arranged in increasing order according to \( f \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Now, condition 2: For each \( n \) in the domain \( \{-1005, \ldots, 1005\} \), \( |f(n)| \neq |n| \). So, we need to ensure that \( f(n) \) is not at a distance of \( |n| \) from 0.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Let's interpret this: For each \( n \), \( f(n) \) must not be in the set \( \{ -|n|, -|n|+1, \ldots, |n|-1, |n| \} \). So, \( |f(n)| \) must not be \(|n|\). So, \( f(n) \) must be in \( \{-2010, \ldots, -|n|-1, |n|+1, \ldots, 2010\} \). That is, \( f(n) \) cannot be in the range \( \{-|n|, -|n|+1, \ldots, |n|-1, |n|\} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, for each \( n \), \( f(n) \) must lie in \( \{-2010, \ldots, -1\} \cup \{1, 2, \ldots, 2010\} \setminus \{-|n|, \ldots, |n|\} \) except? Wait, no, perhaps simpler: \( f(n) \) must not be in \( \{-|n|, -|n|+1, \ldots, |n|-1, |n|\} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Therefore, \( f(n) \) must be in \( \{-2010, \ldots, -|n|-1, |n|+1, \ldots, 2010\} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, for each \( n \), the available choices for \( f(n) \) are outside the interval \( \{-|n|, \ldots, |n|\} \) except 0? Wait, not exactly. For each \( n \), \( |n| \) could be 0, which would mean \( |f(n)| \neq 0 \), so \( f(n) \neq 0 \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, let's take \( n = 0 \), then \( |n| = 0 \), so condition 2 says \( |f(0)| \neq 0 \), so \( f(0) \neq 0 \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m For \( n \neq 0 \), \( |n| \) is positive, so \( |f(n)| \neq |n| \), meaning \( f(n) \) is not in \( \{-|n|, \ldots, |n|\} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, in other words, for each \( n \), \( f(n) \) must be in \( \{-2010, \ldots, -1\} \cup \{1, \ldots, 2010\} \) except the \( |n| \) numbers.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Therefore, perhaps for each \( n \), we have a certain number of allowed values.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m But since \( f \) is strictly increasing, the function must assign a unique value to each \( n \), such that \( f(n) \) is strictly increasing, and for each \( n \), \( f(n) \) is not in the interval \( \{-|n|, \ldots, |n|\} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, let's model the codomain.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m We can consider that for each \( n \), the forbidden range is \( \{-|n|, \ldots, |n|\} \). So, excluding that from the codomain.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m The codomain is \( \{-2010, \ldots, -1\} \cup \{1, \ldots, 2010\} \), excluding \( \{-|n|, \ldots, |n|\} \) for each \( n \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, no, perhaps for each \( n \), the forbidden set is \( \{-|n|, -|n|+1, \ldots, |n|-1, |n|\} \), so \( |f(n)| \neq |n| \), which means \( f(n) \) must not be in \( \{-|n|, \ldots, |n|\} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, the allowed values for \( f(n) \) are \( \{-2010, \ldots, -|n|-1\} \cup \{ |n|+1, \ldots, 2010 \} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Let me rephrase. For each \( n \), \( |f(n)| \neq |n| \). So, \( f(n) \) cannot be in \( \{-|n|, -(|n|-1), \ldots, |n|-1, |n|\} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Therefore, the allowed range for \( f(n) \) is:
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m - If \( |n| = 0 \), then \( f(n) \) must not be 0.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m - If \( |n| \geq 1 \), then \( f(n) \) must not be in \( \{-|n|, -|n|+1, \ldots, |n|-1, |n|\} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, the allowed values for \( f(n) \) are:
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m If \( |n| = 0 \), \( \{-2010, \ldots, -1\} \cup \{1, \ldots, 2010\} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m If \( |n| \geq 1 \), \( \{-2010, \ldots, -|n|-1\} \cup \{ |n|+1, \ldots, 2010 \} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Hmm.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, in either case, the number of allowed values for \( f(n) \) is separated into a lower part and an upper part.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m I need to compute the size of the allowed set for each \( n \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, maybe we can model this.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m First, for each \( n \), let's define:
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m allowed(n) = \( \{-2010, \ldots, -1\} \cup \{ |n|+1, \ldots, 2010 \} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, for \( |n| = 0 \), allowed(n) = \( \{-2010, \ldots, -1\} \cup \{1, \ldots, 2010\} \), which is indeed size 4020. But wait, the codomain is \( \{-2010, \ldots, 2010\} \), which has 4021 elements. Since we're excluding 0, allowed(n) for \( |n| = 0 \) is \( \{-2010, \ldots, -1\} \cup \{1, \ldots, 2010\} \), which has 4020 elements.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, 2010 negatives and 2010 positives. Wait no, from \( -2010 \) to \( -1 \) is 2010 numbers, and 1 to 2010 is 2010 numbers, so together 4020 numbers. So, allowed(n) is size 4020.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m For \( |n| \geq 1 \), allowed(n) = \( \{-2010, \ldots, -|n|-1\} \cup \{ |n|+1, \ldots, 2010 \} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m The size of this set is (2010 - |n|) + (2010 - |n|) = 4020 - 2|n|.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, let's see.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m From \( -2010 \) to \( -|n|-1 \): that's 2010 + |n| elements.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Similarly, from \( |n|+1 \) to 2010: that's 2010 - |n| elements.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, total allowed(n) is (2010 + |n|) + (2010 - |n|) = 4020.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, that's interesting. So, in both cases, allowed(n) has size 4020 for each n.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Therefore, for each n, the function f(n) can choose any of the 4020 allowed numbers.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, but in our case, we're trying to choose f(n) strictly increasing, with f(n) in allowed(n).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Which is, for each n, f(n) must be in allowed(n).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Therefore, this is equivalent to choosing an increasing sequence of length 2011, where each term f(n) is in allowed(n), for each n.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m But how do we model this?
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps it's analogous to choosing an injective function from the domain to the codomain, with the additional condition that it lies within allowed(n) for each n.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, another way: in order to satisfy f being strictly increasing, we can imagine that each f(n) is selected from the allowed set, in an increasing order.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, for each n, f(n) is selected from the allowed range, with the additional condition that when sorted, they are increasing.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Hmm, perhaps the way to think about this is using inclusion-exclusion or some combinatorial methods, but it might be complex.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, hold on. Maybe an alternative approach.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Given that for each n, allowed(n) is 4020 elements, which is exactly the number of elements from -2010 to 2010, excluding 0.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m No, wait, allowed(n) is size 4020, same as the codomain without 0.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, perhaps another way: the allowed(n) is exactly the codomain without 0, but in the case of |n| >=1, allowed(n) is allowed(n) for each n, but since in this case, f is strictly increasing, f(n) is assigned to n in a way that each f(n+1) > f(n).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Therefore, perhaps we can model this as choosing a strictly increasing sequence of length 2011, where each term is in allowed(n) for n.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, but allowed(n) is different for different n.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps if we model it as being allowed(n) is allowed(n) for each n, then perhaps the overall problem is equivalent to choosing a strictly increasing sequence of length 2011, each term being selected from allowed(n) = [-2010,..., -|n|-1] U [|n]+1,...,2010], in such a way that it's strictly increasing.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, the number of functions f is equal to the number of ways to choose such sequences, which is the number of 2011-length increasing sequences with each term in allowed(n).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Which is equivalent to the number of ways to choose one element from each allowed(n) in increasing order.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, that might be similar to permutations with certain restrictions.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, alternatively, perhaps we can model this similar to choosing positions in the codomain that satisfy the conditions.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, since allowed(n) is almost the entire codomain, except 0.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, but allowed(n) is for each n, \( \{-2010, \ldots, -|n|-1\} \cup \{ |n|+1, \ldots, 2010 \} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, for each n, allowed(n) is 4020 elements.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, 2010 elements on the negative side and 2010 elements on the positive, except for 0.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, allowed(n) for each n is symmetric in a way.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Perhaps the number of such functions is the same as the number of injective increasing functions with certain restrictions. Hmm.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, is there a standard combinatorial object here? Probably similar to choosing f(n) in a way that for each n, f(n) is in allowed(n), which is similar to selecting a pparsed increasing sequence.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps another idea.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Letâ€™s note that for each n, f(n) is in allowed(n) if f(n) is not in { -|n|, ..., |n| }.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, in other words, in positions with |n|, we have to avoid the central interval.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, but since the sequence must be strictly increasing, maybe we can use some bijection.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, another idea: for each n, except for n=0, allowed(n) is the same as the codomain excluding a central interval.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m But in this case, allowed(n) is independent for each n.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, in the increasing sequence, once f(n) is chosen, the next f(n+1) has to be greater than f(n).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps using generating functions or such.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, realizing this might be too involved, perhaps we can find a bijection to some other set.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, let me consider an alternative.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Suppose we consider that for each n, allowed(n) has 4020 - 2*|n| elements? Wait, no.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, for each n, allowed(n) is 4020 if |n|=0, and 4020 - 2|n| if |n| >=1.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, wait, no.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Earlier, I thought that for each n, allowed(n) has 4020 elements, which is -2010 to 2010 except 0. Which would be 4020 elements.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, 2010 * 2. No, wait, from -2010 to -1 is 2010, 1 to 2010 is another 2010, so in total, 4020.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Yes, so for |n| >=1, allowed(n) has 4020 - 4? Wait, no.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps not. Wait, for allowed(n), for each n, size is (2010 - (|n| +1)) + (2010 - |n| ). Wait, no.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, between -2010 and -|n| -1: that's 2010 - |n| elements.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Between |n| +1 and 2010: that's 2010 - |n| elements.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So total allowed(n) size: (2010 - |n| ) + (2010 - |n| ) = 4020 - 2|n|.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Therefore, for each n with |n| >=1, allowed(n) has 4020 - 2|n| elements.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, the allowed(n) sets vary in size depending on |n|.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Hmm.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, given this, perhaps the number of such functions is the product over n of |allowed(n)|.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, no, because the choices are dependent: once f(n) is chosen, it affects allowed(n+1).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, this seems too complex.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, the problem requires that f is strictly increasing, and for each n, f(n) not in { -|n|, ..., |n| }.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, so the number of such functions is equal to the number of strictly increasing sequences \( f(-1005) < f(-1004) < \ldots < f(1005) \) such that for each \( n \) in the domain, \( |f(n)| \neq |n| \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Which is similar to an injective increasing function with forbidden zones.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, another idea: since the domain is symmetric (from -1005 to 1005), perhaps this is symmetric in some way.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, let's try to model it in general.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Suppose n ranges from -1005 to 1005, and we need f(n) to be strictly increasing.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Also, in each position n, f(n) cannot be in { -|n|, ..., |n| }.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, perhaps the number of such functions is equal to the number of ways to arrange the f(n) such that their restrictions are satisfied.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, in the realm of permutations, this might correspond to the number of injective functions with forbidden positions.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, similar to the inclusion-exclusion principle.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, perhaps the answer is \( \binom{4020}{2011} \). Because allowed(n) has 4020 elements, for each n. But given that f is strictly increasing, the number of such functions is equal to the number of ways to choose 2011 elements in increasing order, with allowed(n). Wait, no, allowed(n) varies.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, no, it's an injective increasing function from domain to codomain.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps in another way: since n ranges from -1005 to 1005, we can map it symmetrically.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Given that, maybe not.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, given that for each n, |f(n)| â‰  |n|, which can be rephrased as f(n) is not in the range [-|n|, |n|].
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, in other words, for each n, f(n) must be outside of that.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, in total, how many choices?
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Since each f(n) is in allowed(n) and f is strictly increasing.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, in the problem, it's equivalent to counting the number of "linear extensions" of a certain poset.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, a better way is to model it as a permutation.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Since f is strictly increasing, it's a bijection between domain and codomain.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, but no, the codomain has larger size.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, no, since f is from domain of size 2011 to codomain of size 4021, otherwise it's impossible.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, 2011 â‰¤ 4021, so yes.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, in this case, f is injective, increasing, mapping domain 2011 elements to the codomain 4021 elements, with the added constraint on each f(n) being outside of its middle.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, since |f(n)| â‰  |n|, but considering both positive and negative.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, in the problem, for each n, |f(n)| â‰  |n|, meaning that in the one-dimensional absolute space, f(n) cannot be in between -|n| and |n|. So, in other words, f(n) must be in the complement.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Therefore, f(n) must lie in the regions \(-2010, \ldots, -|n|-1\) or \(|n|+1, \ldots, 2010\).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, considering this, for each n, except n=0, f(n) has to lie outside the central interval of size 2|n| +1.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Therefore, the number of available choices for each f(n) is 4021 - 2*(2|n| +1) ? Wait, no.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, in each case, allowed(n) is avoiding 2|n| +1 numbers.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, no.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, allowed(n) has size 4020 - 2|n|, for nâ‰ 0, as:
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m For each nâ‰ 0, allowed(n) is 2010 - |n| + (2010 - |n|) = 4020 - 2|n|.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, allowed(n) size is 4020 - 2|n|, so forbidden size is 2*(2|n| +1) ?
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, maybe not.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, okay, maybe it's better to think in terms of for a specific n, allowed(n) has 4020 - 2|n| elements, each strictly increasing and n must choose.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, this seems too tangled. Maybe it's better to switch to another thought.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Given that for each n, allowed(n) is symmetric except n=0.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m But in this problem, because of the symmetry of domain and codomain, perhaps we can pair each n with its negative.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, perhaps it's too time-consuming.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps the answer is the same as the number of 2011-element subsets of the codomain, which is \(\binom{4021}{2011}\), but restricted by f(n) not in certain ranges.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, but in reality, for f to be strictly increasing, each f(n) must be assigned in a way such that f(n) < f(n+1), which already constrains the count.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, another idea.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m If we think of the problem as a permutation matrix, the number of 2011-increasing injective functions with forbidden positions.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m But in our case, forbidden position is |f(n)| = |n|.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, we need to count the number of injective increasing functions avoiding the diagonal |f(n)|=|n|.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, but in such problems, the number is equal to the number of derangements, but for poset.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, I'm getting too confused here.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, perhaps using inclusion-exclusion, the count is \(\prod_{n=-1005}^{1005} \frac{4021 - 2|n|}{2011 + |n|}\) ?
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, not sure.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, since the forbidden set for each n is a central range, and |n| is the middle, and the size of allowed(n) is 4020 - 2|n|, possibly the number is \(\binom{4020}{2011}\).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m But no.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, actually, perhaps for each n, the number of allowed(n) is 4020, except when n is 0.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, but regardless, I'm overcomplicating.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps notice that in the injective increasing function, since we need f: domain â†’ codomain, injective, increasing.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, the number is \(\binom{4021}{2011}\), but restricted by the forbidden positions.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Which is complicated.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, since in each n, the forbidden numbers are 2|n| +1.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, total forbidden positions.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps use the principle of inclusion-exclusion.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Define for each n, A_n as the set of functions where f(n) is in forbidden(n).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Then, the desired count is |âˆ©_{nâ‰ 0} complement A_n|.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Which is complicated.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, since for each n, forbidden(n) has size 2|n| +1.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, the number is the product over n, of the number of available choices given previous choices.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m But again, too much.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, perhaps use the fact that for each n, allowed(n) is 4020 - 2|n|, and each choice for f(n) contributes to the count.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, no, because in reality, once you choose f(n), it affects available choices for f(n+1).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, it's too complex to solve.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, maybe instead, note that the number of such functions is \( \binom{4020}{2011} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Because allowed(n) is { -2010, ..., -|n|-1 } âˆª { |n|+1, ..., 2010 }, which is 4020 - 2|n| elements.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Therefore, in total, for each n, allowed(n) has 4020 - 2|n| elements.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, the total number is the product over n of (4020 - 2|n|), but divided by something? Not exactly.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, in our case, it's not the product, because the choices are dependent due to the strict increasing.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps another idea.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Since f must be strictly increasing, so we're mapping the domain with size 2011 in an increasing fashion.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Which is similar to choosing an increasing sequence of 2011 numbers from the codomain.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Number of such sequences is \( \binom{4021}{2011} \).
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m But under our constraints.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Which is subtracting a certain number.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m But perhaps the answer is \( \binom{4021 - 2*2011}{2011} \) ?
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, no.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps in the forbidden zones.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, given that, in the codomain, when n ranges over -1005 to 1005, |n| ranges over 0 to 1005.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, the forbidden regions for f(n) are in the middle of the codomain.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, perhaps for each n with |n| â‰¤ 1005, the forbidden zone is a central interval of length 2*|n| +1.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, in the codomain, the forbidden regions compound as we move away from zero.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, in this case, the total forbidden region is the union of all |f(n)|=|n|.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, perhaps in that case, the number of allowed functions is \( \binom{4021 - 2*2011}{2011} \) ?
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, no.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, another idea.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, considering that for n in the domain, f(n) must miss certain ranges.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m So, given that, the number of allowed functions is the number of strictly increasing functions f such that |f(n)|â‰ |n| for all n.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Which in terms of forbidden positions, f(n) not in F_n, where F_n = { -|n|, ..., |n| }.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, for each n, allowed(n) = codomain \ F_n.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, for each n, the allowed values are codomain \ F_n.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Thus, if we model this as a set system, and we need a strictly increasing function avoiding certain positions.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, too complicated.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively, in the problem statement, is the condition equivalent to f being a derangement in the sense that f(n) â‰  n.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, no, f is over integers, not necessarily.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, maybe it's equivalent to f(n) being a derangement in the log scale.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Wait, too much.
[36m(TaskRunner pid=1168185)[0m 
[36m(TaskRunner pid=1168185)[0m Alternatively
[36m(TaskRunner pid=1168185)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [13:59:38<22:38, 104.49s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:01:22<20:53, 104.43s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:03:02<18:55, 103.26s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:06:03<21:04, 126.48s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:07:42<17:42, 118.09s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:09:24<15:07, 113.42s/it]
[36m(TaskRunner pid=1168185)[0m WARNING:2025-12-10 09:08:01,487:Timeout during comparison
[36m(TaskRunner pid=1168185)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:11:13<13:04, 112.09s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:12:54<10:52, 108.82s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:14:31<08:46, 105.25s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:16:15<06:58, 104.73s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:17:55<05:10, 103.40s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:19:43<03:29, 104.79s/it]
[36m(TaskRunner pid=1168185)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:21:35<01:47, 107.03s/it]
[36m(WorkerDict pid=1171846)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1171846)[0m   warnings.warn(
[36m(TaskRunner pid=1168185)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:24:57<01:48, 108.35s/it]
[36m(WorkerDict pid=1172104)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1172104)[0m   warnings.warn([32m [repeated 3x across cluster][0m
