
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_tw_covvar_0.00005/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_tw_covvar_0.00005//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_tw_covvar_0.00005//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_tw_covvar_0.00005//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_tw_covvar_0.00005/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-16 22:08:16,697	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8266 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=2016104)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-16 22:08:36,768:Waiting for register center actor 1L3sdl_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2019835)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2019835)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=2019835)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=2019657)[0m [rank0]:[W1116 22:08:54.990954393 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=2019657)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2019657)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2019657)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019657)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m [rank3]:[W1116 22:08:54.163491834 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2019657)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2019657)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2019835)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(WorkerDict pid=2019836)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=2019835)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019835)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:   0%|          | 1/480 [02:00<16:02:55, 120.62s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   0%|          | 2/480 [04:02<16:05:49, 121.23s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   1%|          | 3/480 [06:07<16:17:33, 122.96s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   1%|          | 4/480 [08:07<16:07:44, 121.98s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   1%|          | 5/480 [10:09<16:05:24, 121.95s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   1%|â–         | 6/480 [12:11<16:04:24, 122.08s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   1%|â–         | 7/480 [14:15<16:06:12, 122.56s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   2%|â–         | 8/480 [16:17<16:03:02, 122.42s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-16 22:28:36,776:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:   2%|â–         | 9/480 [18:22<16:06:31, 123.12s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   2%|â–         | 10/480 [21:47<19:21:38, 148.30s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   2%|â–         | 11/480 [23:44<18:06:27, 138.99s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   2%|â–Ž         | 12/480 [25:45<17:19:27, 133.26s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   3%|â–Ž         | 13/480 [27:44<16:45:26, 129.18s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   3%|â–Ž         | 14/480 [29:45<16:23:27, 126.63s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   3%|â–Ž         | 15/480 [31:43<16:00:50, 123.98s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   3%|â–Ž         | 16/480 [33:42<15:47:42, 122.55s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   4%|â–Ž         | 17/480 [35:43<15:41:04, 121.95s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   4%|â–         | 18/480 [37:38<15:22:53, 119.86s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   4%|â–         | 19/480 [39:36<15:16:58, 119.35s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-16 22:53:40,437:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:   4%|â–         | 20/480 [43:01<18:32:02, 145.05s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   4%|â–         | 21/480 [45:00<17:29:59, 137.25s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   5%|â–         | 22/480 [46:58<16:43:35, 131.47s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   5%|â–         | 23/480 [48:55<16:07:36, 127.04s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   5%|â–Œ         | 24/480 [50:51<15:41:38, 123.90s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   5%|â–Œ         | 25/480 [52:47<15:20:30, 121.39s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   5%|â–Œ         | 26/480 [54:44<15:09:42, 120.23s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   6%|â–Œ         | 27/480 [56:43<15:04:52, 119.85s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   6%|â–Œ         | 28/480 [58:36<14:46:42, 117.71s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:34<14:44:51, 117.72s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:44<17:25:35, 139.41s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-16 23:15:54,303:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:37<16:24:09, 131.51s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:24<15:27:50, 124.26s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:17<15:01:20, 120.99s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:12<14:44:48, 119.03s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:03<14:24:50, 116.61s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:53<14:09:09, 114.75s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:44<13:58:11, 113.52s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:40<14:01:04, 114.17s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:27<13:44:02, 112.11s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:36<16:31:16, 135.17s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:27<15:35:07, 127.81s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:20<15:01:25, 123.48s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   9%|â–‰         | 43/480 [1:29:08<14:25:52, 118.89s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:58<14:04:31, 116.22s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:44<13:40:25, 113.16s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:35<13:33:27, 112.46s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:22<13:20:53, 110.98s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:14<13:21:07, 111.27s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:09<13:25:37, 112.15s/it]
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(TaskRunner pid=2016104)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:28<16:30:21, 138.19s/it]
[36m(WorkerDict pid=2019836)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:12<15:16:31, 128.18s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:47:00<14:30:33, 122.04s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:42<13:46:28, 116.13s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:33<13:31:56, 114.36s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:17<13:08:43, 111.35s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:02<12:53:55, 109.52s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:52<12:53:05, 109.66s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:36<12:39:42, 108.02s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 00:09:44,543:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:59:24<12:36:45, 107.85s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:15<14:47:20, 126.76s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:04<14:07:35, 121.37s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:49<13:31:48, 116.53s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:07:34<13:05:18, 112.99s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:09:23<12:56:43, 112.03s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:11:05<12:32:45, 108.83s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:12:54<12:31:13, 108.87s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:14:38<12:19:50, 107.48s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:16:22<12:11:52, 106.58s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:18:10<12:12:26, 106.92s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:21:05<14:29:48, 127.29s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:22:53<13:48:13, 121.50s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:24:38<13:13:10, 116.64s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:26:24<12:49:18, 113.41s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:28:13<12:37:47, 111.99s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 00:40:20,467:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:30:02<12:30:12, 111.14s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:31:51<12:23:33, 110.43s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:33:35<12:08:53, 108.52s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:35:19<11:59:01, 107.32s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:37:08<12:00:20, 107.78s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:40:03<14:12:43, 127.91s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:41:49<13:27:14, 121.39s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:43:33<12:50:46, 116.20s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:45:18<12:26:49, 112.87s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:47:05<12:12:58, 111.06s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:48:49<11:57:32, 108.99s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:50:35<11:49:13, 108.00s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:52:23<11:47:06, 107.96s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:54:12<11:48:15, 108.41s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:55:54<11:33:02, 106.35s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:58:48<13:42:53, 126.60s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:00:29<12:51:04, 118.93s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:02:10<12:13:53, 113.49s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:03:53<11:52:53, 110.53s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 01:16:00,144:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:05:44<11:50:49, 110.49s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:07:26<11:33:42, 108.11s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:09:16<11:35:36, 108.69s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:10:56<11:17:25, 106.13s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:12:32<10:54:57, 102.87s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:14:21<11:05:59, 104.88s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 01:26:28,845:Timeout during comparison
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(WorkerDict pid=2019657)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2019657)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=2016104)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:17:38<13:59:37, 132.57s/it]
[36m(WorkerDict pid=2019836)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:19:17<12:52:37, 122.32s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:20:57<12:09:24, 115.78s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:22:35<11:33:45, 110.41s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:24:14<11:10:53, 107.06s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:25:59<11:04:41, 106.35s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:27:37<10:47:16, 103.84s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:29:21<10:45:52, 103.89s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:30:57<10:29:05, 101.47s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:32:47<10:42:56, 103.98s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:35:39<12:48:25, 124.61s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:37:22<12:06:13, 118.08s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:38:59<11:23:53, 111.50s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:40:40<11:03:33, 108.48s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:42:25<10:54:37, 107.32s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:43:59<10:29:31, 103.48s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:45:36<10:16:22, 101.60s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:47:16<10:10:51, 100.97s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:49:07<10:27:20, 103.98s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 02:01:10,621:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:50:51<10:25:47, 104.01s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:53:43<12:26:59, 124.50s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:55:19<11:34:18, 116.04s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:57:02<11:07:57, 111.95s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 02:09:10,820:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:58:49<10:58:00, 110.59s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:00:39<10:55:25, 110.47s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:02:21<10:37:44, 107.79s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:04:02<10:23:09, 105.62s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:05:43<10:14:22, 104.43s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:07:25<10:08:15, 103.68s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:09:08<10:05:20, 103.48s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:12:01<12:05:47, 124.42s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:13:47<11:30:50, 118.77s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:15:27<10:55:33, 113.03s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:17:09<10:34:18, 109.68s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:18:50<10:18:10, 107.20s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:20:31<10:06:27, 105.47s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:22:16<10:02:39, 105.12s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:23:56<9:51:54, 103.54s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:25:39<9:49:43, 103.46s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:27:22<9:47:34, 103.39s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:30:14<11:41:59, 123.88s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:31:59<11:07:39, 118.17s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:33:38<10:34:00, 112.54s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:35:21<10:15:56, 109.66s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:37:00<9:55:33, 106.35s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:38:43<9:49:08, 105.52s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:40:20<9:33:14, 102.98s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:41:58<9:23:22, 101.51s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:43:38<9:18:30, 100.94s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:45:22<9:22:44, 102.01s/it]
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(TaskRunner pid=2016104)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:48:33<11:46:50, 128.52s/it]
[36m(WorkerDict pid=2019836)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:50:15<11:00:56, 120.54s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:51:58<10:30:06, 115.26s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:53:36<10:00:47, 110.24s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:55:18<9:45:15, 107.72s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:56:59<9:31:54, 105.58s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:58:35<9:14:54, 102.76s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:00:14<9:08:10, 101.83s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:02:00<9:11:57, 102.85s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:03:41<9:07:15, 102.29s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:06:33<10:57:52, 123.35s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:08:23<10:33:48, 119.21s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:10:08<10:10:10, 115.13s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:11:47<9:41:41, 110.10s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:13:26<9:22:58, 106.90s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:15:05<9:09:16, 104.62s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:16:47<9:03:22, 103.83s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:18:26<8:53:10, 102.21s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:20:09<8:53:16, 102.55s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:21:46<8:43:02, 100.91s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:24:37<10:29:00, 121.74s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:26:16<9:52:51, 115.12s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:27:57<9:28:30, 110.75s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:29:37<9:10:27, 107.58s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:31:17<8:56:50, 105.26s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:32:59<8:51:00, 104.46s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:34:42<8:46:13, 103.86s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:36:22<8:38:39, 102.70s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:38:07<8:39:57, 103.30s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:39:50<8:38:07, 103.28s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:42:46<10:26:09, 125.23s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 03:54:53,089:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:44:33<9:55:52, 119.57s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:46:13<9:24:51, 113.73s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:47:55<9:06:31, 110.41s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:49:33<8:46:12, 106.67s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:51:20<8:44:44, 106.73s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:53:01<8:33:58, 104.89s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 04:05:04,494:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:54:44<8:30:11, 104.48s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:56:27<8:25:46, 103.93s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:58:13<8:27:23, 104.62s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:01:03<9:59:36, 124.06s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:02:39<9:18:14, 115.90s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:04:19<8:52:28, 110.93s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:06:00<8:36:01, 107.88s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:07:43<8:27:41, 106.51s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:09:21<8:13:53, 103.98s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:11:03<8:09:57, 103.51s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:12:42<8:00:49, 101.94s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:14:23<7:57:49, 101.67s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:16:00<7:50:18, 100.42s/it]
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(TaskRunner pid=2016104)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:19:13<9:58:39, 128.28s/it]
[36m(WorkerDict pid=2019836)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:20:55<9:19:45, 120.38s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:22:40<8:56:19, 115.75s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 04:34:44,548:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:24:24<8:37:52, 112.18s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:26:04<8:19:39, 108.62s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:27:46<8:08:03, 106.49s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:29:31<8:04:28, 106.09s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:31:17<8:02:21, 106.01s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:32:53<7:47:22, 103.10s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:34:31<7:38:34, 101.53s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:37:29<9:19:37, 124.36s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:39:10<8:45:48, 117.28s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:40:50<8:21:45, 112.33s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:42:34<8:08:08, 109.70s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:44:17<7:57:48, 107.78s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:45:55<7:43:05, 104.85s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:47:33<7:32:34, 102.86s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:49:12<7:25:12, 101.57s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:50:48<7:16:29, 99.96s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:52:35<7:23:58, 102.06s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:55:25<8:50:53, 122.51s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:57:05<8:18:36, 115.51s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:58:48<8:00:50, 111.82s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:00:23<7:37:06, 106.72s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:02:06<7:31:08, 105.74s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:03:44<7:19:46, 103.48s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:05:22<7:10:57, 101.80s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:07:05<7:10:05, 102.00s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:08:45<7:06:36, 101.57s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:10:27<7:05:46, 101.78s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:13:20<8:32:38, 123.03s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:14:59<8:01:00, 115.90s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:16:41<7:41:57, 111.77s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:18:21<7:25:13, 108.15s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:19:59<7:10:45, 105.06s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:21:39<7:02:26, 103.45s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:23:16<6:53:17, 101.63s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:24:56<6:49:28, 101.11s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:26:44<6:56:35, 103.29s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:28:25<6:51:38, 102.48s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:31:21<8:18:14, 124.56s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:33:10<7:57:38, 119.91s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:34:53<7:35:37, 114.87s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:36:35<7:18:13, 110.94s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:38:15<7:03:59, 107.80s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:39:59<6:57:26, 106.58s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:41:38<6:46:29, 104.23s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:43:21<6:44:01, 104.04s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:45:06<6:42:32, 104.11s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:46:50<6:40:29, 104.02s/it]
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(TaskRunner pid=2016104)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:50:00<8:17:36, 129.81s/it]
[36m(WorkerDict pid=2019836)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:51:38<7:40:00, 120.53s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:53:19<7:14:52, 114.44s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:55:00<6:57:33, 110.37s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:56:39<6:43:25, 107.11s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:58:19<6:33:29, 104.93s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:00:02<6:29:47, 104.41s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:01:39<6:20:11, 102.30s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:03:24<6:21:12, 103.03s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:05:02<6:13:30, 101.41s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:07:54<7:29:26, 122.58s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:09:37<7:05:45, 116.65s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:11:23<6:52:43, 113.59s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:13:07<6:40:49, 110.83s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:14:56<6:36:40, 110.19s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:16:34<6:21:28, 106.46s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:18:18<6:17:01, 105.71s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:19:58<6:09:21, 104.05s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:21:35<5:59:47, 101.83s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:23:15<5:56:41, 101.43s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:26:08<7:10:17, 122.94s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:27:51<6:47:20, 116.94s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:29:27<6:23:04, 110.50s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:31:07<6:10:59, 107.53s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:32:53<6:07:28, 107.03s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:34:31<5:56:46, 104.42s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:36:15<5:54:01, 104.12s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:38:02<5:55:11, 104.99s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:39:43<5:49:14, 103.73s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:41:24<5:45:30, 103.13s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:44:16<6:52:39, 123.80s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:45:49<6:19:01, 114.28s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:47:28<6:02:42, 109.91s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:49:08<5:51:01, 106.91s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:50:52<5:46:00, 105.92s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:52:35<5:41:29, 105.08s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:54:14<5:33:40, 103.20s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:55:54<5:28:52, 102.24s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:57:33<5:24:05, 101.28s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:59:13<5:21:02, 100.85s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:02:11<6:33:13, 124.18s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:03:51<6:08:24, 116.95s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:05:31<5:50:32, 111.87s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:07:09<5:35:11, 107.55s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:08:48<5:25:51, 105.11s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:10:29<5:20:05, 103.81s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:12:12<5:18:04, 103.72s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:13:49<5:09:23, 101.44s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:15:31<5:08:28, 101.70s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:17:09<5:03:37, 100.65s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 07:29:13,940:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 07:29:18,961:Timeout during comparison
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(TaskRunner pid=2016104)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:20:22<6:24:53, 128.30s/it]
[36m(WorkerDict pid=2019836)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:22:02<5:57:19, 119.77s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:23:39<5:35:23, 113.06s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:25:20<5:22:14, 109.23s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:27:00<5:12:56, 106.68s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:28:37<5:02:24, 103.68s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:30:16<4:56:38, 102.29s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:31:50<4:48:11, 99.95s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:33:28<4:44:48, 99.35s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 07:45:37,734:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:35:16<4:49:59, 101.75s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:38:03<5:44:08, 121.46s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:39:42<5:23:19, 114.79s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:41:20<5:07:13, 109.72s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:42:58<4:54:58, 105.98s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:44:37<4:48:05, 104.13s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:46:20<4:45:24, 103.79s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:48:07<4:45:45, 104.54s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 08:00:10,566:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 08:00:15,603:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:49:52<4:44:48, 104.84s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:51:32<4:38:50, 103.28s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:53:13<4:35:06, 102.52s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:56:02<5:26:31, 122.44s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:57:42<5:06:47, 115.77s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 08:09:45,112:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:59:26<4:56:07, 112.45s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:01:03<4:41:44, 107.67s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:02:49<4:38:24, 107.08s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:04:28<4:30:57, 104.89s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:06:08<4:25:09, 103.31s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:07:48<4:20:30, 102.16s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:09:27<4:16:42, 101.33s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:11:01<4:09:48, 99.26s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:13:47<4:57:51, 119.14s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:15:19<4:35:21, 110.88s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:16:53<4:21:02, 105.83s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:18:33<4:15:31, 104.30s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:20:09<4:07:22, 101.66s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:21:44<4:00:56, 99.70s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:23:22<3:58:18, 99.30s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:25:00<3:55:35, 98.85s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:26:38<3:53:16, 98.57s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:28:14<3:49:48, 97.79s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:31:04<4:38:35, 119.40s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:32:43<4:22:41, 113.39s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:34:23<4:11:09, 109.20s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:36:01<4:02:00, 105.99s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:37:35<3:52:13, 102.45s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:39:18<3:50:38, 102.51s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:40:58<3:47:25, 101.83s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:42:39<3:45:15, 101.62s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:44:20<3:42:49, 101.28s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:45:56<3:37:45, 99.74s/it] 
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(TaskRunner pid=2016104)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:49:04<4:33:36, 126.28s/it]
[36m(WorkerDict pid=2019836)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:50:46<4:15:29, 118.83s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:52:28<4:03:07, 113.97s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:54:12<3:54:48, 110.93s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:55:55<3:48:12, 108.67s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:57:36<3:41:15, 106.21s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:59:13<3:33:33, 103.33s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:00:53<3:30:18, 102.59s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:02:32<3:26:28, 101.55s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:04:21<3:28:49, 103.55s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:07:14<4:08:39, 124.33s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:08:55<3:52:43, 117.34s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:10:39<3:43:07, 113.46s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:12:18<3:32:41, 109.08s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:13:58<3:25:39, 106.38s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:15:35<3:18:48, 103.72s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:17:12<3:12:43, 101.43s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:18:48<3:08:00, 99.83s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:20:28<3:06:48, 100.07s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 09:32:33,872:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 09:32:39,610:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:22:16<3:09:10, 102.25s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:25:14<3:49:10, 125.00s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:26:55<3:34:16, 117.95s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:28:40<3:25:17, 114.05s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:30:23<3:17:09, 110.56s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:31:59<3:07:36, 106.19s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:33:38<3:02:29, 104.28s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:35:18<2:58:13, 102.82s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:36:59<2:55:33, 102.26s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:38:38<2:52:26, 101.43s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:40:17<2:49:31, 100.71s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:43:10<3:23:53, 122.33s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:44:51<3:11:11, 115.88s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:46:33<3:02:40, 111.85s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:48:16<2:56:18, 109.06s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 10:00:30,354:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:50:10<2:57:03, 110.66s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:51:51<2:50:22, 107.61s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:53:33<2:45:51, 105.87s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:55:20<2:44:55, 106.40s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:56:59<2:39:36, 104.09s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:58:41<2:37:06, 103.58s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:01:37<3:07:47, 125.20s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:03:19<2:55:36, 118.38s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:04:56<2:43:53, 111.74s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:06:31<2:34:55, 106.84s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:08:10<2:29:56, 104.61s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:09:58<2:29:16, 105.37s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:11:32<2:23:02, 102.17s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:13:10<2:19:26, 100.80s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:14:51<2:17:57, 100.94s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:16:29<2:14:50, 99.88s/it] 
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(TaskRunner pid=2016104)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:19:40<2:49:48, 127.36s/it]
[36m(WorkerDict pid=2019836)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:21:21<2:37:10, 119.37s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:23:05<2:29:14, 114.80s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:24:46<2:22:07, 110.75s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:26:25<2:15:42, 107.14s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:28:00<2:09:26, 103.56s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:29:41<2:06:46, 102.79s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:31:23<2:04:42, 102.51s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:33:04<2:02:30, 102.10s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:34:45<2:00:31, 101.86s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:37:40<2:24:18, 123.69s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:39:18<2:13:30, 116.09s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:40:57<2:05:29, 110.73s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:42:35<1:59:37, 107.12s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:44:16<1:55:34, 105.07s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:45:49<1:50:04, 101.60s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:47:26<1:46:53, 100.22s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:49:08<1:45:50, 100.80s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:50:47<1:43:24, 100.07s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:52:24<1:41:02, 99.39s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:55:21<2:02:31, 122.53s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:57:01<1:53:55, 115.86s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:58:48<1:49:26, 113.21s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:00:26<1:43:03, 108.48s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:02:07<1:39:09, 106.25s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:03:47<1:35:47, 104.50s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:05:27<1:32:54, 103.23s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:07:07<1:30:17, 102.21s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:08:50<1:28:39, 102.30s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:10:28<1:25:49, 100.97s/it]
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 11:22:32,087:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m WARNING:2025-11-17 11:22:40,205:Timeout during comparison
[36m(TaskRunner pid=2016104)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:13:28<1:43:54, 124.69s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:15:05<1:35:11, 116.57s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:16:43<1:28:42, 110.88s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:18:29<1:25:45, 109.48s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:20:09<1:21:38, 106.50s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:21:46<1:17:44, 103.65s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:23:26<1:15:14, 102.61s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:25:05<1:12:42, 101.45s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:26:44<1:10:40, 100.97s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:28:26<1:09:03, 101.06s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:31:17<1:21:28, 122.21s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:32:57<1:14:58, 115.35s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:34:41<1:10:52, 111.91s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:36:19<1:06:35, 107.98s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:37:59<1:03:15, 105.42s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:39:40<1:00:48, 104.25s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:41:18<57:56, 102.24s/it]  
[36m(TaskRunner pid=2016104)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:42:53<55:08, 100.26s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:44:29<52:43, 98.85s/it] 
[36m(TaskRunner pid=2016104)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:46:12<51:39, 99.99s/it]
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(TaskRunner pid=2016104)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:49:21<1:03:25, 126.84s/it]
[36m(WorkerDict pid=2019836)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2016104)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:51:02<57:29, 118.93s/it]  
[36m(TaskRunner pid=2016104)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:52:38<52:22, 112.22s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:54:20<49:05, 109.08s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:55:58<45:47, 105.69s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:57:32<42:33, 102.16s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:59:12<40:39, 101.63s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:00:58<39:25, 102.84s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:02:37<37:19, 101.79s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:04:14<35:08, 100.42s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:07:08<40:50, 122.52s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:08:48<36:36, 115.60s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:10:25<33:02, 110.16s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:12:05<30:19, 107.02s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:13:43<27:46, 104.17s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:15:21<25:38, 102.54s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:17:03<23:52, 102.32s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:18:42<21:55, 101.23s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:20:22<20:10, 100.88s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:22:02<18:26, 100.61s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:24:58<20:33, 123.32s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:26:36<17:22, 115.80s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:28:17<14:49, 111.22s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:29:56<12:33, 107.62s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:31:35<10:29, 104.91s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:33:11<08:32, 102.45s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:34:56<06:52, 103.06s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:36:35<05:06, 102.01s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:38:21<03:26, 103.05s/it]
[36m(TaskRunner pid=2016104)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:40:09<01:44, 104.48s/it]
[36m(WorkerDict pid=2019657)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2019657)[0m   warnings.warn(
[36m(TaskRunner pid=2016104)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:43:23<01:50, 110.65s/it]
[36m(WorkerDict pid=2019836)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2019836)[0m   warnings.warn([32m [repeated 3x across cluster][0m
+ DES
./scripts/train_1_5b.sh: line 73: DES: command not found
