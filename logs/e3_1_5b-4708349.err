
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.05/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_covvar_kappa_0.05//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.05//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.05//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_covvar_kappa_0.05/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-09 21:56:33,000	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=2755424)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-09 21:56:56,308:Waiting for register center actor bAnFNh_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2759186)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2759188)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=2759188)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=2759186)[0m [rank1]:[W1109 21:57:17.493895584 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=2758974)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2758974)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2758974)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2758974)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2758974)[0m [rank0]:[W1109 21:57:18.462529854 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2758974)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2758974)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2759186)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(WorkerDict pid=2759187)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:   0%|          | 1/480 [01:59<15:52:32, 119.32s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   0%|          | 2/480 [03:58<15:52:01, 119.50s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   1%|          | 3/480 [06:01<16:01:08, 120.90s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   1%|          | 4/480 [07:58<15:46:50, 119.35s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   1%|          | 5/480 [09:57<15:45:05, 119.38s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   1%|â–         | 6/480 [11:58<15:47:36, 119.95s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   1%|â–         | 7/480 [14:01<15:51:18, 120.67s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-09 22:15:04,189:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:   2%|â–         | 8/480 [16:05<15:59:25, 121.96s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   2%|â–         | 9/480 [18:04<15:48:11, 120.79s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   2%|â–         | 10/480 [21:23<18:55:47, 145.00s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   2%|â–         | 11/480 [23:19<17:43:42, 136.08s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   2%|â–Ž         | 12/480 [25:14<16:51:58, 129.74s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   3%|â–Ž         | 13/480 [27:11<16:20:44, 126.01s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   3%|â–Ž         | 14/480 [29:10<16:01:35, 123.81s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   3%|â–Ž         | 15/480 [31:04<15:36:27, 120.83s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   3%|â–Ž         | 16/480 [33:02<15:27:20, 119.91s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   4%|â–Ž         | 17/480 [35:01<15:23:00, 119.61s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   4%|â–         | 18/480 [36:57<15:13:27, 118.63s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   4%|â–         | 19/480 [38:54<15:07:44, 118.14s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   4%|â–         | 20/480 [42:10<18:05:09, 141.54s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   4%|â–         | 21/480 [44:07<17:07:01, 134.25s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   5%|â–         | 22/480 [46:05<16:26:21, 129.22s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   5%|â–         | 23/480 [48:03<15:58:09, 125.80s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   5%|â–Œ         | 24/480 [49:56<15:28:45, 122.21s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   5%|â–Œ         | 25/480 [51:49<15:05:29, 119.41s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   5%|â–Œ         | 26/480 [53:47<14:59:31, 118.88s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   6%|â–Œ         | 27/480 [55:47<15:00:00, 119.21s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   6%|â–Œ         | 28/480 [57:37<14:37:47, 116.52s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   6%|â–Œ         | 29/480 [59:33<14:33:33, 116.22s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   6%|â–‹         | 30/480 [1:02:38<17:07:08, 136.95s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   6%|â–‹         | 31/480 [1:04:23<15:53:53, 127.47s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:07<14:58:43, 120.37s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:03<14:45:34, 118.87s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   7%|â–‹         | 34/480 [1:09:55<14:28:15, 116.81s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   7%|â–‹         | 35/480 [1:11:45<14:11:07, 114.76s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   8%|â–Š         | 36/480 [1:13:31<13:50:49, 112.27s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   8%|â–Š         | 37/480 [1:15:21<13:43:06, 111.48s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   8%|â–Š         | 38/480 [1:17:15<13:46:31, 112.20s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   8%|â–Š         | 39/480 [1:19:00<13:30:02, 110.21s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   8%|â–Š         | 40/480 [1:22:06<16:15:37, 133.04s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   9%|â–Š         | 41/480 [1:23:54<15:17:32, 125.41s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   9%|â–‰         | 42/480 [1:25:47<14:48:02, 121.65s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   9%|â–‰         | 43/480 [1:27:32<14:10:48, 116.82s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   9%|â–‰         | 44/480 [1:29:20<13:48:42, 114.04s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:   9%|â–‰         | 45/480 [1:31:02<13:20:34, 110.42s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  10%|â–‰         | 46/480 [1:32:49<13:11:53, 109.48s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  10%|â–‰         | 47/480 [1:34:36<13:03:25, 108.56s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:36:23<12:59:55, 108.32s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:38:15<13:04:45, 109.25s/it]
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(TaskRunner pid=2755424)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:41:31<16:09:53, 135.33s/it]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:43:16<15:03:34, 126.37s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:44:59<14:11:03, 119.31s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:46:39<13:27:10, 113.42s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:48:25<13:10:17, 111.31s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:50:07<12:47:27, 108.35s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:51:50<12:35:20, 106.89s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:53:38<12:34:33, 107.03s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:55:18<12:18:28, 105.00s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:56:59<12:07:39, 103.70s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [1:59:48<14:24:35, 123.51s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:01:32<13:40:00, 117.42s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:03:12<13:03:37, 112.48s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:04:53<12:36:53, 108.90s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:06:40<12:31:58, 108.46s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:08:19<12:10:30, 105.62s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:10:05<12:08:56, 105.64s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:11:45<11:56:08, 104.04s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:13:26<11:48:06, 103.12s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:15:09<11:45:50, 103.04s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:18:05<14:13:25, 124.89s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:19:47<13:23:09, 117.82s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:21:26<12:44:32, 112.43s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:23:06<12:17:08, 108.67s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:24:49<12:03:42, 106.95s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:26:31<11:51:38, 105.43s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 00:27:25,723:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:28:22<12:01:10, 107.11s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:30:05<11:50:24, 105.77s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:31:47<11:41:15, 104.66s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:33:32<11:40:53, 104.87s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 00:35:51,880:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:36:28<14:01:50, 126.28s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:38:10<13:10:36, 118.89s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:39:51<12:33:23, 113.58s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:41:34<12:10:19, 110.38s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:43:17<11:52:43, 107.99s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:44:57<11:35:18, 105.62s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:46:40<11:29:55, 105.06s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:48:23<11:23:16, 104.32s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:50:08<11:22:20, 104.44s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:51:46<11:08:11, 102.54s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:54:38<13:21:49, 123.36s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [2:56:14<12:27:50, 115.35s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 00:57:04,353:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [2:57:58<12:03:11, 111.83s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [2:59:39<11:39:46, 108.49s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:01:22<11:26:55, 106.78s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:02:59<11:08:14, 104.14s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:04:43<11:06:08, 104.09s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:06:22<10:53:54, 102.44s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:07:54<10:32:44, 99.38s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:09:39<10:40:45, 100.91s/it]
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(WorkerDict pid=2758974)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2758974)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=2755424)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:12:48<13:26:19, 127.31s/it]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:14:25<12:27:38, 118.36s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:16:05<11:49:43, 112.65s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:17:42<11:18:28, 107.98s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:19:16<10:51:30, 103.96s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:21:01<10:50:52, 104.14s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:22:37<10:35:21, 101.93s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:24:21<10:36:46, 102.43s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:25:57<10:22:28, 100.40s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:27:46<10:38:03, 103.19s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:30:38<12:43:19, 123.78s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:32:20<12:00:43, 117.19s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:33:53<11:13:54, 109.88s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:35:31<10:50:52, 106.41s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:37:14<10:41:59, 105.24s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:38:44<10:12:05, 100.62s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 01:39:30,972:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:40:24<10:09:17, 100.43s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:42:03<10:06:37, 100.27s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:43:41<10:00:08, 99.47s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:45:19<9:55:02, 98.90s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:48:09<12:01:25, 120.24s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:49:41<11:08:46, 111.77s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:51:24<10:51:26, 109.18s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 01:52:12,047:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:53:07<10:38:20, 107.28s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [3:54:54<10:36:15, 107.24s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [3:56:29<10:13:04, 103.62s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [3:58:07<10:01:48, 102.00s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [3:59:43<9:49:50, 100.26s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:01:21<9:44:09, 99.57s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:02:58<9:37:39, 98.74s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:05:47<11:38:06, 119.68s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:07:27<11:01:56, 113.80s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 02:08:11,320:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:09:04<10:30:22, 108.69s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:10:42<10:11:35, 105.75s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:12:20<9:55:36, 103.28s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:14:00<9:48:10, 102.29s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:15:39<9:41:31, 101.43s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:17:15<9:30:35, 99.81s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:18:58<9:33:24, 100.60s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:20:38<9:30:31, 100.39s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:23:25<11:22:41, 120.47s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:25:06<10:46:52, 114.49s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:26:41<10:11:59, 108.64s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:28:20<9:53:56, 105.75s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:29:54<9:32:50, 102.29s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:31:30<9:20:33, 100.40s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:33:01<9:03:31, 97.64s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:34:34<8:54:39, 96.33s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:36:10<8:52:29, 96.23s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:37:52<9:00:23, 97.96s/it]
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(TaskRunner pid=2755424)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:40:54<11:17:36, 123.20s/it]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:42:35<10:39:11, 116.57s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 02:43:23,590:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:44:20<10:16:58, 112.86s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:45:58<9:51:56, 108.61s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:47:39<9:37:29, 106.29s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:49:17<9:21:57, 103.75s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:50:50<9:02:32, 100.47s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [4:52:24<8:51:14, 98.68s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [4:54:05<8:52:42, 99.26s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [4:55:43<8:49:11, 98.92s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [4:58:34<10:43:28, 120.65s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:00:21<10:18:54, 116.41s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:02:02<9:52:30, 111.79s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:03:40<9:28:44, 107.65s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:05:14<9:06:04, 103.68s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:06:51<8:53:30, 101.62s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 03:07:41,244:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:08:36<8:56:30, 102.52s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:10:09<8:40:23, 99.76s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:11:48<8:37:22, 99.50s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:13:22<8:27:46, 97.96s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:16:08<10:11:30, 118.36s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:17:46<9:37:00, 112.04s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:19:22<9:10:55, 107.32s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:20:59<8:53:40, 104.30s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:22:34<8:37:30, 101.47s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:24:16<8:36:09, 101.54s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:25:55<8:30:26, 100.75s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:27:32<8:23:18, 99.66s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:29:12<8:23:06, 99.95s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:30:51<8:19:07, 99.49s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:33:44<10:07:17, 121.46s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:35:23<9:32:25, 114.87s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:37:00<9:03:16, 109.39s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:38:40<8:48:36, 106.79s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:40:14<8:27:30, 102.87s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:41:56<8:24:18, 102.57s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 03:42:42,530:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:43:37<8:20:56, 102.23s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:45:12<8:07:38, 99.86s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:46:51<8:04:54, 99.64s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:48:30<8:02:04, 99.40s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [5:51:14<9:34:09, 118.79s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [5:52:48<8:57:18, 111.55s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [5:54:21<8:28:03, 105.85s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [5:55:57<8:12:34, 102.98s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [5:57:33<8:01:07, 100.93s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [5:59:05<7:46:00, 98.11s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:00:45<7:47:49, 98.84s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:02:23<7:44:37, 98.51s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:04:02<7:42:51, 98.48s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:05:35<7:34:18, 97.01s/it]
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(TaskRunner pid=2755424)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:08:41<9:36:55, 123.63s/it]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:10:16<8:55:40, 115.20s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:11:54<8:28:35, 109.77s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:13:28<8:05:20, 105.13s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:15:05<7:52:12, 102.65s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:16:41<7:41:56, 100.79s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:18:20<7:38:10, 100.33s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:20:01<7:37:21, 100.52s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:21:32<7:22:36, 97.63s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:23:06<7:15:35, 96.44s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:25:56<8:53:48, 118.62s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 04:26:43,123:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:27:36<8:26:54, 113.07s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:29:14<8:03:48, 108.32s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:30:53<7:50:32, 105.74s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:32:32<7:39:53, 103.73s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:34:05<7:23:57, 100.52s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:35:41<7:15:29, 98.98s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:37:17<7:10:21, 98.18s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:38:49<6:59:55, 96.17s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:40:33<7:08:53, 98.59s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 04:42:46,777:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:43:22<8:39:21, 119.85s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:44:58<8:05:43, 112.52s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:46:37<7:47:17, 108.67s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:48:08<7:21:54, 103.17s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [6:49:48<7:16:16, 102.25s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [6:51:24<7:06:40, 100.40s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [6:52:58<6:56:54, 98.48s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [6:54:42<7:02:08, 100.11s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [6:56:19<6:57:12, 99.33s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [6:58:03<7:00:15, 100.46s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:00:51<8:23:51, 120.93s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 05:01:36,111:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:02:33<7:57:55, 115.16s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:04:10<7:33:41, 109.76s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:05:49<7:18:06, 106.42s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:07:23<7:01:28, 102.80s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:09:02<6:54:29, 101.51s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:10:38<6:46:42, 100.01s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:12:12<6:38:02, 98.28s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:13:55<6:42:14, 99.73s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:15:32<6:36:47, 98.79s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:18:25<8:04:16, 121.07s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:20:11<7:44:06, 116.51s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:21:50<7:21:36, 111.33s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:23:32<7:08:03, 108.37s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:25:09<6:53:39, 105.17s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:26:51<6:47:28, 104.04s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:28:30<6:39:50, 102.52s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:30:09<6:34:39, 101.63s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:31:50<6:32:29, 101.51s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:33:32<6:30:58, 101.55s/it]
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(TaskRunner pid=2755424)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:36:41<8:10:00, 127.83s/it]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:38:17<7:31:36, 118.33s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 05:39:04,750:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:40:02<7:14:02, 114.22s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:41:40<6:53:34, 109.31s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 05:42:26,505:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:43:22<6:43:58, 107.25s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 05:44:08,899:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:45:04<6:35:24, 105.44s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:46:44<6:27:53, 103.90s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:48:19<6:16:21, 101.26s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:50:01<6:15:00, 101.35s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [7:51:35<6:05:21, 99.19s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [7:54:21<7:17:46, 119.39s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [7:56:01<6:54:44, 113.63s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [7:57:44<6:40:42, 110.29s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [7:59:24<6:27:21, 107.10s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:01:06<6:20:18, 105.64s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:02:40<6:06:42, 102.34s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:04:19<6:00:29, 101.07s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 06:05:07,422:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:06:01<6:00:25, 101.53s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:07:32<5:47:36, 98.38s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:09:09<5:44:41, 98.02s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:11:59<6:58:37, 119.61s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:13:38<6:35:08, 113.44s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:15:13<6:13:27, 107.73s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:16:49<5:59:54, 104.32s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:18:29<5:54:00, 103.11s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:20:04<5:43:28, 100.53s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:21:44<5:41:26, 100.42s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:23:26<5:41:14, 100.86s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:25:04<5:36:12, 99.86s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:26:44<5:34:55, 99.98s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:29:33<6:42:04, 120.62s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:31:04<6:10:47, 111.79s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:32:40<5:53:08, 107.01s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:34:20<5:44:35, 104.95s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:36:00<5:38:26, 103.61s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:37:41<5:34:18, 102.87s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:39:19<5:27:22, 101.25s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:40:58<5:23:53, 100.69s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:42:39<5:22:22, 100.74s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:44:18<5:18:53, 100.17s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:47:13<6:28:38, 122.73s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:48:51<6:02:29, 115.08s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [8:50:31<5:46:56, 110.72s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [8:52:08<5:32:16, 106.61s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [8:53:47<5:23:00, 104.20s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [8:55:27<5:17:35, 103.00s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [8:57:09<5:15:22, 102.84s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [8:58:43<5:05:37, 100.20s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:00:24<5:04:04, 100.25s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:02:01<4:59:37, 99.32s/it] 
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 07:02:49,162:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 07:02:54,187:Timeout during comparison
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(TaskRunner pid=2755424)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:05:15<6:23:18, 127.77s/it]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:06:54<5:55:11, 119.06s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:08:33<5:35:16, 113.01s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:10:12<5:21:13, 108.89s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:11:50<5:09:43, 105.59s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:13:25<4:58:59, 102.51s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:15:03<4:53:09, 101.09s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:16:39<4:47:04, 99.56s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:18:17<4:43:58, 99.06s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:19:58<4:44:05, 99.68s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:22:45<5:39:59, 120.00s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:24:22<5:17:57, 112.88s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:25:59<5:02:43, 108.12s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:27:36<4:51:29, 104.73s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:29:14<4:44:47, 102.94s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:30:53<4:39:38, 101.69s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:32:33<4:36:50, 101.28s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 07:33:19,249:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:34:12<4:33:11, 100.56s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:35:49<4:28:05, 99.30s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:37:26<4:25:01, 98.76s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:40:15<5:19:22, 119.77s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:41:53<5:00:09, 113.27s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:43:28<4:43:49, 107.78s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:45:03<4:32:12, 104.03s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:46:44<4:27:47, 102.99s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [9:48:22<4:22:11, 101.49s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [9:50:00<4:18:05, 100.56s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [9:51:41<4:16:21, 100.53s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [9:53:19<4:13:17, 99.99s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [9:54:54<4:07:21, 98.29s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [9:57:42<4:58:18, 119.32s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [9:59:17<4:38:13, 112.04s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:00:50<4:21:47, 106.13s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:02:30<4:16:04, 104.52s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:04:05<4:06:57, 101.49s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:05:37<3:58:48, 98.82s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:07:13<3:54:48, 97.84s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:08:52<3:54:02, 98.20s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:10:29<3:51:34, 97.85s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:12:04<3:47:40, 96.88s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:14:51<4:35:26, 118.05s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:16:39<4:26:14, 114.92s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:18:18<4:13:42, 110.31s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:19:57<4:03:55, 106.83s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:21:31<3:53:44, 103.12s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:23:13<3:50:49, 102.59s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:24:51<3:46:29, 101.42s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:26:32<3:43:58, 101.04s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:28:12<3:41:49, 100.83s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:29:47<3:36:21, 99.09s/it] 
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(TaskRunner pid=2755424)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:32:52<4:30:27, 124.83s/it]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:34:34<4:13:42, 118.01s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:36:16<4:01:23, 113.15s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:37:59<3:53:32, 110.33s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:39:43<3:47:13, 108.20s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:41:22<3:40:09, 105.67s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:43:01<3:33:57, 103.53s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:44:40<3:29:26, 102.17s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:46:15<3:23:35, 100.13s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:48:02<3:25:34, 101.94s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [10:50:50<4:03:35, 121.79s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [10:52:27<3:47:10, 114.54s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [10:54:09<3:37:44, 110.72s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [10:55:45<3:27:19, 106.32s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [10:57:21<3:19:39, 103.27s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [10:58:58<3:13:53, 101.16s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:00:31<3:07:39, 98.77s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:02:07<3:04:23, 97.91s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:03:47<3:04:15, 98.71s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 09:04:31,680:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 09:04:37,474:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:05:32<3:05:56, 100.51s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:08:23<3:43:08, 121.71s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:10:01<3:28:01, 114.51s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:11:41<3:18:33, 110.31s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:13:22<3:11:42, 107.50s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:14:55<3:02:19, 103.21s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:16:34<2:58:10, 101.81s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:18:09<2:53:05, 99.86s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:19:48<2:50:45, 99.47s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:21:26<2:48:12, 98.94s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:23:01<2:44:44, 97.87s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:25:49<3:18:02, 118.82s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:27:27<3:06:06, 112.79s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:29:06<2:57:28, 108.66s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:30:47<2:51:47, 106.26s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:32:33<2:49:50, 106.15s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:34:09<2:43:05, 103.00s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:35:46<2:38:32, 101.19s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:37:26<2:36:30, 100.97s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:39:04<2:33:24, 100.05s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:40:43<2:31:22, 99.80s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:43:31<3:00:31, 120.35s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:45:10<2:48:51, 113.84s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:46:46<2:38:56, 108.37s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [11:48:19<2:30:38, 103.89s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [11:49:55<2:25:20, 101.40s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [11:51:38<2:24:25, 101.94s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [11:53:13<2:19:43, 99.81s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [11:54:51<2:17:13, 99.20s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [11:56:33<2:16:55, 100.19s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [11:58:13<2:15:16, 100.20s/it]
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(TaskRunner pid=2755424)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:01:20<2:48:13, 126.17s/it]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:03:00<2:35:41, 118.25s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:04:42<2:27:22, 113.36s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:06:23<2:21:00, 109.88s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:08:02<2:14:41, 106.33s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:09:37<2:08:58, 103.18s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:11:20<2:07:03, 103.03s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:13:03<2:05:26, 103.10s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:14:45<2:03:03, 102.55s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:16:24<2:00:06, 101.50s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:19:15<2:23:00, 122.57s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:20:54<2:12:43, 115.41s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:22:31<2:04:37, 109.96s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:24:10<1:58:53, 106.47s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:25:50<1:55:11, 104.72s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:27:22<1:49:12, 100.81s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:29:00<1:46:47, 100.11s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:30:42<1:45:34, 100.55s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:32:20<1:43:02, 99.71s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:33:58<1:41:01, 99.36s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:36:48<2:00:33, 120.55s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:38:24<1:51:09, 113.05s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:40:08<1:46:33, 110.23s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:41:42<1:40:20, 105.63s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:43:23<1:37:10, 104.12s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:45:01<1:33:52, 102.41s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:46:39<1:30:54, 101.01s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [12:48:16<1:28:12, 99.87s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [12:49:56<1:26:27, 99.75s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [12:51:31<1:23:44, 98.52s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [12:54:18<1:39:00, 118.80s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [12:55:54<1:31:33, 112.12s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [12:57:29<1:25:38, 107.05s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [12:59:11<1:22:39, 105.51s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:00:46<1:18:27, 102.33s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:02:19<1:14:41, 99.59s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:03:57<1:12:30, 98.87s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:05:36<1:10:54, 98.95s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:07:12<1:08:40, 98.10s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:08:50<1:07:08, 98.25s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:11:39<1:19:35, 119.38s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:13:16<1:13:13, 112.64s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:14:56<1:09:00, 108.96s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:16:37<1:05:34, 106.34s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:18:14<1:02:16, 103.79s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:19:52<59:27, 101.92s/it]  
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 11:20:38,073:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:21:32<57:26, 101.37s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:23:07<54:36, 99.29s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:24:42<52:23, 98.25s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:26:22<51:02, 98.79s/it]
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(TaskRunner pid=2755424)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:29:27<1:02:18, 124.62s/it]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2755424)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:31:05<56:21, 116.62s/it]  
[36m(TaskRunner pid=2755424)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:32:38<51:03, 109.40s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:34:17<47:54, 106.47s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:35:54<44:48, 103.41s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:37:26<41:40, 100.03s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:39:03<39:40, 99.18s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:40:45<38:23, 100.16s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:42:23<36:28, 99.46s/it] 
[36m(TaskRunner pid=2755424)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:44:00<34:34, 98.77s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [13:46:50<40:01, 120.06s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [13:48:31<36:09, 114.16s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [13:50:09<32:47, 109.30s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [13:51:48<30:09, 106.45s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [13:53:28<27:50, 104.39s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [13:55:08<25:45, 103.02s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [13:56:49<23:53, 102.37s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [13:58:28<22:00, 101.55s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:00:09<20:15, 101.32s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:01:46<18:20, 100.09s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:04:45<20:35, 123.59s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:06:23<17:22, 115.86s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:08:02<14:47, 110.98s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 12:08:49,279:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 12:08:56,392:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 12:09:02,176:Timeout during comparison
[36m(TaskRunner pid=2755424)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:09:56<13:03, 111.97s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:11:34<10:45, 107.54s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:13:09<08:39, 103.81s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:14:48<06:49, 102.40s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:16:24<05:01, 100.53s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:18:06<03:22, 101.13s/it]
[36m(TaskRunner pid=2755424)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:19:52<01:42, 102.56s/it]
[36m(TaskRunner pid=2755424)[0m WARNING:2025-11-10 12:22:12,273:Timeout during comparison
[36m(WorkerDict pid=2758974)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2758974)[0m   warnings.warn(
[36m(TaskRunner pid=2755424)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:23:06<01:48, 108.11s/it]
[36m(WorkerDict pid=2759187)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2759187)[0m   warnings.warn([32m [repeated 3x across cluster][0m
