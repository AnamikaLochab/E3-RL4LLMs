The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a5/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a5//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a5//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a5//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a5/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-20 11:01:59,724	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=3573749)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 11:02:19,892:Waiting for register center actor SrYNen_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=3577477)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3577477)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=3577477)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=3577303)[0m [rank0]:[W1220 11:02:37.102273395 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=3577477)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3577477)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3577303)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577303)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m [rank3]:[W1220 11:02:37.254399697 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577303)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=3577303)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3577303)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3577477)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(WorkerDict pid=3577480)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=3573749)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3573749)[0m /scratch/gautschi/alochab/E3-RL4LLMs/verl/verl/trainer/ppo/core_algos.py:744: RuntimeWarning: divide by zero encountered in log
[36m(TaskRunner pid=3573749)[0m   print(f"    Entropy H(q):   {Hq.item():.4f} (Max possible: {np.log(corr_mask.sum().item()):.4f})")
[36m(TaskRunner pid=3573749)[0m Training Progress:   0%|          | 1/480 [02:01<16:09:14, 121.41s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   0%|          | 2/480 [04:07<16:29:39, 124.22s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   1%|          | 3/480 [06:14<16:39:05, 125.67s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   1%|          | 4/480 [08:14<16:16:47, 123.13s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   1%|          | 5/480 [10:13<16:04:35, 121.84s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   1%|â–         | 6/480 [12:16<16:03:49, 122.00s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   1%|â–         | 7/480 [14:19<16:04:11, 122.31s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 11:20:20,503:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 11:20:28,475:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:   2%|â–         | 8/480 [16:31<16:28:46, 125.69s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   2%|â–         | 9/480 [18:32<16:14:30, 124.14s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 11:26:28,689:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:   2%|â–         | 10/480 [22:03<19:41:33, 150.84s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   2%|â–         | 11/480 [24:01<18:20:40, 140.81s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   2%|â–Ž         | 12/480 [26:01<17:29:45, 134.58s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   3%|â–Ž         | 13/480 [28:00<16:50:50, 129.87s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   3%|â–Ž         | 14/480 [30:02<16:28:55, 127.33s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   3%|â–Ž         | 15/480 [32:01<16:07:28, 124.83s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   3%|â–Ž         | 16/480 [34:01<15:53:38, 123.32s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 11:40:02,847:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:   4%|â–Ž         | 17/480 [36:05<15:54:22, 123.68s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   4%|â–         | 18/480 [38:02<15:37:09, 121.71s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   4%|â–         | 19/480 [40:02<15:29:51, 121.02s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   4%|â–         | 20/480 [43:26<18:40:39, 146.17s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   4%|â–         | 21/480 [45:29<17:43:01, 138.96s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   5%|â–         | 22/480 [47:30<17:00:06, 133.64s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   5%|â–         | 23/480 [49:29<16:25:42, 129.41s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   5%|â–Œ         | 24/480 [51:31<16:05:10, 127.00s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   5%|â–Œ         | 25/480 [53:24<15:32:30, 122.97s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   5%|â–Œ         | 26/480 [55:21<15:15:46, 121.03s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   6%|â–Œ         | 27/480 [57:22<15:13:34, 121.00s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   6%|â–Œ         | 28/480 [59:14<14:52:30, 118.47s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   6%|â–Œ         | 29/480 [1:01:16<14:57:13, 119.37s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   6%|â–‹         | 30/480 [1:04:25<17:32:21, 140.31s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   6%|â–‹         | 31/480 [1:06:12<16:14:49, 130.27s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:58<15:19:22, 123.13s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   7%|â–‹         | 33/480 [1:10:03<15:21:03, 123.63s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:58<15:00:36, 121.16s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:50<14:36:13, 118.14s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:40<14:17:49, 115.92s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   8%|â–Š         | 37/480 [1:17:33<14:08:46, 114.96s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   8%|â–Š         | 38/480 [1:19:31<14:13:26, 115.85s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   8%|â–Š         | 39/480 [1:21:21<13:58:16, 114.05s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   8%|â–Š         | 40/480 [1:24:28<16:37:54, 136.08s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   9%|â–Š         | 41/480 [1:26:20<15:43:00, 128.88s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   9%|â–‰         | 42/480 [1:28:15<15:10:03, 124.66s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   9%|â–‰         | 43/480 [1:30:02<14:28:46, 119.28s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   9%|â–‰         | 44/480 [1:31:50<14:02:40, 115.97s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:   9%|â–‰         | 45/480 [1:33:36<13:39:21, 113.01s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  10%|â–‰         | 46/480 [1:35:29<13:36:52, 112.93s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  10%|â–‰         | 47/480 [1:37:22<13:35:00, 112.93s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:39:18<13:39:33, 113.83s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:41:17<13:48:19, 115.31s/it]
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(TaskRunner pid=3573749)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:44:35<16:45:27, 140.30s/it]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3573749)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:46:24<15:35:50, 130.89s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:48:15<14:51:40, 125.00s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:50:00<14:05:24, 118.79s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:51:49<13:43:21, 115.96s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:53:36<13:21:59, 113.22s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:55:21<13:03:44, 110.91s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:57:13<13:03:36, 111.15s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:59:00<12:51:52, 109.74s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:00:46<12:43:52, 108.87s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:03:39<14:56:35, 128.08s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:05:32<14:22:40, 123.53s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:07:17<13:41:17, 117.89s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:09:02<13:13:00, 114.10s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:10:58<13:14:28, 114.59s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:12:43<12:52:07, 111.63s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:14:35<12:52:28, 111.95s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:16:27<12:49:21, 111.77s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:18:14<12:37:46, 110.35s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:20:00<12:28:22, 109.25s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:22:59<14:49:23, 130.16s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:24:50<14:07:42, 124.36s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:26:35<13:25:46, 118.50s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:28:20<12:55:36, 114.34s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:30:07<12:39:21, 112.22s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:31:51<12:20:10, 109.66s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:33:41<12:19:10, 109.78s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:35:29<12:14:39, 109.38s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:37:21<12:17:55, 110.14s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 13:43:17,250:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 13:43:22,657:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:39:21<12:35:23, 113.03s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:42:15<14:35:27, 131.32s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:44:03<13:46:15, 124.25s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:45:52<13:13:47, 119.67s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:47:41<12:52:20, 116.73s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:49:29<12:32:38, 114.04s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:51:19<12:22:52, 112.84s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:53:05<12:08:02, 110.87s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:54:55<12:04:12, 110.57s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:56:48<12:06:06, 111.14s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:58:33<11:51:54, 109.24s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:01:28<13:58:35, 129.01s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:03:11<13:07:12, 121.42s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 14:09:01,487:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:04:57<12:35:16, 116.79s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:06:45<12:16:16, 114.15s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 14:12:39,067:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:08:37<12:09:25, 113.38s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:10:24<11:54:37, 111.37s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:12:15<11:51:39, 111.20s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:13:56<11:31:38, 108.35s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:15:35<11:11:33, 105.48s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:17:26<11:19:55, 107.07s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 14:23:18,097:Timeout during comparison
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(WorkerDict pid=3577303)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3577303)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=3573749)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:20:45<14:12:58, 134.68s/it]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3573749)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:22:28<13:11:36, 125.32s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:24:14<12:33:08, 119.55s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:25:57<11:58:57, 114.42s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:27:38<11:31:28, 110.34s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:29:23<11:19:26, 108.71s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:31:02<11:00:07, 105.90s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:32:46<10:54:09, 105.23s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:34:25<10:40:41, 103.34s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:36:17<10:56:28, 106.17s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:39:21<13:18:26, 129.48s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:41:04<12:26:08, 121.33s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:42:39<11:37:09, 113.67s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:44:24<11:17:55, 110.83s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:46:08<11:04:18, 108.90s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:47:42<10:35:11, 104.42s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:49:22<10:24:45, 102.98s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:51:04<10:22:37, 102.91s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:52:53<10:30:43, 104.54s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:54:35<10:25:09, 103.90s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:57:36<12:42:04, 127.01s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:59:16<11:52:02, 119.00s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:01:05<11:31:23, 115.88s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:02:47<11:04:56, 111.76s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:04:44<11:11:55, 113.24s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:06:25<10:49:22, 109.75s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:08:11<10:40:58, 108.64s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:09:52<10:25:20, 106.29s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:11:33<10:14:10, 104.69s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:13:13<10:04:19, 103.30s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:16:08<12:07:46, 124.76s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:17:51<11:27:52, 118.26s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:19:30<10:52:12, 112.45s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:21:13<10:33:17, 109.50s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:22:53<10:15:41, 106.77s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:24:35<10:05:36, 105.32s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:26:19<10:01:38, 104.94s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:28:00<9:53:47, 103.87s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:29:46<9:54:09, 104.24s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:31:29<9:51:31, 104.08s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 15:38:50,560:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:34:24<11:50:46, 125.43s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:36:07<11:10:02, 118.59s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:37:47<10:36:12, 112.94s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:39:30<10:17:18, 109.91s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:41:09<9:58:02, 106.79s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:42:54<9:52:51, 106.18s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:44:30<9:33:23, 103.00s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:46:07<9:22:35, 101.37s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:47:47<9:18:46, 100.98s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:49:37<9:30:58, 103.50s/it]
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(TaskRunner pid=3573749)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:52:47<11:52:07, 129.48s/it]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3573749)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:54:33<11:11:13, 122.41s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:56:18<10:41:02, 117.26s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:57:58<10:11:22, 112.18s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:59:41<9:53:55, 109.31s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:01:22<9:39:47, 107.04s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:02:58<9:18:41, 103.46s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:04:41<9:17:23, 103.54s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:06:24<9:13:57, 103.22s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:08:06<9:11:08, 103.02s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:11:01<11:04:25, 124.58s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:12:50<10:36:34, 119.73s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:14:34<10:10:09, 115.13s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:16:12<9:40:44, 109.92s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:17:47<9:15:27, 105.47s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:19:26<9:03:50, 103.59s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:21:08<8:58:59, 102.99s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:22:47<8:50:53, 101.77s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:24:27<8:47:48, 101.50s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:26:05<8:40:23, 100.40s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:28:53<10:23:24, 120.66s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:30:31<9:46:33, 113.89s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:32:09<9:20:04, 109.10s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:33:47<9:01:23, 105.81s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:35:26<8:49:11, 103.76s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:37:12<8:50:33, 104.37s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:38:56<8:47:27, 104.10s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:40:34<8:36:50, 102.34s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:42:17<8:36:15, 102.57s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:43:59<8:33:57, 102.45s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:46:52<10:17:45, 123.55s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 16:52:45,296:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 16:52:50,314:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 16:52:56,621:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:48:55<10:15:13, 123.46s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:50:36<9:39:30, 116.68s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:52:20<9:19:14, 112.98s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:53:58<8:54:59, 108.44s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:55:51<8:59:35, 109.75s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:57:34<8:47:17, 107.61s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:59:12<8:32:27, 104.94s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:00:56<8:28:56, 104.58s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:02:42<8:29:48, 105.11s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:05:33<10:02:24, 124.64s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:07:13<9:25:42, 117.45s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:08:53<8:57:50, 112.05s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:10:33<8:38:53, 108.48s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:12:14<8:26:43, 106.31s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:13:52<8:12:53, 103.77s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:15:38<8:14:41, 104.51s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:17:14<8:00:58, 101.97s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:18:55<7:57:08, 101.52s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:20:33<7:51:04, 100.58s/it]
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(TaskRunner pid=3573749)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:23:41<9:51:49, 126.82s/it]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3573749)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:25:21<9:11:47, 118.67s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:27:00<8:42:38, 112.80s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:28:40<8:22:37, 108.87s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:30:24<8:14:00, 107.39s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:32:05<8:03:20, 105.46s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:33:48<7:58:41, 104.82s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:35:35<8:00:24, 105.58s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:37:13<7:47:52, 103.21s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:38:51<7:39:32, 101.75s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:41:45<9:15:11, 123.38s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:43:25<8:41:16, 116.27s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:45:03<8:15:37, 110.96s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:46:49<8:06:07, 109.24s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:48:29<7:52:51, 106.66s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:50:07<7:39:05, 103.95s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:51:45<7:29:26, 102.15s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:53:23<7:23:05, 101.09s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:54:59<7:14:50, 99.58s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:56:47<7:23:01, 101.85s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:59:34<8:46:13, 121.44s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:01:12<8:13:54, 114.42s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:02:56<7:58:20, 111.24s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:04:33<7:38:29, 107.04s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:06:18<7:33:44, 106.35s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 18:12:09,474:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:08:05<7:33:43, 106.76s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:09:43<7:20:35, 104.08s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:11:27<7:18:58, 104.11s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:13:09<7:13:40, 103.25s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:14:50<7:09:28, 102.66s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:17:37<8:28:07, 121.95s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:19:17<7:59:14, 115.48s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:20:58<7:39:09, 111.09s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:22:38<7:23:54, 107.83s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:24:13<7:05:57, 103.89s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:25:50<6:56:25, 101.98s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:27:26<6:46:47, 100.03s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:29:01<6:39:25, 98.62s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:30:47<6:46:13, 100.72s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:32:25<6:41:15, 99.90s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:35:17<8:05:44, 121.43s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 18:41:13,563:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:37:09<7:53:11, 118.79s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:38:50<7:29:26, 113.30s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:40:31<7:13:50, 109.83s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:42:10<6:58:12, 106.33s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:43:53<6:53:13, 105.50s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:45:31<6:42:47, 103.28s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:47:11<6:37:05, 102.26s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:48:53<6:34:39, 102.07s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:50:37<6:35:05, 102.62s/it]
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(TaskRunner pid=3573749)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:53:43<8:09:54, 127.80s/it]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3573749)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:55:20<7:31:54, 118.40s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:56:58<7:07:15, 112.44s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:58:34<6:46:58, 107.57s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:00:13<6:35:15, 104.94s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 19:06:00,343:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:01:53<6:28:09, 103.51s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:03:36<6:24:55, 103.10s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:05:14<6:17:31, 101.58s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:06:57<6:17:22, 101.99s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:08:33<6:09:23, 100.29s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:11:20<7:21:14, 120.34s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:13:00<6:57:18, 114.33s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:14:50<6:50:31, 112.99s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:16:30<6:34:19, 109.03s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:18:15<6:28:11, 107.83s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:19:52<6:15:07, 104.69s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:21:38<6:14:33, 105.02s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:23:16<6:05:27, 102.94s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:24:52<5:56:34, 100.92s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:26:31<5:52:09, 100.14s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:29:20<7:02:50, 120.81s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:31:00<6:39:00, 114.55s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:32:34<6:15:50, 108.42s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:34:10<6:01:41, 104.84s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:35:55<6:00:06, 104.89s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:37:30<5:48:06, 101.88s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:39:10<5:44:36, 101.36s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:40:53<5:44:38, 101.87s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:42:33<5:40:35, 101.16s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:44:11<5:36:17, 100.38s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:46:57<6:39:28, 119.84s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:48:26<6:07:32, 110.82s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:50:03<5:51:23, 106.48s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:51:40<5:40:04, 103.57s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:53:21<5:36:31, 103.02s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:55:02<5:32:49, 102.41s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:56:37<5:24:06, 100.24s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:58:17<5:21:49, 100.05s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:59:56<5:19:05, 99.71s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:01:30<5:11:42, 97.92s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:04:16<6:15:15, 118.50s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:05:54<5:53:13, 112.13s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:07:28<5:34:55, 106.89s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:09:05<5:23:47, 103.89s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:10:42<5:15:05, 101.64s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:12:19<5:09:58, 100.53s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:13:59<5:06:59, 100.11s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:15:38<5:04:44, 99.91s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:17:16<5:00:52, 99.19s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:18:51<4:55:55, 98.10s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 20:24:39,809:Timeout during comparison
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(TaskRunner pid=3573749)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:21:57<6:13:13, 124.41s/it]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3573749)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:23:34<5:46:57, 116.30s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:25:09<5:25:46, 109.81s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:26:48<5:14:28, 106.60s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:28:23<5:02:49, 103.23s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:29:57<4:52:12, 100.19s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:31:34<4:48:29, 99.48s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:33:09<4:42:28, 97.97s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:34:43<4:37:37, 96.85s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:36:24<4:39:44, 98.15s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:39:14<5:38:48, 119.58s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:40:48<5:15:20, 111.96s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:42:28<5:03:16, 108.31s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:44:04<4:51:01, 104.56s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:45:42<4:44:13, 102.73s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:47:26<4:43:37, 103.14s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:49:13<4:45:21, 104.40s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 20:54:59,888:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:50:52<4:39:03, 102.72s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:52:29<4:32:15, 100.84s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:54:09<4:30:16, 100.73s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 21:01:27,656:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:57:02<5:26:00, 122.26s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:58:39<5:04:15, 114.82s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:00:21<4:51:44, 110.79s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:01:54<4:36:17, 105.59s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:03:37<4:32:12, 104.70s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:05:15<4:25:20, 102.71s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:06:53<4:20:21, 101.44s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:08:31<4:15:46, 100.31s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:10:10<4:13:32, 100.08s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:11:43<4:05:54, 97.71s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:14:28<4:54:44, 117.90s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:16:00<4:34:01, 110.35s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:17:35<4:20:21, 105.55s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 21:23:25,046:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:19:21<4:19:23, 105.87s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:20:57<4:10:29, 102.94s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:22:32<4:02:35, 100.38s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:24:07<3:56:51, 98.69s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:25:43<3:53:44, 98.07s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:27:20<3:50:54, 97.57s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:28:56<3:48:33, 97.26s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:31:42<4:35:12, 117.95s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:33:26<4:23:06, 113.57s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:35:02<4:09:23, 108.43s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:36:38<3:59:09, 104.74s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:38:12<3:49:54, 101.43s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 21:44:04,623:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:40:00<3:52:47, 103.46s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:41:42<3:49:45, 102.88s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:43:22<3:46:12, 102.05s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:45:03<3:44:17, 101.95s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:46:39<3:38:24, 100.03s/it]
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(TaskRunner pid=3573749)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:49:51<4:36:12, 127.48s/it]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3573749)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:51:31<4:16:45, 119.42s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:53:15<4:04:57, 114.82s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:54:56<3:54:03, 110.58s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:56:44<3:50:29, 109.76s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:58:25<3:43:03, 107.07s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:59:59<3:33:09, 103.14s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:01:40<3:30:29, 102.68s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:03:21<3:27:30, 102.06s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:05:06<3:27:31, 102.90s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:07:49<4:01:52, 120.94s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:09:41<3:54:53, 118.43s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:11:22<3:42:41, 113.23s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:13:03<3:33:11, 109.33s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:14:40<3:24:17, 105.67s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:16:14<3:15:50, 102.18s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:17:47<3:09:09, 99.55s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:19:21<3:04:00, 97.70s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:21:00<3:03:19, 98.21s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:22:33<2:58:33, 96.52s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:25:21<3:36:40, 118.19s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:26:58<3:23:05, 111.79s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:28:37<3:14:15, 107.92s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:30:19<3:09:24, 106.21s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:31:50<2:59:16, 101.47s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:33:27<2:55:28, 100.27s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:35:01<2:50:28, 98.35s/it] 
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 22:40:48,372:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:36:40<2:49:21, 98.66s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:38:15<2:45:27, 97.33s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:39:50<2:42:52, 96.76s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:42:32<3:13:39, 116.19s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:44:09<3:02:38, 110.70s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-20 22:49:54,567:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:45:48<2:54:56, 107.11s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:47:29<2:49:59, 105.15s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:49:12<2:47:29, 104.68s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:50:48<2:41:41, 102.12s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:52:26<2:37:58, 100.84s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:54:05<2:35:16, 100.18s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:55:38<2:30:28, 98.14s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:57:16<2:28:32, 97.94s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:00:05<2:58:47, 119.19s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:01:42<2:46:52, 112.50s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:03:19<2:38:31, 108.09s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:04:50<2:29:09, 102.87s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:06:27<2:25:05, 101.22s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:08:11<2:24:21, 101.90s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:09:45<2:19:34, 99.70s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:11:25<2:18:01, 99.78s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:13:02<2:15:13, 98.95s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:14:44<2:14:30, 99.64s/it]
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(TaskRunner pid=3573749)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:17:48<2:46:40, 125.01s/it]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3573749)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:19:27<2:34:20, 117.22s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:21:13<2:28:03, 113.89s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:22:53<2:20:40, 109.62s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:24:31<2:14:34, 106.25s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:26:08<2:09:25, 103.54s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:27:44<2:04:42, 101.12s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:29:28<2:04:10, 102.06s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:31:06<2:01:08, 100.95s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:32:44<1:58:19, 99.99s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:35:36<2:21:39, 121.42s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:37:14<2:11:33, 114.40s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:38:51<2:03:49, 109.26s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:40:30<1:58:39, 106.26s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:42:10<1:54:41, 104.27s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:43:39<1:48:10, 99.85s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:45:17<1:45:45, 99.15s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:47:00<1:45:29, 100.47s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:48:38<1:43:04, 99.75s/it] 
[36m(TaskRunner pid=3573749)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:50:16<1:40:54, 99.26s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:53:05<2:00:03, 120.05s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:54:43<1:51:26, 113.32s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:56:26<1:46:43, 110.40s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:58:03<1:41:04, 106.39s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:59:43<1:37:28, 104.43s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:01:24<1:34:39, 103.26s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:03:07<1:33:03, 103.40s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:04:48<1:30:38, 102.61s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:06:30<1:28:40, 102.31s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:08:09<1:26:17, 101.53s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:10:57<1:41:10, 121.42s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:12:35<1:33:17, 114.23s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:14:12<1:27:13, 109.02s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:15:58<1:24:52, 108.36s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:17:39<1:21:11, 105.90s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:19:15<1:17:14, 102.98s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:20:56<1:15:02, 102.32s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:22:35<1:12:47, 101.58s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:24:17<1:11:01, 101.46s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:26:04<1:10:32, 103.23s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:28:57<1:22:51, 124.28s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:30:41<1:16:40, 117.96s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:32:24<1:12:00, 113.68s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:34:06<1:07:53, 110.10s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:35:49<1:04:49, 108.03s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:37:32<1:02:05, 106.43s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-21 00:43:22,580:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-21 00:43:27,611:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:39:23<1:01:05, 107.81s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:41:03<58:03, 105.55s/it]  
[36m(TaskRunner pid=3573749)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:42:42<55:12, 103.52s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:44:24<53:16, 103.10s/it]
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(TaskRunner pid=3573749)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:47:31<1:04:07, 128.26s/it]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-21 00:53:23,169:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:49:20<59:09, 122.40s/it]  
[36m(TaskRunner pid=3573749)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:50:57<53:34, 114.81s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:52:42<50:22, 111.93s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:54:25<47:20, 109.24s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:56:01<43:47, 105.12s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:57:40<41:20, 103.36s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:59:27<40:05, 104.58s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:01:12<38:24, 104.74s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:02:51<36:00, 102.88s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:05:45<41:24, 124.21s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:07:31<37:39, 118.90s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:09:12<34:00, 113.35s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-21 01:15:03,636:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:10:59<31:37, 111.60s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:12:40<28:52, 108.31s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:14:23<26:43, 106.88s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:16:05<24:35, 105.41s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:17:47<22:35, 104.26s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:19:29<20:42, 103.51s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:21:10<18:50, 102.81s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-21 01:28:39,764:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:24:14<21:10, 127.09s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:25:55<17:54, 119.44s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:27:37<15:13, 114.18s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:29:22<12:58, 111.25s/it]
[36m(TaskRunner pid=3573749)[0m WARNING:2025-12-21 01:35:13,086:Timeout during comparison
[36m(TaskRunner pid=3573749)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:31:08<10:58, 109.81s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:32:47<08:53, 106.63s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:34:30<07:02, 105.54s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:36:09<05:10, 103.48s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:37:56<03:28, 104.43s/it]
[36m(TaskRunner pid=3573749)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:39:43<01:45, 105.33s/it]
[36m(WorkerDict pid=3577303)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3577303)[0m   warnings.warn(
[36m(TaskRunner pid=3573749)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:42:54<01:50, 110.59s/it]
[36m(WorkerDict pid=3577480)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3577480)[0m   warnings.warn([32m [repeated 3x across cluster][0m
