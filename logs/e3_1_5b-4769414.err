
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_tw_covvar_0.005/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_tw_covvar_0.005//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_tw_covvar_0.005//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_tw_covvar_0.005//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_tw_covvar_0.005/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-13 22:53:02,333	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=1656905)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-13 22:53:22,622:Waiting for register center actor nWyTl6_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=1660687)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1660687)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=1660687)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=1660495)[0m [rank0]:[W1113 22:53:40.206700270 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=1660686)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1660686)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1660495)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660495)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m [rank3]:[W1113 22:53:40.465373491 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1660495)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1660687)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1660686)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660686)[0m   warnings.warn(
[36m(WorkerDict pid=1660689)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:   0%|          | 1/480 [02:06<16:48:06, 126.28s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   0%|          | 2/480 [04:08<16:28:19, 124.06s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   1%|          | 3/480 [06:13<16:28:02, 124.28s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   1%|          | 4/480 [08:18<16:27:32, 124.48s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   1%|          | 5/480 [10:20<16:18:58, 123.66s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   1%|â–         | 6/480 [12:23<16:15:06, 123.43s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   1%|â–         | 7/480 [14:27<16:14:30, 123.62s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   2%|â–         | 8/480 [16:29<16:07:52, 123.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   2%|â–         | 9/480 [18:30<16:01:39, 122.51s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   2%|â–         | 10/480 [21:54<19:16:19, 147.62s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   2%|â–         | 11/480 [23:53<18:05:51, 138.92s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   2%|â–Ž         | 12/480 [25:52<17:16:12, 132.85s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   3%|â–Ž         | 13/480 [27:51<16:42:11, 128.76s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   3%|â–Ž         | 14/480 [29:54<16:24:59, 126.82s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   3%|â–Ž         | 15/480 [31:53<16:05:14, 124.55s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   3%|â–Ž         | 16/480 [33:51<15:48:03, 122.59s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   4%|â–Ž         | 17/480 [35:51<15:39:55, 121.80s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   4%|â–         | 18/480 [37:48<15:25:47, 120.23s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   4%|â–         | 19/480 [39:47<15:22:05, 120.01s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   4%|â–         | 20/480 [43:09<18:28:13, 144.55s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   4%|â–         | 21/480 [45:12<17:37:32, 138.24s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   5%|â–         | 22/480 [47:14<16:57:14, 133.26s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   5%|â–         | 23/480 [49:13<16:22:10, 128.95s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   5%|â–Œ         | 24/480 [51:07<15:46:51, 124.59s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   5%|â–Œ         | 25/480 [53:01<15:19:57, 121.31s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   5%|â–Œ         | 26/480 [54:57<15:05:26, 119.66s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   6%|â–Œ         | 27/480 [56:58<15:07:26, 120.19s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   6%|â–Œ         | 28/480 [58:50<14:46:57, 117.74s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:46<14:41:45, 117.31s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:56<17:21:48, 138.91s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:44<16:10:30, 129.69s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:31<15:17:37, 122.90s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:28<15:03:16, 121.24s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:21<14:41:03, 118.53s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:13<14:25:20, 116.67s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:03<14:07:39, 114.55s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:54<13:59:26, 113.69s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:53<14:08:36, 115.20s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:43<13:56:08, 113.76s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 00:17:45,317:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:57<16:50:29, 137.80s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:46<15:45:28, 129.22s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:42<15:14:01, 125.21s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   9%|â–‰         | 43/480 [1:29:30<14:33:32, 119.94s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   9%|â–‰         | 44/480 [1:31:21<14:12:26, 117.31s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:   9%|â–‰         | 45/480 [1:33:06<13:42:47, 113.49s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:57<13:35:33, 112.75s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:46<13:27:11, 111.85s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:39<13:27:53, 112.21s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:34<13:30:19, 112.81s/it]
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660495)[0m   warnings.warn(
[36m(TaskRunner pid=1656905)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:55<16:38:27, 139.32s/it]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:44<15:31:33, 130.29s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:47:32<14:40:50, 123.48s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:49:18<14:01:45, 118.28s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:51:09<13:45:09, 116.22s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:57<13:26:02, 113.80s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:46<13:13:41, 112.31s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:56:37<13:07:35, 111.72s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:58:21<12:50:35, 109.56s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:00:05<12:37:08, 107.91s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:03:03<15:02:53, 128.99s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:49<14:12:50, 122.13s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:06:36<13:39:20, 117.61s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:08:22<13:11:55, 113.95s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:10:16<13:10:41, 114.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:11:59<12:45:44, 110.71s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:13:50<12:43:42, 110.68s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:15:36<12:32:53, 109.38s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:17:21<12:22:03, 108.07s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:19:15<12:31:26, 109.70s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:22:20<15:04:57, 132.43s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:24:08<14:12:10, 125.01s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:25:53<13:29:16, 119.01s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:27:41<13:04:56, 115.72s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:29:32<12:52:57, 114.23s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:31:21<12:41:25, 112.80s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:33:11<12:34:26, 112.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:35:00<12:26:26, 111.13s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:36:48<12:16:44, 109.96s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:38:37<12:13:56, 109.82s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:41:37<14:31:43, 130.76s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:43:26<13:47:43, 124.47s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:45:12<13:08:47, 118.91s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:46:58<12:40:49, 114.99s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:48:47<12:27:07, 113.20s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 01:45:45,274:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:50:42<12:28:17, 113.67s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:52:30<12:15:52, 112.06s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:54:18<12:05:53, 110.82s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:56:09<12:03:37, 110.76s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:57:58<11:58:32, 110.26s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:01:34<15:23:20, 142.05s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:03:19<14:09:25, 131.02s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:05:07<13:21:14, 123.90s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:06:53<12:45:33, 118.69s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:08:41<12:23:22, 115.55s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:10:29<12:05:50, 113.12s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:12:23<12:04:54, 113.27s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:14:06<11:43:40, 110.24s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:15:43<11:17:35, 106.43s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:17:33<11:22:56, 107.55s/it]
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660495)[0m   warnings.warn(
[36m(WorkerDict pid=1660495)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1660495)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=1656905)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:20:55<14:19:14, 135.67s/it]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:22:36<13:11:45, 125.34s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:24:26<12:40:33, 120.72s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:26:08<12:02:39, 115.01s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:27:51<11:38:12, 111.42s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:29:38<11:29:03, 110.25s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:31:21<11:13:28, 108.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:33:09<11:11:47, 108.06s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:34:52<11:00:55, 106.60s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:36:47<11:14:52, 109.14s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:39:52<13:32:17, 131.72s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:41:38<12:43:07, 124.09s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:43:15<11:51:37, 116.03s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:44:58<11:26:11, 112.18s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:46:45<11:13:13, 110.36s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:48:18<10:41:12, 105.40s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:49:57<10:27:26, 103.42s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:51:39<10:22:59, 102.98s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:53:20<10:17:39, 102.37s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:55:03<10:16:15, 102.42s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:57:58<12:26:31, 124.42s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:59:36<11:35:31, 116.24s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 02:56:32,425:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:01:26<11:22:29, 114.38s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 02:58:18,392:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:03:11<11:04:55, 111.75s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:05:05<11:06:39, 112.36s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:06:47<10:45:36, 109.12s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:08:29<10:31:19, 107.00s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:10:07<10:14:29, 104.45s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:11:49<10:09:05, 103.82s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:13:31<10:03:17, 103.13s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:16:26<12:06:36, 124.56s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:18:08<11:26:24, 118.01s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:19:46<10:48:19, 111.78s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:21:27<10:28:30, 108.67s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:23:08<10:13:54, 106.46s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:24:51<10:05:40, 105.34s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:26:32<9:55:48, 103.92s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:28:11<9:45:43, 102.46s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:29:50<9:39:14, 101.62s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:31:33<9:38:56, 101.87s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:34:23<11:32:54, 122.28s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 03:31:13,918:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:36:08<11:02:59, 117.34s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:37:45<10:26:37, 111.24s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:39:27<10:08:14, 108.29s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:41:04<9:48:16, 105.05s/it] 
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 03:37:56,219:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:42:49<9:45:34, 104.88s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:44:23<9:25:18, 101.55s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:45:58<9:12:34, 99.56s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:47:34<9:05:39, 98.61s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:49:18<9:12:58, 100.24s/it]
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660495)[0m   warnings.warn(
[36m(TaskRunner pid=1656905)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:52:26<11:35:59, 126.54s/it]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:54:05<10:48:03, 118.19s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:55:47<10:19:51, 113.39s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:57:25<9:53:41, 108.94s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:59:05<9:37:11, 106.23s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:00:44<9:23:17, 103.99s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:02:19<9:06:51, 101.27s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:03:57<8:59:11, 100.16s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:05:38<8:59:53, 100.60s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:07:19<8:58:22, 100.63s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:10:08<10:46:49, 121.28s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:11:55<10:21:33, 116.91s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:13:43<10:06:12, 114.38s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:15:21<9:38:12, 109.44s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:16:58<9:16:19, 105.63s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:18:35<9:00:40, 102.99s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:20:17<8:57:22, 102.68s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:21:52<8:44:16, 100.50s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:23:34<8:44:38, 100.89s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:25:10<8:35:38, 99.48s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:28:02<10:25:22, 121.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:29:42<9:51:42, 114.89s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:31:20<9:22:40, 109.61s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:32:58<9:03:27, 106.21s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:34:32<8:43:34, 102.66s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:36:14<8:40:20, 102.36s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:37:53<8:33:33, 101.36s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:39:31<8:26:57, 100.39s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:41:11<8:24:50, 100.30s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:42:51<8:22:44, 100.21s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:45:47<10:14:33, 122.91s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:47:28<9:40:29, 116.49s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:49:08<9:13:44, 111.49s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:50:49<8:56:11, 108.32s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:52:24<8:33:49, 104.15s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:54:07<8:30:37, 103.86s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:55:47<8:22:52, 102.63s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:57:24<8:13:18, 101.02s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:59:05<8:11:18, 100.95s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:00:46<8:10:49, 101.20s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:03:40<9:54:19, 122.96s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:05:17<9:15:04, 115.24s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:06:53<8:45:22, 109.45s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:08:33<8:29:51, 106.59s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:10:12<8:16:21, 104.13s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:11:49<8:04:36, 102.02s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:13:33<8:05:47, 102.63s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:15:11<7:58:21, 101.42s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:16:52<7:55:55, 101.26s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:18:31<7:50:11, 100.40s/it]
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660495)[0m   warnings.warn(
[36m(TaskRunner pid=1656905)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:21:45<9:59:23, 128.44s/it]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:23:23<9:15:28, 119.46s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:25:04<8:47:25, 113.83s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:26:42<8:24:06, 109.19s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:28:21<8:07:33, 105.99s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:30:00<7:57:14, 104.13s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:31:43<7:53:50, 103.76s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:33:28<7:53:40, 104.11s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:35:02<7:37:59, 101.03s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:36:40<7:31:50, 100.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:39:33<9:09:24, 122.09s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:41:12<8:35:16, 114.93s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:42:50<8:11:23, 110.01s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:44:31<7:57:48, 107.37s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:46:12<7:47:36, 105.47s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:47:49<7:34:15, 102.85s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:49:25<7:23:32, 100.80s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:51:05<7:20:26, 100.48s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:52:41<7:13:05, 99.18s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:54:26<7:18:36, 100.83s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:57:16<8:46:48, 121.57s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:58:54<8:15:20, 114.75s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:00:36<7:56:41, 110.86s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:02:09<7:31:40, 105.45s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:03:49<7:23:11, 103.87s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:05:26<7:12:55, 101.87s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:07:01<7:02:14, 99.74s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:08:45<7:05:19, 100.87s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:10:21<6:57:52, 99.50s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:12:03<6:59:19, 100.24s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:14:56<8:28:36, 122.06s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:16:31<7:52:52, 113.94s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:18:08<7:30:12, 108.92s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:19:48<7:17:08, 106.19s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:21:23<7:01:42, 102.86s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:23:00<6:52:40, 101.06s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:24:36<6:44:57, 99.58s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:26:12<6:38:49, 98.48s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:27:57<6:44:29, 100.29s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:29:34<6:38:53, 99.31s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:32:28<8:07:48, 121.95s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:34:15<7:47:42, 117.41s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:35:56<7:25:35, 112.34s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:37:38<7:12:11, 109.42s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:39:18<6:59:13, 106.58s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:40:58<6:49:54, 104.66s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:42:39<6:43:55, 103.57s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:44:18<6:36:47, 102.18s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:45:59<6:33:44, 101.83s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:47:41<6:31:36, 101.72s/it]
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660495)[0m   warnings.warn(
[36m(TaskRunner pid=1656905)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:50:51<8:11:56, 128.33s/it]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:52:26<7:31:27, 118.29s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:54:04<7:05:52, 112.07s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:55:42<6:48:19, 107.93s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 06:52:33,153:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:57:24<6:39:48, 106.14s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:58:59<6:26:09, 102.97s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:00:39<6:20:16, 101.86s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:02:13<6:10:09, 99.59s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:03:52<6:07:25, 99.30s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 07:00:38,213:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 07:00:43,847:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:05:33<6:08:17, 99.99s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:08:22<7:22:24, 120.66s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:10:05<7:00:45, 115.27s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:11:44<6:40:59, 110.37s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:13:25<6:28:51, 107.52s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:15:07<6:21:00, 105.84s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:16:41<6:07:28, 102.55s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 07:13:30,939:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:18:24<6:05:46, 102.55s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:20:00<5:57:13, 100.63s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:21:31<5:45:29, 97.78s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:23:09<5:43:36, 97.71s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 07:20:01,139:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:26:08<7:08:04, 122.31s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:27:49<6:43:28, 115.83s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:29:24<6:19:20, 109.43s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:30:59<6:03:19, 105.31s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:32:39<5:56:04, 103.71s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:34:14<5:45:27, 101.11s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:35:55<5:42:51, 100.84s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:37:36<5:41:45, 101.01s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:39:13<5:35:29, 99.65s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:40:51<5:32:41, 99.31s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 07:39:16,103:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:43:48<6:48:20, 122.50s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:45:20<6:16:20, 113.47s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:46:57<5:58:00, 108.49s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:48:34<5:45:21, 105.19s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:50:16<5:40:24, 104.20s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:51:56<5:34:28, 102.91s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:53:35<5:28:24, 101.57s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:55:12<5:22:22, 100.22s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:56:48<5:17:02, 99.07s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:58:25<5:13:09, 98.37s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:01:23<6:27:28, 122.36s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:03:01<6:02:31, 115.09s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:04:37<5:42:40, 109.37s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:06:10<5:25:09, 104.33s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:07:49<5:18:42, 102.81s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:09:28<5:12:52, 101.47s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:11:11<5:12:51, 102.02s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:12:43<5:02:26, 99.16s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:14:21<4:59:15, 98.66s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:15:59<4:57:08, 98.50s/it]
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660495)[0m   warnings.warn(
[36m(TaskRunner pid=1656905)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:19:04<6:13:00, 124.34s/it]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:20:40<5:46:05, 116.01s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:22:15<5:24:55, 109.52s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:23:52<5:12:08, 105.81s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:25:30<5:03:26, 103.45s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:27:04<4:54:00, 100.80s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:28:39<4:47:04, 98.99s/it] 
[36m(TaskRunner pid=1656905)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:30:12<4:40:02, 97.12s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:31:49<4:38:56, 97.30s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:33:28<4:38:08, 97.59s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:36:17<5:37:05, 118.98s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:37:53<5:16:05, 112.22s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:39:29<5:00:24, 107.29s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:41:06<4:49:49, 104.13s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:42:45<4:43:50, 102.59s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:44:23<4:39:04, 101.48s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:46:04<4:36:46, 101.26s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 08:42:52,219:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 08:42:57,226:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:47:46<4:35:30, 101.41s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:49:22<4:29:27, 99.80s/it] 
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 08:46:11,232:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:51:06<4:31:28, 101.17s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:54:00<5:27:34, 122.84s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:55:38<5:05:46, 115.39s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 08:52:26,427:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:57:16<4:50:36, 110.35s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:58:54<4:38:43, 106.52s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:00:40<4:36:45, 106.44s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:02:28<4:35:49, 106.77s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:04:10<4:30:19, 105.32s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:05:58<4:30:53, 106.23s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:07:46<4:30:35, 106.81s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:09:25<4:22:21, 104.25s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:12:36<5:25:46, 130.31s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:14:16<5:01:27, 121.39s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:16:10<4:53:41, 119.07s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:17:56<4:42:23, 115.26s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:19:38<4:30:53, 111.33s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:21:19<4:21:36, 108.25s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:22:55<4:10:28, 104.36s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:24:34<4:05:06, 102.84s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:26:10<3:58:09, 100.63s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:27:45<3:52:41, 99.02s/it] 
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 09:26:09,946:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:30:42<4:45:28, 122.35s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 09:27:31,274:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:32:25<4:30:23, 116.72s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:34:03<4:15:28, 111.08s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:35:47<4:08:59, 109.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:37:20<3:55:56, 104.10s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:39:04<3:54:13, 104.10s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:40:46<3:51:24, 103.61s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:42:33<3:51:23, 104.39s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:44:20<3:51:37, 105.28s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:46:09<3:52:15, 106.38s/it]
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660495)[0m   warnings.warn(
[36m(TaskRunner pid=1656905)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:49:33<4:54:00, 135.69s/it]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:51:20<4:33:15, 127.10s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:53:18<4:25:28, 124.44s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:55:06<4:12:38, 119.36s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:56:50<4:01:12, 114.86s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:58:34<3:52:20, 111.53s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:00:24<3:49:16, 110.94s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:02:07<3:42:51, 108.71s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:03:47<3:35:26, 105.96s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:05:38<3:37:14, 107.72s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:08:46<4:23:28, 131.74s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:10:33<4:06:14, 124.16s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:12:15<3:51:32, 117.73s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:13:58<3:40:25, 113.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:15:44<3:34:38, 111.02s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:17:24<3:26:25, 107.70s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:19:04<3:20:06, 105.32s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:20:42<3:14:40, 103.37s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:22:37<3:19:15, 106.75s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 10:19:30,660:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:24:19<3:14:42, 105.25s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:27:22<3:55:55, 128.68s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:29:12<3:43:40, 123.12s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:30:58<3:32:04, 117.82s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:32:42<3:23:00, 113.84s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:34:18<3:11:36, 108.45s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:36:01<3:06:46, 106.72s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:37:46<3:04:02, 106.18s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:39:26<2:59:23, 104.50s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:41:07<2:55:31, 103.25s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:42:45<2:51:18, 101.77s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:45:53<3:32:38, 127.59s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:47:36<3:18:22, 120.23s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 10:44:33,322:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:49:26<3:11:16, 117.11s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:51:09<3:02:51, 113.11s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:52:59<2:59:10, 111.99s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:54:39<2:51:50, 108.53s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:56:29<2:50:47, 109.01s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:58:12<2:45:58, 107.08s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 10:55:02,384:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:59:54<2:41:43, 105.47s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:01:32<2:36:49, 103.40s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:04:24<3:05:51, 123.91s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:06:01<2:52:00, 115.96s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:07:38<2:41:27, 110.08s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:09:11<2:32:09, 104.94s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:10:54<2:29:46, 104.50s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:12:45<2:30:42, 106.38s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:14:26<2:26:35, 104.71s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:16:12<2:25:18, 105.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:18:00<2:24:58, 106.08s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:19:41<2:20:58, 104.43s/it]
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660495)[0m   warnings.warn(
[36m(TaskRunner pid=1656905)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:23:04<2:58:53, 134.17s/it]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:25:02<2:50:02, 129.15s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:26:49<2:39:20, 122.58s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:28:35<2:31:06, 117.75s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:30:20<2:24:12, 113.85s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:32:07<2:19:50, 111.87s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:33:54<2:15:52, 110.17s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:35:41<2:12:58, 109.30s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:37:29<2:10:53, 109.07s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:39:26<2:11:46, 111.36s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:42:36<2:37:32, 135.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:44:23<2:25:38, 126.64s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:46:13<2:17:37, 121.43s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:48:01<2:11:03, 117.37s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:49:47<2:05:34, 114.16s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:51:27<1:58:56, 109.79s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:53:13<1:55:54, 108.66s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:55:09<1:56:19, 110.78s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:56:54<1:52:44, 109.11s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:58:40<1:50:07, 108.33s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:01:56<2:14:23, 134.38s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:03:35<2:01:45, 123.82s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:05:21<1:54:40, 118.64s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:07:00<1:46:59, 112.62s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:08:43<1:42:22, 109.69s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 12:05:36,226:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:10:29<1:39:36, 108.67s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:12:08<1:35:13, 105.80s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:13:49<1:32:16, 104.46s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:15:31<1:29:51, 103.69s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:17:11<1:27:10, 102.56s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:20:08<1:44:05, 124.92s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:21:50<1:36:19, 117.95s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:23:29<1:29:46, 112.23s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:25:15<1:26:32, 110.48s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:26:53<1:21:45, 106.65s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:28:34<1:18:46, 105.04s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:30:17<1:16:34, 104.42s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:31:59<1:14:17, 103.67s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:33:41<1:12:08, 103.06s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:35:26<1:10:49, 103.63s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:38:22<1:23:38, 125.47s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:40:05<1:17:02, 118.53s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:41:50<1:12:29, 114.46s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:43:32<1:08:20, 110.84s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:45:15<1:05:06, 108.51s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:46:59<1:02:26, 107.03s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:48:41<59:51, 105.63s/it]  
[36m(TaskRunner pid=1656905)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:50:22<57:17, 104.16s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:52:03<55:07, 103.37s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:53:52<54:12, 104.92s/it]
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660495)[0m   warnings.warn(
[36m(TaskRunner pid=1656905)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:57:22<1:08:16, 136.55s/it]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1656905)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:59:12<1:02:06, 128.49s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:01:08<58:13, 124.77s/it]  
[36m(TaskRunner pid=1656905)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:03:03<54:54, 122.01s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:04:51<50:56, 117.57s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:06:38<47:41, 114.47s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:08:40<46:44, 116.85s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:10:36<44:36, 116.37s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:12:26<42:02, 114.68s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:14:15<39:30, 112.87s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:17:35<46:22, 139.10s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:19:27<41:27, 130.90s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:21:22<37:52, 126.24s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 13:18:31,915:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:23:24<35:22, 124.85s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:25:13<32:03, 120.21s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:27:05<29:24, 117.64s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:28:52<26:43, 114.55s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:30:46<24:45, 114.25s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:32:38<22:43, 113.65s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:34:25<20:27, 111.59s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 13:33:17,174:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:37:51<23:20, 140.00s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:39:38<19:31, 130.17s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:41:24<16:22, 122.83s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:43:12<13:49, 118.49s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:45:09<11:47, 118.00s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:46:53<09:28, 113.68s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:48:39<07:25, 111.42s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:50:25<05:29, 109.69s/it]
[36m(TaskRunner pid=1656905)[0m WARNING:2025-11-14 13:47:39,174:Timeout during comparison
[36m(TaskRunner pid=1656905)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:52:33<03:50, 115.35s/it]
[36m(TaskRunner pid=1656905)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:54:28<01:55, 115.17s/it]
[36m(WorkerDict pid=1660495)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1660495)[0m   warnings.warn(
[36m(TaskRunner pid=1656905)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:58:00<01:52, 112.49s/it]
[36m(WorkerDict pid=1660689)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1660689)[0m   warnings.warn([32m [repeated 3x across cluster][0m
