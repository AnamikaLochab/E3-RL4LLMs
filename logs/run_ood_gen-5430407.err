The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a8/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a8//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a8//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a8//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a8/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-20 22:05:37,460	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8266 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=850984)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-20 22:05:57,643:Waiting for register center actor cBPC7h_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=854720)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=854723)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=854723)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=854541)[0m [rank0]:[W1220 22:06:15.693495204 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=854541)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=854541)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=854541)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854541)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m [rank2]:[W1220 22:06:15.882079976 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854723)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=854541)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=854541)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=854723)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(WorkerDict pid=854722)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=850984)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=850984)[0m /scratch/gautschi/alochab/E3-RL4LLMs/verl/verl/trainer/ppo/core_algos.py:744: RuntimeWarning: divide by zero encountered in log
[36m(TaskRunner pid=850984)[0m   print(f"    Entropy H(q):   {Hq.item():.4f} (Max possible: {np.log(corr_mask.sum().item()):.4f})")
[36m(TaskRunner pid=850984)[0m Training Progress:   0%|          | 1/480 [02:00<16:01:53, 120.49s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   0%|          | 2/480 [04:02<16:05:28, 121.19s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   1%|          | 3/480 [06:04<16:07:19, 121.68s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   1%|          | 4/480 [08:03<15:58:27, 120.81s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   1%|          | 5/480 [10:03<15:53:28, 120.44s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   1%|â–         | 6/480 [12:08<16:01:53, 121.76s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   1%|â–         | 7/480 [14:11<16:05:17, 122.45s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   2%|â–         | 8/480 [16:14<16:04:01, 122.55s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   2%|â–         | 9/480 [18:15<15:57:28, 121.97s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   2%|â–         | 10/480 [21:36<19:07:52, 146.54s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   2%|â–         | 11/480 [23:35<17:57:46, 137.88s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   2%|â–Ž         | 12/480 [25:35<17:13:37, 132.52s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   3%|â–Ž         | 13/480 [27:35<16:42:08, 128.75s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   3%|â–Ž         | 14/480 [29:37<16:23:54, 126.68s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   3%|â–Ž         | 15/480 [31:34<15:59:19, 123.78s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   3%|â–Ž         | 16/480 [33:33<15:45:48, 122.30s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   4%|â–Ž         | 17/480 [35:32<15:37:38, 121.51s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   4%|â–         | 18/480 [37:29<15:24:20, 120.04s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   4%|â–         | 19/480 [39:28<15:20:17, 119.78s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   4%|â–         | 20/480 [42:51<18:29:47, 144.76s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   4%|â–         | 21/480 [44:55<17:39:12, 138.46s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   5%|â–         | 22/480 [46:54<16:52:42, 132.67s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   5%|â–         | 23/480 [48:51<16:14:55, 128.00s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   5%|â–Œ         | 24/480 [50:52<15:56:20, 125.84s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   5%|â–Œ         | 25/480 [52:45<15:24:03, 121.85s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   5%|â–Œ         | 26/480 [54:42<15:12:00, 120.53s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   6%|â–Œ         | 27/480 [56:43<15:10:42, 120.62s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   6%|â–Œ         | 28/480 [58:37<14:53:33, 118.61s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:38<14:56:52, 119.32s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-20 23:11:49,782:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:50<17:38:49, 141.18s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:38<16:21:04, 131.10s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:24<15:22:56, 123.61s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:26<15:18:42, 123.32s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:22<14:59:36, 121.02s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:13<14:36:06, 118.13s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:03<14:15:51, 115.66s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:58<14:12:31, 115.47s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:57<14:17:49, 116.45s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:48<14:03:03, 114.70s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:55<16:41:58, 136.63s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:45<15:39:40, 128.43s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:41<15:10:13, 124.69s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   9%|â–‰         | 43/480 [1:29:28<14:30:33, 119.53s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   9%|â–‰         | 44/480 [1:31:18<14:07:18, 116.60s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:   9%|â–‰         | 45/480 [1:33:02<13:38:53, 112.95s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:55<13:37:00, 112.95s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:52<13:42:38, 113.99s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:44<13:37:55, 113.60s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:39<13:37:59, 113.87s/it]
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(TaskRunner pid=850984)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:57<16:37:11, 139.14s/it]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=850984)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:46<15:30:02, 130.08s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:47:36<14:45:26, 124.13s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:49:23<14:06:10, 118.90s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:51:12<13:43:20, 115.96s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:53:00<13:24:03, 113.52s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:45<13:03:54, 110.93s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:56:34<12:58:23, 110.41s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:58:19<12:44:29, 108.70s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:00:06<12:39:33, 108.25s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:56<14:48:18, 126.90s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:49<14:16:13, 122.61s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:06:32<13:34:14, 116.88s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:08:16<13:05:00, 112.95s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:10:11<13:06:59, 113.51s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:11:56<12:48:27, 111.10s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:13:46<12:43:32, 110.66s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:15:34<12:35:07, 109.70s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:17:22<12:31:30, 109.44s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:19:09<12:24:32, 108.69s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:22:07<14:44:01, 129.37s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:23:54<13:55:53, 122.63s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:25:40<13:19:38, 117.60s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:27:25<12:53:26, 114.02s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:29:14<12:39:38, 112.26s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:30:58<12:22:18, 109.97s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:32:46<12:15:52, 109.29s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:34:34<12:12:12, 109.01s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:36:24<12:12:28, 109.32s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:38:14<12:11:05, 109.39s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:41:09<14:20:37, 129.09s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:42:58<13:39:22, 123.22s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:44:48<13:09:35, 119.03s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:46:38<12:50:44, 116.48s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:48:26<12:31:21, 113.84s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:50:13<12:16:15, 111.84s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:51:59<12:02:56, 110.09s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:53:50<12:02:12, 110.26s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:55:42<12:04:31, 110.90s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:57:29<11:55:07, 109.74s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:00:26<14:04:03, 129.85s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:02:09<13:10:06, 121.87s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 01:11:35,239:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 01:11:41,239:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:04:03<12:52:52, 119.52s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:05:51<12:28:44, 116.08s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:07:47<12:26:20, 116.01s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:09:33<12:04:22, 112.89s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:11:27<12:05:11, 113.31s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:13:07<11:38:43, 109.46s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:14:46<11:16:21, 106.23s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:16:36<11:21:24, 107.31s/it]
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(WorkerDict pid=854541)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=854541)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=850984)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:19:50<14:03:37, 133.20s/it]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=850984)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:21:33<13:03:58, 124.11s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:23:20<12:30:35, 119.14s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:25:05<12:01:59, 114.91s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:26:45<11:31:33, 110.36s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:28:31<11:21:53, 109.10s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:30:10<11:00:17, 105.93s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 01:39:40,111:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:32:00<11:06:26, 107.20s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:33:41<10:54:03, 105.49s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:35:40<11:17:35, 109.58s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:38:36<13:17:43, 129.36s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:40:22<12:31:54, 122.26s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:41:59<11:43:37, 114.72s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:43:45<11:25:32, 112.08s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:45:30<11:12:11, 110.20s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:47:06<10:44:02, 105.87s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:48:43<10:25:58, 103.18s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:50:24<10:20:10, 102.51s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:52:09<10:22:44, 103.22s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:53:49<10:15:41, 102.33s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 02:03:16,515:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:56:50<12:35:29, 125.91s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:58:32<11:49:36, 118.60s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:00:19<11:26:52, 115.12s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 02:09:46,290:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 02:09:51,353:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:02:11<11:20:52, 114.43s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:04:09<11:24:48, 115.42s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:05:54<11:03:25, 112.13s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:07:37<10:45:16, 109.37s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:09:17<10:28:32, 106.83s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:11:00<10:19:54, 105.67s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:12:43<10:13:20, 104.84s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:15:34<12:07:10, 124.66s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:17:18<11:29:29, 118.54s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:18:57<10:53:33, 112.68s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:20:42<10:37:55, 110.30s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:22:22<10:17:50, 107.14s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:24:03<10:05:30, 105.31s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:25:46<9:59:30, 104.57s/it] 
[36m(TaskRunner pid=850984)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:27:27<9:52:34, 103.66s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:29:10<9:48:54, 103.32s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:30:56<9:52:07, 104.19s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 02:41:56,702:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:33:55<11:57:44, 126.66s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:35:37<11:13:19, 119.17s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:37:13<10:32:25, 112.27s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:38:56<10:15:21, 109.56s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:40:36<9:57:32, 106.70s/it] 
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 02:50:05,890:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:42:26<10:00:48, 107.61s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:44:00<9:36:10, 103.50s/it] 
[36m(TaskRunner pid=850984)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:45:37<9:23:35, 101.55s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:47:15<9:16:41, 100.61s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:49:02<9:25:35, 102.53s/it]
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(TaskRunner pid=850984)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:52:19<11:58:19, 130.60s/it]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=850984)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:54:06<11:18:26, 123.73s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 03:03:36,564:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:55:59<10:58:15, 120.41s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:57:42<10:27:12, 115.08s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:59:26<10:08:14, 111.95s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:01:10<9:52:41, 109.42s/it] 
[36m(TaskRunner pid=850984)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:02:47<9:31:41, 105.87s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:04:34<9:31:22, 106.14s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:06:21<9:31:00, 106.40s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:08:06<9:26:52, 105.96s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:11:06<11:23:05, 128.08s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:12:53<10:48:22, 121.95s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:14:43<10:26:42, 118.25s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:16:23<9:56:20, 112.87s/it] 
[36m(TaskRunner pid=850984)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:18:03<9:34:04, 109.00s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:19:45<9:21:01, 106.86s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:21:33<9:21:01, 107.20s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:23:15<9:11:07, 105.65s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:25:01<9:10:15, 105.82s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:26:41<8:58:52, 103.96s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:29:36<10:47:43, 125.37s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:31:19<10:10:49, 118.61s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:32:59<9:40:23, 113.06s/it] 
[36m(TaskRunner pid=850984)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:34:40<9:20:06, 109.47s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:36:20<9:04:00, 106.67s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:38:06<9:00:38, 106.36s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:39:51<8:55:55, 105.78s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:41:32<8:47:12, 104.40s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:43:16<8:45:24, 104.39s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:44:59<8:40:46, 103.81s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:48:01<10:37:37, 127.53s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 03:57:32,782:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:49:55<10:15:04, 123.43s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:51:37<9:41:25, 117.06s/it] 
[36m(TaskRunner pid=850984)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:53:24<9:23:28, 113.83s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:55:07<9:05:53, 110.66s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:57:01<9:08:49, 111.63s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:58:46<8:57:36, 109.72s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 04:08:16,160:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:00:33<8:51:58, 108.94s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:02:18<8:43:26, 107.56s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:04:04<8:39:52, 107.19s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:07:03<10:21:58, 128.68s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:08:45<9:41:38, 120.76s/it] 
[36m(TaskRunner pid=850984)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:10:25<9:09:23, 114.46s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:12:07<8:50:25, 110.89s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:13:51<8:37:49, 108.63s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:15:31<8:24:27, 106.20s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:17:18<8:22:47, 106.22s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:18:55<8:08:49, 103.64s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:20:41<8:09:48, 104.22s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:22:22<8:03:16, 103.19s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 04:33:25,571:Timeout during comparison
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(TaskRunner pid=850984)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:25:43<10:18:31, 132.54s/it]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=850984)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:27:25<9:34:12, 123.49s/it] 
[36m(TaskRunner pid=850984)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:29:06<9:01:01, 116.77s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:30:49<8:40:20, 112.71s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:32:35<8:29:22, 110.73s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:34:18<8:16:01, 108.22s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:36:05<8:13:20, 108.03s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:37:54<8:13:05, 108.37s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:39:36<8:01:54, 106.30s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:41:18<7:53:57, 104.93s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:44:22<9:38:44, 128.61s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:46:06<9:04:12, 121.39s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:47:48<8:36:47, 115.70s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:49:38<8:27:06, 113.96s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:51:21<8:09:43, 110.46s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:53:02<7:55:56, 107.76s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:54:45<7:47:18, 106.21s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:56:26<7:39:13, 104.77s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:58:05<7:30:17, 103.12s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:59:55<7:36:47, 105.01s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:02:50<9:06:17, 126.07s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:04:29<8:29:04, 117.93s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:06:14<8:10:28, 114.06s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:07:48<7:43:09, 108.13s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:09:31<7:33:48, 106.36s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:11:13<7:26:55, 105.16s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:12:51<7:16:28, 103.11s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:14:40<7:21:47, 104.77s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:16:22<7:16:53, 104.02s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:18:05<7:14:11, 103.79s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:21:00<8:40:42, 124.97s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:22:39<8:06:07, 117.14s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:24:23<7:48:54, 113.45s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:26:05<7:32:28, 109.91s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:27:43<7:16:16, 106.41s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:29:21<7:03:43, 103.77s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:30:59<6:55:16, 102.12s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:32:39<6:50:30, 101.36s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:34:27<6:57:02, 103.40s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:36:05<6:48:39, 101.74s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:39:04<8:19:59, 125.00s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:40:57<8:04:00, 121.51s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:42:40<7:39:02, 115.72s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:44:22<7:21:42, 111.83s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:46:05<7:08:51, 109.03s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:47:52<7:05:11, 108.56s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:49:33<6:53:29, 106.02s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:51:15<6:47:36, 104.96s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:53:03<6:49:38, 105.94s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:54:45<6:43:32, 104.82s/it]
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(TaskRunner pid=850984)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:58:01<8:26:10, 132.05s/it]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=850984)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:59:42<7:48:07, 122.65s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:01:19<7:17:32, 115.14s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:02:57<6:56:15, 110.02s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:04:37<6:42:55, 106.97s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:06:16<6:31:38, 104.44s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:08:02<6:31:34, 104.88s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:09:45<6:27:57, 104.38s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:11:35<6:32:19, 106.03s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 06:21:01,452:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 06:21:06,476:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 06:21:11,522:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 06:21:16,545:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:13:34<6:45:03, 109.97s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:16:27<7:53:04, 129.02s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:18:11<7:23:09, 121.41s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:19:58<7:05:33, 117.13s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:21:43<6:50:01, 113.37s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:23:31<6:42:33, 111.82s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:25:13<6:30:26, 108.96s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:26:56<6:22:11, 107.16s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:28:41<6:18:01, 106.48s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:30:19<6:07:21, 103.97s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:32:04<6:05:55, 104.05s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 06:41:31,602:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:35:05<7:25:28, 127.28s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:36:48<6:57:29, 119.85s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:38:27<6:34:14, 113.72s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:40:07<6:17:58, 109.56s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:41:54<6:13:18, 108.73s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:43:31<5:59:34, 105.24s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:45:16<5:57:22, 105.11s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:47:01<5:55:57, 105.21s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:48:44<5:52:23, 104.67s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:50:27<5:48:49, 104.13s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:53:23<6:58:56, 125.68s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:54:59<6:26:38, 116.58s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:56:41<6:10:27, 112.26s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:58:23<5:58:58, 109.33s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [9:00:07<5:51:28, 107.59s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:01:52<5:46:52, 106.73s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:03:34<5:41:23, 105.59s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:05:19<5:38:25, 105.21s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:07:04<5:36:52, 105.27s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:08:43<5:29:21, 103.46s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:11:43<6:39:50, 126.27s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:13:22<6:12:32, 118.27s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:15:02<5:52:43, 112.57s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:16:42<5:39:13, 108.84s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:18:26<5:32:35, 107.29s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:20:08<5:26:22, 105.85s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:21:56<5:26:29, 106.47s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:23:37<5:20:04, 104.94s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:25:21<5:16:51, 104.46s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:27:04<5:14:31, 104.27s/it]
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(TaskRunner pid=850984)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:30:18<6:32:50, 130.95s/it]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 07:39:44,711:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:32:09<6:13:14, 125.11s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:33:52<5:51:38, 118.53s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:35:39<5:39:31, 115.10s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:37:22<5:26:19, 111.25s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:38:59<5:12:11, 107.04s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:40:44<5:08:48, 106.49s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:42:23<5:00:20, 104.16s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:44:05<4:56:33, 103.45s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:45:55<5:00:22, 105.40s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:48:51<5:59:07, 126.75s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:50:33<5:36:08, 119.34s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:52:20<5:23:17, 115.46s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:54:03<5:11:11, 111.80s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:55:49<5:04:57, 110.23s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:57:38<5:01:53, 109.78s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:59:31<5:02:32, 110.69s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 08:08:55,996:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 08:09:01,061:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 08:09:06,070:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 08:09:11,075:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [10:01:29<5:06:45, 112.92s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [10:03:12<4:56:39, 109.88s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:04:56<4:50:14, 108.16s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:07:56<5:45:46, 129.66s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:09:43<5:25:37, 122.88s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 08:19:10,903:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 08:19:15,917:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 08:19:20,949:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:11:45<5:23:14, 122.75s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:13:27<5:04:17, 116.29s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:15:18<4:58:31, 114.82s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:17:10<4:54:07, 113.85s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:19:02<4:50:47, 113.30s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:20:48<4:43:56, 111.35s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:22:36<4:39:26, 110.31s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:24:17<4:30:30, 107.49s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:27:16<5:21:53, 128.76s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:28:56<4:58:53, 120.36s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:30:39<4:43:46, 115.04s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:32:34<4:41:29, 114.89s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:34:17<4:31:01, 111.38s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:36:00<4:22:58, 108.82s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:37:43<4:17:29, 107.29s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:39:31<4:16:02, 107.43s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:41:19<4:14:41, 107.62s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:43:01<4:08:33, 105.77s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:45:59<4:57:54, 127.68s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 08:55:32,932:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:47:58<4:49:48, 125.10s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:49:44<4:34:15, 119.24s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:51:26<4:20:28, 114.08s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:53:06<4:08:46, 109.75s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:54:52<4:04:25, 108.63s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:56:38<4:01:07, 107.96s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:58:23<3:57:29, 107.14s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [11:00:08<3:53:50, 106.29s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [11:01:44<3:45:28, 103.27s/it]
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(TaskRunner pid=850984)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [11:05:05<4:47:12, 132.56s/it]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=850984)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:06:53<4:29:19, 125.27s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:08:44<4:18:06, 120.99s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:10:34<4:08:57, 117.61s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:12:27<4:03:57, 116.17s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:14:12<3:55:26, 113.01s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:15:55<3:46:58, 109.83s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:17:42<3:43:46, 109.16s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:19:24<3:37:11, 106.82s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:21:19<3:40:35, 109.38s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:24:14<4:18:26, 129.22s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:26:04<4:04:50, 123.45s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:27:52<3:53:25, 118.69s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:29:39<3:44:25, 115.09s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:31:21<3:34:55, 111.17s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:33:00<3:26:02, 107.50s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:34:40<3:20:12, 105.38s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:36:19<3:14:40, 103.37s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:38:03<3:13:35, 103.71s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 09:47:26,022:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:39:46<3:11:23, 103.45s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:42:45<3:51:14, 126.13s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:44:31<3:37:48, 119.89s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:46:11<3:25:24, 114.12s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:48:03<3:22:03, 113.31s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:49:42<3:12:38, 109.05s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:51:26<3:08:21, 107.63s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:53:07<3:03:11, 105.69s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:54:48<2:58:59, 104.27s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:56:29<2:55:23, 103.17s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:58:11<2:53:07, 102.85s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [12:01:06<3:27:31, 124.52s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [12:02:50<3:15:25, 118.44s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 10:12:20,690:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [12:04:45<3:11:36, 117.31s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [12:06:32<3:04:41, 114.25s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [12:08:23<3:01:28, 113.42s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:10:03<2:53:00, 109.27s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:11:45<2:47:36, 106.99s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:13:29<2:44:32, 106.15s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:15:09<2:40:05, 104.41s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:16:55<2:39:12, 104.97s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:19:51<3:09:15, 126.18s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:21:36<2:57:28, 119.64s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:23:18<2:47:55, 114.50s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:24:55<2:38:15, 109.14s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:26:39<2:34:33, 107.83s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:28:26<2:32:08, 107.40s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:30:07<2:27:39, 105.47s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:31:52<2:25:50, 105.42s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:33:37<2:23:42, 105.16s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:35:21<2:21:30, 104.82s/it]
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(TaskRunner pid=850984)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:38:35<2:55:24, 131.56s/it]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=850984)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:40:21<2:43:10, 123.92s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:42:10<2:35:21, 119.50s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:43:56<2:28:20, 115.59s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:45:40<2:21:56, 112.07s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:47:21<2:15:40, 108.54s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:49:04<2:11:58, 107.01s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:50:51<2:10:04, 106.91s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:52:35<2:07:14, 106.04s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:54:21<2:05:42, 106.23s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:57:23<2:30:16, 128.80s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:59:08<2:19:59, 121.73s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [13:00:50<2:11:09, 115.73s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [13:02:34<2:05:29, 112.37s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [13:04:19<2:01:02, 110.04s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [13:05:56<1:55:03, 106.20s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [13:07:41<1:52:44, 105.70s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [13:09:27<1:51:05, 105.81s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:11:11<1:48:59, 105.48s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:12:54<1:46:22, 104.63s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:15:54<2:07:16, 127.27s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:17:38<1:58:09, 120.16s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 11:27:09,182:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:19:33<1:54:42, 118.66s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:21:17<1:48:40, 114.40s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:23:03<1:44:21, 111.81s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:24:50<1:41:11, 110.39s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:26:36<1:38:00, 108.90s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 11:36:02,381:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:28:25<1:36:11, 108.89s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 11:37:56,719:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:30:16<1:35:10, 109.81s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:31:59<1:31:34, 107.74s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:34:56<1:47:02, 128.46s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:36:38<1:38:27, 120.56s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:38:18<1:31:19, 114.15s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:40:13<1:29:45, 114.59s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:41:56<1:25:10, 111.10s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:43:37<1:21:01, 108.04s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:45:20<1:18:10, 106.60s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:47:05<1:15:54, 105.92s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:48:49<1:13:51, 105.51s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:50:38<1:12:53, 106.67s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:53:40<1:26:09, 129.24s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:55:25<1:19:10, 121.81s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:57:10<1:14:03, 116.94s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:58:57<1:10:09, 113.76s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [14:00:43<1:06:49, 111.38s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [14:02:27<1:03:41, 109.19s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 12:11:52,592:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 12:11:57,603:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [14:04:17<1:02:01, 109.46s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [14:06:00<59:10, 107.60s/it]  
[36m(TaskRunner pid=850984)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [14:07:47<57:16, 107.39s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [14:09:32<55:10, 106.79s/it]
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(TaskRunner pid=850984)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:12:44<1:06:11, 132.37s/it]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=850984)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:14:28<59:48, 123.74s/it]  
[36m(TaskRunner pid=850984)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:16:08<54:22, 116.52s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:17:57<51:26, 114.30s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:19:43<48:28, 111.87s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:21:25<45:23, 108.95s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:23:11<43:14, 108.09s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:25:01<41:34, 108.47s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:26:50<39:51, 108.70s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:28:32<37:18, 106.61s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:31:33<43:00, 129.01s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:33:26<39:20, 124.25s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:35:08<35:17, 117.65s/it]
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 12:44:35,128:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 12:44:40,138:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 12:44:45,168:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 12:44:50,184:Timeout during comparison
[36m(TaskRunner pid=850984)[0m WARNING:2025-12-21 12:44:55,199:Timeout during comparison
[36m(TaskRunner pid=850984)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:37:16<34:10, 120.60s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:38:59<30:45, 115.31s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:40:42<27:53, 111.59s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:42:27<25:38, 109.88s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:44:11<23:22, 107.91s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:45:53<21:15, 106.32s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:47:38<19:24, 105.83s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:50:41<21:30, 129.02s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:52:22<18:04, 120.54s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:54:08<15:29, 116.23s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:55:54<13:12, 113.20s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:57:38<11:02, 110.34s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:59:18<08:55, 107.18s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [15:01:03<07:06, 106.74s/it]
[36m(TaskRunner pid=850984)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [15:02:48<05:17, 105.97s/it]
[36m(TaskRunner pid=850984)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [15:04:38<03:34, 107.24s/it]
[36m(TaskRunner pid=850984)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:06:30<01:48, 108.84s/it]
[36m(WorkerDict pid=854541)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=854541)[0m   warnings.warn(
[36m(TaskRunner pid=850984)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:09:47<01:53, 113.96s/it]
[36m(WorkerDict pid=854722)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=854722)[0m   warnings.warn([32m [repeated 3x across cluster][0m
