
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_2.0_seqq_norm/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_2.0_seqq_norm//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_2.0_seqq_norm//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_2.0_seqq_norm//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_2.0_seqq_norm/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-22 17:19:17,235	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=3799622)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 17:19:37,453:Waiting for register center actor gjZYuH_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=3803347)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3803347)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=3803347)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=3803169)[0m [rank0]:[W1122 17:19:54.444217310 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=3803169)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3803169)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3803169)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803169)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m [rank2]:[W1122 17:19:55.703804346 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=3803169)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3803169)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3803350)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3803347)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803347)[0m   warnings.warn(
[36m(WorkerDict pid=3803348)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:   0%|          | 1/480 [01:59<15:52:13, 119.28s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   0%|          | 2/480 [03:58<15:51:35, 119.45s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   1%|          | 3/480 [06:01<16:01:57, 121.00s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   1%|          | 4/480 [07:59<15:50:48, 119.85s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   1%|          | 5/480 [10:00<15:50:29, 120.06s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   1%|â–         | 6/480 [12:01<15:51:02, 120.39s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   1%|â–         | 7/480 [14:04<15:55:24, 121.19s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 17:37:24,893:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:   2%|â–         | 8/480 [16:09<16:04:25, 122.60s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   2%|â–         | 9/480 [18:08<15:52:57, 121.40s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   2%|â–         | 10/480 [21:26<18:56:16, 145.06s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   2%|â–         | 11/480 [23:22<17:43:41, 136.08s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   2%|â–Ž         | 12/480 [25:19<16:56:52, 130.37s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   3%|â–Ž         | 13/480 [27:16<16:22:29, 126.23s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   3%|â–Ž         | 14/480 [29:15<16:03:42, 124.08s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   3%|â–Ž         | 15/480 [31:11<15:43:38, 121.76s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   3%|â–Ž         | 16/480 [33:10<15:35:21, 120.95s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   4%|â–Ž         | 17/480 [35:09<15:28:30, 120.33s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   4%|â–         | 18/480 [37:07<15:20:46, 119.58s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   4%|â–         | 19/480 [39:06<15:17:13, 119.38s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   4%|â–         | 20/480 [42:27<18:22:35, 143.82s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   4%|â–         | 21/480 [44:24<17:19:48, 135.92s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 18:07:42,634:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 18:07:50,111:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:   5%|â–         | 22/480 [46:32<16:59:15, 133.53s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   5%|â–         | 23/480 [48:29<16:19:21, 128.58s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   5%|â–Œ         | 24/480 [50:25<15:48:51, 124.85s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   5%|â–Œ         | 25/480 [52:19<15:21:41, 121.54s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   5%|â–Œ         | 26/480 [54:16<15:09:10, 120.15s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   6%|â–Œ         | 27/480 [56:17<15:08:09, 120.29s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   6%|â–Œ         | 28/480 [58:09<14:48:08, 117.89s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:07<14:46:33, 117.95s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:16<17:24:39, 139.29s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:03<16:09:32, 129.56s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:51<15:18:33, 123.02s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:48<15:02:55, 121.20s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:44<14:49:06, 119.61s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:36<14:32:07, 117.59s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:28<14:16:08, 115.69s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:20<14:06:59, 114.72s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:18<14:12:56, 115.79s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:07<13:54:07, 113.49s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:17<16:41:21, 136.55s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:08<15:42:32, 128.82s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:04<15:12:40, 125.02s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:54<14:37:22, 120.46s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:45<14:15:32, 117.74s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:32<13:49:35, 114.43s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:25<13:45:09, 114.08s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:15<13:33:25, 112.72s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:08<13:32:44, 112.88s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:03<13:35:57, 113.59s/it]
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803169)[0m   warnings.warn(
[36m(TaskRunner pid=3799622)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:24<16:40:47, 139.65s/it]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:13<15:34:25, 130.69s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:47:02<14:44:18, 123.97s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:46<14:00:32, 118.11s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 19:12:00,577:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:41<13:51:03, 117.05s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:27<13:26:44, 113.89s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:15<13:12:29, 112.15s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:56:08<13:12:11, 112.37s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:55<12:58:05, 110.63s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:59:42<12:49:10, 109.62s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 19:22:51,969:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 19:22:58,584:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:48<15:27:34, 132.51s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:37<14:37:14, 125.62s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:06:23<13:54:15, 119.75s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:08:10<13:24:55, 115.82s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:10:05<13:21:39, 115.62s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:11:50<12:57:09, 112.36s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:13:42<12:53:31, 112.11s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:15:31<12:46:34, 111.37s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:17:19<12:36:59, 110.24s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:19:08<12:32:41, 109.88s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:22:10<14:59:25, 131.62s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:23:59<14:10:04, 124.71s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:25:46<13:33:03, 119.57s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:27:34<13:07:26, 116.09s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:29:26<12:56:01, 114.68s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:31:11<12:34:55, 111.84s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:33:02<12:31:51, 111.66s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:34:53<12:27:23, 111.27s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:36:44<12:26:27, 111.41s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:38:37<12:28:07, 111.94s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:41:37<14:41:39, 132.25s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:43:28<13:56:27, 125.78s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:45:16<13:19:59, 120.60s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:47:07<12:58:17, 117.63s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:48:57<12:41:13, 115.34s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:50:45<12:25:11, 113.19s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:52:36<12:17:45, 112.35s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:54:27<12:13:09, 111.93s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:56:18<12:11:20, 111.94s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:58:06<12:01:28, 110.71s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:01:09<14:19:54, 132.29s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:02:54<13:24:51, 124.14s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 20:26:07,649:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:04:49<13:04:07, 121.26s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:06:38<12:39:47, 117.80s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:08:30<12:26:14, 116.00s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:10:20<12:12:15, 114.12s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:12:14<12:10:27, 114.13s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:14:01<11:54:29, 111.93s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:15:42<11:32:10, 108.72s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:17:39<11:45:44, 111.14s/it]
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803169)[0m   warnings.warn(
[36m(WorkerDict pid=3803169)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3803169)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=3799622)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:20:58<14:30:36, 137.46s/it]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:22:43<13:27:35, 127.85s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:24:32<12:49:06, 122.08s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:26:16<12:14:05, 116.83s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:27:58<11:44:21, 112.40s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:29:48<11:37:29, 111.60s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:31:32<11:21:37, 109.35s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:33:22<11:19:54, 109.37s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:35:05<11:07:08, 107.60s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:37:03<11:24:22, 110.68s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:40:04<13:32:58, 131.83s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:41:55<12:52:21, 125.59s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:43:36<12:04:15, 118.09s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:45:23<11:42:34, 114.86s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:47:14<11:33:51, 113.75s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:48:59<11:14:59, 110.96s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:50:42<10:59:51, 108.77s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:52:28<10:51:39, 107.71s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:54:13<10:45:51, 107.05s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:55:59<10:41:41, 106.65s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:59:01<12:55:53, 129.31s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:00:45<12:09:00, 121.84s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:02:36<11:47:36, 118.59s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:04:25<11:26:56, 115.45s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:06:27<11:36:48, 117.44s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:08:15<11:18:51, 114.74s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:10:04<11:06:26, 112.96s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:11:47<10:47:27, 110.05s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:13:36<10:43:00, 109.60s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:15:25<10:40:00, 109.40s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:18:26<12:44:21, 131.03s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:20:16<12:05:07, 124.66s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:21:58<11:24:07, 117.95s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:23:46<11:04:04, 114.83s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:25:33<10:49:26, 112.62s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:27:21<10:38:37, 111.07s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:29:09<10:31:42, 110.18s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:30:53<10:18:51, 108.25s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:32:38<10:12:03, 107.38s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:34:27<10:12:47, 107.82s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:37:24<12:09:47, 128.79s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 22:00:34,333:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:39:14<11:35:39, 123.12s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:40:56<10:56:31, 116.54s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:42:43<10:38:32, 113.69s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:44:25<10:17:54, 110.34s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:46:11<10:07:52, 108.87s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:47:49<9:47:49, 105.60s/it] 
[36m(TaskRunner pid=3799622)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:49:27<9:34:54, 103.59s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:51:08<9:28:49, 102.80s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:52:56<9:34:14, 104.09s/it]
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803169)[0m   warnings.warn(
[36m(TaskRunner pid=3799622)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:56:10<12:01:06, 131.11s/it]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:57:57<11:19:03, 123.84s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:59:42<10:47:29, 118.45s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [5:01:26<10:21:26, 114.03s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [5:03:12<10:06:41, 111.66s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:04:55<9:49:47, 108.88s/it] 
[36m(TaskRunner pid=3799622)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:06:35<9:33:35, 106.22s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:08:16<9:23:15, 104.63s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:10:02<9:25:02, 105.29s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:11:44<9:17:54, 104.28s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:14:44<11:16:18, 126.81s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:16:36<10:50:41, 122.39s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:18:21<10:21:59, 117.36s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:20:00<9:51:03, 111.87s/it] 
[36m(TaskRunner pid=3799622)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:21:40<9:30:21, 108.30s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:23:22<9:18:13, 106.33s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:25:04<9:10:10, 105.13s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:26:45<9:00:46, 103.66s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:28:28<8:58:37, 103.58s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:30:08<8:50:46, 102.40s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:33:03<10:42:40, 124.39s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:34:43<10:02:45, 117.04s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:36:25<9:36:20, 112.27s/it] 
[36m(TaskRunner pid=3799622)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:38:04<9:14:45, 108.42s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:39:43<8:59:04, 105.70s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:41:27<8:54:27, 105.14s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:43:10<8:49:09, 104.44s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:44:51<8:42:43, 103.51s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:46:35<8:41:50, 103.68s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:48:19<8:39:39, 103.59s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:51:18<10:31:18, 126.26s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 23:14:27,888:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 23:14:35,280:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:53:12<10:10:26, 122.50s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:54:53<9:37:11, 116.21s/it] 
[36m(TaskRunner pid=3799622)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:56:35<9:13:19, 111.78s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:58:16<8:55:29, 108.55s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [6:00:04<8:53:43, 108.56s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [6:01:46<8:42:36, 106.65s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-22 23:24:58,432:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:03:33<8:41:20, 106.76s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:05:16<8:34:02, 105.62s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:07:02<8:32:47, 105.73s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:09:59<10:13:56, 127.02s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:11:39<9:32:20, 118.82s/it] 
[36m(TaskRunner pid=3799622)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:13:19<9:03:32, 113.24s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:15:01<8:45:18, 109.82s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:16:45<8:35:11, 108.08s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:18:25<8:22:29, 105.79s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:20:09<8:17:48, 105.17s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:21:46<8:04:58, 102.82s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:23:27<8:00:46, 102.29s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:25:07<7:55:38, 101.56s/it]
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803169)[0m   warnings.warn(
[36m(TaskRunner pid=3799622)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:28:21<10:03:02, 129.22s/it]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:30:02<9:21:45, 120.81s/it] 
[36m(TaskRunner pid=3799622)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:31:44<8:53:51, 115.22s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:33:25<8:31:44, 110.85s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:35:06<8:16:42, 107.98s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:36:47<8:05:19, 105.89s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:38:33<8:03:30, 105.88s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:40:20<8:02:50, 106.12s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:41:57<7:48:46, 103.40s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:43:37<7:42:27, 102.39s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:46:37<9:25:10, 125.59s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:48:17<8:48:35, 117.90s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:49:57<8:23:12, 112.66s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:51:40<8:08:03, 109.67s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:53:23<7:57:31, 107.71s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:55:00<7:41:53, 104.58s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:56:39<7:32:44, 102.90s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:58:19<7:26:25, 101.85s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:59:57<7:19:45, 100.71s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [7:01:42<7:24:27, 102.17s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:04:36<8:55:48, 123.65s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:06:14<8:20:52, 116.03s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:07:57<8:01:15, 111.92s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:09:32<7:38:47, 107.11s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:11:13<7:29:02, 105.25s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:12:52<7:18:20, 103.14s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:14:28<7:08:45, 101.28s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 00:37:34,387:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:16:16<7:15:34, 103.30s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:17:55<7:08:09, 101.94s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:19:37<7:05:38, 101.75s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:22:28<8:30:36, 122.55s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:24:03<7:55:16, 114.52s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:25:43<7:34:22, 109.93s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:27:21<7:17:52, 106.36s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:28:57<7:03:40, 103.34s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:30:37<6:58:03, 102.38s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:32:12<6:47:32, 100.22s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:33:48<6:40:57, 99.00s/it] 
[36m(TaskRunner pid=3799622)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:35:31<6:43:07, 99.95s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:37:09<6:39:12, 99.39s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:40:05<8:09:47, 122.45s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 01:03:14,434:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:41:57<7:55:34, 119.39s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:43:36<7:28:36, 113.09s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:45:17<7:12:35, 109.52s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:46:55<6:57:00, 106.02s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:48:34<6:47:03, 103.93s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:50:15<6:42:50, 103.29s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:51:55<6:36:33, 102.12s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:53:35<6:32:28, 101.50s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:55:16<6:30:25, 101.41s/it]
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803169)[0m   warnings.warn(
[36m(TaskRunner pid=3799622)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:58:30<8:14:50, 129.09s/it]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [8:00:07<7:36:10, 119.52s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:01:45<7:09:38, 113.06s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:03:24<6:52:19, 108.98s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 01:26:30,367:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 01:26:36,581:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 01:26:41,593:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:05:17<6:54:56, 110.16s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:06:56<6:40:03, 106.68s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:08:38<6:32:51, 105.23s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:10:15<6:22:15, 102.85s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:11:56<6:18:01, 102.17s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 01:35:00,928:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 01:35:06,633:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:13:41<6:19:52, 103.13s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:16:40<7:41:09, 125.77s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:18:22<7:13:28, 118.76s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:20:06<6:55:49, 114.45s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:21:52<6:44:45, 111.92s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:23:36<6:34:27, 109.57s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:25:15<6:20:12, 106.10s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:26:56<6:13:21, 104.68s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:28:35<6:06:07, 103.13s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:30:12<5:57:24, 101.15s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:31:51<5:53:52, 100.63s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:34:50<7:14:26, 124.13s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:36:30<6:46:31, 116.70s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:38:07<6:24:48, 111.00s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:39:46<6:10:07, 107.28s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:41:29<6:03:52, 105.98s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:43:06<5:52:59, 103.31s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:44:47<5:49:22, 102.76s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:46:29<5:46:51, 102.52s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:48:07<5:40:31, 101.14s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:49:48<5:38:12, 100.96s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:52:44<6:51:57, 123.59s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:54:17<6:18:54, 114.24s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:55:55<6:01:21, 109.50s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:57:35<5:50:07, 106.64s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:59:18<5:44:24, 105.43s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:00:59<5:38:46, 104.24s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:02:36<5:30:16, 102.14s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:04:16<5:26:20, 101.45s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:05:55<5:22:03, 100.64s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:07:33<5:17:37, 99.78s/it] 
[36m(TaskRunner pid=3799622)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:10:34<6:33:05, 124.14s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:12:12<6:06:44, 116.42s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:13:50<5:47:22, 110.87s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:15:28<5:33:08, 106.89s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:17:07<5:24:45, 104.76s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:18:48<5:18:41, 103.36s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:20:29<5:15:37, 102.92s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:22:06<5:08:29, 101.14s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:23:47<5:05:51, 100.84s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:25:22<4:59:16, 99.21s/it] 
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 02:48:32,275:Timeout during comparison
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803169)[0m   warnings.warn(
[36m(TaskRunner pid=3799622)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:28:39<6:25:13, 128.41s/it]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:30:17<5:55:50, 119.28s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:31:55<5:35:13, 113.00s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:33:36<5:22:48, 109.43s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:35:16<5:12:48, 106.64s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:36:52<5:01:35, 103.40s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:38:30<4:55:38, 101.95s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:40:04<4:46:55, 99.51s/it] 
[36m(TaskRunner pid=3799622)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:41:44<4:44:58, 99.41s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:43:26<4:45:56, 100.33s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:46:22<5:48:29, 123.00s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:47:59<5:24:54, 115.35s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:49:39<5:09:32, 110.55s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:51:15<4:55:45, 106.26s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:52:54<4:48:07, 104.14s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:54:36<4:44:29, 103.45s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:56:24<4:46:13, 104.72s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:57:58<4:36:16, 101.69s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:59:38<4:32:55, 101.08s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 03:22:46,588:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:01:25<4:36:13, 102.94s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:04:26<5:36:49, 126.31s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:06:05<5:13:06, 118.15s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 03:29:14,994:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:07:49<4:59:49, 113.86s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:09:27<4:45:04, 108.95s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:11:11<4:39:38, 107.56s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:12:55<4:35:06, 106.50s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:14:37<4:30:01, 105.21s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:16:19<4:25:47, 104.23s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:18:03<4:24:08, 104.27s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:19:44<4:19:41, 103.19s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:22:44<5:15:52, 126.35s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:24:21<4:51:51, 117.53s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:26:01<4:36:33, 112.12s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:27:46<4:29:13, 109.89s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:29:29<4:22:22, 107.83s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:31:10<4:15:37, 105.78s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:32:52<4:11:17, 104.70s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:34:35<4:08:16, 104.17s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:36:18<4:05:37, 103.78s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:37:58<4:01:48, 102.90s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:41:01<4:56:11, 126.94s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:42:45<4:37:34, 119.81s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:44:27<4:23:28, 114.55s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:46:11<4:14:23, 111.42s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:47:50<4:04:14, 107.75s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:49:35<4:00:08, 106.73s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:51:18<3:55:57, 105.65s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:53:00<3:51:39, 104.50s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:54:45<3:50:46, 104.90s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:56:26<3:46:05, 103.55s/it]
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803169)[0m   warnings.warn(
[36m(TaskRunner pid=3799622)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:59:48<4:48:37, 133.21s/it]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:01:35<4:29:41, 125.44s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:03:21<4:14:35, 119.34s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 04:26:30,571:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:05:11<4:06:37, 116.51s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:06:59<3:59:48, 114.19s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:08:44<3:51:46, 111.25s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:10:26<3:44:11, 108.48s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:12:10<3:39:42, 107.18s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:13:52<3:34:43, 105.61s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:15:43<3:36:16, 107.25s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:18:48<4:21:05, 130.55s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:20:35<4:04:56, 123.50s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:22:22<3:53:30, 118.74s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:24:08<3:43:58, 114.86s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:25:50<3:34:29, 110.95s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:27:33<3:28:03, 108.55s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:29:16<3:23:12, 106.95s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:30:58<3:18:28, 105.38s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:32:44<3:16:55, 105.50s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 04:55:55,390:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:34:32<3:16:50, 106.40s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:37:44<4:02:02, 132.02s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:39:32<3:46:29, 124.68s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:41:20<3:35:28, 119.71s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:43:08<3:27:07, 116.14s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:44:51<3:18:23, 112.30s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:46:41<3:15:10, 111.53s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:48:27<3:10:38, 109.99s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:50:16<3:08:06, 109.57s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:52:01<3:04:00, 108.24s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:53:44<2:59:43, 106.77s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:56:55<3:40:17, 132.17s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:58:42<3:25:21, 124.46s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 05:21:52,923:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 05:22:00,048:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 05:22:06,281:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 05:22:11,294:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [12:00:49<3:24:44, 125.35s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [12:02:39<3:14:48, 120.50s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 05:25:55,931:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [12:04:42<3:14:10, 121.36s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:06:30<3:05:44, 117.32s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:08:16<2:58:28, 113.92s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:10:04<2:54:09, 112.36s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 05:33:18,105:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:11:56<2:51:53, 112.11s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:13:46<2:48:56, 111.39s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:16:58<3:23:24, 135.61s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:18:45<3:08:33, 127.11s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:20:28<2:55:43, 119.82s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:22:13<2:47:21, 115.42s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:23:57<2:40:35, 112.04s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:25:49<2:38:37, 111.97s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:27:31<2:32:22, 108.84s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:29:16<2:29:15, 107.90s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:31:05<2:27:40, 108.06s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:32:51<2:25:04, 107.46s/it]
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803169)[0m   warnings.warn(
[36m(TaskRunner pid=3799622)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:36:18<3:03:13, 137.42s/it]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:38:08<2:50:01, 129.14s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:40:01<2:41:33, 124.27s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:41:47<2:32:35, 118.90s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:43:32<2:25:13, 114.66s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:45:17<2:19:36, 111.68s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:47:04<2:15:59, 110.27s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:48:52<2:13:24, 109.65s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:50:40<2:11:01, 109.19s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:52:28<2:08:43, 108.79s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:55:40<2:36:06, 133.81s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:57:28<2:25:00, 126.10s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:59:16<2:16:33, 120.49s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [13:01:01<2:09:27, 115.93s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [13:02:49<2:05:03, 113.69s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [13:04:33<1:59:56, 110.72s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [13:06:21<1:57:08, 109.82s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [13:08:12<1:55:50, 110.33s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:10:01<1:53:28, 109.82s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:11:49<1:51:09, 109.33s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:15:04<2:15:01, 135.02s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:16:52<2:04:52, 127.00s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:18:46<1:58:59, 123.09s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:20:36<1:53:08, 119.10s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:22:27<1:48:57, 116.74s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:24:17<1:45:11, 114.75s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:26:06<1:41:40, 112.97s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 06:49:23,640:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:28:04<1:41:00, 114.35s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:29:57<1:38:48, 114.01s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:31:48<1:36:08, 113.11s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 06:55:04,728:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 06:55:11,403:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 06:55:16,424:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 06:55:21,446:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:35:27<2:00:43, 144.87s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:37:22<1:51:01, 135.95s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:39:16<1:43:31, 129.42s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:41:17<1:39:12, 126.64s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:43:13<1:34:42, 123.54s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:45:12<1:31:45, 122.34s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:47:15<1:29:51, 122.54s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:49:17<1:27:42, 122.38s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:51:23<1:26:21, 123.38s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:53:30<1:25:05, 124.52s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 07:16:56,491:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:57:08<1:41:44, 152.61s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 07:20:33,475:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:59:20<1:35:03, 146.24s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [14:01:28<1:29:05, 140.68s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [14:03:38<1:24:48, 137.52s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [14:05:53<1:22:01, 136.72s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [14:08:08<1:19:28, 136.24s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [14:10:20<1:16:30, 135.01s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [14:12:34<1:14:02, 134.62s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [14:14:48<1:11:45, 134.56s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [14:17:02<1:09:26, 134.39s/it]
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803169)[0m   warnings.warn(
[36m(TaskRunner pid=3799622)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:20:57<1:22:22, 164.73s/it]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3799622)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:23:10<1:14:53, 154.94s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:25:23<1:09:16, 148.45s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:27:34<1:04:31, 143.39s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 07:51:02,695:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:29:50<1:01:07, 141.07s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:32:00<57:21, 137.66s/it]  
[36m(TaskRunner pid=3799622)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:34:12<54:23, 136.00s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:36:26<51:52, 135.32s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:38:38<49:16, 134.40s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:40:52<47:01, 134.36s/it]
[36m(TaskRunner pid=3799622)[0m WARNING:2025-11-23 08:04:20,638:Timeout during comparison
[36m(TaskRunner pid=3799622)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:44:38<53:57, 161.86s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:46:52<48:33, 153.36s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:49:07<44:25, 148.08s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:51:24<40:58, 144.59s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:53:41<37:57, 142.32s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:55:58<35:13, 140.88s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:58:18<32:48, 140.60s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [15:00:36<30:15, 139.64s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [15:02:52<27:43, 138.60s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [15:05:07<25:13, 137.62s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [15:08:49<27:08, 162.87s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [15:11:05<23:13, 154.80s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [15:13:20<19:50, 148.84s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [15:15:35<16:52, 144.62s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [15:17:52<14:13, 142.33s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [15:20:07<11:40, 140.15s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [15:22:25<09:18, 139.51s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [15:24:39<06:53, 137.94s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [15:26:56<04:35, 137.64s/it]
[36m(TaskRunner pid=3799622)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:29:13<02:17, 137.40s/it]
[36m(WorkerDict pid=3803169)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3803169)[0m   warnings.warn(
[36m(TaskRunner pid=3799622)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:33:10<01:56, 116.89s/it]
[36m(WorkerDict pid=3803348)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3803348)[0m   warnings.warn([32m [repeated 3x across cluster][0m
