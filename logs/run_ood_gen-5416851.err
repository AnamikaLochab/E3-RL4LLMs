The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a6/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a6//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a6//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a6//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a6/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-20 14:16:01,426	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=1699144)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 14:16:22,608:Waiting for register center actor rMiVgm_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=1702905)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=1702906)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=1702700)[0m [rank0]:[W1220 14:16:40.338321086 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=1702903)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1702903)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1702700)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702903)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702903)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702903)[0m [rank1]:[W1220 14:16:41.019816037 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702700)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1702700)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1702700)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1702905)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(WorkerDict pid=1702906)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=1699144)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1699144)[0m /scratch/gautschi/alochab/E3-RL4LLMs/verl/verl/trainer/ppo/core_algos.py:744: RuntimeWarning: divide by zero encountered in log
[36m(TaskRunner pid=1699144)[0m   print(f"    Entropy H(q):   {Hq.item():.4f} (Max possible: {np.log(corr_mask.sum().item()):.4f})")
[36m(TaskRunner pid=1699144)[0m Training Progress:   0%|          | 1/480 [02:01<16:07:02, 121.13s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   0%|          | 2/480 [04:04<16:16:52, 122.62s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   1%|          | 3/480 [06:10<16:27:38, 124.23s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   1%|          | 4/480 [08:11<16:13:24, 122.70s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   1%|          | 5/480 [10:13<16:09:09, 122.42s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   1%|â–         | 6/480 [12:18<16:14:50, 123.40s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   1%|â–         | 7/480 [14:22<16:15:09, 123.70s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   2%|â–         | 8/480 [16:26<16:12:05, 123.57s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   2%|â–         | 9/480 [18:27<16:05:38, 123.01s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   2%|â–         | 10/480 [21:52<19:21:20, 148.26s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   2%|â–         | 11/480 [23:50<18:05:47, 138.91s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   2%|â–Ž         | 12/480 [25:53<17:26:01, 134.11s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   3%|â–Ž         | 13/480 [27:56<16:57:56, 130.78s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   3%|â–Ž         | 14/480 [30:00<16:39:18, 128.67s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   3%|â–Ž         | 15/480 [32:01<16:18:15, 126.23s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   3%|â–Ž         | 16/480 [34:01<16:02:16, 124.43s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   4%|â–Ž         | 17/480 [36:02<15:51:37, 123.32s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   4%|â–         | 18/480 [38:00<15:37:48, 121.79s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   4%|â–         | 19/480 [40:00<15:31:24, 121.22s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   4%|â–         | 20/480 [43:28<18:49:06, 147.28s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   4%|â–         | 21/480 [45:32<17:53:27, 140.32s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   5%|â–         | 22/480 [47:36<17:14:10, 135.48s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   5%|â–         | 23/480 [49:36<16:35:46, 130.74s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   5%|â–Œ         | 24/480 [51:38<16:15:09, 128.31s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   5%|â–Œ         | 25/480 [53:35<15:46:17, 124.79s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   5%|â–Œ         | 26/480 [55:36<15:36:17, 123.74s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   6%|â–Œ         | 27/480 [57:41<15:37:41, 124.20s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   6%|â–Œ         | 28/480 [59:38<15:18:23, 121.91s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   6%|â–Œ         | 29/480 [1:01:40<15:16:36, 121.94s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   6%|â–‹         | 30/480 [1:04:53<17:54:27, 143.26s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 15:24:51,626:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:   6%|â–‹         | 31/480 [1:06:47<16:47:18, 134.61s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   7%|â–‹         | 32/480 [1:08:35<15:43:58, 126.42s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   7%|â–‹         | 33/480 [1:10:39<15:37:56, 125.90s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   7%|â–‹         | 34/480 [1:12:34<15:10:04, 122.43s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   7%|â–‹         | 35/480 [1:14:25<14:43:35, 119.14s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   8%|â–Š         | 36/480 [1:16:16<14:24:05, 116.77s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   8%|â–Š         | 37/480 [1:18:11<14:18:02, 116.21s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   8%|â–Š         | 38/480 [1:20:10<14:22:22, 117.06s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   8%|â–Š         | 39/480 [1:22:04<14:13:05, 116.07s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   8%|â–Š         | 40/480 [1:25:16<16:57:23, 138.73s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   9%|â–Š         | 41/480 [1:27:12<16:04:34, 131.83s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 15:47:13,662:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:   9%|â–‰         | 42/480 [1:29:14<15:42:34, 129.12s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   9%|â–‰         | 43/480 [1:31:05<14:59:24, 123.49s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   9%|â–‰         | 44/480 [1:32:59<14:36:54, 120.68s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:   9%|â–‰         | 45/480 [1:34:47<14:07:14, 116.86s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  10%|â–‰         | 46/480 [1:36:42<14:02:31, 116.48s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  10%|â–‰         | 47/480 [1:38:37<13:56:53, 115.97s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:40:38<14:04:46, 117.33s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:42:34<14:00:46, 117.05s/it]
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(TaskRunner pid=1699144)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:45:58<17:05:26, 143.09s/it]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1699144)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:47:50<15:55:51, 133.69s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:49:43<15:09:22, 127.48s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:51:30<14:23:27, 121.33s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:53:22<14:01:35, 118.53s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:55:11<13:39:32, 115.70s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:57:02<13:28:03, 114.35s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:58:53<13:20:23, 113.53s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [2:00:41<13:05:46, 111.72s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:02:30<12:57:51, 110.86s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 16:24:00,619:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:05:32<15:25:18, 132.19s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:07:22<14:36:17, 125.48s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:09:08<13:53:34, 119.65s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:10:54<13:24:33, 115.76s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:12:49<13:21:01, 115.53s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:14:37<13:03:42, 113.31s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:16:30<13:00:17, 113.09s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:18:21<12:53:19, 112.35s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:20:11<12:46:53, 111.68s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:21:59<12:38:51, 110.78s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:25:02<15:04:54, 132.43s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:26:52<14:15:35, 125.51s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:28:41<13:39:30, 120.52s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:30:30<13:14:32, 117.13s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:32:20<12:57:29, 114.90s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:34:16<12:58:51, 115.39s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:36:06<12:46:27, 113.83s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:37:56<12:35:27, 112.47s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:39:50<12:37:49, 113.11s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:41:41<12:32:01, 112.52s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:44:36<14:34:24, 131.16s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:46:25<13:47:12, 124.39s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:48:13<13:12:22, 119.45s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:50:04<12:54:54, 117.11s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:51:53<12:37:02, 114.70s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:53:43<12:24:39, 113.11s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:55:31<12:13:22, 111.68s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:57:24<12:14:17, 112.10s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:59:19<12:18:04, 112.97s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [3:01:04<12:00:41, 110.59s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:04:02<14:09:53, 130.75s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:05:46<13:15:33, 122.71s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 17:25:42,143:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:07:37<12:51:16, 119.27s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:09:27<12:30:40, 116.38s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:11:17<12:17:36, 114.65s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:13:05<12:02:34, 112.61s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:14:56<11:56:59, 112.03s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:16:39<11:38:18, 109.39s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:18:18<11:15:57, 106.17s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:20:08<11:22:02, 107.41s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 17:40:03,811:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 17:40:08,835:Timeout during comparison
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(WorkerDict pid=1702700)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1702700)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=1699144)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:23:31<14:20:53, 135.93s/it]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1699144)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:25:15<13:18:47, 126.46s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:27:04<12:43:52, 121.25s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:28:48<12:09:22, 116.08s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:30:28<11:38:01, 111.39s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:32:16<11:28:48, 110.21s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:33:55<11:06:13, 106.88s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:35:42<11:05:12, 107.00s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:37:22<10:50:12, 104.87s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:39:19<11:10:20, 108.41s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:42:15<13:13:23, 128.66s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:44:04<12:34:49, 122.73s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:45:42<11:47:49, 115.41s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:47:30<11:32:00, 113.13s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:49:19<11:23:40, 112.08s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:50:56<10:54:02, 107.51s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:52:36<10:37:42, 105.12s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:54:20<10:34:40, 104.90s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:56:09<10:39:00, 105.91s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:57:53<10:35:15, 105.58s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [4:00:50<12:42:14, 127.04s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:02:34<11:58:04, 120.01s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:04:25<11:39:25, 117.22s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:06:10<11:16:48, 113.75s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:08:13<11:31:03, 116.47s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:10:03<11:16:21, 114.32s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:11:47<10:56:18, 111.24s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:13:32<10:43:24, 109.36s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:15:17<10:34:02, 108.08s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:17:00<10:24:23, 106.73s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:19:56<12:23:21, 127.43s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:21:41<11:41:28, 120.60s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:23:20<11:02:08, 114.16s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:25:07<10:47:27, 111.95s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:26:51<10:33:02, 109.78s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:28:37<10:23:25, 108.42s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:30:22<10:17:19, 107.67s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:32:04<10:05:24, 105.90s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:33:52<10:06:13, 106.36s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:35:39<10:05:52, 106.61s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 18:57:04,882:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:38:36<12:04:18, 127.82s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:40:19<11:20:09, 120.38s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:41:59<10:42:55, 114.13s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:43:43<10:24:58, 111.27s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:45:26<10:07:53, 108.55s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:47:10<9:59:28, 107.37s/it] 
[36m(TaskRunner pid=1699144)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:48:49<9:43:43, 104.86s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:50:27<9:30:49, 102.85s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:52:11<9:30:33, 103.11s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:54:02<9:42:03, 105.51s/it]
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(TaskRunner pid=1699144)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:57:14<12:02:00, 131.28s/it]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1699144)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:59:04<11:26:27, 125.19s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [5:00:50<10:52:16, 119.32s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [5:02:32<10:21:25, 114.02s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [5:04:15<10:02:36, 110.91s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:05:58<9:46:38, 108.30s/it] 
[36m(TaskRunner pid=1699144)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:07:32<9:22:41, 104.20s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:09:14<9:16:15, 103.33s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:10:56<9:13:42, 103.18s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:12:39<9:11:08, 103.02s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:15:36<11:08:26, 125.33s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:17:21<10:33:54, 119.23s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:19:06<10:07:54, 114.70s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:20:43<9:38:29, 109.49s/it] 
[36m(TaskRunner pid=1699144)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:22:19<9:14:46, 105.34s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:23:59<9:05:38, 103.93s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:25:43<9:03:05, 103.78s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:27:19<8:49:24, 101.48s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:29:02<8:49:54, 101.90s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:30:37<8:37:37, 99.86s/it] 
[36m(TaskRunner pid=1699144)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:33:26<10:23:47, 120.73s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:35:04<9:46:34, 113.90s/it] 
[36m(TaskRunner pid=1699144)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:36:42<9:19:28, 108.99s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:38:20<9:01:55, 105.91s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:39:55<8:42:33, 102.46s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:41:37<8:40:49, 102.46s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:43:19<8:37:36, 102.16s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:44:55<8:26:54, 100.38s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:46:36<8:26:29, 100.63s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:48:16<8:24:08, 100.49s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:51:10<10:12:11, 122.44s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 20:11:05,438:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 20:11:10,454:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:53:06<10:00:06, 120.42s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:54:43<9:24:19, 113.62s/it] 
[36m(TaskRunner pid=1699144)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:56:26<9:05:34, 110.22s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:58:03<8:43:57, 106.21s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:59:53<8:48:22, 107.47s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [6:01:34<8:37:15, 105.56s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:03:11<8:22:13, 102.85s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:04:53<8:19:14, 102.58s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:06:36<8:19:26, 102.98s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:09:29<9:59:07, 123.96s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:11:09<9:22:12, 116.72s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:12:49<8:56:29, 111.77s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:14:28<8:35:48, 107.83s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:16:08<8:22:46, 105.48s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:17:46<8:10:54, 103.35s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:19:30<8:09:18, 103.38s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:21:05<7:55:44, 100.86s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 20:40:55,694:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:22:48<7:57:12, 101.53s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:24:24<7:48:05, 99.95s/it] 
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(TaskRunner pid=1699144)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:27:32<9:48:48, 126.17s/it]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1699144)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:29:10<9:08:02, 117.86s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:30:49<8:39:25, 112.11s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:32:29<8:21:31, 108.63s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:34:13<8:12:45, 107.12s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:35:53<8:00:51, 104.92s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:37:36<7:56:47, 104.41s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:39:24<8:00:02, 105.50s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:41:03<7:49:44, 103.62s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:42:39<7:37:53, 101.38s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:45:35<9:16:13, 123.60s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:47:15<8:42:40, 116.58s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:48:54<8:16:37, 111.19s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:50:39<8:07:45, 109.61s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:52:20<7:54:29, 107.03s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:53:57<7:38:26, 103.80s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:55:34<7:28:32, 101.94s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:57:14<7:23:21, 101.15s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:58:49<7:14:04, 99.41s/it] 
[36m(TaskRunner pid=1699144)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [7:00:35<7:20:32, 101.28s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:03:25<8:48:05, 121.87s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:05:03<8:15:08, 114.71s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:06:44<7:56:29, 110.81s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:08:20<7:35:24, 106.32s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:10:07<7:34:38, 106.56s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:11:49<7:26:38, 105.09s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:13:29<7:18:00, 103.47s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:15:13<7:17:08, 103.67s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:16:57<7:15:42, 103.74s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:18:37<7:10:23, 102.88s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:21:26<8:30:58, 122.63s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:23:07<8:01:12, 115.96s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:24:50<7:43:24, 112.11s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:26:28<7:24:05, 107.88s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:28:03<7:06:42, 104.08s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:29:39<6:55:32, 101.76s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:31:15<6:46:08, 99.87s/it] 
[36m(TaskRunner pid=1699144)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:32:51<6:40:29, 98.89s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:34:38<6:48:03, 101.17s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:36:18<6:45:44, 101.02s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:39:12<8:11:24, 122.85s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:41:03<7:54:40, 119.17s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:42:43<7:29:41, 113.37s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:44:27<7:16:38, 110.54s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:46:05<7:00:28, 106.90s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:47:48<6:53:50, 105.66s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:49:32<6:49:50, 105.09s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:51:12<6:43:14, 103.84s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:52:55<6:40:14, 103.51s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:54:40<6:40:27, 104.01s/it]
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(TaskRunner pid=1699144)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:57:51<8:18:43, 130.10s/it]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1699144)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:59:29<7:38:58, 120.25s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:01:07<7:12:25, 113.79s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:02:45<6:52:23, 109.00s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 22:22:36,065:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:04:30<6:45:17, 107.60s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:06:07<6:31:42, 104.45s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:07:49<6:27:30, 103.80s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:09:27<6:19:49, 102.20s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:11:12<6:21:11, 103.03s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:12:50<6:13:29, 101.40s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 22:34:15,261:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:15:46<7:34:14, 123.88s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:17:26<7:06:08, 116.75s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:19:14<6:53:56, 113.93s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:20:55<6:37:56, 110.03s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:22:42<6:33:30, 109.31s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:24:21<6:20:20, 106.14s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:26:07<6:18:41, 106.18s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:27:49<6:12:03, 104.81s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:29:26<6:02:04, 102.47s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:31:08<5:59:29, 102.22s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 22:51:01,580:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:34:07<7:19:08, 125.47s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:35:48<6:51:21, 118.10s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:37:24<6:26:29, 111.49s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:39:04<6:12:03, 107.84s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:40:49<6:07:17, 106.98s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:42:26<5:55:38, 104.09s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:44:07<5:50:42, 103.15s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:45:51<5:49:59, 103.44s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:47:35<5:49:09, 103.71s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:49:18<5:46:25, 103.41s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:52:11<6:53:47, 124.14s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:53:44<6:21:38, 115.07s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:55:23<6:03:28, 110.14s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:57:04<5:52:02, 107.22s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 23:16:58,029:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:58:52<5:51:15, 107.53s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:00:35<5:45:41, 106.37s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:02:15<5:36:52, 104.19s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:03:56<5:32:13, 103.28s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:05:40<5:31:53, 103.72s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:07:18<5:23:59, 101.78s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:10:15<6:34:11, 124.48s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:11:55<6:08:33, 117.00s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:13:35<5:50:31, 111.87s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:15:16<5:38:38, 108.66s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:16:57<5:29:37, 106.33s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:18:41<5:26:22, 105.85s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:20:25<5:22:25, 105.14s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:22:07<5:18:00, 104.27s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 23:42:00,642:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:23:57<5:21:21, 105.94s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:25:36<5:13:20, 103.87s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-20 23:45:29,976:Timeout during comparison
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(TaskRunner pid=1699144)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:28:52<6:34:59, 131.67s/it]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1699144)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:30:32<6:04:20, 122.12s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:32:13<5:42:52, 115.58s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:33:56<5:30:29, 112.03s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:35:37<5:18:54, 108.72s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:37:15<5:07:09, 105.31s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:39:00<5:05:20, 105.29s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:40:38<4:57:09, 103.06s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:42:16<4:51:34, 101.71s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:44:03<4:54:12, 103.23s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:46:58<5:53:29, 124.76s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:48:37<5:29:49, 117.10s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:50:20<5:15:29, 112.68s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:51:58<5:01:46, 108.42s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:53:42<4:56:27, 107.15s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:55:28<4:53:37, 106.77s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:57:19<4:54:58, 107.92s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:17:08,562:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:17:13,585:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:17:18,599:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:17:23,663:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:59:14<4:58:57, 110.05s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [10:00:51<4:46:40, 106.17s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:20:44,398:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:02:39<4:46:22, 106.73s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:24:08,527:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:05:40<5:43:40, 128.88s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:07:20<5:18:48, 120.31s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:27:12,562:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:27:17,582:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:27:26,739:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:27:31,747:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 00:27:36,752:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:09:28<5:23:06, 122.70s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:11:06<5:01:29, 115.22s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:12:52<4:52:09, 112.37s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:14:34<4:42:49, 109.48s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:16:16<4:34:55, 107.11s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:17:57<4:28:36, 105.34s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:19:41<4:25:44, 104.90s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:21:20<4:19:24, 103.08s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:24:13<5:10:26, 124.18s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:25:52<4:49:04, 116.40s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:27:27<4:31:52, 110.22s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:29:14<4:27:13, 109.07s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:30:50<4:16:01, 105.22s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:32:28<4:09:20, 103.17s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:34:08<4:04:47, 102.00s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:35:47<4:01:18, 101.25s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:37:30<4:00:34, 101.65s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:39:08<3:56:13, 100.52s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:42:01<4:45:21, 122.29s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:43:48<4:32:37, 117.68s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:45:26<4:17:24, 111.91s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:47:03<4:05:15, 107.42s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:48:37<3:54:06, 103.28s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:50:19<3:51:52, 103.06s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:52:01<3:49:23, 102.72s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:53:43<3:46:57, 102.39s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:55:23<3:44:07, 101.88s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:57:02<3:40:31, 101.00s/it]
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(TaskRunner pid=1699144)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [11:00:19<4:41:03, 129.72s/it]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1699144)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:02:02<4:21:36, 121.68s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:03:48<4:09:38, 117.02s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:05:32<3:59:13, 113.02s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:07:20<3:54:19, 111.58s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:09:02<3:46:26, 108.69s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:10:41<3:38:48, 105.87s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:12:25<3:35:32, 105.14s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:14:04<3:30:10, 103.37s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:15:54<3:32:37, 105.43s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:18:44<4:09:40, 124.84s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:20:30<3:56:07, 119.06s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:22:15<3:45:50, 114.84s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:24:00<3:37:56, 111.76s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:25:39<3:28:54, 108.06s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 01:45:30,542:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:27:20<3:23:13, 106.03s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:28:55<3:15:04, 102.67s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:30:29<3:08:22, 100.02s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:32:09<3:06:31, 99.92s/it] 
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 01:51:56,704:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:33:48<3:04:41, 99.83s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:36:46<3:45:41, 123.11s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:38:28<3:32:23, 116.91s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:40:10<3:22:20, 112.42s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:41:54<3:16:01, 109.92s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:43:27<3:05:13, 104.85s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:45:08<3:01:22, 103.65s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:46:47<2:57:18, 102.29s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:48:26<2:53:52, 101.28s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:50:03<2:49:52, 99.93s/it] 
[36m(TaskRunner pid=1699144)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:51:43<2:48:32, 100.12s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:54:36<3:23:15, 121.95s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:56:18<3:11:14, 115.90s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 02:16:12,747:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 02:16:17,786:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 02:16:22,804:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:58:18<3:11:26, 117.21s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [12:00:05<3:04:11, 113.93s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [12:01:55<3:00:29, 112.81s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:03:38<2:54:16, 110.07s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:05:20<2:48:29, 107.55s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:07:02<2:44:06, 105.88s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:08:45<2:40:56, 104.96s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:10:30<2:39:25, 105.12s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:13:25<3:09:00, 126.00s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:15:06<2:55:54, 118.59s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:16:46<2:45:20, 112.73s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:18:23<2:36:55, 108.22s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:20:06<2:32:41, 106.52s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:21:53<2:31:14, 106.76s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:23:31<2:25:44, 104.10s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:25:14<2:23:34, 103.78s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:26:59<2:22:29, 104.26s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:28:42<2:20:08, 103.81s/it]
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(TaskRunner pid=1699144)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:32:01<2:56:27, 132.35s/it]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1699144)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:33:48<2:44:20, 124.81s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:35:40<2:37:08, 120.88s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:37:26<2:29:31, 116.51s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:39:11<2:23:10, 113.03s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:40:53<2:17:09, 109.73s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:42:37<2:13:09, 107.97s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:44:25<2:11:18, 107.92s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:46:11<2:08:38, 107.21s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:47:59<2:07:25, 107.68s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:51:02<2:32:03, 130.34s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:52:46<2:20:43, 122.37s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:54:30<2:12:11, 116.64s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:56:16<2:06:53, 113.63s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:58:02<2:02:24, 111.28s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:59:42<1:56:56, 107.94s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [13:01:25<1:53:26, 106.34s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [13:03:13<1:52:17, 106.95s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:04:55<1:49:01, 105.50s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:06:40<1:47:00, 105.25s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:09:40<2:07:45, 127.76s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:11:21<1:57:41, 119.69s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:13:11<1:52:59, 116.89s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:14:53<1:46:41, 112.30s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:16:34<1:41:42, 108.97s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:18:17<1:38:16, 107.20s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:19:59<1:35:00, 105.56s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:21:41<1:32:20, 104.53s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:23:27<1:30:54, 104.90s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:25:07<1:28:03, 103.59s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 03:45:01,593:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:28:09<1:45:42, 126.85s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:29:49<1:37:11, 119.02s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:31:30<1:30:46, 113.46s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:33:21<1:28:17, 112.72s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:35:03<1:23:57, 109.52s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:36:43<1:20:09, 106.87s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:38:25<1:17:17, 105.39s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:40:08<1:15:01, 104.68s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:41:51<1:12:51, 104.08s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:43:34<1:10:54, 103.78s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 04:05:03,467:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:46:36<1:24:47, 127.18s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:48:17<1:17:32, 119.29s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:50:00<1:12:25, 114.34s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:51:45<1:08:46, 111.54s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:53:29<1:05:38, 109.41s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:55:13<1:02:50, 107.74s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:56:56<1:00:13, 106.27s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:58:35<57:19, 104.23s/it]  
[36m(TaskRunner pid=1699144)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [14:00:12<54:25, 102.05s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [14:01:56<52:55, 102.44s/it]
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(TaskRunner pid=1699144)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:05:08<1:04:45, 129.52s/it]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1699144)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:06:50<58:36, 121.27s/it]  
[36m(TaskRunner pid=1699144)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:08:26<52:58, 113.51s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:10:11<49:56, 110.98s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:11:53<46:56, 108.34s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:13:31<43:49, 105.20s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:15:12<41:32, 103.87s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:16:58<40:09, 104.78s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:18:42<38:18, 104.46s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:20:23<36:13, 103.48s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 04:41:57,080:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:23:28<42:36, 127.83s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:25:18<38:45, 122.40s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:26:57<34:38, 115.49s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:28:39<31:32, 111.30s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:30:21<28:55, 108.48s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:32:04<26:44, 106.98s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:33:47<24:38, 105.63s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:35:29<22:42, 104.79s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:37:10<20:41, 103.47s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:38:50<18:47, 102.54s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:41:55<21:12, 127.25s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:43:37<17:56, 119.64s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:45:24<15:25, 115.74s/it]
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 05:05:20,464:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m WARNING:2025-12-21 05:05:25,820:Timeout during comparison
[36m(TaskRunner pid=1699144)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:47:21<13:33, 116.15s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:49:03<11:11, 111.99s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:50:42<09:01, 108.22s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:52:27<07:08, 107.01s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:54:09<05:16, 105.60s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:55:57<03:32, 106.49s/it]
[36m(TaskRunner pid=1699144)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:57:50<01:48, 108.22s/it]
[36m(WorkerDict pid=1702700)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1702700)[0m   warnings.warn(
[36m(TaskRunner pid=1699144)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:01:14<01:52, 112.89s/it]
[36m(WorkerDict pid=1702906)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1702906)[0m   warnings.warn([32m [repeated 3x across cluster][0m
