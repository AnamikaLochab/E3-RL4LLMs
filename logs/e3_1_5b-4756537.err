
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_covvar_kappa__ac_0.1/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_covvar_kappa__ac_0.1//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa__ac_0.1//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa__ac_0.1//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_covvar_kappa__ac_0.1/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-11 22:50:43,655	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=1851369)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-11 22:51:04,597:Waiting for register center actor uUa3N5_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=1855134)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=1854924)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=1854924)[0m [rank0]:[W1111 22:51:22.352255036 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=1854924)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1854924)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1854924)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m [rank2]:[W1111 22:51:23.693186504 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855137)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1855134)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1855137)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1855137)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1855137)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(WorkerDict pid=1855135)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=1855134)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855134)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:   0%|          | 1/480 [01:58<15:44:07, 118.26s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   0%|          | 2/480 [03:57<15:47:35, 118.95s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   1%|          | 3/480 [06:01<16:04:12, 121.28s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   1%|          | 4/480 [07:59<15:52:19, 120.04s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   1%|          | 5/480 [09:59<15:48:22, 119.79s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   1%|â–         | 6/480 [12:00<15:49:02, 120.13s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   1%|â–         | 7/480 [14:02<15:53:33, 120.96s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   2%|â–         | 8/480 [16:04<15:54:47, 121.37s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   2%|â–         | 9/480 [18:05<15:50:29, 121.08s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   2%|â–         | 10/480 [21:25<18:59:55, 145.52s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   2%|â–         | 11/480 [23:23<17:51:47, 137.12s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   2%|â–Ž         | 12/480 [25:22<17:04:55, 131.40s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   3%|â–Ž         | 13/480 [27:20<16:32:00, 127.45s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   3%|â–Ž         | 14/480 [29:19<16:10:25, 124.95s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   3%|â–Ž         | 15/480 [31:18<15:53:24, 123.02s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   3%|â–Ž         | 16/480 [33:18<15:45:21, 122.24s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   4%|â–Ž         | 17/480 [35:19<15:39:33, 121.76s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   4%|â–         | 18/480 [37:17<15:30:38, 120.86s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   4%|â–         | 19/480 [39:17<15:25:31, 120.46s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-11 23:35:56,911:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:   4%|â–         | 20/480 [42:45<18:44:23, 146.66s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   4%|â–         | 21/480 [44:42<17:35:32, 137.98s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   5%|â–         | 22/480 [46:43<16:52:29, 132.64s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   5%|â–         | 23/480 [48:42<16:19:23, 128.59s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   5%|â–Œ         | 24/480 [50:38<15:48:24, 124.79s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   5%|â–Œ         | 25/480 [52:33<15:23:40, 121.80s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   5%|â–Œ         | 26/480 [54:31<15:13:57, 120.79s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   6%|â–Œ         | 27/480 [56:33<15:14:31, 121.13s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   6%|â–Œ         | 28/480 [58:26<14:55:00, 118.81s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:24<14:51:36, 118.62s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:32<17:24:44, 139.30s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:18<16:08:47, 129.46s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:06<15:18:05, 122.96s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:04<15:03:25, 121.27s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:59<14:48:03, 119.47s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:52<14:32:21, 117.62s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:44<14:16:53, 115.80s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:37<14:09:03, 115.00s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:37<14:19:27, 116.67s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:28<14:03:11, 114.72s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:40<16:52:07, 138.02s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:34<15:57:03, 130.81s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:32<15:27:41, 127.08s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   9%|â–‰         | 43/480 [1:29:24<14:51:23, 122.39s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   9%|â–‰         | 44/480 [1:31:16<14:27:28, 119.38s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:   9%|â–‰         | 45/480 [1:33:03<13:58:33, 115.66s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:58<13:54:40, 115.39s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:48<13:41:10, 113.79s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:42<13:40:12, 113.92s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:38<13:41:56, 114.42s/it]
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(TaskRunner pid=1851369)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:44:01<16:51:14, 141.10s/it]
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:51<15:42:04, 131.76s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:47:39<14:49:38, 124.72s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:49:26<14:08:04, 119.17s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:51:19<13:54:22, 117.52s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:53:06<13:30:22, 114.40s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:56<13:18:52, 113.05s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:56:48<13:14:53, 112.75s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:58:35<13:00:21, 110.95s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 00:53:20,488:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:00:27<13:01:26, 111.37s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:03:25<15:17:50, 131.12s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:05:17<14:35:26, 125.36s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:07:04<13:55:32, 119.93s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:08:50<13:24:35, 115.77s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:10:43<13:18:03, 115.11s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:12:30<12:57:48, 112.45s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:14:23<12:57:07, 112.63s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:16:09<12:42:12, 110.73s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:18:00<12:41:06, 110.84s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:19:50<12:37:52, 110.64s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:22:55<15:08:27, 132.95s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:24:42<14:12:44, 125.10s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:26:31<13:36:43, 120.11s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:28:20<13:12:17, 116.80s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:30:11<13:00:10, 115.30s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:32:01<12:45:55, 113.47s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:33:54<12:43:48, 113.44s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:35:45<12:36:11, 112.58s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:37:39<12:37:15, 113.02s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:39:31<12:33:26, 112.73s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:42:34<14:52:47, 133.92s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 01:37:20,822:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:44:28<14:11:07, 127.99s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:46:20<13:37:02, 123.17s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:48:11<13:10:05, 119.41s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:50:00<12:47:22, 116.27s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:51:49<12:32:31, 114.31s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:53:39<12:21:34, 112.93s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:55:31<12:17:23, 112.58s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:57:21<12:10:25, 111.80s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:59:09<12:01:28, 110.71s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:02:13<14:21:33, 132.55s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:04:01<13:31:50, 125.22s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 01:58:43,383:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:05:56<13:11:03, 122.33s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:07:45<12:43:34, 118.38s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 02:02:29,656:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:09:41<12:35:50, 117.49s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:11:28<12:13:17, 114.28s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:13:22<12:10:55, 114.21s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:15:08<11:54:42, 111.97s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:16:50<11:32:58, 108.84s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:18:47<11:46:48, 111.31s/it]
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(WorkerDict pid=1854924)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1854924)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=1851369)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:22:08<14:35:30, 138.24s/it]
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:23:52<13:28:54, 128.06s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 02:18:35,272:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:25:44<12:56:13, 123.21s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:27:28<12:17:06, 117.31s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:29:13<11:52:06, 113.63s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:31:03<11:43:18, 112.53s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:32:48<11:27:08, 110.24s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:34:38<11:25:51, 110.33s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:36:21<11:10:37, 108.17s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:38:21<11:29:41, 111.54s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:41:26<13:43:49, 133.59s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:43:15<12:55:47, 126.15s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:44:55<12:06:14, 118.41s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:46:42<11:44:07, 115.12s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:48:31<11:31:06, 113.30s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:50:09<11:00:48, 108.63s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:51:53<10:50:37, 107.24s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:53:38<10:43:43, 106.40s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:55:22<10:37:40, 105.69s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:57:07<10:35:27, 105.62s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [4:00:08<12:49:10, 128.20s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:01:47<11:54:50, 119.47s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:03:35<11:32:45, 116.11s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:05:18<11:06:58, 112.10s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 03:00:08,326:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:07:19<11:20:56, 114.76s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:09:01<10:55:54, 110.86s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:10:45<10:42:23, 108.88s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:12:25<10:24:34, 106.16s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:14:10<10:20:40, 105.80s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:15:53<10:13:39, 104.90s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:18:49<12:16:16, 126.22s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:20:33<11:36:03, 119.67s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:22:10<10:55:22, 113.00s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:23:54<10:36:31, 110.06s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 03:18:35,439:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:25:41<10:29:10, 109.11s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:27:25<10:18:51, 107.63s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:29:09<10:10:48, 106.53s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:30:48<9:56:15, 104.30s/it] 
[36m(TaskRunner pid=1851369)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:32:31<9:53:29, 104.12s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:34:15<9:49:53, 103.79s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:37:09<11:49:00, 125.12s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:38:52<11:07:55, 118.22s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:40:30<10:33:23, 112.44s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:42:14<10:17:18, 109.91s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:43:54<9:58:37, 106.90s/it] 
[36m(TaskRunner pid=1851369)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:45:35<9:46:28, 105.04s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:47:11<9:29:57, 102.39s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:48:49<9:20:33, 101.00s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:50:29<9:17:04, 100.68s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:52:16<9:26:23, 102.67s/it]
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(TaskRunner pid=1851369)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:55:31<11:55:55, 130.17s/it]
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:57:15<11:11:14, 122.42s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:59:00<10:39:58, 117.07s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [5:00:41<10:12:01, 112.30s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [5:02:25<9:57:46, 110.02s/it] 
[36m(TaskRunner pid=1851369)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:04:08<9:43:38, 107.75s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:05:47<9:27:09, 105.03s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:07:28<9:20:16, 104.08s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:09:13<9:19:59, 104.35s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:10:56<9:15:37, 103.86s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:13:58<11:18:46, 127.27s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:15:51<10:53:46, 122.97s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:17:39<10:27:21, 118.37s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:19:20<9:58:24, 113.26s/it] 
[36m(TaskRunner pid=1851369)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:21:02<9:38:34, 109.85s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:22:46<9:27:47, 108.15s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:24:31<9:20:25, 107.09s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:26:12<9:09:10, 105.27s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:27:59<9:10:41, 105.90s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:29:41<9:02:28, 104.66s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:32:44<11:02:50, 128.29s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:34:29<10:23:44, 121.12s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:36:12<9:55:01, 115.92s/it] 
[36m(TaskRunner pid=1851369)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:37:56<9:34:28, 112.28s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:39:40<9:20:20, 109.87s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:41:27<9:13:44, 108.93s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:43:14<9:09:15, 108.41s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:45:00<9:03:11, 107.56s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 04:39:43,706:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:46:53<9:09:24, 109.15s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:48:38<9:02:06, 108.06s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:51:47<11:01:41, 132.34s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 04:46:33,088:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:53:41<10:32:11, 126.86s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:55:28<10:00:04, 120.82s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:57:15<9:37:36, 116.69s/it] 
[36m(TaskRunner pid=1851369)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:58:59<9:17:28, 113.00s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [6:00:54<9:18:08, 113.52s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [6:02:41<9:06:52, 111.61s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 04:57:26,372:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:04:34<9:05:55, 111.79s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:06:20<8:55:52, 110.11s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:08:09<8:52:21, 109.76s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:11:16<10:43:07, 133.06s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:12:59<9:56:35, 123.86s/it] 
[36m(TaskRunner pid=1851369)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:14:42<9:25:00, 117.71s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:16:30<9:09:17, 114.84s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:19:03<10:01:14, 126.13s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:21:32<10:32:17, 133.11s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:24:06<11:00:07, 139.46s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:26:34<11:08:54, 141.82s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:29:05<11:20:34, 144.80s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:31:34<11:23:58, 146.05s/it]
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(TaskRunner pid=1851369)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:36:25<14:43:52, 189.40s/it]
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:38:28<13:08:09, 169.49s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:40:13<11:36:35, 150.34s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:41:59<10:32:11, 136.94s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:43:47<9:50:21, 128.34s/it] 
[36m(TaskRunner pid=1851369)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:45:45<9:33:08, 125.05s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:47:33<9:08:17, 120.07s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:49:25<8:54:46, 117.53s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:51:05<8:29:43, 112.44s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:52:49<8:15:25, 109.69s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:55:59<10:02:11, 133.82s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 05:50:40,853:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:57:49<9:27:30, 126.58s/it] 
[36m(TaskRunner pid=1851369)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:59:34<8:57:08, 120.26s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [7:01:23<8:40:00, 116.85s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [7:03:09<8:23:59, 113.68s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [7:04:51<8:06:36, 110.17s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [7:06:34<7:55:29, 108.07s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [7:08:18<7:47:56, 106.76s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [7:09:59<7:38:38, 105.03s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [7:11:51<7:46:04, 107.14s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:14:55<9:24:31, 130.27s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:16:38<8:46:26, 121.95s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:18:26<8:25:55, 117.66s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:20:04<7:59:38, 111.98s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:21:50<7:50:23, 110.25s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:23:34<7:40:31, 108.36s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:25:17<7:30:47, 106.48s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:27:05<7:31:50, 107.16s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:28:51<7:28:06, 106.69s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 06:23:36,880:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:30:43<7:33:43, 108.46s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:33:51<9:10:36, 132.15s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:35:34<8:32:44, 123.55s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:37:20<8:08:18, 118.14s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:39:04<7:48:55, 113.91s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:40:47<7:33:30, 110.61s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:42:32<7:25:05, 109.00s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:44:17<7:18:23, 107.80s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:46:00<7:10:55, 106.40s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:47:52<7:15:28, 107.97s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:49:38<7:12:02, 107.56s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:52:53<8:55:03, 133.77s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:54:48<8:30:09, 128.07s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:56:37<8:04:46, 122.21s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:58:25<7:46:27, 118.09s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [8:00:13<7:32:48, 115.12s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [8:02:05<7:26:20, 113.96s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [8:03:51<7:15:05, 111.56s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [8:05:38<7:08:53, 110.44s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [8:07:29<7:07:17, 110.51s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [8:09:19<7:05:07, 110.42s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 07:05:50,540:Timeout during comparison
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(TaskRunner pid=1851369)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [8:12:56<9:05:32, 142.32s/it]
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [8:14:43<8:23:10, 131.84s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:16:30<7:52:28, 124.34s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:18:16<7:29:30, 118.81s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:20:01<7:11:19, 114.51s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 07:14:43,574:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:21:52<7:06:02, 113.61s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:23:42<7:00:03, 112.52s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:25:28<6:50:24, 110.42s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:27:19<6:49:25, 110.66s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 07:22:01,967:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:29:09<6:46:38, 110.40s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:32:20<8:14:18, 134.81s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:34:09<7:43:19, 126.94s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:36:01<7:25:23, 122.59s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:37:52<7:09:51, 118.85s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:39:48<7:04:45, 117.99s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:41:35<6:51:43, 114.90s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:43:23<6:42:32, 112.86s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:45:15<6:38:52, 112.36s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:47:03<6:33:20, 111.32s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:48:54<6:30:33, 111.06s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 07:43:40,011:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 07:43:45,020:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:52:21<8:09:40, 139.91s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:54:12<7:37:17, 131.28s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:56:01<7:11:49, 124.57s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:57:50<6:53:45, 119.93s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:59:44<6:44:53, 117.93s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [9:01:31<6:32:28, 114.87s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [9:03:25<6:29:27, 114.55s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [9:05:22<6:30:21, 115.38s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [9:07:17<6:27:29, 115.10s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [9:09:07<6:20:41, 113.64s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 08:05:42,798:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [9:12:27<7:44:52, 139.46s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [9:14:09<7:05:54, 128.42s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [9:15:57<6:43:07, 122.16s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [9:17:45<6:27:12, 117.93s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [9:19:37<6:19:08, 116.06s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:21:29<6:13:17, 114.86s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:23:16<6:03:34, 112.45s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:25:04<5:58:00, 111.30s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:26:53<5:53:46, 110.56s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:28:41<5:49:19, 109.73s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:31:56<7:09:04, 135.50s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:33:43<6:39:38, 126.87s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:35:30<6:18:40, 120.86s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:37:15<6:01:46, 116.08s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:39:03<5:52:32, 113.72s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:40:52<5:46:08, 112.26s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:42:41<5:41:21, 111.31s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:44:24<5:32:01, 108.86s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:46:13<5:30:12, 108.86s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:47:57<5:24:00, 107.41s/it]
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(TaskRunner pid=1851369)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:51:26<6:53:13, 137.74s/it]
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:53:13<6:23:55, 128.69s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:54:59<6:01:41, 121.92s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:56:48<5:47:39, 117.85s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:58:37<5:37:42, 115.13s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [10:00:23<5:27:52, 112.42s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [10:02:08<5:19:56, 110.33s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [10:03:53<5:13:27, 108.72s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [10:05:40<5:10:01, 108.15s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [10:07:31<5:10:56, 109.10s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [10:10:46<6:21:38, 134.70s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [10:12:34<5:57:17, 126.85s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [10:14:21<5:38:26, 120.87s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [10:16:07<5:23:58, 116.40s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [10:17:55<5:15:16, 113.95s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 09:12:40,930:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [10:19:51<5:14:32, 114.38s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [10:21:48<5:15:15, 115.34s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [10:23:34<5:05:44, 112.54s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [10:25:24<5:01:22, 111.62s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:27:12<4:56:44, 110.59s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:30:28<6:03:11, 136.20s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:32:17<5:39:37, 128.16s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 09:26:58,026:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 09:27:04,392:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:34:13<5:27:41, 124.44s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:35:59<5:10:49, 118.79s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:37:50<5:03:13, 116.62s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:39:37<4:53:36, 113.65s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:41:30<4:51:23, 113.53s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:43:20<4:46:45, 112.46s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 09:38:08,215:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:45:17<4:48:29, 113.88s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:47:03<4:40:22, 111.41s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:50:14<5:38:17, 135.31s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:52:00<5:14:21, 126.59s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:53:46<4:56:41, 120.28s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:55:37<4:48:05, 117.59s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:57:25<4:38:45, 114.56s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:59:11<4:30:45, 112.04s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [11:01:00<4:26:37, 111.09s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [11:02:50<4:24:30, 110.98s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [11:04:42<4:23:07, 111.18s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [11:06:30<4:18:57, 110.19s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [11:09:47<5:17:37, 136.12s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [11:11:39<4:58:45, 128.96s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [11:13:29<4:43:42, 123.35s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [11:15:19<4:32:20, 119.27s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [11:17:05<4:21:34, 115.40s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [11:18:59<4:18:45, 115.00s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [11:20:49<4:13:21, 113.44s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [11:22:38<4:08:28, 112.10s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [11:24:31<4:07:08, 112.34s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [11:26:18<4:02:05, 110.88s/it]
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(TaskRunner pid=1851369)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [11:29:50<5:05:48, 141.14s/it]
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:31:44<4:45:33, 132.82s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:33:38<4:31:30, 127.27s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:35:31<4:20:12, 122.93s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:37:26<4:13:10, 120.56s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:39:17<4:05:06, 117.65s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:41:04<3:56:55, 114.64s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:42:56<3:53:26, 113.87s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:44:42<3:46:37, 111.45s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:46:38<3:47:22, 112.75s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:49:50<4:33:24, 136.70s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:51:41<4:15:45, 128.95s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:53:32<4:02:33, 123.33s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:55:20<3:51:46, 118.86s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:57:04<3:41:15, 114.44s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:58:51<3:35:03, 112.20s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [12:00:38<3:30:24, 110.74s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [12:02:23<3:25:14, 108.98s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [12:04:11<3:22:52, 108.68s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [12:05:58<3:19:44, 107.97s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [12:09:16<4:07:55, 135.23s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [12:11:05<3:50:58, 127.14s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [12:12:53<3:38:52, 121.60s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 11:07:39,284:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [12:14:50<3:34:03, 120.04s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [12:16:34<3:23:58, 115.46s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [12:18:26<3:19:57, 114.26s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [12:20:15<3:15:06, 112.56s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [12:22:05<3:12:12, 111.97s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [12:23:53<3:08:16, 110.75s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [12:25:42<3:05:47, 110.37s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [12:29:00<3:47:19, 136.39s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [12:30:51<3:32:38, 128.88s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 11:25:35,573:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 11:25:40,604:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 11:25:46,625:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 11:25:51,634:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 11:25:56,651:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [12:33:07<3:33:51, 130.93s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [12:35:02<3:24:06, 126.25s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [12:37:05<3:20:28, 125.29s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:39:01<3:13:47, 122.40s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:40:58<3:09:28, 120.94s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:42:56<3:05:53, 119.93s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 11:37:43,164:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:44:55<3:03:28, 119.65s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:46:54<3:01:22, 119.58s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:50:18<3:37:18, 144.87s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:52:16<3:22:53, 136.78s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:54:12<3:11:37, 130.65s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:56:10<3:03:51, 126.80s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:58:09<2:58:10, 124.30s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [13:00:12<2:55:32, 123.91s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [13:02:09<2:50:41, 121.93s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [13:04:11<2:48:52, 122.07s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [13:06:11<2:45:57, 121.43s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [13:08:13<2:44:06, 121.56s/it]
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(TaskRunner pid=1851369)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [13:11:56<3:22:27, 151.85s/it]
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [13:14:07<3:11:52, 145.73s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [13:16:13<3:01:49, 139.87s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [13:18:15<2:52:36, 134.50s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [13:20:18<2:46:03, 131.10s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [13:22:19<2:40:01, 128.02s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [13:24:22<2:36:00, 126.50s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 12:19:17,138:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [13:26:31<2:34:40, 127.13s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [13:28:35<2:31:34, 126.31s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [13:30:37<2:28:00, 125.08s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [13:34:07<2:55:27, 150.39s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [13:36:08<2:42:59, 141.73s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [13:38:08<2:33:05, 135.07s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [13:40:09<2:26:01, 130.77s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [13:42:10<2:20:45, 127.96s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [13:44:06<2:14:41, 124.33s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [13:46:05<2:10:55, 122.75s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [13:48:07<2:08:30, 122.39s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:50:04<2:05:04, 121.04s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:52:02<2:02:01, 120.02s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:55:35<2:28:01, 148.02s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:57:33<2:16:39, 138.98s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:59:39<2:10:28, 134.98s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [14:01:36<2:03:09, 129.64s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [14:03:35<1:57:58, 126.41s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 12:58:23,307:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 12:58:29,470:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [14:05:43<1:56:15, 126.83s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [14:07:39<1:51:18, 123.68s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [14:09:34<1:46:57, 121.09s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [14:11:35<1:44:46, 120.90s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [14:13:29<1:41:12, 119.07s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 13:08:14,826:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 13:08:22,211:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 13:08:28,457:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [14:17:04<2:03:04, 147.69s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [14:18:59<1:52:30, 137.76s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [14:20:49<1:43:38, 129.54s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [14:22:47<1:38:41, 125.99s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [14:24:38<1:33:16, 121.67s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [14:26:30<1:29:08, 118.85s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [14:28:26<1:26:27, 117.90s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [14:30:22<1:24:03, 117.28s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [14:32:16<1:21:20, 116.20s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [14:34:11<1:19:10, 115.88s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [14:37:29<1:33:42, 140.55s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [14:39:24<1:26:22, 132.89s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [14:41:20<1:20:56, 127.81s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [14:43:16<1:16:40, 124.34s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [14:45:12<1:13:07, 121.87s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [14:47:09<1:10:17, 120.49s/it]
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 13:42:00,204:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m WARNING:2025-11-12 13:42:06,047:Timeout during comparison
[36m(TaskRunner pid=1851369)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [14:49:18<1:09:42, 123.00s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [14:51:17<1:06:54, 121.66s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [14:53:13<1:03:59, 119.98s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [14:55:16<1:02:25, 120.81s/it]
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(TaskRunner pid=1851369)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:59:00<1:16:00, 152.00s/it]
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1851369)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [15:01:05<1:09:28, 143.76s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [15:03:03<1:03:29, 136.07s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [15:05:02<58:56, 130.98s/it]  
[36m(TaskRunner pid=1851369)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [15:07:02<55:21, 127.76s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [15:08:59<51:49, 124.37s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [15:10:59<49:15, 123.14s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [15:13:02<47:08, 122.96s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [15:15:04<45:00, 122.75s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [15:17:02<42:25, 121.23s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [15:20:30<49:05, 147.26s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [15:22:31<44:09, 139.47s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [15:24:30<40:00, 133.37s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [15:26:28<36:30, 128.85s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [15:28:25<33:23, 125.23s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [15:30:30<31:17, 125.17s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [15:32:31<28:54, 123.90s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [15:34:28<26:24, 121.91s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [15:36:28<24:15, 121.30s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [15:38:28<22:08, 120.76s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [15:41:57<24:33, 147.32s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [15:43:54<20:44, 138.33s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [15:45:55<17:44, 133.08s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [15:47:53<14:59, 128.57s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [15:49:50<12:29, 125.00s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [15:51:45<10:09, 121.92s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [15:53:43<08:03, 120.79s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [15:55:38<05:57, 119.03s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [15:57:36<03:57, 118.65s/it]
[36m(TaskRunner pid=1851369)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:59:37<01:59, 119.47s/it]
[36m(WorkerDict pid=1854924)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1854924)[0m   warnings.warn(
[36m(TaskRunner pid=1851369)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [16:03:18<02:00, 120.66s/it]
[36m(WorkerDict pid=1855135)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1855135)[0m   warnings.warn([32m [repeated 3x across cluster][0m
