
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_0.00001_3_clamped_2.0/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_0.00001_3_clamped_2.0//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.00001_3_clamped_2.0//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.00001_3_clamped_2.0//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_0.00001_3_clamped_2.0/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-18 01:03:30,078	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=1786626)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 01:03:50,355:Waiting for register center actor 5CMQUP_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=1790358)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=1790178)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=1790178)[0m [rank0]:[W1118 01:04:08.256392976 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=1790178)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1790178)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1790178)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m [rank1]:[W1118 01:04:08.591266398 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1790178)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1790358)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(WorkerDict pid=1790357)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:   0%|          | 1/480 [01:59<15:51:49, 119.23s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   0%|          | 2/480 [03:59<15:56:52, 120.11s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   1%|          | 3/480 [06:02<16:03:09, 121.15s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   1%|          | 4/480 [07:59<15:48:06, 119.51s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   1%|          | 5/480 [09:59<15:49:16, 119.91s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   1%|â–         | 6/480 [12:01<15:52:21, 120.55s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   1%|â–         | 7/480 [14:05<15:58:08, 121.54s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   2%|â–         | 8/480 [16:05<15:53:43, 121.24s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   2%|â–         | 9/480 [18:05<15:47:17, 120.68s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   2%|â–         | 10/480 [21:27<19:03:30, 145.98s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   2%|â–         | 11/480 [23:26<17:55:31, 137.59s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   2%|â–Ž         | 12/480 [25:25<17:07:54, 131.78s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   3%|â–Ž         | 13/480 [27:25<16:39:14, 128.38s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   3%|â–Ž         | 14/480 [29:27<16:21:01, 126.31s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   3%|â–Ž         | 15/480 [31:23<15:55:20, 123.27s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   3%|â–Ž         | 16/480 [33:23<15:45:23, 122.25s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   4%|â–Ž         | 17/480 [35:22<15:36:43, 121.39s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   4%|â–         | 18/480 [37:19<15:25:10, 120.15s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   4%|â–         | 19/480 [39:19<15:22:35, 120.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   4%|â–         | 20/480 [42:41<18:28:25, 144.58s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   4%|â–         | 21/480 [44:42<17:31:59, 137.52s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   5%|â–         | 22/480 [46:42<16:48:22, 132.10s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   5%|â–         | 23/480 [48:40<16:15:35, 128.09s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   5%|â–Œ         | 24/480 [50:35<15:43:41, 124.17s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   5%|â–Œ         | 25/480 [52:31<15:21:34, 121.53s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   5%|â–Œ         | 26/480 [54:28<15:11:12, 120.42s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   6%|â–Œ         | 27/480 [56:31<15:14:15, 121.09s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   6%|â–Œ         | 28/480 [58:24<14:54:29, 118.74s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:23<14:52:26, 118.73s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:33<17:30:50, 140.11s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:20<16:14:37, 130.24s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:07<15:20:30, 123.28s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:04<15:03:26, 121.27s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:55<14:38:50, 118.23s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:48<14:24:26, 116.55s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:37<14:06:03, 114.33s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:28<13:56:15, 113.26s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:25<14:02:22, 114.35s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:13<13:47:15, 112.55s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 02:29:25,346:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:28<16:46:57, 137.31s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:17<15:41:53, 128.73s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:10<15:05:59, 124.11s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:59<14:30:55, 119.58s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:50<14:09:38, 116.92s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:34<13:40:56, 113.23s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:25<13:32:53, 112.38s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:16<13:28:21, 112.01s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:09<13:28:47, 112.33s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:02<13:28:02, 112.49s/it]
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(TaskRunner pid=1786626)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:21<16:33:36, 138.64s/it]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:09<15:23:54, 129.22s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:56<14:34:45, 122.63s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:40<13:53:11, 117.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:29<13:33:44, 114.61s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:12<13:07:58, 111.24s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:00<12:57:52, 110.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:49<12:54:40, 109.88s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:31<12:36:26, 107.55s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:59:15<12:26:00, 106.32s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:10<14:50:01, 127.15s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:03:54<13:59:19, 120.19s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:39<13:25:04, 115.56s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:07:23<12:58:52, 112.07s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 03:14:54,204:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:09:19<13:04:57, 113.22s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:10:59<12:35:23, 109.21s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:12:45<12:28:08, 108.43s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:14:29<12:16:16, 106.96s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:16:15<12:11:42, 106.56s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:18:02<12:11:05, 106.73s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:21:06<14:48:50, 130.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:22:50<13:52:25, 122.12s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:24:33<13:11:19, 116.37s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:26:16<12:42:38, 112.43s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:28:04<12:32:19, 111.18s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 03:35:31,166:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:29:54<12:26:34, 110.60s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:31:42<12:20:58, 110.05s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:33:30<12:14:40, 109.38s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:35:16<12:05:43, 108.32s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:37:04<12:04:08, 108.35s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:40:01<14:19:00, 128.85s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:41:46<13:28:12, 121.53s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:43:29<12:50:48, 116.20s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:45:16<12:30:52, 113.48s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:47:02<12:13:15, 111.10s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:48:47<11:59:16, 109.26s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:50:34<11:52:22, 108.48s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:52:19<11:45:17, 107.68s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:54:07<11:43:01, 107.61s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:55:49<11:29:52, 105.86s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:58:47<13:50:24, 127.76s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:00:29<12:57:45, 119.96s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 04:07:52,024:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 04:07:58,825:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:02:20<12:38:11, 117.25s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:04:06<12:13:24, 113.71s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:05:54<12:02:08, 112.25s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:07:37<11:40:56, 109.24s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:09:28<11:43:06, 109.86s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:11:09<11:24:38, 107.25s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:12:45<11:01:56, 103.97s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:14:34<11:09:34, 105.45s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 04:23:36,534:Timeout during comparison
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(WorkerDict pid=1790178)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1790178)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=1786626)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:17:55<14:09:17, 134.10s/it]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:19:35<13:01:12, 123.67s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 04:26:59,316:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:21:25<12:34:40, 119.79s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:23:05<11:53:59, 113.63s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:24:46<11:29:23, 110.01s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:26:32<11:20:02, 108.81s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:28:13<11:04:13, 106.56s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:30:02<11:05:50, 107.11s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:31:43<10:53:13, 105.36s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:33:37<11:06:47, 107.84s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:36:36<13:17:22, 129.30s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:38:22<12:31:27, 122.19s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:39:59<11:44:06, 114.80s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:41:45<11:25:41, 112.10s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:43:32<11:14:09, 110.52s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:45:10<10:49:06, 106.70s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:46:51<10:37:51, 105.14s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:48:36<10:35:43, 105.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:50:20<10:32:04, 104.76s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:52:04<10:28:17, 104.42s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 04:59:31,266:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:55:10<12:54:32, 129.09s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:56:48<11:56:33, 119.76s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:58:37<11:35:18, 116.53s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:00:22<11:11:43, 112.90s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:02:17<11:13:30, 113.51s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:03:58<10:49:29, 109.77s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:05:43<10:39:13, 108.34s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:07:21<10:19:55, 105.37s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:09:06<10:17:15, 105.21s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:10:50<10:12:41, 104.73s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:13:49<12:21:08, 127.05s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:15:35<11:42:31, 120.78s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:17:12<10:59:45, 113.75s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:18:57<10:42:06, 111.03s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:20:41<10:27:54, 108.89s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:22:26<10:18:48, 107.62s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:24:10<10:11:17, 106.62s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:25:54<10:05:23, 105.90s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:27:42<10:06:13, 106.36s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:29:22<9:54:26, 104.59s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:32:19<11:55:04, 126.19s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:34:03<11:15:52, 119.62s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:35:45<10:43:29, 114.23s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:37:32<10:29:49, 112.14s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:39:14<10:12:02, 109.29s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:40:55<9:55:35, 106.67s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:42:32<9:37:48, 103.80s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:44:12<9:30:20, 102.76s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:45:54<9:26:10, 102.32s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:47:40<9:30:51, 103.48s/it]
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(TaskRunner pid=1786626)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:50:53<11:56:26, 130.26s/it]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:52:36<11:09:27, 122.09s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:54:17<10:33:32, 115.89s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:55:56<10:04:07, 110.85s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:57:41<9:51:57, 108.95s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:59:22<9:37:09, 106.55s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:01:00<9:21:22, 103.96s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:02:36<9:06:42, 101.56s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:04:22<9:12:21, 102.93s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:06:04<9:10:23, 102.88s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:09:02<11:08:42, 125.38s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:10:54<10:44:46, 121.27s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:12:37<10:13:28, 115.75s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:14:17<9:47:04, 111.12s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:15:55<9:24:05, 107.10s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:17:37<9:14:45, 105.67s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:19:19<9:06:16, 104.38s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:20:57<8:54:31, 102.47s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:22:39<8:52:14, 102.35s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:24:17<8:44:46, 101.24s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:27:12<10:36:34, 123.21s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:28:57<10:06:20, 117.73s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:30:37<9:36:42, 112.34s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:32:15<9:13:40, 108.21s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:33:52<8:54:15, 104.76s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:35:30<8:43:04, 102.90s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:37:11<8:38:14, 102.28s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:38:51<8:31:59, 101.38s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:40:33<8:32:27, 101.81s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:42:12<8:26:01, 100.87s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:45:07<10:16:12, 123.24s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 06:52:31,090:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:46:52<9:46:29, 117.69s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:48:33<9:19:00, 112.55s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:50:13<8:59:02, 108.90s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:51:50<8:38:56, 105.19s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:53:31<8:30:52, 103.91s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:55:09<8:21:29, 102.34s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:56:45<8:09:55, 100.33s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:58:25<8:07:56, 100.26s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:00:03<8:03:28, 99.68s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:02:54<9:44:06, 120.85s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:04:29<9:04:42, 113.09s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:06:03<8:36:15, 107.55s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:07:40<8:18:38, 104.25s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:09:16<8:05:58, 101.95s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:10:50<7:53:08, 99.61s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:12:31<7:53:12, 99.97s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:14:05<7:43:20, 98.23s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:15:44<7:41:27, 98.18s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:17:18<7:33:57, 96.93s/it]
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(TaskRunner pid=1786626)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:20:26<9:40:02, 124.30s/it]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:22:04<9:01:56, 116.55s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:23:42<8:34:26, 111.03s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:25:19<8:12:47, 106.74s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:26:54<7:54:27, 103.14s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:28:31<7:44:35, 101.37s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:30:09<7:38:43, 100.45s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:31:50<7:37:00, 100.44s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:33:20<7:21:16, 97.34s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:34:54<7:15:42, 96.47s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:37:45<8:53:47, 118.62s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 07:45:04,933:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 07:45:10,631:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:39:30<8:34:02, 114.66s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:41:06<8:07:26, 109.13s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:42:45<7:51:22, 105.93s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:44:25<7:41:38, 104.13s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:45:57<7:23:48, 100.48s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:47:31<7:14:04, 98.66s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:49:05<7:06:27, 97.29s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:50:36<6:56:15, 95.33s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:52:19<7:04:31, 97.59s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:55:04<8:30:48, 117.88s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:56:39<7:58:56, 110.95s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:58:16<7:38:55, 106.73s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:59:45<7:15:06, 101.58s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:01:20<7:04:59, 99.61s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:02:52<6:53:58, 97.41s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:04:24<6:44:40, 95.59s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 08:11:42,146:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 08:11:51,682:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:06:12<6:59:05, 99.39s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:07:45<6:49:25, 97.48s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:09:23<6:48:19, 97.61s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:12:14<8:18:44, 119.70s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:13:45<7:40:42, 111.02s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:15:17<7:15:44, 105.42s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:16:52<7:00:59, 102.27s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:18:30<6:53:19, 100.81s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:20:02<6:41:23, 98.30s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:21:33<6:31:06, 96.17s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:23:05<6:23:57, 94.80s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:24:40<6:22:55, 94.94s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:26:14<6:19:41, 94.53s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:29:02<7:47:11, 116.80s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:30:44<7:27:23, 112.32s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:32:20<7:05:33, 107.28s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:33:57<6:51:07, 104.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:35:30<6:37:22, 101.03s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:37:05<6:28:37, 99.22s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:38:39<6:20:08, 97.47s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:40:15<6:16:34, 96.97s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:41:52<6:15:23, 97.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:43:27<6:11:17, 96.44s/it]
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(TaskRunner pid=1786626)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:46:36<7:56:42, 124.36s/it]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:48:09<7:18:20, 114.85s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:49:43<6:52:03, 108.44s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:51:15<6:32:37, 103.78s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:52:50<6:20:43, 101.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:54:24<6:10:26, 98.78s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:56:00<6:05:58, 98.03s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:57:32<5:57:09, 96.10s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:59:07<5:54:23, 95.78s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 09:06:22,112:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:00:40<5:50:02, 95.03s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:03:25<7:06:01, 116.19s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:05:01<6:41:29, 110.00s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:06:39<6:26:40, 106.43s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:08:16<6:14:13, 103.47s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:09:56<6:08:57, 102.49s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:11:28<5:56:02, 99.36s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:13:02<5:48:59, 97.85s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:14:34<5:40:33, 95.93s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:16:06<5:35:15, 94.89s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:17:41<5:33:15, 94.76s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:20:28<6:47:36, 116.46s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:22:03<6:23:47, 110.18s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:23:36<6:04:00, 105.00s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:25:11<5:51:25, 101.86s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:26:50<5:47:23, 101.18s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:28:24<5:38:15, 99.00s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:30:01<5:34:49, 98.48s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 09:37:24,263:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:31:49<5:42:24, 101.21s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:33:25<5:35:12, 99.56s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:35:01<5:30:38, 98.70s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:37:50<6:39:22, 119.81s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:39:22<6:09:12, 111.32s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:40:57<5:51:37, 106.55s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:42:34<5:39:37, 103.44s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:44:15<5:35:28, 102.70s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:45:54<5:30:33, 101.71s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:47:33<5:26:34, 101.00s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:49:10<5:21:07, 99.83s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:50:47<5:16:16, 98.84s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:52:23<5:12:10, 98.07s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:55:18<6:23:34, 121.13s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:56:56<5:59:34, 114.15s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [8:58:34<5:42:31, 109.32s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:00:11<5:28:49, 105.50s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:01:52<5:23:03, 104.21s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:03:33<5:18:36, 103.33s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:05:16<5:16:34, 103.23s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:06:52<5:08:06, 101.02s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:08:33<5:06:38, 101.09s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:10:16<5:06:11, 101.50s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:17:36,567:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:17:42,770:Timeout during comparison
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(TaskRunner pid=1786626)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:13:34<6:31:46, 130.59s/it]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:15:14<6:01:50, 121.29s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:16:55<5:41:33, 115.13s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:18:36<5:27:23, 110.98s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:20:17<5:17:04, 108.10s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:21:56<5:07:06, 105.29s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:23:35<5:00:12, 103.52s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:25:13<4:53:03, 101.64s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:26:53<4:50:06, 101.20s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:28:35<4:49:33, 101.60s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:31:30<5:49:59, 123.52s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:33:09<5:27:20, 116.21s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:34:49<5:11:59, 111.43s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:36:28<4:59:41, 107.67s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:38:12<4:54:16, 106.37s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:39:54<4:49:38, 105.32s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:41:41<4:49:13, 105.81s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:49:01,361:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:49:06,377:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:49:11,385:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:49:16,407:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:49:22,065:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:49:27,669:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:43:48<5:03:58, 111.89s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:45:28<4:52:42, 108.41s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:52:51,326:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:52:58,646:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:47:21<4:54:40, 109.82s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:50:15<5:44:07, 129.05s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:51:55<5:19:17, 120.49s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:59:19,312:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:59:24,320:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:59:31,379:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 10:59:36,386:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:53:57<5:18:24, 120.91s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:55:36<4:58:59, 114.26s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:57:22<4:51:00, 111.93s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [9:59:04<4:40:47, 108.69s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:00:50<4:36:57, 107.91s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:02:41<4:37:39, 108.89s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:04:30<4:35:41, 108.82s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:06:09<4:26:57, 106.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:09:02<5:15:07, 126.05s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:10:35<4:48:52, 116.32s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:12:09<4:30:10, 109.53s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:13:49<4:21:03, 106.55s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:15:25<4:11:54, 103.53s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:17:00<4:03:49, 100.90s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:18:37<3:59:15, 99.69s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:20:17<3:57:46, 99.76s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:21:54<3:54:17, 99.00s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:23:30<3:50:29, 98.08s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 11:32:21,427:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 11:32:27,647:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:26:30<4:46:33, 122.81s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:28:10<4:28:36, 115.94s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:29:50<4:15:07, 110.92s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:31:27<4:04:18, 107.00s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:33:01<3:53:20, 102.95s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:34:41<3:49:36, 102.05s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:36:18<3:44:51, 100.69s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:37:57<3:41:35, 99.97s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:39:38<3:40:31, 100.24s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:41:12<3:35:13, 98.57s/it] 
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 11:50:06,028:Timeout during comparison
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(TaskRunner pid=1786626)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:44:25<4:34:42, 126.79s/it]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:46:09<4:18:09, 120.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:47:54<4:06:32, 115.56s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:49:38<3:56:50, 111.89s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:51:21<3:49:44, 109.40s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:53:01<3:41:57, 106.54s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:54:38<3:34:27, 103.77s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:56:16<3:28:42, 101.81s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:57:52<3:23:43, 100.20s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:59:37<3:24:41, 101.50s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:02:25<4:03:18, 121.66s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:04:01<3:46:07, 114.01s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:05:43<3:36:54, 110.29s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:07:18<3:26:15, 105.78s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:08:56<3:19:34, 103.22s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:10:30<3:13:03, 100.73s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:12:05<3:07:34, 98.72s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:13:39<3:03:46, 97.58s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:15:18<3:02:25, 97.73s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 12:22:37,520:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:16:57<3:01:50, 98.30s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 12:25:51,442:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:19:54<3:43:13, 121.76s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:21:32<3:28:27, 114.75s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:23:12<3:18:36, 110.33s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:24:51<3:10:34, 106.86s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:26:24<3:01:30, 102.74s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:28:02<2:57:10, 101.24s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:29:37<2:52:12, 99.35s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:31:15<2:50:09, 99.12s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:32:52<2:47:23, 98.47s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:34:28<2:44:21, 97.64s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:37:20<3:20:08, 120.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:38:58<3:07:10, 113.44s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:40:40<2:59:18, 109.78s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:42:21<2:53:13, 107.15s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:44:07<2:51:18, 107.07s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:45:45<2:44:58, 104.19s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:47:21<2:39:39, 101.91s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:49:04<2:38:05, 102.00s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:50:42<2:34:54, 101.03s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:52:20<2:31:27, 99.86s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:55:10<3:01:21, 120.91s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:56:46<2:48:26, 113.55s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:58:21<2:38:20, 107.95s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [11:59:54<2:30:09, 103.56s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:01:29<2:24:38, 100.91s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:03:11<2:23:34, 101.35s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:04:44<2:18:06, 98.65s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:06:18<2:14:35, 97.30s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:08:02<2:15:44, 99.33s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:09:36<2:12:02, 97.81s/it]
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(TaskRunner pid=1786626)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:12:40<2:44:54, 123.68s/it]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:14:17<2:32:24, 115.76s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:15:57<2:24:12, 110.93s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:17:35<2:17:19, 107.00s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:19:10<2:10:57, 103.39s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:20:43<2:05:12, 100.16s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:22:23<2:03:37, 100.24s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:24:01<2:00:59, 99.45s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:25:40<1:59:17, 99.40s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:27:15<1:55:59, 98.02s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:30:01<2:18:25, 118.65s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:31:37<2:08:32, 111.78s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:33:12<2:01:01, 106.79s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:34:46<1:55:00, 102.99s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:36:23<1:51:04, 100.98s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:37:52<1:45:36, 97.49s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:39:25<1:42:32, 96.13s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:41:04<1:41:42, 96.86s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:42:41<1:40:14, 97.01s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:44:17<1:38:20, 96.73s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 13:53:10,213:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:47:12<2:00:18, 120.31s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:48:48<1:50:53, 112.77s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:50:30<1:46:09, 109.82s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:52:06<1:40:11, 105.46s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:53:44<1:36:25, 103.31s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 14:01:04,987:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:55:27<1:34:34, 103.17s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:57:02<1:30:34, 100.65s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [12:58:38<1:27:42, 99.29s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:00:19<1:26:38, 99.96s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:01:56<1:24:10, 99.02s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:04:43<1:39:32, 119.45s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:06:22<1:32:24, 113.15s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:07:59<1:26:41, 108.37s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:09:41<1:23:30, 106.60s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:11:16<1:19:02, 103.11s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:12:52<1:15:36, 100.81s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:14:31<1:13:37, 100.41s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:16:12<1:12:06, 100.62s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:17:53<1:10:29, 100.70s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:19:33<1:08:38, 100.45s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:22:22<1:20:41, 121.05s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:23:59<1:13:53, 113.67s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:25:44<1:10:22, 111.12s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:27:19<1:05:38, 106.44s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:28:57<1:02:15, 103.77s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:30:36<59:43, 102.40s/it]  
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 14:37:56,808:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 14:38:03,199:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:32:23<58:42, 103.60s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:33:58<55:39, 101.21s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:35:32<52:46, 98.95s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:37:15<51:44, 100.16s/it]
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(TaskRunner pid=1786626)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:40:19<1:02:42, 125.40s/it]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1786626)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:41:58<56:49, 117.56s/it]  
[36m(TaskRunner pid=1786626)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:43:32<51:31, 110.42s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:45:12<48:15, 107.23s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:46:50<45:16, 104.49s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:48:22<42:01, 100.85s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:50:01<40:02, 100.08s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:51:44<38:47, 101.18s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:53:22<36:42, 100.12s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:54:58<34:35, 98.85s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [13:57:53<40:32, 121.60s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [13:59:32<36:24, 114.97s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:01:09<32:53, 109.63s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:02:49<30:11, 106.56s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:04:25<27:37, 103.58s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:06:05<25:35, 102.34s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:07:45<23:42, 101.61s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:09:23<21:49, 100.69s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:11:02<20:02, 100.21s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:12:42<18:19, 99.97s/it] 
[36m(TaskRunner pid=1786626)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:15:36<20:23, 122.30s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:17:18<17:25, 116.12s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:18:59<14:53, 111.69s/it]
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 15:26:23,972:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m WARNING:2025-11-18 15:26:29,042:Timeout during comparison
[36m(TaskRunner pid=1786626)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:20:49<12:58, 111.27s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:22:30<10:48, 108.00s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:24:04<08:39, 103.96s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:25:45<06:51, 102.97s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:27:22<05:03, 101.17s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:29:06<03:24, 102.14s/it]
[36m(TaskRunner pid=1786626)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:30:53<01:43, 103.45s/it]
[36m(WorkerDict pid=1790178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1790178)[0m   warnings.warn(
[36m(TaskRunner pid=1786626)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:34:04<01:49, 109.49s/it]
[36m(WorkerDict pid=1790357)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1790357)[0m   warnings.warn([32m [repeated 3x across cluster][0m
