The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a7/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a7//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a7//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a7//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a7/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-20 21:43:34,606	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=820584)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-20 21:44:09,782:Waiting for register center actor rTxayn_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=824368)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=824368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=824368)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=824191)[0m [rank0]:[W1220 21:44:27.810829231 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=824365)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=824365)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=824191)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824191)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m [rank2]:[W1220 21:44:27.828165207 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=824191)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=824368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=824368)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=824368)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=824368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824368)[0m   warnings.warn(
[36m(WorkerDict pid=824366)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824191)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:   0%|          | 1/480 [02:01<16:07:51, 121.23s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   0%|          | 2/480 [04:02<16:06:19, 121.30s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   1%|          | 3/480 [06:07<16:19:14, 123.17s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   1%|          | 4/480 [08:06<16:02:54, 121.38s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   1%|          | 5/480 [10:06<15:55:50, 120.74s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   1%|â–         | 6/480 [12:13<16:11:55, 123.03s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   1%|â–         | 7/480 [14:17<16:11:46, 123.27s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   2%|â–         | 8/480 [16:24<16:19:27, 124.51s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   2%|â–         | 9/480 [18:23<16:03:33, 122.75s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   2%|â–         | 10/480 [21:50<19:24:56, 148.72s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   2%|â–         | 11/480 [23:46<18:04:09, 138.70s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   2%|â–Ž         | 12/480 [25:46<17:18:52, 133.19s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   3%|â–Ž         | 13/480 [27:48<16:49:56, 129.76s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   3%|â–Ž         | 14/480 [29:52<16:33:42, 127.94s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   3%|â–Ž         | 15/480 [31:51<16:11:35, 125.37s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   3%|â–Ž         | 16/480 [33:50<15:53:55, 123.35s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   4%|â–Ž         | 17/480 [35:50<15:44:24, 122.39s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   4%|â–         | 18/480 [37:47<15:28:19, 120.56s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   4%|â–         | 19/480 [39:46<15:22:59, 120.13s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   4%|â–         | 20/480 [43:11<18:36:26, 145.62s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   4%|â–         | 21/480 [45:17<17:49:21, 139.79s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   5%|â–         | 22/480 [47:18<17:04:05, 134.16s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   5%|â–         | 23/480 [49:16<16:24:56, 129.31s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   5%|â–Œ         | 24/480 [51:15<15:59:46, 126.29s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   5%|â–Œ         | 25/480 [53:10<15:31:37, 122.85s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   5%|â–Œ         | 26/480 [55:10<15:23:19, 122.03s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   6%|â–Œ         | 27/480 [57:11<15:17:42, 121.55s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   6%|â–Œ         | 28/480 [59:03<14:55:26, 118.86s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   6%|â–Œ         | 29/480 [1:01:06<15:01:36, 119.95s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   6%|â–‹         | 30/480 [1:04:17<17:39:27, 141.26s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-20 22:52:00,585:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:   6%|â–‹         | 31/480 [1:06:10<16:34:04, 132.84s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:57<15:33:24, 125.01s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   7%|â–‹         | 33/480 [1:10:03<15:34:14, 125.40s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:57<15:06:43, 121.98s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:49<14:42:21, 118.97s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:40<14:23:02, 116.63s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   8%|â–Š         | 37/480 [1:17:35<14:16:47, 116.04s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   8%|â–Š         | 38/480 [1:19:33<14:19:04, 116.62s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   8%|â–Š         | 39/480 [1:21:21<13:59:48, 114.26s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   8%|â–Š         | 40/480 [1:24:29<16:40:21, 136.41s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   9%|â–Š         | 41/480 [1:26:20<15:41:33, 128.69s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   9%|â–‰         | 42/480 [1:28:16<15:11:51, 124.91s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   9%|â–‰         | 43/480 [1:30:03<14:29:57, 119.45s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   9%|â–‰         | 44/480 [1:31:54<14:10:31, 117.04s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:   9%|â–‰         | 45/480 [1:33:39<13:42:35, 113.46s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  10%|â–‰         | 46/480 [1:35:33<13:39:49, 113.34s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  10%|â–‰         | 47/480 [1:37:26<13:37:43, 113.31s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:39:19<13:36:24, 113.39s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:41:14<13:37:52, 113.86s/it]
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824191)[0m   warnings.warn(
[36m(TaskRunner pid=820584)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:44:38<16:49:11, 140.82s/it]
[36m(WorkerDict pid=824366)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:46:27<15:39:11, 131.35s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:48:19<14:54:44, 125.43s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:50:05<14:10:53, 119.56s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:51:54<13:46:40, 116.43s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:53:39<13:21:18, 113.13s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:55:26<13:06:02, 111.23s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:57:17<13:04:29, 111.28s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:59:01<12:46:49, 109.03s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:00:47<12:37:34, 107.97s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:03:39<14:51:38, 127.38s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:05:28<14:10:03, 121.73s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:07:10<13:27:25, 115.90s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:08:54<13:00:15, 112.27s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:10:50<13:05:07, 113.24s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:12:35<12:47:07, 110.91s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:14:24<12:40:54, 110.28s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:16:12<12:35:01, 109.69s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:18:00<12:29:18, 109.12s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:19:48<12:25:12, 108.79s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:22:50<14:53:12, 130.71s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:24:37<14:03:03, 123.68s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:26:21<13:20:36, 117.74s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:28:06<12:52:56, 113.95s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:29:54<12:38:46, 112.13s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:31:38<12:19:42, 109.59s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:33:27<12:17:39, 109.55s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:35:15<12:11:34, 108.92s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:37:02<12:06:56, 108.50s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:38:51<12:06:22, 108.68s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:41:44<14:12:44, 127.91s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:43:29<13:24:48, 121.02s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:45:14<12:51:33, 116.31s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:47:05<12:38:58, 114.71s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:48:50<12:17:30, 111.74s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:50:38<12:09:06, 110.75s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:52:26<12:01:28, 109.87s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:54:13<11:54:19, 109.06s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:56:02<11:52:22, 109.04s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:57:43<11:34:27, 106.57s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:00:37<13:44:29, 126.85s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:02:20<12:54:35, 119.47s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 00:49:58,726:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:04:05<12:26:02, 115.37s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:05:49<12:00:42, 111.74s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:07:35<11:47:27, 109.97s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:09:16<11:28:16, 107.26s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:11:04<11:29:47, 107.78s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:12:44<11:12:37, 105.37s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:14:19<10:51:30, 102.33s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:16:08<11:01:01, 104.10s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 01:03:47,456:Timeout during comparison
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824191)[0m   warnings.warn(
[36m(WorkerDict pid=824191)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=824191)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=820584)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:19:23<13:52:08, 131.39s/it]
[36m(WorkerDict pid=824366)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:21:01<12:47:51, 121.56s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:22:45<12:11:02, 116.04s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:24:26<11:41:00, 111.57s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:26:03<11:12:47, 107.36s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:27:48<11:05:32, 106.49s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:29:26<10:47:37, 103.90s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:31:07<10:41:04, 103.12s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:32:44<10:28:31, 101.38s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:34:38<10:50:39, 105.23s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:37:34<12:59:13, 126.36s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:39:17<12:13:23, 119.25s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:40:51<11:25:32, 111.77s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:42:32<11:03:42, 108.51s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:44:16<10:53:22, 107.11s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:45:47<10:22:20, 102.30s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:47:26<10:14:35, 101.31s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:49:08<10:13:34, 101.42s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:50:52<10:17:36, 102.37s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:52:35<10:16:06, 102.40s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:55:28<12:22:50, 123.81s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:57:09<11:38:27, 116.73s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:58:56<11:20:06, 113.99s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 01:46:37,433:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:00:45<11:08:23, 112.34s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:02:40<11:12:01, 113.26s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:04:23<10:51:07, 110.05s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:06:04<10:33:51, 107.43s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:07:43<10:18:07, 105.06s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:09:26<10:11:17, 104.20s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:11:08<10:07:01, 103.76s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:14:00<12:03:33, 124.04s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:15:44<11:26:54, 118.09s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:17:22<10:50:45, 112.20s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:19:04<10:30:39, 109.05s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:20:45<10:14:33, 106.57s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:22:25<10:02:25, 104.77s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:24:05<9:51:33, 103.18s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:25:45<9:44:48, 102.30s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:27:26<9:39:58, 101.75s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:29:09<9:41:01, 102.23s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:31:55<11:27:54, 121.40s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:33:34<10:47:53, 114.67s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:35:09<10:11:54, 108.62s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:36:49<9:55:29, 106.02s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:38:26<9:39:49, 103.54s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:40:08<9:34:54, 102.97s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:41:41<9:16:58, 100.06s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:43:15<9:05:11, 98.23s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:44:53<9:02:56, 98.12s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:46:42<9:18:55, 101.32s/it]
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824191)[0m   warnings.warn(
[36m(TaskRunner pid=820584)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:49:48<11:36:55, 126.71s/it]
[36m(WorkerDict pid=824366)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:51:30<10:54:41, 119.40s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:53:12<10:23:47, 114.11s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:54:49<9:53:27, 108.89s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:56:30<9:40:09, 106.78s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:58:10<9:27:18, 104.73s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:59:43<9:06:39, 101.23s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:01:23<9:02:58, 100.86s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:03:03<8:58:50, 100.40s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:04:42<8:55:47, 100.15s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:07:34<10:49:02, 121.70s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:09:18<10:18:48, 116.39s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:10:59<9:51:15, 111.56s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:12:31<9:19:13, 105.85s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:14:05<8:59:02, 102.35s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:15:40<8:45:30, 100.10s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:17:22<8:46:39, 100.63s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:18:57<8:35:58, 98.91s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:20:35<8:33:31, 98.75s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:22:07<8:21:27, 96.74s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:24:55<10:09:40, 118.00s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:26:32<9:34:46, 111.61s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:28:07<9:07:57, 106.75s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:29:42<8:48:37, 103.32s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:31:15<8:31:00, 100.20s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:32:54<8:26:39, 99.67s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:34:32<8:23:23, 99.35s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:36:08<8:15:32, 98.13s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:37:45<8:12:09, 97.78s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:39:22<8:10:29, 97.77s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:42:12<9:57:05, 119.42s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:43:50<9:23:16, 113.03s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:45:26<8:55:45, 107.87s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:47:05<8:40:09, 105.08s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:48:36<8:18:33, 101.06s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:50:20<8:20:04, 101.71s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 03:37:58,994:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:52:03<8:20:06, 102.06s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 03:39:39,395:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:53:40<8:11:21, 100.62s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:55:18<8:05:54, 99.84s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:56:56<8:02:20, 99.45s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 03:46:03,668:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [5:59:48<9:45:55, 121.22s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:01:23<9:05:31, 113.26s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:02:57<8:35:04, 107.31s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:04:32<8:15:44, 103.64s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:06:11<8:07:33, 102.29s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:07:48<7:58:53, 100.82s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:09:32<8:01:03, 101.63s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:11:04<7:46:54, 98.99s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:12:43<7:44:19, 98.79s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:14:17<7:36:00, 97.37s/it]
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824191)[0m   warnings.warn(
[36m(TaskRunner pid=820584)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:17:19<9:33:05, 122.80s/it]
[36m(WorkerDict pid=824366)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:18:57<8:56:04, 115.28s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:20:31<8:24:48, 108.95s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:22:06<8:04:12, 104.88s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:23:46<7:55:04, 103.28s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:25:22<7:43:52, 101.21s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:27:01<7:38:52, 100.48s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:28:46<7:42:55, 101.74s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:30:21<7:33:05, 99.94s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:31:57<7:25:10, 98.56s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:34:50<9:04:48, 121.07s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:36:27<8:30:28, 113.86s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:38:03<8:04:06, 108.38s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:39:45<7:54:14, 106.57s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:41:25<7:42:53, 104.41s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:42:58<7:26:25, 101.08s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:44:37<7:21:19, 100.30s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:46:15<7:17:22, 99.78s/it] 
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 04:33:50,438:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:47:52<7:12:05, 98.95s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:49:36<7:16:41, 100.39s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:52:23<8:41:45, 120.41s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:54:00<8:09:42, 113.45s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:55:40<7:50:00, 109.30s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:57:12<7:26:41, 104.28s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [6:58:52<7:18:30, 102.78s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:00:30<7:11:06, 101.44s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:02:04<7:00:28, 99.33s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:03:52<7:09:35, 101.88s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:05:30<7:02:51, 100.68s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:07:12<7:02:07, 100.91s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:10:01<8:26:28, 121.55s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:11:38<7:53:41, 114.14s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:13:17<7:33:14, 109.65s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:14:59<7:22:14, 107.43s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:16:34<7:04:52, 103.63s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:18:11<6:54:34, 101.53s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:19:48<6:46:57, 100.07s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:21:23<6:39:46, 98.71s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:23:08<6:45:37, 100.57s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:24:45<6:39:38, 99.50s/it] 
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 05:13:59,484:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:27:44<8:13:50, 123.46s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 05:15:29,396:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:29:35<7:56:22, 119.59s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:31:17<7:32:59, 114.20s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:32:57<7:15:19, 110.21s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:34:36<6:59:38, 106.69s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:36:20<6:55:19, 106.04s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 05:23:57,952:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:38:04<6:50:37, 105.29s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:39:45<6:43:58, 104.03s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:41:28<6:41:13, 103.76s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:43:11<6:38:02, 103.39s/it]
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824191)[0m   warnings.warn(
[36m(TaskRunner pid=820584)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:46:22<8:17:00, 129.65s/it]
[36m(WorkerDict pid=824366)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:48:01<7:39:49, 120.48s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:49:38<7:11:29, 113.55s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:51:14<6:49:51, 108.33s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 05:38:53,045:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:53:00<6:45:02, 107.53s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:54:37<6:31:28, 104.39s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:56:20<6:28:25, 104.04s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:57:59<6:20:25, 102.36s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:59:44<6:21:47, 103.19s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:01:23<6:15:49, 102.04s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:04:12<7:27:27, 122.03s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:05:52<7:01:34, 115.50s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:07:37<6:48:08, 112.33s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:09:18<6:34:00, 108.94s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:11:03<6:27:52, 107.74s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:12:43<6:17:17, 105.29s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:14:26<6:13:07, 104.61s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:16:07<6:08:21, 103.76s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:17:44<5:59:34, 101.77s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:19:29<6:00:25, 102.49s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 06:07:09,319:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:22:28<7:19:08, 125.47s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:24:11<6:54:00, 118.85s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:25:50<6:31:33, 112.95s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:27:29<6:14:38, 108.59s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 06:15:09,947:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:29:19<6:14:01, 108.94s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:30:56<6:00:21, 105.47s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:32:42<5:58:48, 105.53s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:34:24<5:53:47, 104.57s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:36:07<5:50:54, 104.23s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:37:49<5:46:21, 103.39s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:40:41<6:53:23, 124.02s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:42:15<6:21:04, 114.90s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:43:55<6:04:37, 110.49s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:45:36<5:53:13, 107.58s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:47:21<5:49:32, 107.00s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:49:06<5:45:26, 106.29s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:50:45<5:37:10, 104.28s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:52:29<5:34:37, 104.03s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:54:14<5:34:13, 104.45s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:55:52<5:26:21, 102.52s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:58:49<6:35:15, 124.82s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:00:30<6:10:48, 117.72s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:02:11<5:52:38, 112.54s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:03:50<5:38:40, 108.67s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:05:33<5:31:25, 106.91s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:07:16<5:25:32, 105.58s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:09:00<5:22:59, 105.32s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:10:41<5:17:19, 104.04s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:12:24<5:14:24, 103.65s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:14:09<5:13:51, 104.04s/it]
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824191)[0m   warnings.warn(
[36m(TaskRunner pid=820584)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:17:20<6:30:19, 130.11s/it]
[36m(WorkerDict pid=824366)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:19:02<6:03:03, 121.70s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:20:45<5:44:30, 116.13s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:22:31<5:33:19, 112.99s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:24:14<5:22:39, 110.00s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:25:49<5:08:09, 105.66s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:27:33<5:04:48, 105.11s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:29:13<4:58:45, 103.62s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:30:53<4:53:46, 102.48s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:32:40<4:56:05, 103.89s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 07:21:55,737:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:35:40<5:58:21, 126.48s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:37:20<5:33:46, 118.50s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:39:02<5:18:09, 113.63s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:40:44<5:06:26, 110.10s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:42:32<5:03:27, 109.68s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:44:16<4:56:45, 107.91s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:46:06<4:56:45, 108.57s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 07:33:43,362:Timeout during comparison
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 07:33:48,378:Timeout during comparison
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 07:33:53,402:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:47:57<4:56:27, 109.13s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:49:36<4:46:22, 106.06s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:51:17<4:41:11, 104.79s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:54:14<5:36:30, 126.19s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:55:56<5:15:55, 119.22s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 07:43:32,616:Timeout during comparison
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 07:43:37,642:Timeout during comparison
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 07:43:42,652:Timeout during comparison
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 07:43:47,677:Timeout during comparison
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 07:43:52,687:Timeout during comparison
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 07:43:57,713:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:58:03<5:19:35, 121.36s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:59:38<4:57:01, 113.51s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:01:23<4:48:04, 110.80s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:03:06<4:40:40, 108.65s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:04:49<4:34:25, 106.92s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:06:32<4:29:31, 105.70s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:08:13<4:24:01, 104.22s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:09:50<4:16:52, 102.07s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:12:42<5:07:37, 123.05s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:14:19<4:46:15, 115.27s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:15:56<4:30:39, 109.73s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:17:43<4:27:18, 109.10s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:19:21<4:17:28, 105.81s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:20:59<4:09:29, 103.24s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:22:35<4:02:45, 101.15s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:24:14<3:59:42, 100.58s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:25:56<3:58:53, 100.94s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:27:33<3:54:38, 99.85s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:30:25<4:43:02, 121.30s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:32:09<4:29:06, 116.16s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:33:49<4:16:20, 111.46s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:35:28<4:05:45, 107.63s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:37:02<3:54:34, 103.49s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:38:44<3:51:54, 103.07s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:40:23<3:47:15, 101.76s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:42:01<3:43:16, 100.72s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:43:39<3:40:10, 100.08s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:45:12<3:33:20, 97.72s/it] 
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824191)[0m   warnings.warn(
[36m(TaskRunner pid=820584)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:48:24<4:33:19, 126.15s/it]
[36m(WorkerDict pid=824366)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:50:05<4:15:02, 118.63s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:51:50<4:04:23, 114.56s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:53:31<3:53:26, 110.29s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:55:16<3:48:28, 108.80s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:56:55<3:40:49, 105.99s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:58:32<3:33:23, 103.25s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:00:16<3:31:46, 103.31s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:01:53<3:26:32, 101.58s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:03:39<3:27:38, 102.97s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:06:28<4:05:19, 122.66s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:08:12<3:51:55, 116.94s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:09:52<3:40:21, 112.05s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:11:32<3:31:27, 108.44s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:13:11<3:23:58, 105.50s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:14:47<3:16:32, 102.54s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:16:21<3:10:27, 100.24s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:17:57<3:06:09, 98.85s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:19:39<3:06:18, 99.80s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:21:18<3:03:57, 99.44s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:24:15<3:45:02, 122.75s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:25:56<3:31:20, 116.34s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:27:38<3:21:21, 111.87s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:29:25<3:17:07, 110.54s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:31:02<3:08:10, 106.51s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:32:44<3:03:43, 104.99s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:34:23<2:59:11, 103.38s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 09:22:01,441:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:36:08<2:58:07, 103.76s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:37:47<2:54:04, 102.40s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:39:26<2:50:44, 101.43s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:42:17<3:23:44, 122.24s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:44:00<3:12:03, 116.40s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 09:31:37,825:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:45:47<3:05:28, 113.56s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:47:32<2:59:31, 111.05s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:49:23<2:57:46, 111.11s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:51:05<2:51:30, 108.32s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:52:46<2:46:09, 106.05s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:54:30<2:43:38, 105.57s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:56:10<2:39:07, 103.77s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:57:53<2:37:13, 103.66s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:00:47<3:06:56, 124.63s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:02:27<2:53:54, 117.25s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:04:05<2:43:34, 111.53s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:05:39<2:34:10, 106.33s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:07:21<2:30:34, 105.06s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:09:05<2:28:13, 104.63s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:10:39<2:22:08, 101.53s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:12:20<2:20:09, 101.32s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:13:59<2:17:34, 100.66s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:15:39<2:15:32, 100.41s/it]
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824191)[0m   warnings.warn(
[36m(TaskRunner pid=820584)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:18:45<2:48:09, 126.11s/it]
[36m(WorkerDict pid=824366)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:20:29<2:37:05, 119.31s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:22:11<2:28:29, 114.22s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:23:57<2:23:20, 111.70s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:25:36<2:16:51, 108.05s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:27:13<2:10:55, 104.74s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:28:53<2:07:15, 103.19s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:30:36<2:05:41, 103.31s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 10:18:16,546:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:32:22<2:04:41, 103.91s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:33:58<2:00:06, 101.50s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:36:53<2:24:26, 123.81s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:38:30<2:13:03, 115.70s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:40:09<2:05:28, 110.71s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:41:49<1:59:52, 107.35s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:43:28<1:55:15, 104.78s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:44:59<1:49:03, 100.67s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:46:36<1:46:18, 99.66s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:48:18<1:45:23, 100.37s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:49:56<1:42:52, 99.55s/it] 
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 10:37:35,080:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:51:38<1:42:06, 100.43s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 10:39:17,239:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:54:32<2:02:33, 122.57s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:56:08<1:52:27, 114.37s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:57:50<1:47:02, 110.74s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:59:28<1:41:33, 106.91s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:01:06<1:37:26, 104.40s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:02:46<1:34:17, 102.87s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:04:24<1:31:18, 101.46s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:06:00<1:28:16, 99.93s/it] 
[36m(TaskRunner pid=820584)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:07:43<1:27:24, 100.86s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:09:25<1:25:53, 101.05s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:12:14<1:41:14, 121.49s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:13:52<1:33:26, 114.41s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:15:29<1:27:17, 109.11s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:17:18<1:25:29, 109.14s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:18:56<1:21:17, 106.03s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:20:31<1:17:02, 102.72s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:22:10<1:14:20, 101.38s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:23:50<1:12:24, 101.04s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:25:29<1:10:22, 100.53s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:27:13<1:09:21, 101.50s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:30:05<1:21:43, 122.58s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:31:44<1:15:01, 115.43s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:33:24<1:10:18, 111.00s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:35:03<1:06:05, 107.17s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:36:44<1:03:15, 105.42s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:38:24<1:00:30, 103.72s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 11:26:01,347:Timeout during comparison
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 11:26:06,389:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:40:11<59:24, 104.82s/it]  
[36m(TaskRunner pid=820584)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:41:50<56:43, 103.13s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:43:31<54:35, 102.36s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 11:31:10,205:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:45:16<53:24, 103.36s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 11:32:53,564:Timeout during comparison
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824191)[0m   warnings.warn(
[36m(TaskRunner pid=820584)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:48:25<1:04:28, 128.96s/it]
[36m(WorkerDict pid=824366)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=820584)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:50:04<57:59, 119.97s/it]  
[36m(TaskRunner pid=820584)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:51:38<52:23, 112.28s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:53:22<49:18, 109.59s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 11:41:00,294:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:55:06<46:50, 108.11s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:56:44<43:47, 105.10s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:58:22<41:11, 102.97s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:00:10<39:57, 104.24s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:01:54<38:14, 104.30s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:03:33<35:56, 102.68s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 11:51:13,079:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:06:33<41:57, 125.86s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:08:19<38:00, 120.03s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:09:59<34:08, 113.78s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:11:38<31:03, 109.59s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:13:20<28:36, 107.26s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:15:00<26:13, 104.91s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:16:42<24:18, 104.19s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:18:24<22:26, 103.59s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:20:05<20:31, 102.63s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:21:46<18:45, 102.30s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:24:46<20:56, 125.61s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:26:31<17:53, 119.25s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:28:12<15:12, 114.01s/it]
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 12:15:52,415:Timeout during comparison
[36m(TaskRunner pid=820584)[0m WARNING:2025-12-21 12:15:57,439:Timeout during comparison
[36m(TaskRunner pid=820584)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:30:04<13:13, 113.40s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:31:45<10:57, 109.53s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:33:24<08:52, 106.54s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:35:05<06:58, 104.68s/it]
[36m(TaskRunner pid=820584)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:36:44<05:08, 102.90s/it]
[36m(TaskRunner pid=820584)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:38:32<03:28, 104.42s/it]
[36m(TaskRunner pid=820584)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:40:22<01:46, 106.14s/it]
[36m(WorkerDict pid=824191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=824191)[0m   warnings.warn(
[36m(TaskRunner pid=820584)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:43:36<01:50, 110.68s/it]
[36m(WorkerDict pid=824366)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=824366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
