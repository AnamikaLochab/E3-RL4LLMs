
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_0.8_seqq_norm/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_0.8_seqq_norm//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.8_seqq_norm//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.8_seqq_norm//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_0.8_seqq_norm/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-29 14:53:34,388	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=260426)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 14:53:54,694:Waiting for register center actor fju7Yp_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=264193)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=264192)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=264012)[0m [rank0]:[W1129 14:54:12.639986209 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=264193)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=264193)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=264012)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264012)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264193)[0m [rank2]:[W1129 14:54:12.843424632 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264012)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=264012)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=264193)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(WorkerDict pid=264194)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:   0%|          | 1/480 [01:58<15:48:03, 118.75s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   0%|          | 2/480 [03:58<15:51:31, 119.44s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   1%|          | 3/480 [06:02<16:05:28, 121.44s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   1%|          | 4/480 [07:59<15:50:32, 119.82s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   1%|          | 5/480 [10:00<15:50:34, 120.07s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   1%|â–         | 6/480 [12:01<15:51:48, 120.48s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   1%|â–         | 7/480 [14:04<15:55:00, 121.14s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 15:11:43,546:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:   2%|â–         | 8/480 [16:07<15:58:48, 121.88s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   2%|â–         | 9/480 [18:06<15:48:14, 120.80s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   2%|â–         | 10/480 [21:27<19:01:33, 145.73s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   2%|â–         | 11/480 [23:24<17:50:24, 136.94s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   2%|â–Ž         | 12/480 [25:21<17:00:54, 130.89s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   3%|â–Ž         | 13/480 [27:19<16:27:39, 126.89s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   3%|â–Ž         | 14/480 [29:18<16:08:31, 124.70s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   3%|â–Ž         | 15/480 [31:14<15:45:24, 121.99s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   3%|â–Ž         | 16/480 [33:12<15:34:09, 120.80s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   4%|â–Ž         | 17/480 [35:10<15:24:48, 119.85s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   4%|â–         | 18/480 [37:06<15:13:45, 118.67s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   4%|â–         | 19/480 [39:02<15:06:21, 117.96s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   4%|â–         | 20/480 [42:22<18:12:52, 142.55s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   4%|â–         | 21/480 [44:20<17:13:16, 135.07s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   5%|â–         | 22/480 [46:19<16:35:19, 130.39s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   5%|â–         | 23/480 [48:16<16:02:04, 126.31s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   5%|â–Œ         | 24/480 [50:09<15:28:58, 122.23s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   5%|â–Œ         | 25/480 [52:01<15:03:32, 119.15s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   5%|â–Œ         | 26/480 [53:55<14:51:13, 117.78s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   6%|â–Œ         | 27/480 [55:55<14:54:26, 118.47s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   6%|â–Œ         | 28/480 [57:46<14:34:23, 116.07s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   6%|â–Œ         | 29/480 [59:40<14:27:32, 115.41s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   6%|â–‹         | 30/480 [1:02:47<17:08:09, 137.09s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 16:00:20,838:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:   6%|â–‹         | 31/480 [1:04:39<16:08:23, 129.41s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:24<15:13:13, 122.31s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:20<14:55:42, 120.23s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:12<14:34:54, 117.70s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:02<14:17:29, 115.62s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   8%|â–Š         | 36/480 [1:13:51<13:59:34, 113.46s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   8%|â–Š         | 37/480 [1:15:39<13:45:57, 111.87s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   8%|â–Š         | 38/480 [1:17:36<13:54:30, 113.28s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   8%|â–Š         | 39/480 [1:19:23<13:39:00, 111.43s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 16:18:37,131:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:   8%|â–Š         | 40/480 [1:22:36<16:37:04, 135.97s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   9%|â–Š         | 41/480 [1:24:24<15:34:51, 127.77s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   9%|â–‰         | 42/480 [1:26:18<15:01:06, 123.44s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:04<14:22:23, 118.41s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   9%|â–‰         | 44/480 [1:29:53<13:59:39, 115.55s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:   9%|â–‰         | 45/480 [1:31:37<13:31:06, 111.88s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  10%|â–‰         | 46/480 [1:33:27<13:26:13, 111.46s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:16<13:18:36, 110.66s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:07<13:17:46, 110.80s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:02<13:24:53, 112.05s/it]
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(TaskRunner pid=260426)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:42:20<16:28:08, 137.88s/it]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:10<15:24:40, 129.32s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:45:56<14:33:05, 122.40s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:47:40<13:52:25, 116.97s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:49:30<13:35:00, 114.79s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:51:15<13:12:04, 111.82s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:01<12:58:56, 110.23s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:54:52<12:57:37, 110.30s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:56:34<12:38:49, 107.89s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 16:54:02,281:Timeout during comparison
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 16:54:08,820:Timeout during comparison
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 16:54:13,831:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:58:31<12:56:39, 110.69s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 16:57:33,588:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:01:32<15:22:56, 131.85s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:03:20<14:29:55, 124.57s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:05<13:47:50, 118.83s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:06:49<13:14:59, 114.39s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:08:43<13:11:08, 114.11s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:10:25<12:43:56, 110.45s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:12:15<12:40:46, 110.26s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:14:02<12:32:07, 109.27s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:15:47<12:22:37, 108.15s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:17:36<12:22:50, 108.44s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:20:39<14:53:21, 130.74s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:22:26<14:02:09, 123.54s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:24:11<13:22:54, 118.08s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:25:58<12:57:33, 114.63s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:27:47<12:45:25, 113.12s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:29:34<12:31:00, 111.26s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:31:26<12:30:27, 111.46s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:33:15<12:23:12, 110.65s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:35:03<12:16:45, 109.96s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:36:55<12:18:56, 110.56s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 17:35:57,996:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:39:57<14:39:47, 131.97s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:41:44<13:46:57, 124.35s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:43:30<13:09:55, 119.08s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:45:20<12:48:49, 116.19s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:47:08<12:29:52, 113.62s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:48:56<12:17:25, 112.01s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:50:42<12:04:41, 110.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:52:31<11:59:18, 109.82s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:54:22<11:59:36, 110.14s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:56:07<11:47:25, 108.56s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:59:06<14:04:33, 129.93s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:00:50<13:10:35, 121.94s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 17:58:17,446:Timeout during comparison
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 17:58:25,101:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:02:42<12:49:33, 119.00s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:04:26<12:19:20, 114.63s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 18:01:59,313:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:06:19<12:13:40, 114.04s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:08:03<11:52:48, 111.09s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:09:54<11:50:30, 111.02s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:11:41<11:40:27, 109.73s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:13:22<11:22:04, 107.13s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:15:17<11:35:57, 109.60s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 18:12:49,761:Timeout during comparison
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(WorkerDict pid=264012)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=264012)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=260426)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:18:39<14:29:23, 137.27s/it]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:20:20<13:18:40, 126.44s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 18:17:50,766:Timeout during comparison
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 18:17:57,975:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:22:15<12:55:35, 123.11s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:23:57<12:11:57, 116.49s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:25:40<11:45:29, 112.58s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:27:30<11:39:18, 111.89s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:29:16<11:26:29, 110.13s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:31:06<11:24:19, 110.08s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:32:47<11:05:07, 107.28s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:34:42<11:17:49, 109.62s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:37:46<13:33:26, 131.91s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:39:35<12:49:19, 125.09s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:41:16<12:02:45, 117.84s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:43:05<11:44:29, 115.18s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:44:54<11:31:48, 113.41s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:46:32<11:00:16, 108.54s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:48:13<10:44:54, 106.30s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:49:58<10:41:01, 105.95s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:51:45<10:41:19, 106.30s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:53:28<10:33:53, 105.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:56:33<12:55:22, 129.23s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:58:12<11:59:39, 120.28s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:59:59<11:33:45, 116.27s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 18:57:28,723:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:01:49<11:20:02, 114.29s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:03:43<11:17:04, 114.11s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:05:25<10:53:32, 110.46s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:07:10<10:42:34, 108.91s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:08:52<10:29:38, 107.02s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:10:38<10:24:45, 106.49s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:12:19<10:14:28, 105.04s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:15:17<12:19:50, 126.83s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:17:03<11:41:25, 120.59s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:18:41<10:59:15, 113.67s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:20:25<10:41:11, 110.87s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:22:10<10:28:44, 109.03s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:23:55<10:21:00, 108.00s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:25:40<10:13:13, 106.96s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:27:20<10:00:06, 104.97s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:29:07<10:01:50, 105.59s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:30:50<9:55:11, 104.72s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:33:47<11:55:50, 126.33s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:35:31<11:16:31, 119.74s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:37:12<10:42:36, 114.07s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:38:56<10:24:38, 111.21s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:40:38<10:06:09, 108.24s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 19:38:05,949:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:42:24<10:01:05, 107.66s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:43:59<9:38:10, 103.86s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:45:36<9:25:50, 101.95s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:47:16<9:20:50, 101.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:49:03<9:27:00, 102.78s/it]
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(TaskRunner pid=260426)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:52:14<11:50:51, 129.25s/it]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:53:55<11:02:35, 120.84s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:55:40<10:34:18, 116.03s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:57:20<10:06:53, 111.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:59:03<9:51:49, 108.93s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:00:44<9:36:24, 106.41s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:02:20<9:17:37, 103.26s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:03:58<9:08:16, 101.85s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:05:43<9:11:41, 102.80s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:07:25<9:08:57, 102.61s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:10:21<11:03:23, 124.39s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:12:09<10:35:01, 119.44s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:13:54<10:11:24, 115.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:15:34<9:44:42, 110.67s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:17:13<9:23:44, 107.04s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:18:54<9:12:19, 105.21s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:20:34<9:03:45, 103.90s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:22:15<8:56:33, 102.85s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:23:58<8:54:41, 102.83s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:25:37<8:47:40, 101.80s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:28:31<10:37:23, 123.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:30:13<10:03:25, 117.17s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:31:55<9:37:01, 112.41s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:33:36<9:17:30, 108.96s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:35:16<9:01:53, 106.25s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:37:06<9:05:50, 107.38s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:38:49<8:57:33, 106.10s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:40:32<8:50:54, 105.13s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:42:16<8:47:59, 104.90s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:43:58<8:42:33, 104.16s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:47:02<10:39:52, 127.98s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 20:44:30,626:Timeout during comparison
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 20:44:37,362:Timeout during comparison
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 20:44:42,368:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:49:01<10:24:49, 125.38s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:50:45<9:50:53, 118.97s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:52:30<9:27:54, 114.73s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:54:10<9:03:42, 110.21s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:55:59<9:01:01, 110.04s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:57:44<8:51:43, 108.51s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 20:55:17,444:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:59:32<8:48:40, 108.26s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:01:19<8:45:02, 107.89s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:03:06<8:42:33, 107.74s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:06:04<10:21:45, 128.64s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:07:44<9:38:16, 120.06s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:09:28<9:12:55, 115.19s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:11:13<8:56:24, 112.14s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:12:58<8:45:03, 110.15s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:14:40<8:31:46, 107.74s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:16:26<8:27:01, 107.12s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:18:08<8:17:35, 105.50s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:19:51<8:13:08, 104.92s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:21:32<8:05:12, 103.60s/it]
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(TaskRunner pid=260426)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:24:49<10:13:51, 131.54s/it]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:26:36<9:37:17, 124.15s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:28:20<9:08:33, 118.39s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:30:04<8:45:18, 113.79s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:31:45<8:26:34, 110.13s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:33:28<8:14:11, 107.82s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:35:16<8:13:09, 107.99s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:37:05<8:13:10, 108.39s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:38:43<7:57:16, 105.28s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:40:25<7:50:58, 104.27s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:43:26<9:33:07, 127.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:45:10<8:58:52, 120.20s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:46:52<8:32:30, 114.74s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:48:36<8:16:44, 111.63s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:50:20<8:04:41, 109.33s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:51:59<7:49:09, 106.23s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:53:40<7:40:07, 104.57s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:55:20<7:32:51, 103.31s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:56:59<7:25:38, 102.06s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:58:49<7:33:09, 104.17s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:01:43<9:03:17, 125.38s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:03:24<8:29:15, 117.97s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:05:07<8:07:27, 113.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:06:44<7:44:42, 108.49s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:08:28<7:37:11, 107.16s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:10:06<7:24:20, 104.55s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:11:47<7:17:36, 103.37s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:13:32<7:18:29, 103.99s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:15:15<7:14:45, 103.52s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:16:57<7:11:24, 103.12s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:19:51<8:37:40, 124.24s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:21:30<8:04:23, 116.72s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:23:11<7:42:51, 111.98s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:24:52<7:27:30, 108.71s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:26:29<7:11:45, 105.31s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:28:12<7:07:31, 104.70s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:29:50<6:57:27, 102.66s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:31:29<6:50:43, 101.41s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:33:15<6:54:52, 102.86s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:34:56<6:50:37, 102.23s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:37:52<8:17:56, 124.49s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:39:40<7:55:40, 119.42s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:41:21<7:31:42, 113.88s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:43:03<7:16:02, 110.39s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:44:46<7:05:08, 108.09s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:46:29<6:57:18, 106.55s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:48:07<6:46:09, 104.14s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:49:50<6:43:07, 103.81s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:51:33<6:40:03, 103.46s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:53:15<6:36:53, 103.09s/it]
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(TaskRunner pid=260426)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:56:24<8:13:20, 128.70s/it]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:58:03<7:37:10, 119.78s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:59:39<7:09:01, 112.90s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:01:18<6:50:46, 108.58s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:02:55<6:35:57, 105.12s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:04:30<6:22:52, 102.10s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:06:10<6:18:20, 101.34s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:07:45<6:10:16, 99.62s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:09:26<6:10:31, 100.14s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 23:06:49,803:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:11:03<6:05:12, 99.15s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:13:50<7:18:12, 119.51s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:15:29<6:52:56, 113.13s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:17:11<6:39:33, 109.97s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:18:51<6:26:42, 106.92s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:20:31<6:17:53, 104.97s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:22:07<6:05:58, 102.13s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:23:46<6:01:21, 101.32s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:25:22<5:53:25, 99.56s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:26:53<5:43:19, 97.17s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:28:29<5:40:22, 96.79s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-29 23:25:54,862:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:31:22<6:58:57, 119.70s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:33:01<6:35:08, 113.44s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:34:37<6:14:58, 108.16s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:36:14<6:01:33, 104.80s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:37:54<5:55:11, 103.45s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:39:29<5:44:15, 100.76s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:41:10<5:42:35, 100.76s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:42:50<5:40:39, 100.69s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:44:27<5:34:39, 99.40s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:46:08<5:35:00, 100.00s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:48:56<6:41:52, 120.56s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:50:28<6:11:11, 111.92s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:52:05<5:54:00, 107.27s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:53:42<5:42:21, 104.27s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:55:26<5:40:09, 104.13s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:57:08<5:36:18, 103.48s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:58:45<5:28:21, 101.55s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:00:23<5:23:37, 100.61s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:02:03<5:21:11, 100.37s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:03:40<5:16:06, 99.30s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:06:36<6:27:09, 122.26s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:08:14<6:02:05, 114.95s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:09:51<5:44:11, 109.85s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:11:29<5:30:59, 106.20s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:13:07<5:21:40, 103.77s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:14:47<5:16:27, 102.64s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:16:30<5:14:32, 102.57s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:18:07<5:08:01, 100.99s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:19:49<5:07:20, 101.32s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:21:25<5:00:45, 99.70s/it] 
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 00:18:51,990:Timeout during comparison
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(TaskRunner pid=260426)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:24:34<6:19:35, 126.53s/it]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:26:14<5:54:02, 118.67s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:27:53<5:33:49, 112.52s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:29:33<5:21:17, 108.91s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:31:13<5:11:51, 106.32s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:32:49<5:00:35, 103.06s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:34:30<4:57:24, 102.55s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:36:06<4:50:17, 100.68s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:37:45<4:46:41, 100.01s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:39:29<4:48:25, 101.20s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:42:21<5:47:18, 122.58s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:44:01<5:25:43, 115.64s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:45:41<5:10:42, 110.97s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:47:20<4:58:34, 107.27s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:48:59<4:49:56, 104.80s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:50:39<4:44:47, 103.56s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:52:26<4:45:52, 104.59s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 00:49:51,056:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:54:10<4:43:30, 104.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:55:50<4:38:17, 103.07s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 00:53:17,550:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:57:37<4:39:14, 104.07s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:00:29<5:32:20, 124.63s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:02:07<5:09:16, 116.71s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 00:59:34,203:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:03:51<4:57:08, 112.84s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:05:28<4:42:49, 108.09s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:07:11<4:37:12, 106.62s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:08:51<4:29:43, 104.41s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:10:33<4:26:33, 103.86s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:12:16<4:23:51, 103.47s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:14:00<4:22:41, 103.70s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:15:36<4:15:16, 101.43s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:18:27<5:05:32, 122.22s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:20:03<4:44:12, 114.45s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:21:40<4:29:21, 109.20s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:23:24<4:23:40, 107.62s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:25:01<4:14:24, 104.55s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:26:37<4:06:11, 101.87s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:28:17<4:02:56, 101.23s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:29:58<4:01:01, 101.13s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:31:40<4:00:08, 101.47s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:33:20<3:57:48, 101.20s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:36:16<4:48:28, 123.63s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:37:58<4:31:16, 117.09s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:39:39<4:17:41, 112.04s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:41:20<4:08:49, 108.98s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:42:58<3:59:29, 105.66s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:44:43<3:56:53, 105.28s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:46:26<3:53:45, 104.67s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:48:08<3:50:18, 103.90s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:49:52<3:48:44, 103.97s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:51:30<3:43:12, 102.23s/it]
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(TaskRunner pid=260426)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:54:42<4:39:54, 129.19s/it]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:56:26<4:21:03, 121.42s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:58:11<4:08:39, 116.56s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:59:57<3:59:44, 113.26s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:01:46<3:55:13, 112.01s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:03:29<3:47:50, 109.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:05:08<3:39:58, 106.44s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:06:53<3:37:13, 105.96s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:08:34<3:32:13, 104.37s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:10:25<3:34:33, 106.39s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:13:19<4:13:21, 126.68s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:15:02<3:57:15, 119.63s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:16:47<3:46:28, 115.16s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:18:29<3:37:06, 111.34s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:20:09<3:28:41, 107.94s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:21:50<3:22:42, 105.76s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:23:28<3:16:42, 103.53s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:25:08<3:12:37, 102.28s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:26:51<3:11:13, 102.45s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 02:24:18,787:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:28:35<3:10:30, 102.98s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:31:33<3:49:52, 125.39s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:33:15<3:35:17, 118.51s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:35:01<3:26:31, 114.74s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:36:48<3:20:34, 112.47s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:38:28<3:11:52, 108.61s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:40:12<3:07:43, 107.27s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:41:54<3:03:12, 105.69s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:43:37<3:00:17, 105.02s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:45:20<2:57:18, 104.29s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:47:02<2:54:19, 103.56s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:49:59<3:29:33, 125.74s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:51:45<3:17:20, 119.60s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 02:49:14,953:Timeout during comparison
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 02:49:21,886:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:53:41<3:13:48, 118.66s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:55:27<3:05:36, 114.80s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 02:52:57,458:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:57:23<3:04:29, 115.30s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:59:07<2:56:51, 111.70s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:00:48<2:50:10, 108.62s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:02:33<2:46:51, 107.65s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:04:16<2:42:41, 106.11s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:06:00<2:39:59, 105.49s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:08:57<3:10:39, 127.10s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:10:41<2:58:03, 120.04s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:12:20<2:46:58, 113.84s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:14:01<2:39:11, 109.79s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:15:41<2:33:20, 106.98s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:17:29<2:32:03, 107.34s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:19:08<2:26:47, 104.86s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:20:52<2:24:28, 104.43s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:22:34<2:21:46, 103.74s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:24:15<2:18:53, 102.88s/it]
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(TaskRunner pid=260426)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:27:30<2:53:53, 130.42s/it]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:29:11<2:40:21, 121.79s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:30:59<2:33:01, 117.71s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:32:44<2:26:01, 113.78s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:34:26<2:19:38, 110.24s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:36:06<2:13:52, 107.09s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:37:50<2:11:06, 106.31s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:39:35<2:08:58, 106.00s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:41:19<2:06:26, 105.37s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:43:03<2:03:59, 104.79s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:46:03<2:28:46, 127.52s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:47:47<2:18:24, 120.36s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:49:32<2:11:08, 115.71s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:51:15<2:05:02, 111.98s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:52:59<2:00:39, 109.69s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:54:37<1:54:51, 106.03s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:56:19<1:51:57, 104.97s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:58:05<1:50:14, 104.99s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:59:50<1:48:36, 105.10s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:01:31<1:45:46, 104.05s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:04:31<2:06:46, 126.78s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:06:14<1:57:38, 119.63s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:08:04<1:52:50, 116.73s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:09:46<1:46:35, 112.19s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:11:30<1:42:21, 109.67s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:13:15<1:39:18, 108.34s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:14:56<1:35:40, 106.31s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:16:41<1:33:20, 105.67s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:18:27<1:31:52, 106.02s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:20:10<1:29:11, 104.93s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:23:09<1:45:53, 127.08s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:24:50<1:37:32, 119.45s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:26:31<1:31:00, 113.77s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:28:18<1:27:36, 111.83s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:29:59<1:23:12, 108.54s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:31:37<1:19:03, 105.40s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:33:18<1:16:22, 104.16s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:35:00<1:14:14, 103.58s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:36:41<1:11:50, 102.64s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:38:22<1:09:43, 102.05s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:41:16<1:22:27, 123.69s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:42:56<1:15:52, 116.73s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:44:38<1:11:04, 112.21s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:46:18<1:06:55, 108.52s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:48:00<1:03:54, 106.52s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:49:40<1:01:08, 104.80s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 04:47:07,049:Timeout during comparison
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 04:47:13,306:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:51:28<59:51, 105.63s/it]  
[36m(TaskRunner pid=260426)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:53:06<56:51, 103.38s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:54:41<53:42, 100.72s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:56:21<51:59, 100.64s/it]
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(TaskRunner pid=260426)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:59:26<1:02:55, 125.85s/it]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=260426)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:01:05<57:00, 117.95s/it]  
[36m(TaskRunner pid=260426)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:02:39<51:39, 110.68s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:04:19<48:20, 107.43s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:06:00<45:47, 105.67s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:07:36<42:43, 102.53s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:09:13<40:22, 100.93s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:10:57<39:06, 102.01s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:12:35<36:55, 100.72s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:14:11<34:47, 99.42s/it] 
[36m(TaskRunner pid=260426)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:17:03<40:19, 120.99s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:18:45<36:28, 115.21s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:20:22<33:00, 110.00s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 05:17:51,395:Timeout during comparison
[36m(TaskRunner pid=260426)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:22:07<30:40, 108.29s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:23:44<28:02, 105.13s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:25:23<25:45, 103.04s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:27:04<23:56, 102.61s/it]
[36m(TaskRunner pid=260426)[0m WARNING:2025-11-30 05:24:32,923:Timeout during parsing: Okay, so I have this problem here about counting the number of functions \( f \) from the set \( \{-1005, \ldots, 1005\} \) to \( \{-2010, \ldots, 2010\} \). There are two conditions:
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m 1. If \( a < b \), then \( f(a) < f(b) \). So, the function is strictly increasing.
[36m(TaskRunner pid=260426)[0m 2. There is no \( n \) in \( \{-1005, \ldots, 1005\} \) such that \( |f(n)| = |n| \). So, the image of each \( n \) under \( f \) is not equal in absolute value to \( n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alright, let's break this down step by step.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m First, the first condition: \( f \) is strictly increasing. That means \( f \) must be injective (one-to-one) and order-preserving. So, if we can choose 2011 elements (since the domain has 2011 elements: from -1005 to 1005 inclusive) within the codomain, and arrange them in increasing order.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, let's double-check the size of the domain and codomain.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Domain: From -1005 to 1005. So, that's \( 1005 \) negative numbers, zero, and \( 1005 \) positive numbers. So total elements: \( 1005 + 1 + 1005 = 2011 \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Codomain: From -2010 to 2010. So, that's \( 2010 \) negative numbers, zero, and \( 2010 \) positive numbers. So total elements: \( 2010 + 1 + 2010 = 4021 \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m So, \( f \) is a strictly increasing function from a 2011-element set to a 4021-element set. Therefore, the number of strictly increasing functions without any restrictions is equal to the number of ways to choose 2011 elements from 4021 and arrange them in increasing order. That is \( \dbinom{4021}{2011} \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But then, there's the second condition: for every \( n \) in the domain, \( |f(n)| \neq |n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Hmm. So, we have to count the number of strictly increasing functions \( f \) such that for each \( n \), \( |f(n)| \neq |n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This seems like a problem that can be approached using inclusion-exclusion or maybe considering restricted choices when constructing the function.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Let's parse the second condition.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m "For there is no \( n \) such that \( |f(n)| = |n| \)."
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m So, for every \( n \in \{-1005, \ldots, 1005\} \), \( f(n) \) is not equal to \( n \) or \( -n \). Wait, but because of the absolute value, \( |f(n)| \neq |n| \) is equivalent to \( f(n) \neq n \) and \( f(n) \neq -n \), but \( f(n) \) is a non-negative integer because the codomain is symmetric around zero. Wait, no.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, the codomain is \( \{-2010, \ldots, 2010\} \), which includes negative numbers as well as positive.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But considering \( |f(n)| \neq |n| \). So, that implies that the absolute value of the function's output is not equal to the absolute value of the input. So, \( f(n) \) cannot satisfy \( f(n) = n \) or \( f(n) = -n \). So, more formally, for each \( n \), \( f(n) \in \{-2010, \ldots, -1\} \cup \{1, 2, \ldots, 2010\} \) and \( f(n) \neq -n \) and \( f(n) \neq n \)?
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, but \( f(n) \) is from the codomain \( \{-2010, \ldots, 2010\} \). So, if \( |f(n)| \neq |n| \), then \( f(n) \) must lie strictly inside the range of \( (-2010,2010) \setminus \{-2010, 2010\} \), but near zero.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, no. The exact condition is \( |f(n)| \neq |n| \), so for each \( n \), if \( |f(n)| = |n| \), that would be rejected. So, \( f(n) \) cannot be \( n \) or \( -n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, for each \( n \), \( f(n) \) must lie in \( \{-2010, \ldots, -1\} \cup \{1, \ldots, 2010\} \) and \( f(n) \neq -n \) and \( f(n) \neq n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, let's see. Suppose \( n \) is positive. Then \( |n| = n \), so \( |f(n)| \neq n \), so \( f(n) \) cannot be \( n \) or \( -n \). Similarly, for negative \( n \), but since \( f \) is from negative to positive or zero? Wait, domain is from -1005 to 1005 inclusive, so includes negative numbers. Codomain is from -2010 to 2010 inclusive, so both positive and negative. So, for each \( n \in \{-1005, \ldots, 1005\} \), \( |f(n)| \neq |n| \), which is to say that \( f(n) \notin \{-|n|, |n|\} \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, for each \( n \), \( f(n) \) must be in \( \{-2010, \ldots, -1, 1, \ldots, 2010\} \) and \( f(n) \neq -|n| \), \( f(n) \neq |n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But because the function is strictly increasing, once we choose the values of \( f(n) \), they have to form an increasing sequence.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m So, one approach is to choose 2011 elements from the codomain \( \{-2010, \ldots, 2010\} \setminus \{-|n|, |n|\} \) for each \( n \), but wait, that's not the case.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, actually, to count the number of strictly increasing functions \( f \) such that \( f(n) \notin \{-n, n\} \) for all \( n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Hmm, this seems complicated.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m So, perhaps, to model this, we can model this as a choice of 2011 elements from the 4021 elements in the codomain, such that for each chosen element \( a \), \( a \neq -|n| \) and \( a \neq |n| \) for the respective \( n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But it's tricky because each \( n \) imposes restrictions on the possible \( f(n) \) values.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, perhaps we can model this as a problem where the function \( f \) maps the domain in order (increasing) to the codomain, avoiding specific points \( \{-|n|, |n|\} \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, maybe a better approach is to first figure out the size of the codomain we can choose from.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m The codomain is from -2010 to 2010 inclusive, which is 4021 numbers.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m We need to choose 2011 numbers for \( f \) such that:
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m 1. They are strictly increasing.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m 2. For each \( n \), \( f(n) \) is not equal to \( -|n| \) or \( |n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m So, for each \( n \in \{-1005, \ldots, 1005\} \), we have two forbidden values in the codomain: \( |n| \) and \( -|n| \). Therefore, for each \( n \), \( f(n) \) must lie in \( \{-2010, \ldots, -1\} \cup \{1, \ldots, 2010\} \) and \( f(n) \neq |n| \), \( f(n) \neq -|n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Thus, each \( f(n) \) can be thought of as selecting one element from the available pool for each \( n \), without repetition, and the selections must form an increasing sequence.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This seems similar to a problem where we have multiple forbidden elements for each position, and we need to count the number of increasing sequences avoiding these forbidden elements.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This is similar to the inclusion-exclusion principle where we count the total number without restrictions and subtract the cases where at least one forbidden element is chosen.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But inclusion-exclusion seems complicated here because there are 2011 forbidden values? Wait, actually, for each \( n \), there's two forbidden values, so 2011*2 forbidden elements.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But 2011 is the number of positions, each with two forbidden values.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, perhaps we can model this using the principle of inclusion-exclusion but it might get too complicated.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, we can model this as a permutation. Wait, but since it's strictly increasing, we have to choose 2011 elements and assign them to the domain in order.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m So, the total number of strictly increasing functions is \( \dbinom{4021}{2011} \). Then, we need to subtract the number of strictly increasing functions where at least one \( f(n) \) equals \( |n| \) or \( -|n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But since each \( f(n) \) is forbidden from certain values, perhaps we can model this by subtracting the cases where each \( f(n) \) equals \( |n| \) or \( -|n| \), then adding back those where two are forbidden, etc.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But inclusion-exclusion would require considering all subsets of the forbidden values.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This can be intractable due to the number of subsets.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, maybe we can model this problem using recursion.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But perhaps another approach is better.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, since we are dealing with a function that is strictly increasing, it's equivalent to choosing 2011 distinct elements from the 4021 elements in the codomain and arranging them in increasing order.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, the total number without any restrictions is \( \dbinom{4021}{2011} \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Then, to subtract the cases where \( f(n) = |n| \) or \( f(n) = -|n| \) for some \( n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m However, considering that multiple positions \( n \) may have forbidden values in common, this is a classic inclusion-exclusion problem.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But since the forbidden values are specific, perhaps for each position \( n \), the forbidden values are exactly \( |n| \) and \( -|n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, for each \( n \in \{-1005, ..., 1005\} \), the forbidden values are \( |n| \) and \( -|n| \), but since \( f \) is strictly increasing, \( f(n) \) is the image. But since \( f(n) \) must satisfy \( |f(n)| \neq |n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, the forbidden values for \( f(n) \) are \( \{ -|n|, -|n| +1, ..., 0, ..., |n| -1, |n| \} \). Wait, no.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, perhaps another approach.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, the forbidden values for \( f(n) \) are \( |n| \) and \( -|n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Since \( f(n) \) has to be strictly increasing, once we choose \( f(n) = k \), the next \( f(m) \) has to be greater than \( k \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Thus, the forbidden values \( k \) for \( f(n) = \pm |n| \) can only be in the codomain where \( k \in \{ -2010, ..., -1, 1, ..., 2010 \} \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Thus, the problem reduces to counting the number of increasing sequences \( a_1 < a_2 < \ldots < a_{2011} \) such that none of the \( a_i \) is equal to \( i \) when considered in terms of their absolute values.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, maybe.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, let's reindex.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, for each \( n \), \( |f(n)| \neq |n| \). So, \( |f(n)| \) is the absolute value which is not equal to \( |n| \). So, for each \( n \), \( f(n) \) cannot be \( |n| \) or \( -|n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, the image of each \( n \) is among all elements except \( |n| \) and \( -|n| \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Thus, to compute the number of such functions, it's equivalent to counting the number of strictly increasing sequences \( a_1 < a_2 < \ldots < a_{2011} \) in the set \( \{-2010, \ldots, -1, 1, \ldots, 2010\} \) (i.e., excluding \( 0 \)) and each term \( a_i \) is not equal to \( i \) or \( -i \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, because if \( |a_i| \neq |i| \), then \( a_i \neq i \) and \( a_i \neq -i \). So, \( a_i \notin \{ \pm i \} \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, our set \( C = \{-2010, \ldots, -1, 1, \ldots, 2010\} \) has size 4020.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m We need to choose a strictly increasing sequence of length 2011 such that each \( a_i \notin \{ -i, i \} \) for each \( i \in \{-1005, \ldots, 1005\} \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This seems like a derangement-like problem but over a larger set with forbidden positions.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But since the sequences are strictly increasing, once we choose \( a_1 < a_2 < \ldots < a_{2011} \), it automatically satisfies \( a_i < a_j \) for \( i < j \), so the order is fixed.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, to count the number of such sequences, it's the same as counting the number of ways to choose 2011 elements from 4020, such that none of them is in the set \( S = \{ -1005, ..., 1005 \} \), and also none of the elements \( a_i \) is equal to \( i \) or \( -i \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, but the forbidden values depend on \( a_i \)'s position.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This complicates things because the forbidden value for each \( a_i \) is \( i \) or \( -i \), which is dependent on \( a_i \) itself.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, it's not a standard derangement problem.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, another approach: think of the entire set \( C \) as a poset and count the number of chains of length 2011 avoiding the elements \( S = \{ -1005, ..., 1005 \} \cup \{ -1005, ..., 1005 \} \), but \( S \) is confusing.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, perhaps a bijection approach. Since we need to exclude \( a_i \in \{ -1005, ..., 1005 \} \) for each \( a_i \) and also \( a_i \neq \pm i \). Hmm.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, perhaps consider shifting the indices.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, the standard approach in such problems where we have forbidden values is inclusion-exclusion.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m However, with 2011 being a large number, I wonder if there's a general formula or pattern.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, I remember that when selecting strictly increasing functions from a set of size m to a set of size n, avoiding certain elements.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But in our case, the forbidden elements depend on the position as well.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, so perhaps define \( F \) as the set of forbidden mappings: for each \( i \in \{-1005, ..., 1005\} \), the values \( -i \) and \( i \) are forbidden.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Thus, the total number of valid functions is equal to the total number of injective functions from the domain to the codomain minus the number of functions where \( f(i) \in \{-i, i\} \) for at least one \( i \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But this seems hard.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, another idea: think of the codomain as a poset where each element is a number, and we need to choose an increasing sequence avoiding certain elements.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This is similar to the number of chains of length k in the poset.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But if we have a linearly ordered poset, the number of chains of length k is straightforward, but here the forbidden elements vary per position.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, maybe the problem can be transformed into choosing elements such that none are selected in certain positions.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, perhaps.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But because each element \( f(n) \) is forbidden to be \( n \) or \( -n \), and we have to avoid all such mappings.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But this seems like a problem where we need to subtract the cases where any \( f(n) = n \) or \( f(n) = -n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But since these are forbidden, the total number is total functions minus the number of functions where at least one \( f(n) = n \) or \( f(n) = -n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But due to inclusion-exclusion.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Let \( A_n \) be the set of functions where \( f(n) = n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m \( B_n \) be the set of functions where \( f(n) = -n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Then, we want the count equal to \( \dbinom{4021}{2011} - \sum |A_n \cup B_n| + \sum |A_n \cap B_m| - \cdots \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But the inclusion-exclusion formula would be quite involved because for each \( A_n \) and \( B_n \), the forbidden conditions are present for every \( n \in \{-1005, ..., 1005\} \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m However, since the forbidden values vary for each \( n \), perhaps we can consider for each \( n \), \( f(n) \) must avoid \( \{ -n, n \} \), so it's a standard restricted permutation problem.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, think of it as a rook polynomial problem, but that might be overkill.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, given the constraints, perhaps the answer is simply \( \dbinom{4021 - 2 \times 1006}{2011} \). But let's compute.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, when you have a set of size N, and you need to choose a subset of size k with certain forbidden elements, the number of subsets is \( \dbinom{N - t}{k} \), where t is the total number of forbidden elements.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But in our case, the forbidden elements per position depend on the position n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m So, perhaps each position n has two forbidden values: \( n \) and \( -n \). Since for each position, f(n) cannot be equal to n or -n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, the forbidden elements form a set of size 2*(2011) = 4022.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But wait, the codomain size is 4021, so this can't be.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, another approach.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Since for each n, we have to avoid two elements in the codomain: n and -n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But when we count the number of injective functions f: domain â†’ codomain such that f(n) is not equal to n or -n for any n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This is equivalent to the number of injective functions from the domain to the codomain, minus those functions which have f(n)=n or f(n)=-n for some n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But since the forbidden mappings for each n are 2 specific numbers.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This is similar to derangements on a larger set.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But since both the domain and codomain are both linearly ordered sets, and the forbidden mappings are in some sense "forbidden positions", the count can be calculated with inclusion-exclusion.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But the inclusion-exclusion formula will involve a lot of terms, specifically involving the size of the domain and codomain.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, let's note that the forbidden mappings are n and -n for each n. So, the forbidden constraints are two per n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But since f has to be injective, each forbidden value must be assigned to a unique n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, so to count the number of injective functions f where f(n) â‰  n and f(n) â‰  -n, we can use inclusion-exclusion.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m The total number of injective functions is \( \dbinom{4021}{2011} \times 2011! \), since we can arrange the chosen elements in increasing order.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But perhaps the formula is:
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Number of injective functions avoiding f(n) âˆˆ {n, -n} for all n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This is equivalent to:
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m \( \sum_{k=0}^{2011} (-1)^k \dbinom{2011 + k}{k} \dbinom{4021 - 2k}{2011} } \)
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, maybe.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, actually, recall that the number of injective functions from a set of size m to a codomain of size M where some elements are forbidden can be calculated using inclusion-exclusion.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m The formula is:
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m \( \sum_{k=0}^{m} (-1)^k \dbinom{M}{k} \dbinom{M - k}{m - k} } \)
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, not exactly.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, it's the inclusion-exclusion where we subtract the cases where any forbidden condition is violated.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m In our case, each forbidden condition is f(n) = n or f(n) = -n for each n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Thus, the total number is:
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Total injective functions: \( \dbinom{4021}{2011} \times 2011! \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But I need to subtract the number of functions where for at least one n, f(n)=n or f(n)=-n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m To compute this, it's:
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m N = total injective functions - sum functions with f(n)=n or f(n)=-n for some n + sum functions with f(n)=n or f(n)=-n for two different n's - ... etc.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m By inclusion-exclusion.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m So, letâ€™s denote by \( S_k \) the set of injective functions where \( f(n)=n \) or \( f(n)=-n \) for at least \( k \) values \( n \).
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Then, the number we want is:
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m \( \sum_{k=0}^{2011} (-1)^k \dbinom{2011}{k} \dbinom{4021 - 2k}{2011 - k} } \)
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, that seems too vague.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, perhaps more precise.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Inclusion-exclusion formula for surjective functions but here it's injective.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, an alternative way: since for each n, the forbidden values are two elements: n and -n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Thus, the number of injective functions avoiding these forbidden values can be found as follows.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m First, think of the domain as size 2011, and the codomain as size 4021.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m We have 2011 forbidden elements per n, but since n ranges up to 1005.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, perhaps for each element in the domain, when choosing the images, they have to avoid their corresponding two elements in the codomain.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, the number of injective functions is equal to the coefficient in the generating function.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But this is too vague.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, perhaps using rook polynomials.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But without more specific knowledge, perhaps the answer is \( \dbinom{4021 - 2 \times 2011 + 1}{2011} \), but that seems too simplistic.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, maybe the problem is actually similar to choosing a subset of size 2011 from a 4021 element set, avoiding 2 forbidden elements per position.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But I don't recall the exact formula.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, the problem is isomorphic to choosing 2011 elements from 4021 such that none are equal to their position element or negative position element.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, which is a derangement problem but on an extended domain.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But again, I can't recall an exact formula.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, but if we consider the forbidden elements as two per n, and n ranges from -1005 to 1005.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m The inclusion-exclusion formula would require subtracting the cases where at least one n has f(n)=n or f(n)=-n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Each such event is dependent on n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, the inclusion-exclusion formula would be:
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Total injective functions - (number with f(n)=n for any n) + (number with f(n)=n and f(m)=-m for any n and m) - ... and so on.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But since the forbidden conditions are symmetric, perhaps the total number is:
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m \( \dbinom{4021}{2011} \times 2011! \) times \( \prod_{k=0}^{2011} \left(1 - \frac{2}{4021}\right)^k \). But this is incorrect.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, perhaps another approach.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Since the forbidden values are two per position.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, but each forbidden value is a specific element, and each element can be forbidden by multiple n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m This is getting too convoluted.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, perhaps we can think that for each position n, we have two forbidden values: n and -n. Since for each n, the forbidden value is unique.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Thus, the total forbidden size is 2*2011=4022, but since the codomain size is 4021, it's impossible.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Therefore, there must be at least one overlapping forbidden element.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Thus, inclusion-exclusion is required.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But due to the time constraints, perhaps the answer is just \( \dbinom{4021 - 2011}{2011} = \dbinom{2010}{2011} \), which is zero.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, that can't be.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Alternatively, perhaps the number is simply \( \dbinom{4021 - 2*2011}{2011} } \), which is \( \dbinom{4021 - 4022}{2011} \) which is negative, so not possible.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, perhaps the number is zero because the forbidden set is too large.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But the answer is expecting a box, so likely the answer is \( \dbinom{4021 - 2011 \times 2}{2011} \) minus something.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, maybe think of it as the forbidden positions are 2011*2=4022 elements, but the codomain is 4021 elements, so we can choose the images from 4021 - 2011*2= -1.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Which is invalid, meaning there's no such functions.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m But that can't be.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Wait, another idea.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m Since for each n, f(n) cannot be equal to n or -n.
[36m(TaskRunner pid=260426)[0m 
[36m(TaskRunner pid=260426)[0m So, each f(n) must
[36m(TaskRunner pid=260426)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:28:50<22:26, 103.60s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:30:31<20:32, 102.68s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:32:09<18:34, 101.30s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:35:03<20:33, 123.35s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:36:46<17:33, 117.11s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:38:29<15:03, 112.90s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:40:08<12:41, 108.72s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:41:49<10:38, 106.37s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:43:27<08:38, 103.72s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:45:06<06:49, 102.31s/it]
[36m(TaskRunner pid=260426)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:46:44<05:03, 101.08s/it]
[36m(TaskRunner pid=260426)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:48:30<03:25, 102.61s/it]
[36m(TaskRunner pid=260426)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:50:18<01:44, 104.26s/it]
[36m(WorkerDict pid=264012)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=264012)[0m   warnings.warn(
[36m(TaskRunner pid=260426)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:53:32<01:51, 111.93s/it]
[36m(WorkerDict pid=264192)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=264192)[0m   warnings.warn([32m [repeated 3x across cluster][0m
