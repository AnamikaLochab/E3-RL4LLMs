The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a11/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a11//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a11//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a11//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a11/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-21 16:31:03,682	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=127897)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 16:31:23,724:Waiting for register center actor kKgZK3_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=131650)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=131650)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=131650)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=131472)[0m [rank0]:[W1221 16:31:41.715781373 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=131472)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=131472)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=131472)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131472)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m [rank1]:[W1221 16:31:41.796958769 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=131650)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=131649)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=131649)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=131647)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131472)[0m   warnings.warn(
[36m(WorkerDict pid=131649)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=127897)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=131647)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=127897)[0m /scratch/gautschi/alochab/E3-RL4LLMs/verl/verl/trainer/ppo/core_algos.py:745: RuntimeWarning: divide by zero encountered in log
[36m(TaskRunner pid=127897)[0m   print(f"    Entropy H(q):   {Hq.item():.4f} (Max possible: {np.log(corr_mask.sum().item()):.4f})")
[36m(TaskRunner pid=127897)[0m Training Progress:   0%|          | 1/480 [02:03<16:29:54, 124.00s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   0%|          | 2/480 [04:05<16:16:53, 122.62s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   1%|          | 3/480 [06:09<16:21:04, 123.41s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   1%|          | 4/480 [08:07<16:00:52, 121.12s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   1%|          | 5/480 [10:09<16:02:15, 121.55s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   1%|â–         | 6/480 [12:15<16:11:11, 122.94s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   1%|â–         | 7/480 [14:18<16:09:59, 123.04s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   2%|â–         | 8/480 [16:20<16:03:49, 122.52s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   2%|â–         | 9/480 [18:26<16:12:03, 123.83s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 16:55:20,433:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:   2%|â–         | 10/480 [21:58<19:42:46, 150.99s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   2%|â–         | 11/480 [23:57<18:23:59, 141.23s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   2%|â–Ž         | 12/480 [26:00<17:37:20, 135.56s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   3%|â–Ž         | 13/480 [28:00<16:59:01, 130.92s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   3%|â–Ž         | 14/480 [30:04<16:39:16, 128.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   3%|â–Ž         | 15/480 [32:02<16:12:57, 125.54s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   3%|â–Ž         | 16/480 [34:00<15:53:18, 123.27s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   4%|â–Ž         | 17/480 [36:01<15:45:40, 122.55s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   4%|â–         | 18/480 [37:57<15:28:31, 120.59s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   4%|â–         | 19/480 [39:55<15:20:37, 119.82s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   4%|â–         | 20/480 [43:18<18:29:23, 144.70s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   4%|â–         | 21/480 [45:20<17:35:00, 137.91s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   5%|â–         | 22/480 [47:20<16:51:29, 132.51s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   5%|â–         | 23/480 [49:22<16:27:14, 129.62s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   5%|â–Œ         | 24/480 [51:24<16:07:30, 127.30s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   5%|â–Œ         | 25/480 [53:21<15:41:57, 124.21s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   5%|â–Œ         | 26/480 [55:24<15:36:17, 123.74s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   6%|â–Œ         | 27/480 [57:25<15:29:14, 123.08s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   6%|â–Œ         | 28/480 [59:17<15:01:21, 119.65s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   6%|â–Œ         | 29/480 [1:01:21<15:08:13, 120.83s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 17:37:57,855:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:   6%|â–‹         | 30/480 [1:04:33<17:47:24, 142.32s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   6%|â–‹         | 31/480 [1:06:23<16:31:30, 132.50s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   7%|â–‹         | 32/480 [1:08:10<15:32:25, 124.88s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   7%|â–‹         | 33/480 [1:10:12<15:24:07, 124.04s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   7%|â–‹         | 34/480 [1:12:06<15:00:32, 121.15s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 17:47:04,769:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:   7%|â–‹         | 35/480 [1:14:03<14:47:59, 119.73s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:54<14:26:07, 117.04s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   8%|â–Š         | 37/480 [1:17:47<14:15:28, 115.87s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   8%|â–Š         | 38/480 [1:19:43<14:15:10, 116.09s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   8%|â–Š         | 39/480 [1:21:33<13:59:15, 114.18s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   8%|â–Š         | 40/480 [1:24:37<16:31:06, 135.15s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   9%|â–Š         | 41/480 [1:26:27<15:33:53, 127.64s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   9%|â–‰         | 42/480 [1:28:22<15:03:37, 123.79s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   9%|â–‰         | 43/480 [1:30:09<14:24:14, 118.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   9%|â–‰         | 44/480 [1:31:59<14:04:01, 116.15s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:   9%|â–‰         | 45/480 [1:33:48<13:45:38, 113.88s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  10%|â–‰         | 46/480 [1:35:38<13:36:40, 112.90s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  10%|â–‰         | 47/480 [1:37:30<13:32:17, 112.56s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:39:21<13:26:32, 112.02s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:41:18<13:36:07, 113.61s/it]
[36m(WorkerDict pid=131650)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131650)[0m   warnings.warn(
[36m(TaskRunner pid=127897)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:44:40<16:44:37, 140.18s/it]
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131472)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=127897)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:46:31<15:39:53, 131.45s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:48:23<14:56:02, 125.61s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 18:23:16,905:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:50:14<14:21:26, 121.05s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:52:04<13:57:24, 117.94s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:53:50<13:28:41, 114.17s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:55:39<13:16:16, 112.68s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:57:34<13:19:50, 113.45s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:59:19<13:00:14, 110.94s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:01:05<12:46:53, 109.30s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 18:35:56,583:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:04:06<15:15:23, 130.77s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:05:57<14:33:04, 125.02s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:07:42<13:48:38, 118.94s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:09:31<13:24:57, 115.82s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:11:29<13:28:22, 116.59s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:13:15<13:04:35, 113.43s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:15:07<12:58:53, 112.88s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:16:59<12:55:22, 112.65s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:18:47<12:45:04, 111.42s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:20:36<12:37:37, 110.60s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 18:57:15,326:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:23:50<15:27:32, 135.74s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:25:42<14:36:14, 128.54s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:27:29<13:50:51, 122.19s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:29:15<13:15:13, 117.23s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:31:04<12:57:04, 114.84s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 19:05:57,478:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:32:57<12:50:52, 114.20s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:34:51<12:48:55, 114.20s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:36:44<12:43:47, 113.72s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:38:37<12:39:56, 113.42s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:40:30<12:37:05, 113.28s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:43:30<14:49:37, 133.44s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:45:20<14:00:26, 126.38s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:47:08<13:21:47, 120.87s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:48:59<13:00:00, 117.89s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:50:47<12:39:04, 115.01s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:52:35<12:22:21, 112.76s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:54:26<12:16:50, 112.21s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:56:14<12:08:02, 111.15s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:58:07<12:09:12, 111.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:59:51<11:52:05, 109.27s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:02:51<14:08:32, 130.55s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:04:34<13:12:47, 122.28s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:06:21<12:41:13, 117.72s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:08:08<12:19:12, 114.61s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 19:43:02,967:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:10:02<12:15:16, 114.29s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:11:48<11:58:02, 111.90s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:13:40<11:55:41, 111.83s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:15:22<11:34:37, 108.82s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:17:02<11:17:14, 106.37s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:18:55<11:26:41, 108.14s/it]
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131472)[0m   warnings.warn(
[36m(WorkerDict pid=131472)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=131472)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=127897)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:22:08<14:06:48, 133.71s/it]
[36m(WorkerDict pid=131647)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=127897)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:23:48<13:01:23, 123.70s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:25:33<12:23:22, 118.00s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:27:14<11:50:14, 113.04s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:28:54<11:22:37, 108.93s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:30:40<11:15:10, 108.03s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:32:17<10:53:45, 104.88s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:34:01<10:49:09, 104.42s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:35:38<10:33:56, 102.25s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:37:32<10:54:48, 105.90s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:40:27<13:01:20, 126.70s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:42:12<12:17:46, 119.96s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:43:46<11:29:02, 112.34s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:45:29<11:09:13, 109.41s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:47:12<10:55:58, 107.54s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:48:45<10:26:53, 103.05s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:50:20<10:10:58, 100.71s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:52:02<10:12:03, 101.17s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:53:49<10:21:35, 103.03s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:55:31<10:17:50, 102.69s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 20:30:24,134:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:58:36<12:43:02, 127.17s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:00:15<11:51:11, 118.86s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:02:01<11:26:16, 115.02s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:03:42<10:58:23, 110.65s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:05:40<11:10:20, 112.98s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:07:22<10:49:20, 109.75s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:09:06<10:36:31, 107.89s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:10:49<10:26:22, 106.47s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:12:31<10:17:10, 105.20s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:14:10<10:03:24, 103.15s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:17:00<11:59:28, 123.34s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:18:42<11:20:40, 117.02s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:20:23<10:50:03, 112.08s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:22:02<10:26:15, 108.29s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:23:42<10:09:08, 105.63s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:25:22<9:57:20, 103.89s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:27:02<9:49:57, 102.90s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:28:45<9:47:20, 102.74s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:30:27<9:44:22, 102.52s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:32:09<9:43:00, 102.58s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:34:59<11:35:27, 122.73s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:36:41<10:58:03, 116.47s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:38:17<10:21:29, 110.32s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:39:56<10:01:01, 107.01s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:41:33<9:42:25, 104.00s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:43:15<9:37:22, 103.41s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:44:49<9:19:11, 100.45s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:46:22<9:06:24, 98.45s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:47:58<9:00:02, 97.60s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:49:45<9:14:21, 100.49s/it]
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131472)[0m   warnings.warn(
[36m(TaskRunner pid=127897)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:52:52<11:35:04, 126.38s/it]
[36m(WorkerDict pid=131647)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=127897)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:54:33<10:51:51, 118.88s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:56:16<10:23:11, 114.00s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:57:54<9:54:56, 109.17s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:59:35<9:39:14, 106.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:01:14<9:25:46, 104.45s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:02:47<9:05:00, 100.93s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:04:29<9:05:24, 101.31s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:06:11<9:05:18, 101.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:07:55<9:07:38, 102.36s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:10:48<10:58:27, 123.46s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:12:35<10:29:18, 118.36s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:14:17<10:02:20, 113.65s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:15:56<9:37:02, 109.22s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:17:32<9:14:26, 105.27s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:19:10<9:00:22, 102.93s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:20:53<8:59:53, 103.16s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:22:33<8:52:12, 102.02s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:24:15<8:50:38, 102.05s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:25:53<8:43:32, 101.00s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:28:44<10:30:00, 121.94s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:30:24<9:54:00, 115.34s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:32:03<9:26:38, 110.38s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:33:43<9:08:35, 107.22s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:35:20<8:51:45, 104.27s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:37:04<8:50:09, 104.29s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:38:44<8:41:42, 102.97s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:40:23<8:33:15, 101.64s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:42:05<8:32:03, 101.73s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:43:47<8:31:29, 101.96s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:46:41<10:17:57, 123.59s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:48:26<9:48:07, 118.02s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:50:06<9:19:08, 112.58s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:51:53<9:08:16, 110.76s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:53:31<8:47:14, 106.87s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:55:22<8:51:46, 108.16s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:57:04<8:41:10, 106.36s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:58:43<8:29:11, 104.27s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:00:26<8:25:42, 103.91s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:02:12<8:26:45, 104.49s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:05:08<10:08:42, 125.94s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:06:50<9:31:10, 118.58s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:08:27<8:58:44, 112.24s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:10:08<8:41:00, 108.92s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:11:50<8:28:54, 106.76s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:13:29<8:15:50, 104.39s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:15:15<8:17:15, 105.05s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:16:53<8:04:33, 102.73s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:18:37<8:04:40, 103.12s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:20:16<7:57:54, 102.04s/it]
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131472)[0m   warnings.warn(
[36m(TaskRunner pid=127897)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:23:30<10:04:43, 129.58s/it]
[36m(WorkerDict pid=131647)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=127897)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:25:12<9:23:14, 121.13s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:26:53<8:54:16, 115.31s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:28:35<8:33:20, 111.19s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:30:19<8:21:52, 109.10s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:32:01<8:10:11, 106.95s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:33:47<8:06:50, 106.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:35:37<8:09:37, 107.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:37:17<7:58:10, 105.48s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:38:58<7:50:16, 104.12s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:41:59<9:32:23, 127.20s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:43:42<8:57:52, 119.97s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:45:26<8:34:06, 115.10s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:47:15<8:23:45, 113.20s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:48:57<8:07:25, 109.95s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:50:38<7:53:25, 107.19s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:52:20<7:45:28, 105.79s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:54:06<7:43:08, 105.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:55:45<7:32:29, 103.62s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:57:34<7:38:05, 105.31s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:00:27<9:03:56, 125.53s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:02:07<8:28:45, 117.86s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:03:52<8:10:25, 114.05s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:05:29<7:46:53, 109.00s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:07:14<7:40:00, 107.81s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:08:57<7:32:03, 106.37s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:10:36<7:20:59, 104.17s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-21 23:45:27,914:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:12:31<7:32:48, 107.38s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:14:15<7:26:19, 106.27s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:15:58<7:20:46, 105.36s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:18:54<8:47:32, 126.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:20:35<8:13:38, 118.95s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:22:19<7:53:22, 114.53s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:24:01<7:35:28, 110.64s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:25:39<7:17:38, 106.74s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:27:19<7:08:13, 104.87s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:28:58<6:59:27, 103.15s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:30:36<6:51:20, 101.57s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:32:24<6:57:42, 103.56s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:34:04<6:51:13, 102.38s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:37:02<8:20:03, 125.01s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:38:50<7:57:45, 119.94s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:40:31<7:33:19, 114.28s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:42:13<7:17:30, 110.76s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:43:54<7:03:26, 107.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:45:39<6:59:11, 107.03s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:47:21<6:50:49, 105.34s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:49:03<6:45:38, 104.46s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:50:48<6:44:38, 104.65s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:52:34<6:44:34, 105.09s/it]
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131472)[0m   warnings.warn(
[36m(TaskRunner pid=127897)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:55:51<8:27:44, 132.45s/it]
[36m(WorkerDict pid=131647)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=127897)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:57:30<7:47:59, 122.62s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:59:10<7:19:42, 115.71s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:00:49<6:58:30, 110.62s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:02:31<6:47:16, 108.13s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:04:08<6:33:16, 104.87s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:05:51<6:29:18, 104.28s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:07:30<6:21:25, 102.62s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 00:42:25,740:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:09:26<6:35:02, 106.77s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:11:06<6:25:18, 104.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:13:58<7:37:12, 124.69s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:15:43<7:14:16, 118.98s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:17:36<7:05:16, 117.05s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:19:18<6:47:34, 112.69s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:21:08<6:42:42, 111.86s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:22:48<6:27:19, 108.09s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:24:34<6:23:20, 107.48s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:26:13<6:12:34, 104.95s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:27:48<6:00:20, 101.99s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:29:30<5:59:25, 102.20s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 01:05:56,521:Timeout during comparison
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 01:06:03,186:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:32:37<7:25:55, 127.40s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:34:20<6:58:23, 120.11s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:35:58<6:33:14, 113.43s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:37:41<6:21:26, 110.56s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:39:30<6:17:11, 109.86s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:41:09<6:04:21, 106.64s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:42:54<6:01:37, 106.36s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:44:41<5:59:56, 106.38s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:46:25<5:55:33, 105.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:48:08<5:51:26, 104.91s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:51:01<6:58:03, 125.42s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:52:37<6:26:33, 116.55s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:54:19<6:09:36, 112.00s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:56:03<6:00:08, 109.69s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:57:49<5:54:36, 108.55s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:59:35<5:50:17, 107.78s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:01:17<5:43:03, 106.10s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 01:36:10,010:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:03:07<5:45:07, 107.29s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:04:51<5:40:09, 106.30s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:06:32<5:33:50, 104.87s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:09:31<6:41:37, 126.83s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:11:15<6:18:30, 120.16s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:12:55<5:57:11, 114.00s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:14:38<5:45:28, 110.85s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:16:21<5:35:43, 108.30s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:18:04<5:29:28, 106.86s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:19:47<5:24:30, 105.82s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:21:32<5:21:12, 105.32s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:23:16<5:18:19, 104.94s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:25:01<5:16:26, 104.90s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 01:59:50,720:Timeout during comparison
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 01:59:55,789:Timeout during comparison
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131472)[0m   warnings.warn(
[36m(TaskRunner pid=127897)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:28:18<6:38:22, 132.79s/it]
[36m(WorkerDict pid=131647)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 02:03:09,399:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:30:04<6:11:50, 124.64s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:31:46<5:49:56, 117.96s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:33:29<5:34:25, 113.36s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:35:09<5:20:57, 109.42s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:36:44<5:06:02, 104.93s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:38:27<5:03:00, 104.49s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:40:02<4:53:20, 101.73s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:41:43<4:50:30, 101.34s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:43:27<4:51:26, 102.26s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:46:14<5:44:47, 121.69s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:47:51<5:21:18, 114.07s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:49:33<5:09:45, 110.63s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:51:14<4:59:45, 107.70s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:52:58<4:55:01, 106.64s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:54:42<4:50:34, 105.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:56:28<4:49:32, 105.93s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:58:03<4:38:43, 102.60s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:59:38<4:31:12, 100.45s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 02:34:28,631:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:01:25<4:34:19, 102.23s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 02:36:16,162:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:04:21<5:31:35, 124.35s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:06:03<5:11:49, 117.67s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 02:40:52,651:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:07:46<4:58:42, 113.44s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:09:21<4:42:01, 107.78s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:11:06<4:37:50, 106.86s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:12:48<4:32:22, 105.44s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:14:28<4:26:42, 103.91s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:16:09<4:22:59, 103.14s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:17:54<4:22:34, 103.65s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:19:30<4:15:00, 101.33s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:22:17<5:02:05, 120.84s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:23:52<4:41:04, 113.18s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:25:25<4:24:35, 107.26s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:27:06<4:17:51, 105.25s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:28:39<4:07:26, 101.69s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:30:17<4:02:30, 100.35s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:31:53<3:57:48, 99.09s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:33:33<3:57:01, 99.45s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:35:11<3:54:31, 99.09s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:36:47<3:50:48, 98.22s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:39:35<4:37:24, 118.89s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 03:14:25,343:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:41:23<4:28:27, 115.88s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:43:02<4:14:44, 110.76s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:44:39<4:03:32, 106.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:46:11<3:51:45, 102.25s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:47:51<3:48:27, 101.53s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:49:32<3:46:36, 101.47s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:51:11<3:43:08, 100.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:52:50<3:40:05, 100.04s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:54:22<3:33:28, 97.77s/it] 
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131472)[0m   warnings.warn(
[36m(TaskRunner pid=127897)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:57:30<4:30:18, 124.76s/it]
[36m(WorkerDict pid=131647)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=127897)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:59:11<4:13:00, 117.68s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:00:53<4:00:42, 112.83s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:02:32<3:50:26, 108.87s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:04:20<3:47:38, 108.40s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:05:57<3:39:03, 105.14s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:07:32<3:30:49, 102.02s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:09:10<3:26:37, 100.79s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:10:47<3:22:56, 99.81s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:12:33<3:24:41, 101.50s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:15:18<4:00:58, 120.49s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:16:57<3:46:34, 114.24s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:18:34<3:34:33, 109.09s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:20:08<3:23:55, 104.58s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:21:44<3:16:57, 101.87s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 03:56:31,623:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:23:22<3:13:20, 100.87s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:24:53<3:05:35, 97.68s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:26:25<3:01:02, 96.13s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:28:03<3:00:21, 96.62s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:29:35<2:56:06, 95.19s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:32:28<3:37:32, 118.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:34:05<3:23:31, 112.04s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:35:43<3:13:55, 107.74s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:37:25<3:09:12, 106.10s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:38:56<2:59:30, 101.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:40:30<2:53:56, 99.39s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:42:05<2:49:42, 97.91s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:43:41<2:47:18, 97.46s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:45:14<2:43:09, 95.98s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:46:48<2:40:47, 95.52s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:49:31<3:13:04, 115.84s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:51:07<3:01:25, 109.95s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 04:25:57,002:Timeout during comparison
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 04:26:02,009:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:52:59<3:00:08, 110.30s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:54:38<2:53:03, 107.05s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:56:21<2:49:28, 105.93s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:57:56<2:42:28, 102.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:59:33<2:37:54, 100.80s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:01:12<2:35:29, 100.32s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 04:36:00,991:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:02:52<2:33:43, 100.25s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:04:30<2:30:48, 99.43s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:07:17<2:59:55, 119.95s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:08:56<2:48:20, 113.49s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:10:32<2:38:47, 108.26s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:12:05<2:30:18, 103.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:13:46<2:27:22, 102.82s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:15:32<2:26:56, 103.73s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:17:07<2:21:50, 101.32s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:18:45<2:18:37, 100.21s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:20:25<2:16:53, 100.16s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:22:03<2:14:16, 99.46s/it] 
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131472)[0m   warnings.warn(
[36m(TaskRunner pid=127897)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:25:10<2:47:41, 125.77s/it]
[36m(WorkerDict pid=131647)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=127897)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:26:51<2:35:40, 118.24s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:28:38<2:29:35, 115.07s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:30:24<2:24:04, 112.26s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:32:04<2:17:39, 108.67s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 05:06:54,142:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:33:47<2:13:39, 106.93s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:35:28<2:09:41, 105.15s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:37:13<2:07:49, 105.06s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:38:55<2:05:10, 104.32s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:40:34<2:01:22, 102.57s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:43:28<2:24:29, 123.86s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:45:08<2:14:18, 116.79s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:46:47<2:06:13, 111.37s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:48:26<2:00:19, 107.75s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:50:04<1:55:21, 104.87s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:51:36<1:49:32, 101.11s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:53:14<1:46:46, 100.10s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:54:57<1:45:50, 100.81s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:56:34<1:43:10, 99.84s/it] 
[36m(TaskRunner pid=127897)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:58:11<1:40:38, 98.99s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:01:02<2:00:41, 120.70s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:02:41<1:52:02, 113.95s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:04:23<1:46:54, 110.59s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:06:00<1:40:57, 106.27s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:07:41<1:37:46, 104.75s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:09:22<1:34:57, 103.60s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:11:00<1:31:45, 101.95s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:12:40<1:29:40, 101.52s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:14:22<1:27:55, 101.45s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:16:00<1:25:33, 100.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:18:48<1:40:42, 120.84s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:20:25<1:32:51, 113.70s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:22:03<1:27:08, 108.93s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:23:47<1:24:07, 107.40s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:25:27<1:20:44, 105.30s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:27:03<1:16:40, 102.23s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:28:42<1:14:28, 101.55s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:30:22<1:12:15, 100.82s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:32:00<1:10:01, 100.04s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:33:44<1:09:15, 101.35s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:36:35<1:21:23, 122.08s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:38:13<1:14:42, 114.94s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:39:57<1:10:39, 111.57s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:41:36<1:06:30, 107.84s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:43:16<1:03:23, 105.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:44:58<1:00:52, 104.35s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:46:39<58:40, 103.55s/it]  
[36m(TaskRunner pid=127897)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:48:17<55:56, 101.71s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:49:55<53:43, 100.74s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:51:36<51:59, 100.64s/it]
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131472)[0m   warnings.warn(
[36m(TaskRunner pid=127897)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:54:40<1:02:51, 125.71s/it]
[36m(WorkerDict pid=131647)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=127897)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:56:21<57:12, 118.36s/it]  
[36m(TaskRunner pid=127897)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:57:55<51:52, 111.15s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:59:42<49:28, 109.93s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:01:25<46:40, 107.70s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:03:00<43:14, 103.79s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:04:41<41:15, 103.14s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:06:29<40:06, 104.62s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:08:10<37:52, 103.31s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:09:48<35:39, 101.89s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:12:41<41:05, 123.26s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:14:26<37:14, 117.61s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:16:04<33:30, 111.72s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 06:50:53,769:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:17:47<30:56, 109.22s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:19:26<28:17, 106.09s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:21:08<26:11, 104.75s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:22:50<24:18, 104.17s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:24:30<22:18, 102.94s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:26:11<20:25, 102.15s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:27:50<18:35, 101.37s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:30:48<20:42, 124.23s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:32:28<17:33, 117.05s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:34:11<15:01, 112.72s/it]
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 07:09:01,960:Timeout during comparison
[36m(TaskRunner pid=127897)[0m WARNING:2025-12-22 07:09:06,988:Timeout during comparison
[36m(TaskRunner pid=127897)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:36:04<13:09, 112.79s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:37:43<10:51, 108.66s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:39:19<08:44, 104.88s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:40:59<06:53, 103.46s/it]
[36m(TaskRunner pid=127897)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:42:36<05:04, 101.43s/it]
[36m(TaskRunner pid=127897)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:44:23<03:26, 103.09s/it]
[36m(TaskRunner pid=127897)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:46:11<01:44, 104.58s/it]
[36m(WorkerDict pid=131472)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131472)[0m   warnings.warn(
[36m(TaskRunner pid=127897)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:49:23<01:51, 111.41s/it]
[36m(WorkerDict pid=131647)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131647)[0m   warnings.warn([32m [repeated 3x across cluster][0m
