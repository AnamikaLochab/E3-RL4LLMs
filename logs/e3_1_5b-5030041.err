
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_0.2_seqq_norm/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_0.2_seqq_norm//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.2_seqq_norm//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.2_seqq_norm//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_0.2_seqq_norm/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-29 15:11:42,798	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=2879679)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 15:12:03,118:Waiting for register center actor BC9xod_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2883410)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2883408)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=2883408)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=2883230)[0m [rank0]:[W1129 15:12:20.805742981 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=2883410)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2883410)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2883230)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883410)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m [rank2]:[W1129 15:12:20.066826450 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2883230)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2883230)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2883410)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883409)[0m   warnings.warn(
[36m(WorkerDict pid=2883409)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=2883408)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883408)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:   0%|          | 1/480 [01:58<15:44:31, 118.31s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   0%|          | 2/480 [03:58<15:52:54, 119.61s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   1%|          | 3/480 [06:01<16:00:43, 120.84s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   1%|          | 4/480 [07:59<15:49:55, 119.74s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   1%|          | 5/480 [09:59<15:48:11, 119.77s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   1%|â–         | 6/480 [12:00<15:50:50, 120.36s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   1%|â–         | 7/480 [14:02<15:51:58, 120.76s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 15:29:48,752:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:   2%|â–         | 8/480 [16:08<16:03:16, 122.45s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 15:31:55,629:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:   2%|â–         | 9/480 [18:13<16:09:28, 123.50s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   2%|â–         | 10/480 [21:35<19:16:44, 147.67s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   2%|â–         | 11/480 [23:36<18:09:40, 139.40s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   2%|â–Ž         | 12/480 [25:34<17:17:53, 133.06s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   3%|â–Ž         | 13/480 [27:32<16:39:26, 128.41s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   3%|â–Ž         | 14/480 [29:33<16:20:01, 126.18s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   3%|â–Ž         | 15/480 [31:30<15:56:29, 123.42s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   3%|â–Ž         | 16/480 [33:28<15:41:20, 121.73s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   4%|â–Ž         | 17/480 [35:27<15:32:22, 120.83s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   4%|â–         | 18/480 [37:23<15:20:13, 119.51s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   4%|â–         | 19/480 [39:21<15:14:43, 119.05s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   4%|â–         | 20/480 [42:42<18:20:34, 143.55s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   4%|â–         | 21/480 [44:40<17:19:57, 135.94s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   5%|â–         | 22/480 [46:39<16:38:38, 130.83s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   5%|â–         | 23/480 [48:37<16:06:33, 126.90s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   5%|â–Œ         | 24/480 [50:31<15:35:14, 123.06s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   5%|â–Œ         | 25/480 [52:23<15:09:03, 119.88s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   5%|â–Œ         | 26/480 [54:20<15:00:01, 118.95s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   6%|â–Œ         | 27/480 [56:20<15:01:08, 119.36s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   6%|â–Œ         | 28/480 [58:11<14:39:35, 116.76s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:08<14:37:00, 116.68s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:16<17:17:10, 138.29s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:04<16:06:39, 129.17s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:51<15:15:01, 122.55s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:47<14:58:41, 120.63s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:39<14:36:03, 117.86s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:29<14:17:52, 115.67s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:17<13:59:12, 113.41s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:07<13:48:14, 112.18s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:02<13:53:02, 113.08s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   8%|â–Š         | 39/480 [1:19:48<13:35:39, 110.97s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   8%|â–Š         | 40/480 [1:22:53<16:17:35, 133.31s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   9%|â–Š         | 41/480 [1:24:41<15:17:59, 125.47s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   9%|â–‰         | 42/480 [1:26:34<14:49:20, 121.83s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:22<14:17:40, 117.76s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:12<13:57:44, 115.28s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 16:45:48,274:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:00<13:39:56, 113.09s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  10%|â–‰         | 46/480 [1:33:49<13:29:52, 111.96s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:37<13:19:55, 110.84s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:28<13:18:16, 110.87s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:21<13:20:32, 111.44s/it]
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883230)[0m   warnings.warn(
[36m(TaskRunner pid=2879679)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:42:39<16:25:36, 137.53s/it]
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:26<15:16:43, 128.21s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:10<14:22:22, 120.89s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:47:50<13:36:15, 114.70s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:49:37<13:17:13, 112.28s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:51:20<12:56:19, 109.60s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:05<12:45:56, 108.39s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:54:53<12:42:07, 108.10s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:56:35<12:28:15, 106.39s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:58:16<12:14:33, 104.69s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:01:10<14:37:46, 125.40s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:02:55<13:53:26, 119.35s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:04:38<13:16:32, 114.34s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:06:20<12:49:34, 110.73s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:08:10<12:46:55, 110.61s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:09:52<12:26:49, 107.97s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:11:39<12:22:59, 107.68s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:13:21<12:09:12, 105.94s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:15:04<12:01:06, 105.02s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:16:49<11:58:56, 104.95s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 17:34:01,970:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:19:53<14:39:05, 128.65s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:21:34<13:41:56, 120.58s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:23:15<12:59:44, 114.67s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:24:58<12:32:56, 111.00s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:26:43<12:20:02, 109.37s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:28:26<12:04:45, 107.37s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:30:12<12:00:33, 107.01s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:31:57<11:55:01, 106.45s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:33:42<11:48:59, 105.82s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:35:28<11:48:05, 105.95s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:38:21<14:00:19, 126.05s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:40:06<13:16:09, 119.72s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:41:49<12:41:21, 114.78s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:43:33<12:18:10, 111.56s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:45:15<11:58:01, 108.79s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:46:58<11:45:03, 107.10s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:48:44<11:39:34, 106.54s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:50:28<11:33:45, 105.92s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:52:15<11:33:32, 106.15s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:53:54<11:17:56, 104.03s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:56:48<13:32:42, 125.03s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [2:58:27<12:40:25, 117.29s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 18:13:59,944:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 18:14:07,834:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 18:14:12,851:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:00:22<12:32:41, 116.40s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:02:03<12:01:15, 111.82s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:03:47<11:44:33, 109.52s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:05:24<11:18:55, 105.81s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:07:10<11:16:59, 105.78s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:08:48<11:01:06, 103.57s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:10:21<10:39:51, 100.50s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:12:07<10:47:34, 101.98s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 18:27:39,324:Timeout during comparison
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883230)[0m   warnings.warn(
[36m(WorkerDict pid=2883230)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2883230)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=2879679)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:15:19<13:37:21, 129.06s/it]
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:16:55<12:32:45, 119.17s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 18:32:31,976:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:18:42<12:06:30, 115.32s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:20:19<11:30:31, 109.90s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:21:54<11:00:22, 105.38s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:23:38<10:56:38, 105.06s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:25:14<10:38:51, 102.49s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:26:57<10:36:41, 102.42s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:28:32<10:22:11, 100.35s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:30:22<10:37:20, 103.08s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:33:14<12:44:35, 123.99s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:34:55<12:00:15, 117.11s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:36:29<11:14:23, 109.96s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:38:08<10:52:23, 106.66s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:39:49<10:39:56, 104.91s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:41:21<10:14:49, 101.07s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 18:56:52,635:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 18:56:59,148:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:43:08<10:23:54, 102.84s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:44:47<10:15:14, 101.69s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:46:24<10:05:07, 100.30s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:48:03<10:02:02, 100.06s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 19:03:40,062:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:51:03<12:24:23, 124.07s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:52:37<11:28:21, 115.05s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:54:18<11:01:29, 110.87s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:55:56<10:35:09, 106.75s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [3:57:46<10:39:30, 107.78s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [3:59:24<10:21:13, 104.99s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:01:02<10:06:24, 102.78s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:02:38<9:52:11, 100.65s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:04:18<9:50:58, 100.74s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:05:56<9:43:23, 99.72s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:08:46<11:45:14, 120.90s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:10:27<11:09:02, 115.02s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:11:59<10:26:16, 107.98s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:13:37<10:06:52, 104.94s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:15:16<9:54:40, 103.12s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:16:52<9:41:04, 101.06s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:18:30<9:34:22, 100.18s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:20:05<9:23:44, 98.61s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:21:44<9:23:13, 98.81s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:23:23<9:21:06, 98.73s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:26:14<11:22:58, 120.52s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:27:54<10:46:30, 114.43s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:29:30<10:12:50, 108.79s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:31:10<9:56:10, 106.14s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:32:47<9:38:14, 103.26s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 19:48:16,722:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:34:27<9:32:28, 102.53s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:35:59<9:12:26, 99.24s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:37:35<9:05:33, 98.30s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:39:12<9:01:41, 97.90s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:40:56<9:09:44, 99.65s/it]
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883230)[0m   warnings.warn(
[36m(TaskRunner pid=2879679)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:44:03<11:32:27, 125.90s/it]
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:45:41<10:45:03, 117.64s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:47:20<10:11:52, 111.93s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:48:57<9:46:28, 107.61s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:50:35<9:29:04, 104.74s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:52:12<9:14:23, 102.35s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:53:45<8:56:38, 99.38s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [4:55:19<8:47:38, 98.01s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [4:57:01<8:51:36, 99.06s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [4:58:39<8:48:16, 98.74s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:01:30<10:41:29, 120.28s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:03:13<10:12:30, 115.21s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:04:53<9:47:10, 110.79s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:06:30<9:22:39, 106.50s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:08:05<9:02:23, 102.99s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:09:41<8:50:51, 101.12s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:11:21<8:46:03, 100.52s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:12:56<8:36:58, 99.10s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:14:36<8:35:45, 99.18s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:16:13<8:30:51, 98.56s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:19:05<10:23:22, 120.65s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:20:45<9:48:42, 114.31s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:22:23<9:21:43, 109.43s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:24:01<9:03:46, 106.27s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:25:37<8:45:52, 103.11s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:27:17<8:38:38, 102.03s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:28:57<8:34:49, 101.61s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:30:36<8:28:10, 100.63s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:32:17<8:26:54, 100.71s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:33:55<8:21:04, 99.88s/it] 
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 20:51:05,019:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:36:56<10:21:40, 124.33s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 20:52:28,495:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 20:52:33,522:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:38:47<9:59:09, 120.23s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:40:25<9:24:58, 113.75s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:42:06<9:03:39, 109.83s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:43:43<8:42:26, 105.90s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:45:28<8:39:53, 105.74s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:47:08<8:29:38, 104.01s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:48:46<8:18:37, 102.11s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:50:27<8:16:16, 101.98s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:52:11<8:16:26, 102.36s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [5:55:03<9:56:01, 123.31s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [5:56:40<9:15:54, 115.41s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [5:58:19<8:50:17, 110.48s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [5:59:58<8:32:53, 107.22s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:01:40<8:23:19, 105.59s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:03:19<8:11:32, 103.48s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:05:02<8:09:26, 103.40s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:06:39<7:59:17, 101.62s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:08:23<7:59:51, 102.10s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:10:00<7:52:03, 100.80s/it]
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883230)[0m   warnings.warn(
[36m(TaskRunner pid=2879679)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:13:13<9:58:41, 128.29s/it]
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:14:53<9:17:04, 119.80s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:16:36<8:52:28, 114.92s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:18:17<8:31:28, 110.79s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:19:56<8:13:05, 107.19s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:21:38<8:03:27, 105.48s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:23:22<8:00:24, 105.20s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:25:09<8:00:17, 105.56s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:26:46<7:47:19, 103.09s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:28:25<7:40:21, 101.92s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:31:22<9:19:52, 124.42s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 21:46:55,815:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:33:07<8:51:42, 118.60s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:34:50<8:28:28, 113.84s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:36:33<8:11:56, 110.55s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:38:14<7:57:42, 107.75s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:39:52<7:42:52, 104.80s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:41:32<7:35:32, 103.53s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:43:12<7:28:53, 102.41s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:44:48<7:17:55, 100.29s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:46:33<7:23:34, 101.97s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:49:24<8:51:15, 122.60s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:51:04<8:20:10, 115.87s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:52:48<8:01:57, 112.08s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:54:21<7:36:22, 106.55s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [6:56:03<7:29:01, 105.24s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [6:57:43<7:19:30, 103.42s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [6:59:21<7:11:17, 101.88s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:01:05<7:11:50, 102.41s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:02:44<7:06:56, 101.65s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:04:28<7:07:19, 102.15s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:07:21<8:34:47, 123.55s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:08:59<8:00:38, 115.82s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:10:37<7:36:59, 110.56s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:12:16<7:20:30, 107.01s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:13:52<7:05:38, 103.82s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:15:31<6:57:24, 102.22s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:17:06<6:47:17, 100.16s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:18:42<6:39:48, 98.72s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:20:25<6:43:52, 100.13s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-29 22:35:54,793:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:22:07<6:44:41, 100.75s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:25:03<8:13:27, 123.36s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:26:48<7:48:33, 117.63s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:28:28<7:25:45, 112.38s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:30:14<7:16:18, 110.46s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:31:52<7:00:09, 106.82s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:33:33<6:51:12, 104.99s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:35:09<6:39:32, 102.45s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:36:49<6:34:52, 101.68s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:38:30<6:31:41, 101.30s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:40:09<6:27:21, 100.61s/it]
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883230)[0m   warnings.warn(
[36m(TaskRunner pid=2879679)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:43:17<8:06:55, 127.03s/it]
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:44:54<7:30:03, 117.92s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:46:30<7:03:11, 111.37s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:48:06<6:43:34, 106.67s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:49:43<6:31:03, 103.82s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:51:17<6:18:58, 101.06s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:52:58<6:16:30, 100.85s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:54:33<6:08:19, 99.10s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:56:16<6:10:45, 100.21s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [7:57:50<6:02:53, 98.52s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:00:37<7:16:19, 119.00s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:02:18<6:54:41, 113.61s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:03:59<6:38:30, 109.68s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:05:38<6:26:03, 106.74s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:07:21<6:19:52, 105.52s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:08:58<6:09:05, 103.00s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:10:36<6:02:09, 101.54s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:12:14<5:55:51, 100.24s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:13:48<5:47:52, 98.46s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:15:27<5:47:17, 98.76s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:18:18<7:01:35, 120.46s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:20:02<6:41:31, 115.27s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:21:37<6:19:05, 109.35s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:23:15<6:05:05, 105.82s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:24:56<5:58:52, 104.53s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:26:32<5:48:25, 101.98s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:28:15<5:47:30, 102.21s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:29:58<5:47:06, 102.59s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:31:38<5:42:21, 101.69s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:33:18<5:39:07, 101.23s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:36:10<6:47:34, 122.27s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:37:42<6:15:53, 113.33s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:39:22<6:00:23, 109.21s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:41:01<5:48:37, 106.18s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:42:45<5:44:53, 105.58s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:44:27<5:39:26, 104.44s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:46:06<5:32:25, 102.81s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:47:47<5:29:36, 102.47s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:49:29<5:27:21, 102.30s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:51:08<5:21:49, 101.10s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 00:08:17,460:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:54:09<6:36:12, 125.12s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:55:48<6:10:00, 117.46s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [8:57:27<5:50:21, 111.82s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [8:59:05<5:35:32, 107.66s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:00:46<5:27:07, 105.52s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:02:26<5:20:46, 104.03s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:04:10<5:18:38, 103.91s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 00:19:39,947:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:05:51<5:14:34, 103.14s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:07:33<5:12:02, 102.87s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:09:11<5:05:53, 101.40s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 00:24:43,388:Timeout during comparison
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883230)[0m   warnings.warn(
[36m(TaskRunner pid=2879679)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:12:23<6:25:27, 128.49s/it]
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:14:07<6:01:16, 121.10s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:15:46<5:39:57, 114.59s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:17:27<5:26:10, 110.57s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:19:08<5:15:42, 107.63s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:20:46<5:05:24, 104.71s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:22:26<4:59:49, 103.39s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:24:01<4:50:23, 100.71s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:25:40<4:47:08, 100.17s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:27:22<4:47:13, 100.78s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 00:44:30,073:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:30:20<5:51:06, 123.92s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:31:58<5:26:55, 116.07s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:33:37<5:11:17, 111.17s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:35:14<4:57:29, 106.88s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:36:54<4:49:33, 104.66s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:38:35<4:45:07, 103.68s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:40:21<4:45:22, 104.40s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 00:55:51,061:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 00:55:57,413:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:42:05<4:43:08, 104.22s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:43:43<4:36:35, 102.44s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 00:59:13,948:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:45:26<4:35:14, 102.57s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 01:02:30,253:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:48:21<5:31:26, 124.29s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:50:01<5:09:47, 116.90s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:51:36<4:50:26, 110.29s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:53:11<4:36:55, 105.83s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:54:53<4:32:07, 104.67s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [9:56:36<4:29:15, 104.23s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [9:58:16<4:23:55, 102.83s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [9:59:56<4:20:21, 102.10s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:01:35<4:16:26, 101.23s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:03:09<4:08:59, 98.94s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:05:59<5:00:28, 120.19s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:07:32<4:38:03, 111.97s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:09:05<4:22:37, 106.47s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:10:47<4:17:21, 105.04s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:12:25<4:10:40, 103.02s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:14:01<4:04:00, 100.97s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:15:39<3:59:42, 99.88s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:17:18<3:57:44, 99.75s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:18:58<3:55:53, 99.67s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:20:32<3:50:19, 98.01s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:23:21<4:38:46, 119.48s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:25:00<4:22:06, 113.14s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:26:39<4:10:29, 108.91s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:28:17<4:01:02, 105.57s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:29:50<3:51:01, 101.92s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:31:30<3:48:13, 101.43s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:33:08<3:43:52, 100.25s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 01:48:39,763:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:34:50<3:43:54, 101.01s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:36:30<3:41:01, 100.47s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:38:05<3:35:39, 98.78s/it] 
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883230)[0m   warnings.warn(
[36m(TaskRunner pid=2879679)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:41:15<4:33:22, 126.17s/it]
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:42:54<4:14:08, 118.20s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:44:35<4:00:59, 112.97s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:46:16<3:51:22, 109.31s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:47:56<3:43:57, 106.65s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:49:37<3:38:23, 104.83s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:51:13<3:31:11, 102.19s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:52:52<3:27:54, 101.42s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:54:26<3:21:41, 99.19s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:56:12<3:23:49, 101.07s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [10:59:01<4:02:51, 121.43s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:00:40<3:47:23, 114.65s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:02:20<3:36:50, 110.26s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:03:58<3:28:11, 106.77s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:05:35<3:20:30, 103.71s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 02:21:05,028:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:07:14<3:16:20, 102.44s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:08:49<3:10:28, 100.25s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:10:25<3:06:07, 98.82s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:12:06<3:05:39, 99.46s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:13:42<3:02:03, 98.41s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:16:39<3:43:46, 122.06s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:18:18<3:29:00, 115.05s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:19:59<3:19:21, 110.75s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:21:41<3:13:12, 108.34s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:23:17<3:04:32, 104.46s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:24:58<3:01:02, 103.45s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:26:34<2:55:44, 101.39s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:28:13<2:52:40, 100.59s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:29:53<2:50:28, 100.28s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:31:28<2:46:21, 98.83s/it] 
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 02:48:33,200:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:34:25<3:23:34, 122.15s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:36:05<3:10:34, 115.50s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:37:43<3:00:27, 110.49s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:39:24<2:53:43, 107.46s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:41:11<2:51:43, 107.33s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:42:47<2:44:51, 104.12s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:44:26<2:40:41, 102.57s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:46:09<2:38:57, 102.55s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:47:47<2:35:25, 101.36s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:49:29<2:33:57, 101.51s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:52:21<3:03:55, 122.61s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:54:02<2:52:09, 116.06s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:55:38<2:41:32, 110.15s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [11:57:12<2:32:21, 105.07s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [11:58:50<2:27:47, 103.11s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:00:34<2:26:17, 103.27s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:02:09<2:21:18, 100.94s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:03:49<2:19:02, 100.51s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:05:27<2:16:16, 99.71s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:07:04<2:13:36, 98.97s/it]
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883230)[0m   warnings.warn(
[36m(TaskRunner pid=2879679)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:10:13<2:47:55, 125.95s/it]
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:11:51<2:35:05, 117.79s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:13:38<2:28:51, 114.51s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:15:20<2:22:02, 110.69s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:17:03<2:17:06, 108.24s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:18:36<2:09:52, 103.91s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:20:16<2:06:39, 102.69s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:21:59<2:04:49, 102.60s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:23:38<2:02:07, 101.77s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:25:18<1:59:41, 101.15s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:28:12<2:23:26, 122.95s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:29:50<2:12:56, 115.60s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:31:28<2:05:01, 110.32s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:33:08<1:59:31, 107.04s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:34:49<1:55:46, 105.25s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:36:21<1:49:44, 101.30s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:37:59<1:47:02, 100.35s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:39:40<1:45:34, 100.55s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:41:19<1:43:17, 99.97s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:42:57<1:41:03, 99.41s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:45:53<2:02:30, 122.51s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:47:33<1:53:52, 115.80s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:49:22<1:49:48, 113.60s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:51:01<1:43:52, 109.34s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:52:42<1:39:37, 106.74s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:54:22<1:36:07, 104.87s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:56:01<1:32:41, 102.99s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [12:57:40<1:29:47, 101.66s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 04:13:14,328:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [12:59:28<1:29:46, 103.58s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:01:06<1:26:41, 101.98s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 04:16:38,851:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:04:07<1:44:38, 125.57s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:05:45<1:35:58, 117.52s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:07:23<1:29:15, 111.56s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:09:07<1:25:35, 109.28s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:10:46<1:21:28, 106.27s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:12:22<1:17:16, 103.03s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:14:00<1:14:35, 101.71s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:15:38<1:12:07, 100.64s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:17:17<1:10:06, 100.16s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:18:57<1:08:18, 99.96s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:21:47<1:20:41, 121.05s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:23:23<1:13:42, 113.39s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:25:03<1:09:22, 109.53s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:26:41<1:05:20, 105.97s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:28:18<1:01:57, 103.26s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:29:56<59:23, 101.83s/it]  
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 04:45:26,318:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:31:34<57:02, 100.67s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:33:08<54:11, 98.52s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:34:42<51:47, 97.12s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:36:21<50:35, 97.91s/it]
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883230)[0m   warnings.warn(
[36m(TaskRunner pid=2879679)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:39:27<1:02:08, 124.29s/it]
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2879679)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:41:04<56:04, 116.03s/it]  
[36m(TaskRunner pid=2879679)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:42:37<50:59, 109.28s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:44:19<48:05, 106.86s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:45:56<45:05, 104.04s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:47:30<42:01, 100.87s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:49:06<39:46, 99.43s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:50:47<38:20, 100.00s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:52:26<36:33, 99.72s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:54:03<34:36, 98.86s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 05:11:07,189:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [13:56:58<40:33, 121.69s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [13:58:37<36:23, 114.92s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:00:13<32:44, 109.12s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:01:48<29:47, 105.14s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:03:25<27:21, 102.62s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:05:02<25:11, 100.76s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:06:40<23:19, 99.97s/it] 
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 05:22:13,647:Timeout during parsing: Okay, so I need to find the number of functions \( f \) from the set \( \{-1005, \ldots, 1005\} \) to \( \{-2010, \ldots, 2010\} \) that satisfy two conditions:
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m 1. If \( a < b \), then \( f(a) < f(b) \). So, \( f \) is strictly increasing.
[36m(TaskRunner pid=2879679)[0m 2. There is no \( n \) in \( \{-1005, \ldots, 1005\} \) such that \( |f(n)| = |n| \). So, for every \( n \), \( f(n) \neq \pm n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Hmm, okay. Let me break this down step by step.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m First, the domain is \( \{-1005, \ldots, 1005\} \). That's from -1005 to 1005 inclusive, so the total number of elements is \( 1005 - (-1005) + 1 = 2011 \) elements.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m The codomain is \( \{-2010, \ldots, 2010\} \), so that's from -2010 to 2010 inclusive, totaling \( 2010 - (-2010) + 1 = 4021 \) elements.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m The function \( f \) is strictly increasing, which means it's injective (one-to-one). In such a function, we can think of mapping each element in the domain to a strictly increasing sequence in the codomain. So, we can model this as choosing an increasing sequence of numbers in the codomain of length 2011.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But before that, we have the second condition: there is no \( n \) such that \( |f(n)| = |n| \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m First, let me note that the absolute value condition says that for every \( n \), \( f(n) \) cannot be equal to \( n \) or \( -n \). So, for each \( n \), \( f(n) \) can be any number in \( \{-2010, \ldots, 2010\} \) except for \( n, -n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Given that \( f \) is strictly increasing, the values \( f(n) \) must be assigned such that each subsequent value is greater than the previous one, avoiding the points where \( f(n) = n \) or \( f(n) = -n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Therefore, it's similar to counting the number of strictly increasing sequences of length 2011, where each term is not in \( \{n, -n\} \) for each \( n \in \{-1005, \ldots, 1005\} \). Hmm, okay.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but how do we model this? Maybe it's similar to the classic problem of counting the number of ways to choose elements without certain exclusions, in a strictly increasing order.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, perhaps we can model this using combinatorics, considering the forbidden values.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But before getting bogged down, let me think of the structure.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Since \( f \) is strictly increasing, we can think of it as choosing 2011 distinct numbers from the codomain \( \{-2010, \ldots, 2010\} \) in increasing order, such that none of the chosen numbers equals either \( n \) or \( -n \) for each \( n \in \{-1005, \ldots, 1005\} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but the codomain is \( \{-2010, \ldots, 2010\} \), which includes the numbers from -2010 to 2010, so it's a range of 4021 numbers, same as the number of possible strictly increasing sequences except for the forbidden \( |f(n)| = |n| \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, perhaps the problem is similar to choosing 2011 numbers from a set of size 4021, but avoiding certain numbers in specific positions.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But the forbidden numbers are \( n \) and \( -n \) for each \( n \in \{-1005, \ldots, 1005\} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, actually, for each \( n \) in the domain, \( f(n) \) cannot be equal to \( n \) or \( -n \). So, we have restricted positions for \( f(n) \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But perhaps this can be modeled similarly to the concept of derangements, but in a more general setting.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but in this case, the forbidden numbers for each position \( n \) are \( n \) and \( -n \). So, each position has two forbidden values, but the function is strictly increasing, which complicates things because the choices are interdependent.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Hmm, is there a standard combinatorial approach for such restricted injective functions?
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, perhaps the forbidden pairs \( (n, -n) \) create certain transitions in the function.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, if we think of the function \( f \) as a selection of 2011 numbers, each assigned to a unique \( n \) in the domain, such that \( f(n) \) is not equal to \( n \) or \( -n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, another thought: since \( f \) is strictly increasing, the numbers \( f(n) \) are mapped in order, so we can consider the mapping as picking numbers in a line from \( -2010 \) to \( 2010 \), avoiding the points that are \( n \) or \( -n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, can we model this as a permutation problem with certain restrictions?
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, perhaps think of choosing 2011 numbers such that none of them are in the sets \( S_n = \{n, -n\} \) for \( n \in \{-1005, \ldots, 1005\} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Thus, we need to count the number of strictly increasing sequences of length 2011 from the codomain \( \{-2010, \ldots, 2010\} \) excluding the points \( n \) and \( -n \) for each \( n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, so the forbidden numbers are \( S = \{ -2010, -2009, \ldots, -1005, 0, 1, \ldots, 1005, 1006, \ldots, 2010 \} \) except for the specific forbidden pairs \( n \) and \( -n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But wait, in the codomain \( \{-2010, \ldots, 2010\} \), the numbers \( 0 \) to \( 2010 \) and \( -1 \) to \( -2010 \). So, the forbidden numbers are \( n \) and \( -n \) for \( n \) in \( \{-1005, \ldots, 1005\} \). So, for each \( n=1,2,\ldots,1005 \), the numbers \( n \) and \( -n \) are forbidden, and for \( n=-1005 \), if \( n \) is already covered.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, maybe not exactly, since \( 0 \) is allowed as well.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, this is getting a bit complicated.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, maybe we can perform a substitution.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Let me think of the codomain as \( \{-2010, \ldots, 2010\} \), and the domain as \( \{-1005, \ldots, 1005\} \). So, each \( n \) in the domain maps to \( f(n) \) in the codomain.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m We need to choose 2011 strictly increasing numbers such that \( f(n) \notin \{n, -n\} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, perhaps the function \( f \) is a bijection between the domain and codomain? No, the domain and codomain have the same size, 2011 and 4021 respectively, so it's injective but not necessarily surjective.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, hang on: the domain has 2011 elements, the codomain has 4021 elements, so the function is injective but not necessarily surjective.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But the only constraints are the two conditions: strictly increasing, and no \( f(n) = \pm n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, we can model the problem as choosing a subset of 2011 numbers from the codomain \( \{-2010, \ldots, 2010\} \) that are strictly avoiding the points \( n \) and \( -n \), in such a way that the overall ordering is maintained.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, maybe this is similar to the concept of linear extensions in posets, but I'm not sure.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, perhaps the problem is similar to arranging books on a shelf, where certain positions are forbidden.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, let me think differently.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Suppose we model the problem as follows:
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m We need to choose 2011 numbers from the interval \( \{-2010, \ldots, 2010\} \), excluding the numbers \( \{\pm 1, \pm2, \ldots, \pm1005, 0\} \)?
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m No, wait: for each \( n \), we can't have \( f(n) = n \) or \( f(n) = -n \). So, for each \( n \in \{-1005, \ldots, 1005\} \), the value \( f(n) \) can be any number in \( \{-2010, \ldots, 2010\} \) except \( n \) and \( -n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But since \( f(n) \) must be strictly increasing, we have dependencies between the choices.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, perhaps it's helpful to consider a transformed version of the problem.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Let me think of the forbidden numbers. For each \( n \in \{-1005, \ldots, 1005\} \), \( f(n) \) can't be in \( \mathcal{S}_n = \{n, -n\} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Therefore, the total number of allowable values for \( f(n) \) is \( 4021 - 2 \times 2011 = 4021 - 4022 = -1 \). Wait, no, that can't be.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, hold on: the domain has 2011 elements, so a strictly increasing function is equivalent to choosing 2011 distinct numbers from the codomain in increasing order. So, we have 2011 numbers selected from 4021, excluding certain numbers per element.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, maybe we can model this as a permutation problem where we subtract the forbidden positions.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, actually, inclusion-exclusion may be applicable here, but inclusion-exclusion on such a large problem may be complex.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, maybe the forbidden pairs \( (n, -n) \) can be considered as derangements in the range.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, because of the injectivity and uniqueness of the function, maybe the number of such functions is equal to the number of ways to choose 2011 numbers from the 4021, avoiding the 2011 pairs \( \{n, -n\} \)?
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but not exactly. Each \( n \) has two forbidden numbers, so for each \( n \), we cannot choose two specific numbers.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, no, the mapping \( f(n) \) is injective, so each \( f(n) \) must be unique. However, for each \( n \), \( f(n) \) can't be \( \pm n \). Therefore, for each \( n \in \{-1005, \ldots, 1005\} \), the number \( f(n) \) is excluded from the subset if it is \( n \) or \( -n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Therefore, we are to count the number of strictly increasing sequences \( f(1), f(2), \ldots, f(1005), f(1006), \ldots, f(2011) \) such that \( f(k) \notin \{k, -k\} \) for each \( k \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, no, hold on: domain is \( \{-1005, \ldots, 1005\} \), so \( k \) ranges from \( -1005 \) to \( 1005 \). So for each \( k \in \{-1005, \ldots, 1005\} \), \( f(k) \notin \{k, -k\} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Since \( f \) is strictly increasing, the function is entirely determined by the choices \( f(k) \) for each \( k \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, perhaps we can model this as shifting the forbidden points.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, the set of forbidden elements are \( \{-1005, \ldots, 1005\} \) and their negatives, so we can think of it as "exclusion zones".
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, this is getting a bit complex, but let me consider transforming the problem.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Suppose we change variables: \( g(n) = f(n) \) if \( f(n) \neq \pm n \), but this doesn't directly help.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, another idea: shift the numbers so that forbidden positions align.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, perhaps if we model the forbidden pairs \( (n, -n) \) as forbidden numbers, and construct a bijection avoiding these numbers.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but I'm not sure. Alternatively, note that \( f(n) \) must avoid \( n \) and \( -n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Thus, the number of allowable numbers for each \( n \) is \( 4021 - 2 = 4019 \) numbers in total, but considering the mapping.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, no, the allowable numbers for each \( n \) are 4021 total numbers, excluding 2 for each \( n \), but since multiple \( n \) can overlap in forbidden numbers.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but each \( n \) maps to two numbers, but they don't all overlap since for each \( n \), the forbidden numbers \( n \) and \( -n \) are unique except for \( n=0 \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m For \( n = 0 \), \( f(0) \) cannot be 0 because \( n = 0 \), but wait, is \( n \) allowed to be 0?
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, the domain includes \( -1005 \) to \( 1005 \), so yes, \( n = 0 \) is included. So, \( f(0) \neq 0 \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Thus, for each \( n \in \{-1005, \ldots, 1005\} \), \( f(n) \neq \pm n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Therefore, for each \( n \in \{-1005, \ldots, 1005\} \), \( f(n) \) can be any number except \( n \) and \( -n \). So, total number of allowable choices for \( f(n) \) is \( 4021 - 2 \times 2011 + 1 = 4021 - 4022 + 1 = 0 \). Wait, that can't be. It suggests no allowable numbers, but that's impossible because \( f(n) \) needs to be in the codomain.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, wait, maybe not for each \( n \), but the total number of forbidden values across all positions.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, this approach is getting too tangled.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, perhaps another angle: the only constraints are that the function is strictly increasing and \( f(n) \neq \pm n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Therefore, the total number is equal to the number of strictly increasing sequences of length 2011 from \(-2010\) to \(2010\), avoiding the points \( n \) and \( -n \) for each \(n\).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m This is similar to counting the number of injective functions from the domain to the codomain with the given constraints.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but how?
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, since both the domain and codomain are consecutive integers, perhaps the number of such functions is equal to the number of ways to choose 2011 numbers from the codomain, avoiding the points \(n\) and \(-n\), but maintaining the order.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, since we can model this as arranging 2011 numbers such that none are in the forbidden positions.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, think of the linear case: if the domain was a singleton, say {1}, codomain larger... Hmm, not directly applicable.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, similar to the number of derangements, but in a larger set.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, alternatively, let me think in terms of shifted indices:
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Let me shift the codomain by an offset to account for the forbidden points.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, not sure.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, another idea: the allowed values for each \( f(n) \) is \( \{-2010, \ldots, 2010\} \setminus \{n, -n\} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but because \( f \) is injective and strictly increasing, the values are determined in a particular order.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, perhaps we can model the problem as a modified version of combination counting.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Given that the standard number of ways is \( \binom{4021}{2011} \), but we have two constraints: no \( f(n) = n \) or \( -n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but given the overlapping constraints, inclusion-exclusion is necessary.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, the total number without any forbidden values is \( \binom{4021}{2011} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Minus the number of sequences where at least one \( f(k) = k \) or \( f(k) = -k \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But this requires inclusion-exclusion over all \( k \), which may be feasible, but calculation could be complex.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Given the labels are \( n \in \{-1005, \ldots, 1005\} \), we have 2011 such \( n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Each forbidden event is the occurrence of \( f(k) = \pm k \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But due to injectivity, these events are not independent, making inclusion-exclusion calculation complex because the events can overlap.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but is there a possible symmetry or formula to simplify this?
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, actually, this problem might be similar to counting the number of permutations avoiding a certain set of points, or derangements.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, no, not exactly.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, hold on. Let me think that this problem reduces to counting the number of injective functions \( f \) from the domain to codomain avoiding certain points.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m In our case, injective, strictly increasing, and avoiding \( f(n) = \pm n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m This is similar to the concept of linear extensions or such, but perhaps too advanced.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, since the forbidden positions are symmetric, perhaps we can model the choices.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, if we perform a coordinate transformation.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, since the forbidden values are symmetric around the center, perhaps think of the shifted problem.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, let me consider what if I subtract the forbidden points.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But perhaps I'm overcomplicating.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, is there a standard combinatorial formula for this?
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, without the \( f(n) = \pm n \) constraint, the number of strictly increasing functions would be \( \binom{4021}{2011} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m With the constraint of \( f(n) \neq \pm n \), the number of such functions would be a certain number of these combinations minus those that include \( f(n) = \pm n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but perhaps another way: the allowed total number of functions is equal to the number of ways to choose 2011 numbers from \(-2010\) to \(2010\), excluding the points \( n, -n \) for each \( n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, perhaps the number of such functions is equal to \( \binom{4021 - 2 \times 2011 + 1}{2011} \). Wait, let me compute:
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Total number of numbers is 4021.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Total forbidden positions: for each \( n \in \{-1005, \ldots, 1005\} \), two prohibited numbers \( n \) and \(-n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But the forbidden points can't overlap except perhaps for \( n = 0 \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, for \( n = 0 \): \( f(0) \neq 0 \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m So, total number of forbidden values:
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m - For \( n=0 \): 1 forbidden number (0)
[36m(TaskRunner pid=2879679)[0m - For each non-zero \( n \): 2 forbidden numbers.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Number of non-zero \( n \): \( 2 \times 1005 = 2010 \) (from 1 to 1005 and their negatives)
[36m(TaskRunner pid=2879679)[0m Each contributing 2 forbidden numbers, so total forbidden non-zero numbers: \( 2010 \times 2 = 4020 \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Plus the forbidden number for \( n=0 \): 1.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Total forbidden numbers: \( 4020 + 1 = 4021 \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but total forbidden numbers are 4021, same as the total number of numbers in codomain. Which means no possible number can be chosen without overlapping forbidden numbers? That can't be.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, clearly, something is wrong with this reasoning. Because the codomain is 4021 numbers, but we have forbidden assignments of 4021 "forbidden" numbers, each number is forbidden for exactly one \( n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Therefore, each number in the codomain is forbidden as a result of exactly one \( n \in \{-1005, \ldots, 1005\} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, no: for each number, except 0, there are two \( n \): for example, 1 is assigned to \( n=1 \) or \( n=-1 \). Similarly, -1 is also in codomain but assigned only when \( n=1 \) or \( n=-1 \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, so in this model, each non-zero number in the codomain is forbidden by exactly two different functions \( f(n) \). However, we are not conditioning on \( f(n) \) being forbidden for each \( n \), but rather avoiding forbidden \( f(n) = \pm n \) for each \( n \) in the domain.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, perhaps using inclusion-exclusion is still possible.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Number of allowed sequences = total sequences - sequences where \( f(k) = k \) or \( f(k) = -k \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But due to overlapping, inclusion-exclusion is complicated.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, but maybe the forbidden assignments are symmetric, so we can say the number of such sequences is \( \binom{4021 - 2 \times 2011 +1}{2011} \)?
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, symmetries in combinatorics. Hmm.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, total number of functions: \( \binom{4021}{2011} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Number of forbidden functions: consider the forbidden mappings.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, no, this is getting foggier.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, if we fix the domain as a linear set, and codomain as a linear set, with forbidden positions, the number of injective strictly increasing functions avoiding certain points is the same as the number of ways to choose 2011 elements from 4021, avoiding specific 4022 points (for each n, exclude two points). But since 4021 total elements, excluding 4022 points is impossible, as we can't exclude more points than available.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, confused.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, perhaps this bijection parallels the problem of derangements, where forbidden positions are considered.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, in the standard derangement problem, the number is \( !n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But in our case, the problem is more involved due to the injectivity and order constraints.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, perhaps considering that each function is a combination, no two overlapping.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, this is getting too tangled.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, another idea: if the forbidden positions are symmetrical for each n and -n, then the number of such functions is \( \binom{4021 - 2 \times 0 - 2 \times 2011 +1}{2011} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, unclear.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, another approach: independent of specifics, the constraint is similar to deranging a non-linear space.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Not sure.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, the total number is equal to \( \binom{4021 - 2 \times 2011 +1}{2011} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, 4021 - 2*2011 +1 = 1.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, so \( \binom{1}{2011} = 0 \), which cannot be.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, that approach is flawed.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, alternative idea: the forbidden assignments per position cannot include the forbidden numbers, thus the number of ways is equal to the number of injective strictly increasing sequences avoiding \( f(n) = \pm n \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Which would be similar to arranging numbers in a line without certain points.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, too vague.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Given the time invested, perhaps I need to simplify.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, since the forbidden assignments are symmetrical, and for the purposes of the problem, maybe the number is \( \binom{2011}{2011} \times ... \), no, not likely.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, stepping back.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m The problem is equivalent to the number of strictly increasing sequences \( g(1) < g(2) < \ldots < g(2011) \) in \(\{-2010, -2009, \ldots, 2009, 2010\}\), avoiding \( g(k) = \pm k \) for each \(k\).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Given linearity, the number is equal to the number of ways to choose 2011 numbers from the 4021, avoiding 4022 forbidden positions, but due to overlaps, which complicates things.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, maybe, but given the size, perhaps the answer is \( \binom{4021 - 2 \times 2011}{2011} \)?
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, 4021 - 4022 = -1. Not possible.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, no, not helpful.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, perhaps the number is zero, but that's unlikely.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, no, given that injective, strictly increasing, avoiding forbidden positions, it's feasible as long as forbidden positions are not all covering the codomain.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m But given the complexity, perhaps the answer is \( \binom{4021 - 2 \times (2 \times 2011) +1}{2011} \).
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, 4021 - 2*(4022) +1 = 4021 -8044 +1 = -4022. Negative again, which doesn't make sense.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, I'm stuck.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, another thought: the number of such functions is equal to the number of derangements on 2011 elements, but that's not directly applicable.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, since each number is only forbidden once, total derangements in such a setup is similar to inclusion-exclusion, which is intractable manually for such a large number.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, perhaps considering the problem is the same as choosing a subset of 2011 numbers, which is a linear extension poset, but seems too high.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Wait, I'm running out of ideas. Maybe I recall that the count is equal to \( \binom{4021 - 2011}{2011} \), but 4021 - 2011 = 2010, so \( \binom{2010}{2011} = 0 \). Nope.
[36m(TaskRunner pid=2879679)[0m 
[36m(TaskRunner pid=2879679)[0m Alternatively, accept that this
[36m(TaskRunner pid=2879679)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:08:24<21:54, 101.11s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:10:02<20:04, 100.34s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:11:39<18:10, 99.17s/it] 
[36m(TaskRunner pid=2879679)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:14:32<20:15, 121.53s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:16:11<17:11, 114.66s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:17:49<14:37, 109.74s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 05:33:20,552:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 05:33:25,604:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 05:33:31,630:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:19:41<12:52, 110.39s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:21:17<10:36, 106.11s/it]
[36m(TaskRunner pid=2879679)[0m WARNING:2025-11-30 05:36:48,943:Timeout during comparison
[36m(TaskRunner pid=2879679)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:23:02<08:48, 105.64s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:24:41<06:55, 103.79s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:26:16<05:03, 101.13s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:27:59<03:23, 101.75s/it]
[36m(TaskRunner pid=2879679)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:29:42<01:42, 102.17s/it]
[36m(WorkerDict pid=2883230)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2883230)[0m   warnings.warn(
[36m(TaskRunner pid=2879679)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:32:55<01:49, 109.34s/it]
[36m(WorkerDict pid=2883409)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2883409)[0m   warnings.warn([32m [repeated 3x across cluster][0m
