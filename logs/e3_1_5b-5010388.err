
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_grpo_2/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_grpo_2//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_grpo_2//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_grpo_2//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=grpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_grpo_2/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-28 15:13:52,946	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=4068776)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 15:14:13,275:Waiting for register center actor yz4Ys6_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=4072509)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=4072509)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=4072509)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=4072334)[0m [rank0]:[W1128 15:14:30.145358547 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=4072334)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=4072334)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=4072334)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072334)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m [rank3]:[W1128 15:14:31.270968388 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=4072509)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=4072334)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=4072508)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=4072508)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072508)[0m   warnings.warn(
[36m(WorkerDict pid=4072334)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=4072509)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072509)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:   0%|          | 1/480 [01:58<15:47:28, 118.68s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   0%|          | 2/480 [03:57<15:45:33, 118.69s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   1%|          | 3/480 [06:01<16:04:15, 121.29s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   1%|          | 4/480 [07:59<15:51:57, 120.00s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   1%|          | 5/480 [09:58<15:47:19, 119.66s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   1%|â–         | 6/480 [12:00<15:50:23, 120.30s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   1%|â–         | 7/480 [14:02<15:52:33, 120.83s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   2%|â–         | 8/480 [16:01<15:46:31, 120.32s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 15:33:59,557:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:   2%|â–         | 9/480 [18:07<15:58:39, 122.12s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   2%|â–         | 10/480 [21:29<19:10:39, 146.89s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   2%|â–         | 11/480 [23:27<17:58:28, 137.97s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   2%|â–Ž         | 12/480 [25:25<17:08:35, 131.87s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   3%|â–Ž         | 13/480 [27:24<16:34:48, 127.81s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   3%|â–Ž         | 14/480 [29:23<16:11:53, 125.14s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   3%|â–Ž         | 15/480 [31:19<15:50:21, 122.63s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   3%|â–Ž         | 16/480 [33:18<15:39:10, 121.45s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   4%|â–Ž         | 17/480 [35:17<15:31:44, 120.74s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   4%|â–         | 18/480 [37:15<15:23:00, 119.87s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   4%|â–         | 19/480 [39:13<15:17:19, 119.39s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   4%|â–         | 20/480 [42:35<18:23:53, 143.99s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   4%|â–         | 21/480 [44:35<17:27:45, 136.96s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   5%|â–         | 22/480 [46:35<16:45:31, 131.73s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   5%|â–         | 23/480 [48:33<16:11:47, 127.59s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   5%|â–Œ         | 24/480 [50:29<15:43:46, 124.18s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   5%|â–Œ         | 25/480 [52:24<15:21:22, 121.50s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   5%|â–Œ         | 26/480 [54:19<15:03:48, 119.45s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   6%|â–Œ         | 27/480 [56:21<15:08:19, 120.31s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   6%|â–Œ         | 28/480 [58:13<14:48:00, 117.88s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:10<14:44:27, 117.67s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 16:19:45,446:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:25<17:34:50, 140.64s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 16:21:14,786:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:16<16:27:09, 131.92s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:03<15:29:00, 124.42s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:02<15:13:25, 122.61s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:57<14:54:11, 120.30s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:48<14:31:33, 117.51s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:37<14:11:16, 115.04s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:29<14:02:04, 114.05s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:26<14:07:38, 115.06s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:14<13:50:30, 112.99s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:21<16:31:55, 135.26s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:09<15:29:47, 127.08s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:02<14:56:39, 122.83s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:50<14:22:28, 118.42s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:40<14:02:23, 115.92s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:25<13:34:35, 112.36s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:15<13:28:50, 111.82s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:03<13:18:49, 110.69s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:54<13:16:45, 110.66s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:49<13:23:55, 111.92s/it]
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072334)[0m   warnings.warn(
[36m(TaskRunner pid=4068776)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:06<16:25:45, 137.55s/it]
[36m(WorkerDict pid=4072510)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:54<15:20:41, 128.77s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:43<14:34:55, 122.65s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:28<13:56:28, 117.54s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:20<13:43:04, 115.93s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:06<13:20:13, 112.97s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:55<13:08:22, 111.56s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:46<13:05:05, 111.36s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:29<12:46:43, 109.01s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 17:15:16,429:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 17:15:23,976:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:59:22<12:53:46, 110.28s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 17:17:08,488:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 17:17:14,374:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:26<15:25:22, 132.20s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:13<14:30:37, 124.67s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:58<13:46:58, 118.70s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:07:42<13:15:20, 114.44s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:09:35<13:10:57, 114.08s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:11:17<12:42:20, 110.22s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:13:06<12:38:16, 109.90s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:14:50<12:25:50, 108.35s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:16:35<12:16:11, 107.21s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:18:23<12:16:59, 107.59s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:21:24<14:44:28, 129.43s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:23:10<13:54:44, 122.46s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:24:55<13:16:10, 117.09s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:26:39<12:47:53, 113.20s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:28:31<12:43:40, 112.86s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:30:15<12:23:25, 110.14s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:32:04<12:20:26, 109.97s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:33:51<12:12:17, 109.03s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 17:51:41,768:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:35:43<12:15:57, 109.84s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:37:30<12:08:46, 109.04s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:40:27<14:23:43, 129.56s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:42:14<13:36:14, 122.74s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:43:59<12:59:14, 117.47s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:45:48<12:39:47, 114.83s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:47:33<12:19:03, 111.98s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:49:20<12:06:34, 110.37s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:51:05<11:54:10, 108.76s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:52:52<11:48:56, 108.23s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:54:42<11:49:58, 108.67s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:56:24<11:34:51, 106.63s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:59:22<13:53:09, 128.18s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:01:04<13:01:07, 120.48s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:02:49<12:28:51, 115.80s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:04:33<12:04:11, 112.28s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 18:22:26,148:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 18:22:31,175:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:06:34<12:17:23, 114.62s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:08:15<11:50:29, 110.73s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:10:03<11:43:16, 109.89s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:11:46<11:27:19, 107.67s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:13:20<11:01:00, 103.82s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:15:11<11:11:32, 105.76s/it]
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072334)[0m   warnings.warn(
[36m(WorkerDict pid=4072334)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=4072334)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=4068776)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:18:25<13:57:12, 132.19s/it]
[36m(WorkerDict pid=4072510)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:20:04<12:52:07, 122.24s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:21:47<12:15:06, 116.68s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:23:27<11:41:12, 111.60s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:25:06<11:16:21, 107.93s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:26:51<11:08:10, 106.91s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:28:29<10:49:41, 104.23s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:30:15<10:52:01, 104.88s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:31:54<10:38:31, 102.99s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:33:43<10:47:41, 104.75s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:36:42<13:03:10, 127.00s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:38:23<12:14:18, 119.40s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:40:00<11:29:47, 112.47s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:41:43<11:11:20, 109.76s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:43:27<10:59:17, 108.08s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:45:03<10:34:39, 104.33s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 19:02:48,385:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:46:47<10:32:34, 104.27s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:48:28<10:24:26, 103.21s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:50:09<10:19:09, 102.62s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:51:49<10:12:13, 101.75s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:54:47<12:28:14, 124.71s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:56:22<11:33:36, 115.92s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:58:09<11:14:46, 113.09s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 19:15:57,103:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:59:55<11:00:42, 111.04s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 19:17:47,652:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:01:50<11:06:28, 112.33s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:03:29<10:40:22, 108.23s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:05:12<10:29:05, 106.62s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:06:51<10:13:12, 104.23s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:08:31<10:05:01, 103.13s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:10:14<10:02:36, 103.01s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:13:11<12:09:44, 125.10s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:14:54<11:29:29, 118.54s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:16:29<10:46:25, 111.45s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:18:11<10:29:01, 108.76s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 19:35:58,128:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:19:58<10:23:09, 108.06s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:21:39<10:10:31, 106.18s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:23:20<10:00:01, 104.65s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:24:59<9:48:24, 102.93s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:26:41<9:44:42, 102.58s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:28:20<9:36:27, 101.43s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:31:10<11:30:53, 121.92s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:32:50<10:52:37, 115.51s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:34:28<10:20:06, 110.08s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:36:07<10:00:38, 106.94s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:37:44<9:41:02, 103.76s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:39:20<9:26:21, 101.44s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:40:52<9:09:05, 98.64s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:42:26<8:59:49, 97.27s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:44:02<8:55:59, 96.87s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:45:44<9:03:31, 98.53s/it]
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072334)[0m   warnings.warn(
[36m(TaskRunner pid=4068776)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:48:50<11:26:15, 124.77s/it]
[36m(WorkerDict pid=4072510)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:50:31<10:44:46, 117.59s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:52:09<10:11:15, 111.82s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:53:46<9:45:12, 107.38s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:55:26<9:31:15, 105.14s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:57:00<9:11:42, 101.85s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:58:34<8:56:38, 99.38s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:00:08<8:46:15, 97.76s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:01:50<8:51:48, 99.09s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:03:28<8:48:43, 98.83s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:06:20<10:43:18, 120.62s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:08:05<10:17:25, 116.13s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:09:45<9:48:54, 111.11s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:11:18<9:18:19, 105.68s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:12:54<9:00:52, 102.70s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:14:30<8:48:51, 100.73s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:16:07<8:41:33, 99.66s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:17:40<8:29:25, 97.65s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:19:19<8:30:00, 98.08s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:20:53<8:22:05, 96.87s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:23:43<10:13:10, 118.68s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:25:17<9:34:13, 111.50s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:26:51<9:05:29, 106.26s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:28:26<8:46:30, 102.90s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:29:59<8:28:28, 99.70s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:31:38<8:26:34, 99.65s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:33:18<8:24:31, 99.58s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:34:53<8:15:50, 98.19s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:36:32<8:15:36, 98.47s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:38:09<8:12:19, 98.14s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:41:01<10:01:49, 120.37s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:42:39<9:25:54, 113.56s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:44:16<8:58:45, 108.48s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:45:54<8:41:33, 105.37s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:47:27<8:22:40, 101.89s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:49:11<8:23:08, 102.33s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:50:49<8:15:47, 101.18s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:52:25<8:05:54, 99.50s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:54:03<8:02:09, 99.07s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:55:43<8:02:24, 99.47s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [5:58:29<9:37:21, 119.45s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:00:03<8:57:16, 111.54s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:01:37<8:31:06, 106.48s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:03:16<8:17:53, 104.09s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:04:53<8:06:27, 102.05s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:06:29<7:55:30, 100.11s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:08:08<7:52:12, 99.76s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:09:42<7:42:35, 98.07s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:11:20<7:41:49, 98.26s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:12:56<7:36:23, 97.45s/it]
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072334)[0m   warnings.warn(
[36m(TaskRunner pid=4068776)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:16:04<9:41:02, 124.51s/it]
[36m(WorkerDict pid=4072510)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:17:42<9:02:56, 116.76s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:19:20<8:34:16, 110.99s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:20:56<8:12:22, 106.65s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:22:35<7:59:19, 104.20s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:24:13<7:48:48, 102.29s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:25:57<7:49:43, 102.86s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:27:39<7:47:35, 102.77s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:29:14<7:34:20, 100.22s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:30:51<7:28:33, 99.31s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:33:44<9:06:07, 121.36s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:35:24<8:35:48, 115.05s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:37:04<8:13:28, 110.48s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:38:47<8:01:36, 108.23s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:40:27<7:48:35, 105.70s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:42:02<7:33:51, 102.76s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:43:42<7:27:18, 101.66s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:45:19<7:19:48, 100.34s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:46:53<7:10:38, 98.62s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:48:39<7:18:11, 100.74s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:51:27<8:43:56, 120.91s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:53:04<8:11:23, 113.84s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:54:44<7:51:04, 109.55s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:56:16<7:26:27, 104.23s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [6:57:57<7:20:18, 103.20s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [6:59:33<7:10:23, 101.27s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:01:11<7:03:57, 100.15s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:02:53<7:04:37, 100.70s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:04:31<7:00:01, 100.00s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:06:10<6:57:17, 99.75s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:08:59<8:21:22, 120.33s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:10:35<7:48:52, 112.98s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:12:11<7:26:50, 108.11s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:13:47<7:10:14, 104.51s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:15:22<6:56:02, 101.48s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:16:58<6:47:52, 99.89s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:18:32<6:38:26, 97.98s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:20:05<6:31:31, 96.67s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:21:46<6:35:11, 97.98s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:23:23<6:32:11, 97.64s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:26:15<7:59:41, 119.92s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:27:59<7:38:14, 115.04s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:29:37<7:16:36, 110.07s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:31:16<7:01:34, 106.73s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:32:54<6:49:07, 104.01s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:34:35<6:43:41, 103.07s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:36:10<6:33:30, 100.90s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:37:49<6:29:31, 100.31s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:39:33<6:31:32, 101.26s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:41:15<6:30:29, 101.43s/it]
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072334)[0m   warnings.warn(
[36m(TaskRunner pid=4068776)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:44:20<8:05:21, 126.62s/it]
[36m(WorkerDict pid=4072510)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:45:55<7:27:23, 117.22s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:47:31<7:00:36, 110.68s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:49:05<6:40:29, 105.86s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:50:41<6:27:21, 102.84s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:52:17<6:17:26, 100.65s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:53:56<6:14:03, 100.19s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:55:30<6:05:11, 98.26s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:57:10<6:05:38, 98.82s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [7:58:43<5:58:26, 97.31s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:01:28<7:10:40, 117.46s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:03:04<6:45:21, 111.06s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:04:43<6:30:19, 107.43s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:06:20<6:17:06, 104.27s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:08:01<6:12:19, 103.42s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:09:36<6:01:07, 100.78s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:11:14<5:56:54, 100.07s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:12:51<5:51:12, 98.93s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:14:21<5:40:33, 96.39s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:15:58<5:39:56, 96.67s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-28 23:33:40,549:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:18:51<6:58:09, 119.47s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:20:30<6:34:45, 113.33s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:22:02<6:10:59, 107.01s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:23:37<5:56:43, 103.40s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:25:17<5:50:38, 102.13s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:26:50<5:40:05, 99.54s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:28:30<5:39:21, 99.81s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:30:09<5:36:43, 99.53s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:31:44<5:30:20, 98.12s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:33:21<5:26:56, 97.60s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:36:08<6:35:34, 118.67s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:37:37<6:03:53, 109.71s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:39:13<5:48:37, 105.64s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:40:51<5:39:05, 103.28s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:42:34<5:36:49, 103.11s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:44:14<5:32:15, 102.23s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:45:52<5:26:11, 100.88s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:47:31<5:23:13, 100.48s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:49:11<5:20:27, 100.14s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:50:47<5:14:52, 98.92s/it] 
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 00:10:09,036:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:53:48<6:31:49, 123.73s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:55:28<6:07:13, 116.58s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [8:57:06<5:47:23, 110.87s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [8:58:44<5:33:17, 106.94s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:00:23<5:24:26, 104.66s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:02:03<5:18:53, 103.43s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 00:19:51,531:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:03:53<5:22:31, 105.17s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:05:30<5:13:58, 102.94s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:07:13<5:11:53, 102.82s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:08:50<5:04:35, 100.97s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 00:26:33,297:Timeout during comparison
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072334)[0m   warnings.warn(
[36m(TaskRunner pid=4068776)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:12:02<6:25:13, 128.41s/it]
[36m(WorkerDict pid=4072510)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:13:43<5:58:28, 120.16s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:15:24<5:39:21, 114.39s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:17:07<5:27:47, 111.11s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:18:50<5:18:30, 108.58s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:20:29<5:07:52, 105.56s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:22:10<5:02:27, 104.30s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:23:47<4:54:14, 102.05s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:25:27<4:51:27, 101.67s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:27:14<4:53:41, 103.05s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:30:09<5:53:19, 124.71s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:31:50<5:31:12, 117.59s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:33:32<5:16:01, 112.87s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:35:11<5:02:29, 108.68s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:36:50<4:53:15, 106.00s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:38:34<4:49:20, 105.21s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:40:20<4:48:00, 105.37s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 00:58:03,008:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 00:58:12,762:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:42:10<4:50:04, 106.77s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:43:52<4:44:25, 105.35s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:45:34<4:40:17, 104.46s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:48:29<5:35:19, 125.75s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:50:14<5:16:08, 119.30s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:51:51<4:56:36, 112.64s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:53:28<4:42:45, 108.06s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:55:11<4:37:00, 106.54s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [9:56:52<4:30:32, 104.72s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [9:58:35<4:27:57, 104.40s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:00:18<4:25:16, 104.03s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:02:01<4:22:10, 103.49s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:03:38<4:15:33, 101.55s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 01:22:56,211:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:06:37<5:12:05, 124.84s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:08:17<4:51:55, 117.55s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:09:56<4:36:05, 111.93s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:11:42<4:29:21, 109.94s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:13:21<4:20:09, 106.92s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:15:00<4:12:04, 104.31s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:16:39<4:06:41, 102.79s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:18:19<4:03:07, 102.01s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:20:00<4:00:39, 101.69s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:21:41<3:58:11, 101.36s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:24:33<4:46:23, 122.74s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:26:14<4:28:59, 116.11s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:27:54<4:16:13, 111.40s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:29:34<4:06:36, 108.00s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:31:10<3:56:18, 104.25s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:32:54<3:54:14, 104.11s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:34:34<3:50:18, 103.12s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:36:15<3:46:39, 102.25s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:37:58<3:45:27, 102.48s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:39:33<3:39:05, 100.35s/it]
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072334)[0m   warnings.warn(
[36m(TaskRunner pid=4068776)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:42:44<4:36:27, 127.59s/it]
[36m(WorkerDict pid=4072510)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:44:26<4:17:37, 119.82s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:46:06<4:03:07, 113.96s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:47:56<3:58:33, 112.70s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:49:39<3:50:43, 109.87s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:51:22<3:44:34, 107.80s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:53:01<3:37:23, 105.19s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:54:44<3:34:00, 104.39s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:56:22<3:28:31, 102.55s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:58:12<3:31:07, 104.69s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:01:04<4:09:49, 124.91s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:02:45<3:53:22, 117.67s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:04:30<3:43:52, 113.83s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:06:09<3:33:31, 109.50s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:07:46<3:24:36, 105.83s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:09:25<3:18:39, 103.65s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:11:02<3:13:32, 101.86s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:12:40<3:09:34, 100.66s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:14:25<3:10:10, 101.88s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 02:32:07,091:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:16:09<3:09:28, 102.42s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:19:05<3:48:35, 124.69s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:20:45<3:32:49, 117.16s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:22:27<3:22:45, 112.64s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:24:12<3:16:44, 110.32s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:25:50<3:08:12, 106.54s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:27:31<3:03:58, 105.12s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:29:11<2:59:21, 103.48s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:30:52<2:56:13, 102.66s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:32:31<2:52:48, 101.66s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:34:09<2:49:16, 100.56s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:37:02<3:23:34, 122.15s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:38:43<3:11:05, 115.82s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 02:56:27,165:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 02:56:33,201:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:40:33<3:06:35, 114.24s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:42:15<2:58:27, 110.39s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:44:02<2:55:20, 109.59s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:45:41<2:48:17, 106.29s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:47:17<2:41:35, 103.15s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:48:57<2:38:36, 102.33s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:50:34<2:34:16, 100.61s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:52:13<2:31:48, 100.10s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:55:03<3:01:42, 121.14s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:56:41<2:49:14, 114.10s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:58:15<2:38:34, 108.12s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [11:59:47<2:29:46, 103.30s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:01:22<2:24:32, 100.84s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:03:04<2:23:19, 101.17s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:04:38<2:18:49, 99.16s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:06:14<2:15:47, 98.17s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:07:50<2:13:17, 97.53s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:09:26<2:11:02, 97.07s/it]
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072334)[0m   warnings.warn(
[36m(TaskRunner pid=4068776)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:12:30<2:44:02, 123.04s/it]
[36m(WorkerDict pid=4072510)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:14:07<2:31:45, 115.27s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:15:45<2:23:01, 110.02s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:17:19<2:15:16, 105.41s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:18:58<2:10:51, 103.31s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:20:29<2:04:31, 99.63s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:22:07<2:02:28, 99.31s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:23:46<2:00:22, 98.93s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:25:24<1:58:38, 98.87s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:26:59<1:55:40, 97.76s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:29:52<2:20:04, 120.06s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:31:28<2:09:56, 112.99s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:33:04<2:02:08, 107.77s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:34:40<1:56:41, 104.49s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:36:18<1:52:41, 102.45s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:37:49<1:47:19, 99.07s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:39:26<1:44:59, 98.43s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:41:08<1:44:19, 99.35s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:42:46<1:42:28, 99.17s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:44:25<1:40:44, 99.09s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:47:21<2:02:03, 122.05s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:49:00<1:53:04, 114.99s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:50:44<1:48:03, 111.79s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:52:20<1:41:40, 107.03s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 04:10:06,993:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:54:06<1:39:44, 106.86s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:55:48<1:36:25, 105.18s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:57:25<1:32:41, 102.99s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [12:59:06<1:30:24, 102.35s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:00:50<1:29:01, 102.73s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:02:28<1:26:11, 101.41s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:05:20<1:42:00, 122.41s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:06:57<1:33:49, 114.89s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:08:33<1:27:24, 109.25s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:10:17<1:24:19, 107.65s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:11:54<1:20:10, 104.57s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:13:29<1:16:14, 101.66s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:15:05<1:13:20, 100.01s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:16:44<1:11:21, 99.57s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:18:23<1:09:34, 99.39s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:20:05<1:08:23, 100.10s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:22:51<1:20:04, 120.11s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:24:29<1:13:43, 113.43s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:26:10<1:09:28, 109.69s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:27:47<1:05:13, 105.77s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:29:25<1:02:01, 103.38s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:31:01<59:09, 101.41s/it]  
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 04:48:43,019:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 04:48:48,038:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 04:48:54,447:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:32:50<58:36, 103.44s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:34:24<55:20, 100.64s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:35:57<52:26, 98.32s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:37:34<50:39, 98.03s/it]
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072334)[0m   warnings.warn(
[36m(TaskRunner pid=4068776)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:40:36<1:01:40, 123.35s/it]
[36m(WorkerDict pid=4072510)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4068776)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:42:13<55:42, 115.28s/it]  
[36m(TaskRunner pid=4068776)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:43:43<50:18, 107.80s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:45:20<47:03, 104.56s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:46:56<44:13, 102.05s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:48:27<41:08, 98.74s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:50:02<38:56, 97.36s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:51:43<37:50, 98.71s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:53:18<35:42, 97.37s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:54:51<33:40, 96.22s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [13:57:41<39:24, 118.24s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [13:59:17<35:22, 111.69s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:00:50<31:46, 105.94s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:02:25<29:04, 102.60s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:03:57<26:33, 99.59s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:05:33<24:34, 98.32s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:07:11<22:59, 98.51s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:08:47<21:09, 97.65s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:10:22<19:22, 96.90s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:11:56<17:36, 96.04s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:14:48<19:47, 118.78s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:16:24<16:47, 111.92s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:18:01<14:20, 107.54s/it]
[36m(TaskRunner pid=4068776)[0m WARNING:2025-11-29 05:35:42,687:Timeout during comparison
[36m(TaskRunner pid=4068776)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:19:43<12:20, 105.77s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:21:18<10:15, 102.50s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:22:51<08:18, 99.75s/it] 
[36m(TaskRunner pid=4068776)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:24:27<06:34, 98.62s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:26:02<04:52, 97.53s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:27:43<03:17, 98.59s/it]
[36m(TaskRunner pid=4068776)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:29:25<01:39, 99.48s/it]
[36m(WorkerDict pid=4072334)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4072334)[0m   warnings.warn(
[36m(TaskRunner pid=4068776)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:32:32<01:49, 109.30s/it]
[36m(WorkerDict pid=4072510)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4072510)[0m   warnings.warn([32m [repeated 3x across cluster][0m
