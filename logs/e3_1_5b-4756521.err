
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_covvar_kappa__ac_0.05/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_covvar_kappa__ac_0.05//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa__ac_0.05//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa__ac_0.05//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_covvar_kappa__ac_0.05/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-11 22:43:52,508	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=4121036)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-11 22:44:13,891:Waiting for register center actor EMu8vn_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=4124801)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=4124801)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=4124801)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=4124801)[0m [rank3]:[W1111 22:44:32.093040404 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=4124593)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=4124593)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=4124593)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124593)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124593)[0m [rank0]:[W1111 22:44:33.227881982 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=4124593)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=4124801)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(WorkerDict pid=4124800)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=4121036)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4121036)[0m Training Progress:   0%|          | 1/480 [02:01<16:07:40, 121.21s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   0%|          | 2/480 [04:03<16:12:31, 122.07s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   1%|          | 3/480 [06:11<16:32:12, 124.81s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   1%|          | 4/480 [08:14<16:24:38, 124.11s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-11 22:56:20,117:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:   1%|          | 5/480 [10:21<16:30:09, 125.07s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   1%|â–         | 6/480 [12:25<16:24:34, 124.63s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   1%|â–         | 7/480 [14:34<16:32:32, 125.90s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   2%|â–         | 8/480 [16:39<16:29:24, 125.77s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   2%|â–         | 9/480 [18:42<16:20:25, 124.90s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   2%|â–         | 10/480 [22:11<19:42:51, 151.00s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   2%|â–         | 11/480 [24:14<18:31:21, 142.18s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   2%|â–Ž         | 12/480 [26:16<17:41:11, 136.05s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   3%|â–Ž         | 13/480 [28:18<17:06:25, 131.87s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   3%|â–Ž         | 14/480 [30:22<16:46:13, 129.56s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   3%|â–Ž         | 15/480 [32:24<16:24:57, 127.09s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   3%|â–Ž         | 16/480 [34:28<16:15:38, 126.16s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   4%|â–Ž         | 17/480 [36:32<16:08:57, 125.57s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   4%|â–         | 18/480 [38:34<15:59:23, 124.60s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   4%|â–         | 19/480 [40:37<15:54:29, 124.23s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   4%|â–         | 20/480 [44:08<19:12:02, 150.27s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-11 23:32:13,373:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:   4%|â–         | 21/480 [46:17<18:19:55, 143.78s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   5%|â–         | 22/480 [48:20<17:30:43, 137.65s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   5%|â–         | 23/480 [50:24<16:55:14, 133.29s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   5%|â–Œ         | 24/480 [52:21<16:16:56, 128.55s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   5%|â–Œ         | 25/480 [54:20<15:53:26, 125.73s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   5%|â–Œ         | 26/480 [56:22<15:43:32, 124.70s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   6%|â–Œ         | 27/480 [58:29<15:45:17, 125.20s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   6%|â–Œ         | 28/480 [1:00:28<15:28:59, 123.32s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   6%|â–Œ         | 29/480 [1:02:32<15:29:10, 123.61s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   6%|â–‹         | 30/480 [1:05:53<18:21:03, 146.81s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-11 23:53:55,082:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-11 23:54:01,314:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:   6%|â–‹         | 31/480 [1:07:58<17:29:24, 140.23s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   7%|â–‹         | 32/480 [1:09:50<16:25:02, 131.92s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   7%|â–‹         | 33/480 [1:11:51<15:58:07, 128.61s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   7%|â–‹         | 34/480 [1:13:54<15:41:56, 126.72s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   7%|â–‹         | 35/480 [1:15:54<15:24:57, 124.71s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   8%|â–Š         | 36/480 [1:17:50<15:05:10, 122.32s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   8%|â–Š         | 37/480 [1:19:51<14:59:03, 121.77s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   8%|â–Š         | 38/480 [1:21:57<15:06:00, 122.99s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   8%|â–Š         | 39/480 [1:23:52<14:47:10, 120.70s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   8%|â–Š         | 40/480 [1:27:16<17:47:44, 145.60s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   9%|â–Š         | 41/480 [1:29:14<16:45:41, 137.45s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   9%|â–‰         | 42/480 [1:31:17<16:11:50, 133.13s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   9%|â–‰         | 43/480 [1:33:13<15:31:30, 127.89s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   9%|â–‰         | 44/480 [1:35:08<15:01:08, 124.01s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:   9%|â–‰         | 45/480 [1:36:58<14:29:50, 119.98s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  10%|â–‰         | 46/480 [1:38:53<14:16:08, 118.36s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  10%|â–‰         | 47/480 [1:40:48<14:05:57, 117.22s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:42:44<14:02:29, 117.01s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:44:41<14:01:16, 117.11s/it]
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(TaskRunner pid=4121036)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:48:08<17:12:05, 144.01s/it]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4121036)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:50:03<16:06:17, 135.14s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:51:51<15:06:39, 127.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:53:38<14:22:27, 121.19s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:55:32<14:03:23, 118.79s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:57:25<13:50:55, 117.31s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:59:18<13:38:32, 115.83s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [2:01:11<13:30:58, 115.03s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [2:02:59<13:14:22, 112.95s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 00:50:58,132:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:04:56<13:20:33, 114.09s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:07:54<15:32:59, 133.28s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:09:46<14:47:17, 127.06s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:11:35<14:06:18, 121.48s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:13:23<13:36:04, 117.42s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:15:18<13:29:51, 116.81s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:17:10<13:17:38, 115.32s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:19:05<13:14:56, 115.21s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:20:53<12:57:26, 112.95s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:22:43<12:49:17, 112.03s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:24:34<12:46:08, 111.85s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:27:42<15:19:52, 134.62s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:29:33<14:30:22, 127.68s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:31:23<13:52:36, 122.44s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:33:14<13:27:08, 118.99s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:35:09<13:15:20, 117.54s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:36:58<12:56:43, 115.07s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:38:52<12:52:25, 114.72s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:40:45<12:46:55, 114.18s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:42:37<12:42:07, 113.75s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:44:31<12:40:08, 113.74s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:47:35<14:57:44, 134.66s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:49:28<14:12:47, 128.24s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:51:19<13:37:18, 123.21s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:53:10<13:10:55, 119.54s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:55:01<12:52:08, 116.99s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:56:54<12:41:56, 115.74s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:58:45<12:30:44, 114.33s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [3:00:38<12:26:41, 114.00s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [3:02:31<12:21:02, 113.43s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [3:04:20<12:11:36, 112.27s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:07:23<14:28:05, 133.55s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:09:11<13:35:08, 125.73s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 01:57:06,119:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 01:57:16,646:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:11:13<13:25:22, 124.54s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:13:04<12:58:50, 120.75s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:14:56<12:39:57, 118.13s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:16:44<12:17:53, 115.00s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:18:38<12:14:33, 114.78s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:20:24<11:55:48, 112.14s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:22:04<11:30:11, 108.41s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:23:59<11:40:44, 110.35s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 02:11:53,042:Timeout during comparison
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(WorkerDict pid=4124593)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=4124593)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=4121036)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:27:23<14:37:17, 138.52s/it]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4121036)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:29:08<13:30:47, 128.36s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:30:56<12:50:12, 122.25s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:32:42<12:17:36, 117.39s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:34:26<11:51:19, 113.51s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:36:16<11:41:30, 112.24s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:38:00<11:25:24, 109.96s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:39:53<11:28:05, 110.69s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:41:39<11:17:33, 109.28s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:43:37<11:32:04, 111.93s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:46:39<13:40:53, 133.12s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:48:27<12:51:43, 125.48s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:50:08<12:03:45, 118.00s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:51:55<11:43:03, 114.94s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:53:46<11:33:18, 113.66s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:55:25<11:04:32, 109.24s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:57:08<10:52:11, 107.51s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:58:54<10:46:12, 106.81s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [4:00:38<10:40:44, 106.20s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [4:02:22<10:34:33, 105.47s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [4:05:23<12:47:47, 127.97s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:07:03<11:56:09, 119.69s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:08:52<11:34:25, 116.38s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:10:36<11:10:08, 112.63s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:12:32<11:14:18, 113.65s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:14:15<10:54:49, 110.67s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:16:00<10:42:00, 108.82s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:17:42<10:28:46, 106.87s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:19:29<10:27:02, 106.88s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:21:15<10:23:36, 106.60s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:24:13<12:27:14, 128.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:26:01<11:50:13, 122.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:27:44<11:14:47, 116.34s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:29:28<10:51:08, 112.59s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:31:15<10:40:10, 111.01s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:33:02<10:30:32, 109.66s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:34:45<10:18:06, 107.81s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:36:28<10:07:48, 106.32s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:38:14<10:04:46, 106.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:39:59<10:01:42, 105.87s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:42:59<12:05:13, 127.98s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:44:45<11:26:17, 121.47s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:46:28<10:53:23, 115.99s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:48:16<10:36:47, 113.38s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:49:58<10:16:29, 110.09s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:51:41<10:02:32, 107.92s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:53:17<9:41:33, 104.47s/it] 
[36m(TaskRunner pid=4121036)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:54:58<9:32:52, 103.22s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:56:41<9:31:24, 103.27s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:58:29<9:38:06, 104.79s/it]
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(TaskRunner pid=4121036)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [5:01:41<11:59:43, 130.86s/it]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4121036)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [5:03:24<11:11:47, 122.52s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [5:05:08<10:39:32, 116.99s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [5:06:52<10:16:25, 113.11s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [5:08:38<10:03:08, 111.01s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:10:22<9:49:11, 108.77s/it] 
[36m(TaskRunner pid=4121036)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:12:01<9:31:50, 105.90s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:13:40<9:18:19, 103.71s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:15:28<9:23:38, 105.03s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:17:13<9:22:54, 105.22s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:20:11<11:17:34, 127.05s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:22:02<10:49:56, 122.24s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:23:50<10:24:49, 117.89s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 04:11:45,733:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:25:39<10:08:39, 115.20s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:27:20<9:43:31, 110.79s/it] 
[36m(TaskRunner pid=4121036)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:29:00<9:25:59, 107.81s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:30:44<9:17:46, 106.58s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:32:24<9:04:49, 104.44s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:34:10<9:06:30, 105.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:35:51<8:58:53, 103.97s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:38:49<10:51:12, 126.04s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:40:35<10:17:26, 119.89s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:42:19<9:52:07, 115.35s/it] 
[36m(TaskRunner pid=4121036)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:44:06<9:36:11, 112.61s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:45:46<9:15:55, 109.00s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:47:33<9:10:25, 108.28s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:49:17<9:02:42, 107.11s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:51:01<8:56:01, 106.14s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:52:48<8:55:03, 106.30s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:54:33<8:52:28, 106.14s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:57:35<10:44:33, 128.91s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:59:23<10:09:43, 122.35s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [6:01:07<9:41:08, 117.01s/it] 
[36m(TaskRunner pid=4121036)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [6:02:54<9:24:06, 113.96s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [6:04:36<9:04:24, 110.35s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [6:06:27<9:03:46, 110.60s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [6:08:11<8:52:11, 108.61s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 04:56:06,431:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:09:59<8:49:51, 108.50s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:11:45<8:43:30, 107.57s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:13:33<8:42:31, 107.74s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 05:03:01,674:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:16:36<10:30:26, 130.44s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:18:17<9:45:06, 121.48s/it] 
[36m(TaskRunner pid=4121036)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:19:58<9:14:36, 115.54s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:21:43<8:57:26, 112.36s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:23:28<8:45:05, 110.16s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:25:12<8:33:30, 108.11s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:27:00<8:32:08, 108.20s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:28:43<8:23:09, 106.68s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:30:33<8:25:40, 107.59s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:32:16<8:17:48, 106.29s/it]
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(TaskRunner pid=4121036)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:35:35<10:24:49, 133.89s/it]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4121036)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:37:21<9:43:49, 125.55s/it] 
[36m(TaskRunner pid=4121036)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:39:06<9:14:01, 119.58s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:40:52<8:52:15, 115.29s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:42:36<8:35:31, 112.07s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:44:22<8:25:24, 110.27s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:46:10<8:20:49, 109.67s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:48:01<8:20:45, 110.06s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:49:41<8:04:40, 106.91s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:51:25<7:58:57, 106.04s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:54:28<9:40:39, 129.04s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:56:14<9:07:59, 122.23s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:57:59<8:42:40, 117.02s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:59:46<8:27:18, 114.00s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [7:01:32<8:14:51, 111.62s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [7:03:15<8:01:26, 109.01s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [7:04:57<7:51:10, 107.08s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [7:06:41<7:44:59, 106.08s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [7:08:21<7:35:01, 104.20s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [7:10:12<7:42:12, 106.25s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:13:08<9:11:38, 127.30s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:14:52<8:38:13, 120.05s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:16:37<8:17:36, 115.72s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:18:15<7:52:41, 110.36s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:19:58<7:41:58, 108.28s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:21:43<7:35:13, 107.11s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:23:22<7:23:21, 104.73s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:25:10<7:25:50, 105.73s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:26:51<7:18:04, 104.30s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:28:35<7:15:18, 104.06s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:32:20<9:45:26, 140.50s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:34:45<9:48:26, 141.79s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:37:10<9:50:28, 142.86s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:39:08<9:17:43, 135.48s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:40:49<8:33:01, 125.13s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:43:14<8:54:29, 130.89s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:45:43<9:15:02, 136.48s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:48:12<9:27:31, 140.13s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:50:51<9:47:51, 145.75s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:53:20<9:49:13, 146.70s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:57:04<11:20:15, 170.06s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 06:44:58,867:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:58:56<10:07:38, 152.55s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [8:00:37<9:03:59, 137.14s/it] 
[36m(TaskRunner pid=4121036)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [8:02:21<8:21:46, 127.03s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [8:04:01<7:48:12, 119.03s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [8:05:43<7:26:29, 114.00s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [8:07:24<7:08:43, 109.93s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [8:09:03<6:54:04, 106.63s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [8:10:47<6:49:54, 106.01s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [8:12:31<6:45:08, 105.23s/it]
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(TaskRunner pid=4121036)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [8:15:43<8:23:33, 131.36s/it]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 07:03:31,615:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [8:17:26<7:49:03, 122.90s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:19:06<7:20:45, 115.99s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:20:44<6:58:58, 110.74s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 07:08:33,135:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 07:08:40,216:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:22:33<6:54:44, 110.11s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 07:10:21,874:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:24:16<6:45:05, 108.02s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:25:57<6:35:40, 105.98s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:27:36<6:25:08, 103.63s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:29:17<6:21:08, 103.01s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:30:56<6:14:42, 101.73s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:33:48<7:30:39, 122.91s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:35:30<7:05:00, 116.44s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:37:12<6:47:54, 112.27s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:38:56<6:37:27, 109.90s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:40:39<6:27:38, 107.68s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:42:17<6:15:39, 104.84s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:43:57<6:08:20, 103.27s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:45:36<6:02:02, 101.98s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:47:13<5:55:43, 100.68s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:48:54<5:54:04, 100.69s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:51:52<7:13:35, 123.88s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:53:36<6:50:28, 117.84s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:55:16<6:30:06, 112.53s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:56:59<6:18:01, 109.57s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:58:45<6:13:17, 108.72s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [9:00:27<6:04:21, 106.64s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [9:02:14<6:02:58, 106.76s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 07:50:09,199:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [9:04:09<6:09:37, 109.25s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [9:05:55<6:04:25, 108.25s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [9:07:41<6:00:29, 107.61s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [9:10:48<7:17:53, 131.37s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [9:12:29<6:44:57, 122.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [9:14:14<6:26:12, 117.03s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [9:16:02<6:15:14, 114.29s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [9:17:53<6:10:18, 113.36s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:19:43<6:04:56, 112.29s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:21:31<5:58:46, 110.96s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:23:20<5:55:19, 110.47s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:25:08<5:51:24, 109.82s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:26:56<5:47:17, 109.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:30:07<7:04:08, 133.94s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:31:56<6:37:40, 126.25s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:33:46<6:20:30, 121.44s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:35:31<6:02:52, 116.43s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:37:19<5:53:12, 113.94s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:39:08<5:46:25, 112.36s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:40:59<5:43:52, 112.13s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:42:44<5:34:57, 109.82s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:44:33<5:33:07, 109.82s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:46:19<5:27:45, 108.65s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 08:34:15,279:Timeout during comparison
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(TaskRunner pid=4121036)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:49:47<6:55:00, 138.34s/it]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 08:37:40,626:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 08:37:46,831:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:51:45<6:34:53, 132.36s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:53:31<6:08:39, 124.27s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:55:20<5:53:29, 119.83s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:57:09<5:41:25, 116.40s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:58:52<5:28:18, 112.56s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [10:00:38<5:20:45, 110.60s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [10:02:22<5:13:02, 108.57s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [10:04:08<5:08:37, 107.66s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [10:05:57<5:08:07, 108.11s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [10:09:01<6:11:25, 131.09s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [10:10:46<5:46:39, 123.07s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [10:12:32<5:30:16, 117.95s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [10:14:18<5:18:21, 114.38s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [10:16:06<5:11:33, 112.61s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [10:17:55<5:06:12, 111.35s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [10:19:50<5:07:55, 112.65s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 09:07:41,946:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [10:21:38<5:01:52, 111.12s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [10:23:25<4:56:17, 109.74s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 09:11:17,318:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 09:11:22,602:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:25:23<5:01:31, 112.37s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:28:29<5:58:30, 134.44s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:30:14<5:33:08, 125.72s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 09:18:09,204:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 09:18:14,229:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 09:18:20,576:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:32:17<5:28:18, 124.68s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:34:01<5:10:30, 118.66s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:35:53<5:03:11, 116.61s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:37:41<4:54:11, 113.88s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:39:28<4:47:05, 111.85s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:41:14<4:40:51, 110.14s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:43:04<4:38:50, 110.07s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:44:45<4:30:24, 107.45s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:47:50<5:26:43, 130.69s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:49:31<5:02:33, 121.84s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:51:13<4:45:25, 115.71s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:52:58<4:36:12, 112.74s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:54:42<4:27:22, 109.88s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:56:23<4:19:28, 107.37s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:58:07<4:14:54, 106.21s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:59:53<4:13:17, 106.28s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [11:01:36<4:09:06, 105.26s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [11:03:17<4:04:37, 104.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [11:06:22<4:59:01, 128.16s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [11:08:06<4:40:44, 121.18s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [11:09:50<4:26:34, 115.90s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [11:11:37<4:18:20, 113.15s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [11:13:18<4:08:21, 109.57s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [11:15:04<4:03:59, 108.44s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [11:16:48<3:59:17, 107.15s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [11:18:33<3:56:23, 106.64s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [11:20:22<3:55:41, 107.13s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [11:22:04<3:50:39, 105.64s/it]
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(TaskRunner pid=4121036)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [11:25:25<4:50:54, 134.27s/it]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4121036)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:27:14<4:32:18, 126.65s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:29:01<4:17:43, 120.81s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:30:47<4:06:26, 116.43s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:32:36<3:59:25, 114.01s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:34:20<3:51:50, 111.28s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:36:04<3:45:10, 108.95s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:37:50<3:41:21, 107.98s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:39:33<3:36:29, 106.47s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:41:23<3:37:01, 107.61s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:44:25<4:19:53, 129.95s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:46:12<4:03:59, 123.02s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:47:59<3:52:43, 118.34s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:49:43<3:42:11, 113.94s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:51:26<3:34:01, 110.71s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:53:08<3:27:06, 108.06s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:54:50<3:21:55, 106.27s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:56:32<3:17:25, 104.83s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:58:18<3:16:44, 105.39s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [12:00:02<3:13:57, 104.84s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 10:49:40,035:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [12:03:14<4:00:25, 131.14s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [12:04:59<3:43:48, 123.20s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [12:06:44<3:32:10, 117.88s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [12:08:31<3:24:19, 114.57s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [12:10:12<3:15:12, 110.49s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [12:11:58<3:10:54, 109.09s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [12:13:40<3:05:31, 107.03s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [12:15:26<3:02:49, 106.50s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [12:17:09<2:59:28, 105.58s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [12:18:53<2:56:48, 105.03s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [12:21:55<3:33:48, 128.28s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [12:23:41<3:20:17, 121.38s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 11:11:31,693:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 11:11:36,711:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [12:25:36<3:15:17, 119.57s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [12:27:22<3:06:38, 115.44s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [12:29:19<3:05:33, 115.97s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:31:05<2:59:02, 113.08s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:32:51<2:53:39, 110.85s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:34:40<2:51:01, 110.33s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:36:26<2:47:16, 109.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:38:15<2:45:09, 108.89s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:41:18<3:16:51, 131.24s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:43:04<3:03:26, 123.67s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:44:46<2:51:48, 117.14s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:46:29<2:43:36, 112.84s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:48:14<2:38:15, 110.42s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:50:02<2:35:32, 109.80s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:51:44<2:30:17, 107.35s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:53:29<2:27:34, 106.69s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:55:12<2:24:22, 105.63s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:56:57<2:22:25, 105.51s/it]
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(TaskRunner pid=4121036)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [13:00:19<2:59:13, 134.41s/it]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4121036)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [13:02:08<2:46:59, 126.82s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [13:03:57<2:38:04, 121.59s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [13:05:45<2:30:35, 117.35s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [13:07:31<2:24:29, 114.07s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [13:09:13<2:17:59, 110.40s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [13:11:00<2:14:41, 109.21s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [13:12:48<2:12:26, 108.85s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [13:14:39<2:11:41, 109.75s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [13:16:28<2:09:25, 109.37s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [13:19:41<2:36:54, 134.49s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [13:21:29<2:25:25, 126.46s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [13:23:15<2:16:38, 120.56s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [13:25:01<2:09:35, 116.05s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [13:26:55<2:06:48, 115.29s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [13:28:44<2:02:51, 113.41s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [13:30:33<1:59:46, 112.29s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [13:32:23<1:57:04, 111.50s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:34:15<1:55:15, 111.54s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:36:04<1:52:50, 110.99s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:39:17<2:15:36, 135.60s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:41:07<2:05:35, 127.72s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:42:59<1:59:06, 123.21s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:44:46<1:52:27, 118.38s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:46:35<1:47:49, 115.53s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:48:23<1:43:52, 113.32s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:50:10<1:40:14, 111.37s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:51:59<1:37:44, 110.65s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:53:59<1:38:10, 113.29s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:55:45<1:34:35, 111.29s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 12:43:40,695:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:59:00<1:53:41, 136.43s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [14:00:48<1:44:25, 127.86s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [14:02:34<1:36:59, 121.25s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [14:04:25<1:32:30, 118.09s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [14:06:11<1:27:50, 114.57s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [14:07:57<1:24:03, 112.09s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [14:09:44<1:20:57, 110.41s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [14:11:33<1:18:45, 109.90s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [14:13:22<1:16:50, 109.77s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [14:15:10<1:14:31, 109.07s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [14:18:19<1:28:51, 133.28s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [14:20:08<1:21:55, 126.05s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [14:21:59<1:16:48, 121.27s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [14:23:44<1:11:46, 116.39s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [14:25:30<1:07:56, 113.25s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [14:27:17<1:05:04, 111.55s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 13:15:13,030:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [14:29:09<1:03:15, 111.64s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [14:30:59<1:01:11, 111.25s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [14:32:43<58:03, 108.86s/it]  
[36m(TaskRunner pid=4121036)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [14:34:30<56:04, 108.55s/it]
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(TaskRunner pid=4121036)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:37:55<1:08:37, 137.26s/it]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=4121036)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:39:43<1:02:11, 128.69s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:41:27<56:33, 121.20s/it]  
[36m(TaskRunner pid=4121036)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:43:14<52:35, 116.89s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:45:00<49:11, 113.52s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:46:41<45:50, 110.02s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:48:25<43:11, 107.99s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:50:12<41:22, 107.93s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:51:57<39:13, 106.96s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:53:40<36:57, 105.58s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:56:50<43:41, 131.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:58:35<39:02, 123.31s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [15:00:18<35:10, 117.26s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [15:02:02<32:01, 113.03s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [15:03:44<29:16, 109.78s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [15:05:30<27:11, 108.78s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [15:07:15<25:06, 107.62s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [15:08:55<22:47, 105.20s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [15:10:40<21:01, 105.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [15:12:25<19:18, 105.30s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [15:15:40<22:01, 132.13s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [15:17:21<18:24, 122.74s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [15:19:05<15:37, 117.14s/it]
[36m(TaskRunner pid=4121036)[0m WARNING:2025-11-12 14:06:55,641:Timeout during comparison
[36m(TaskRunner pid=4121036)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [15:20:54<13:22, 114.60s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [15:22:36<11:06, 111.06s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [15:24:18<09:00, 108.10s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [15:26:03<07:09, 107.27s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [15:27:47<05:18, 106.30s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [15:29:36<03:34, 107.00s/it]
[36m(TaskRunner pid=4121036)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:31:27<01:48, 108.44s/it]
[36m(WorkerDict pid=4124593)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=4124593)[0m   warnings.warn(
[36m(TaskRunner pid=4121036)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:35:00<01:57, 117.12s/it]
[36m(WorkerDict pid=4124799)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=4124799)[0m   warnings.warn([32m [repeated 3x across cluster][0m
