The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a_norm_dyn/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a_norm_dyn//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a_norm_dyn//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a_norm_dyn//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a_norm_dyn/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-13 13:03:06,265	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=2605172)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 13:03:26,559:Waiting for register center actor N7Kog1_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2608927)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2608928)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=2608928)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=2608719)[0m [rank0]:[W1213 13:03:44.592426661 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=2608927)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2608719)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608719)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m [rank1]:[W1213 13:03:44.647174071 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608927)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2608719)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2608928)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2608925)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608925)[0m   warnings.warn(
[36m(WorkerDict pid=2608927)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=2608927)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608927)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:   0%|          | 1/480 [02:01<16:07:49, 121.23s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   0%|          | 2/480 [04:01<16:02:16, 120.79s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   1%|          | 3/480 [06:06<16:13:54, 122.50s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   1%|          | 4/480 [08:06<16:04:40, 121.60s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   1%|          | 5/480 [10:07<16:01:13, 121.42s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   1%|â–         | 6/480 [12:09<16:00:48, 121.62s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   1%|â–         | 7/480 [14:13<16:05:04, 122.42s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   2%|â–         | 8/480 [16:16<16:03:25, 122.47s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   2%|â–         | 9/480 [18:17<15:57:27, 121.97s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 13:25:26,850:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:   2%|â–         | 10/480 [21:43<19:20:48, 148.19s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   2%|â–         | 11/480 [23:40<18:02:57, 138.55s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   2%|â–Ž         | 12/480 [25:40<17:15:43, 132.79s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   3%|â–Ž         | 13/480 [27:38<16:39:21, 128.40s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   3%|â–Ž         | 14/480 [29:39<16:18:54, 126.04s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   3%|â–Ž         | 15/480 [31:36<15:56:09, 123.37s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   3%|â–Ž         | 16/480 [33:35<15:43:31, 122.01s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 13:40:42,121:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:   4%|â–Ž         | 17/480 [35:40<15:48:08, 122.87s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   4%|â–         | 18/480 [37:36<15:32:09, 121.06s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   4%|â–         | 19/480 [39:35<15:24:30, 120.33s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   4%|â–         | 20/480 [42:57<18:31:10, 144.94s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 13:50:06,465:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:   4%|â–         | 21/480 [45:03<17:45:12, 139.24s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   5%|â–         | 22/480 [47:03<16:57:16, 133.27s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   5%|â–         | 23/480 [49:01<16:19:52, 128.65s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   5%|â–Œ         | 24/480 [51:02<16:01:17, 126.49s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   5%|â–Œ         | 25/480 [52:56<15:30:10, 122.66s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   5%|â–Œ         | 26/480 [54:54<15:17:54, 121.31s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   6%|â–Œ         | 27/480 [56:55<15:16:06, 121.34s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   6%|â–Œ         | 28/480 [58:50<14:58:55, 119.33s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:50<14:58:45, 119.57s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:59<17:32:16, 140.30s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:48<16:21:02, 131.10s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:34<15:22:00, 123.48s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:39<15:22:25, 123.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:34<15:02:15, 121.38s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:27<14:41:49, 118.90s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:19<14:22:45, 116.59s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   8%|â–Š         | 37/480 [1:17:14<14:18:13, 116.24s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   8%|â–Š         | 38/480 [1:19:14<14:23:43, 117.25s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   8%|â–Š         | 39/480 [1:21:03<14:04:06, 114.85s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   8%|â–Š         | 40/480 [1:24:12<16:46:28, 137.25s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   9%|â–Š         | 41/480 [1:26:00<15:39:54, 128.46s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:55<15:08:02, 124.39s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   9%|â–‰         | 43/480 [1:29:43<14:29:36, 119.40s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   9%|â–‰         | 44/480 [1:31:34<14:08:19, 116.74s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:   9%|â–‰         | 45/480 [1:33:21<13:46:17, 113.97s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  10%|â–‰         | 46/480 [1:35:15<13:44:38, 114.00s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  10%|â–‰         | 47/480 [1:37:10<13:45:05, 114.33s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:39:06<13:45:19, 114.63s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:41:01<13:45:45, 114.96s/it]
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608719)[0m   warnings.warn(
[36m(TaskRunner pid=2605172)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:44:25<16:54:39, 141.58s/it]
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:46:15<15:43:48, 132.00s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:48:07<14:59:22, 126.08s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:49:55<14:19:23, 120.76s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:51:46<13:55:13, 117.64s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:53:32<13:30:09, 114.37s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:55:21<13:17:08, 112.80s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:57:14<13:13:35, 112.57s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:59:01<13:01:23, 111.10s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:00:50<12:54:30, 110.38s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:03:46<15:10:34, 130.08s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:05:40<14:34:49, 125.27s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:07:28<13:56:17, 120.04s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:09:15<13:26:57, 116.11s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:11:10<13:24:13, 116.00s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:12:59<13:07:37, 113.87s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:14:57<13:14:23, 115.13s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:16:48<13:02:29, 113.68s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:18:36<12:48:38, 111.94s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:20:23<12:37:31, 110.59s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:23:26<15:04:27, 132.36s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:25:17<14:17:42, 125.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:27:03<13:34:55, 119.84s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:28:49<13:05:38, 115.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:30:36<12:46:15, 113.24s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:32:20<12:25:04, 110.38s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:34:10<12:22:21, 110.25s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:36:01<12:21:15, 110.36s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:37:55<12:27:08, 111.51s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:39:45<12:23:06, 111.19s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:42:41<14:30:49, 130.62s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:44:29<13:42:21, 123.66s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:46:18<13:12:08, 119.42s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:48:08<12:50:48, 116.49s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:49:54<12:28:16, 113.37s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:51:44<12:18:53, 112.24s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:53:33<12:10:48, 111.29s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:55:24<12:09:42, 111.40s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:57:16<12:08:59, 111.58s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:59:01<11:53:41, 109.52s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:01:59<14:04:55, 129.99s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:03:44<13:14:13, 122.50s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 16:10:41,104:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:05:34<12:48:20, 118.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:07:24<12:29:35, 116.22s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 16:14:23,493:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:09:17<12:20:59, 115.18s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:11:04<12:03:06, 112.69s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:12:55<11:58:06, 112.20s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:14:36<11:35:01, 108.88s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:16:13<11:10:37, 105.33s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:18:08<11:26:44, 108.15s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 16:26:40,774:Timeout during comparison
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608719)[0m   warnings.warn(
[36m(WorkerDict pid=2608719)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2608719)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=2605172)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:21:29<14:20:57, 135.94s/it]
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:23:12<13:16:59, 126.17s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:25:03<12:47:18, 121.80s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:26:48<12:13:19, 116.71s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:28:30<11:43:00, 112.18s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:30:18<11:33:28, 110.96s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:31:58<11:11:58, 107.80s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:33:45<11:08:13, 107.49s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:35:28<10:58:01, 106.13s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:37:28<11:21:27, 110.21s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:40:28<13:28:37, 131.13s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:42:16<12:44:05, 124.24s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:43:54<11:53:32, 116.34s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:45:41<11:35:22, 113.68s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:47:31<11:25:03, 112.31s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:49:10<10:58:57, 108.32s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 16:56:05,485:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 16:56:10,501:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:51:01<11:02:06, 109.14s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:52:46<10:53:08, 107.96s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:54:33<10:50:06, 107.75s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:56:18<10:42:19, 106.76s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:59:18<12:53:08, 128.86s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:01:01<12:04:26, 121.08s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:02:50<11:40:15, 117.36s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:04:35<11:17:28, 113.86s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:06:35<11:26:43, 115.74s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:08:21<11:06:22, 112.63s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:10:07<10:53:36, 110.78s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:11:51<10:39:43, 108.73s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:13:37<10:33:08, 107.92s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:15:22<10:26:16, 107.05s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:18:18<12:25:21, 127.78s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:20:04<11:44:56, 121.19s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:21:47<11:11:10, 115.72s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 17:28:47,828:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:23:40<11:04:02, 114.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:25:24<10:44:18, 111.73s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:27:11<10:34:19, 110.32s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:28:56<10:22:17, 108.54s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:30:40<10:12:34, 107.16s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:32:27<10:11:21, 107.26s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:34:14<10:08:37, 107.09s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:37:06<11:57:30, 126.62s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:38:49<11:14:28, 119.38s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:40:27<10:37:46, 113.21s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:42:11<10:19:03, 110.22s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:43:51<10:01:28, 107.41s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:45:41<10:02:35, 107.93s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:47:16<9:40:20, 104.25s/it] 
[36m(TaskRunner pid=2605172)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:48:55<9:28:45, 102.48s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:50:36<9:25:28, 102.19s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:52:27<9:38:28, 104.86s/it]
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608719)[0m   warnings.warn(
[36m(TaskRunner pid=2605172)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:55:39<12:00:49, 131.06s/it]
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:57:25<11:16:51, 123.44s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:59:12<10:48:05, 118.55s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [5:00:54<10:18:38, 113.51s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [5:02:38<10:01:36, 110.73s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:04:21<9:47:03, 108.38s/it] 
[36m(TaskRunner pid=2605172)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:05:57<9:25:29, 104.72s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:07:42<9:23:11, 104.62s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:09:26<9:21:17, 104.59s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:11:13<9:22:28, 105.13s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:14:05<11:08:21, 125.32s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:15:56<10:42:52, 120.92s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:17:43<10:18:45, 116.75s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:19:25<9:53:13, 112.28s/it] 
[36m(TaskRunner pid=2605172)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:21:03<9:29:54, 108.21s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:22:43<9:14:35, 105.64s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:24:33<9:19:08, 106.84s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:26:11<9:04:13, 104.33s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:27:54<9:00:19, 103.91s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:29:33<8:51:26, 102.53s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:32:23<10:33:57, 122.70s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:34:04<9:57:39, 116.05s/it] 
[36m(TaskRunner pid=2605172)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:35:42<9:28:43, 110.79s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:37:22<9:09:44, 107.44s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:39:00<8:53:23, 104.59s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 18:45:57,032:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:40:50<9:01:11, 106.46s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:42:32<8:52:04, 105.01s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:44:12<8:42:32, 103.47s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:45:55<8:40:51, 103.48s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:47:39<8:39:05, 103.47s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:50:34<10:24:30, 124.90s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 18:57:31,819:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:52:25<10:01:25, 120.69s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:54:06<9:30:08, 114.80s/it] 
[36m(TaskRunner pid=2605172)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:55:52<9:15:50, 112.29s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:57:30<8:53:17, 108.10s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:59:23<8:57:36, 109.35s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [6:01:06<8:46:14, 107.40s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 19:08:03,472:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 19:08:08,568:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:02:56<8:49:34, 108.44s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:04:41<8:42:06, 107.28s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:06:27<8:38:10, 106.84s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:09:20<10:12:58, 126.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:11:02<9:34:08, 119.20s/it] 
[36m(TaskRunner pid=2605172)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:12:43<9:06:44, 113.90s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:14:23<8:44:28, 109.65s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:16:04<8:30:49, 107.17s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:17:43<8:16:35, 104.55s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:19:29<8:17:17, 105.06s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 19:26:22,284:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:21:12<8:13:09, 104.56s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:22:57<8:10:43, 104.41s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:24:34<7:58:52, 102.25s/it]
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608719)[0m   warnings.warn(
[36m(TaskRunner pid=2605172)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:27:45<10:01:46, 128.95s/it]
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:29:25<9:19:34, 120.34s/it] 
[36m(TaskRunner pid=2605172)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:31:08<8:52:40, 114.97s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:32:48<8:30:21, 110.55s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:34:30<8:17:12, 108.09s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:36:11<8:05:11, 105.86s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:37:55<8:00:42, 105.26s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:39:46<8:07:04, 107.05s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:41:26<7:55:03, 104.79s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:43:06<7:47:30, 103.51s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:46:05<9:27:31, 126.12s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:47:45<8:50:04, 118.23s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:49:26<8:25:34, 113.19s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:51:12<8:13:25, 110.88s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:52:53<7:58:53, 108.02s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:54:31<7:43:11, 104.88s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:56:10<7:33:47, 103.14s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:57:53<7:31:52, 103.09s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:59:31<7:24:04, 101.70s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [7:01:19<7:30:02, 103.46s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:04:10<8:56:33, 123.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:05:49<8:23:03, 116.54s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:07:34<8:05:38, 112.94s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:09:10<7:41:28, 107.74s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:10:52<7:32:32, 106.06s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:12:34<7:25:56, 104.93s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:14:12<7:15:01, 102.76s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:16:00<7:20:17, 104.42s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:17:42<7:15:30, 103.69s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:19:26<7:14:30, 103.86s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:22:18<8:37:16, 124.14s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:23:57<8:03:58, 116.62s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:25:39<7:43:42, 112.19s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:27:20<7:28:11, 108.87s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:28:57<7:11:56, 105.35s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:30:37<7:03:55, 103.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:32:16<6:56:03, 102.31s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:33:54<6:49:06, 101.02s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:35:43<6:57:21, 103.48s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:37:22<6:49:52, 102.04s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:40:18<8:16:44, 124.18s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:42:06<7:55:03, 119.26s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:43:48<7:32:48, 114.15s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:45:30<7:16:57, 110.62s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:47:11<7:03:15, 107.61s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:48:54<6:56:40, 106.39s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:50:36<6:49:35, 105.02s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:52:20<6:46:32, 104.69s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:54:04<6:43:41, 104.40s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:55:46<6:39:59, 103.90s/it]
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608719)[0m   warnings.warn(
[36m(TaskRunner pid=2605172)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:58:58<8:19:34, 130.33s/it]
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [8:00:37<7:41:34, 120.94s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:02:16<7:14:31, 114.35s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:03:56<6:56:19, 110.04s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:05:39<6:45:37, 107.69s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:07:14<6:30:21, 104.10s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:08:57<6:26:30, 103.53s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:10:34<6:18:07, 101.74s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:12:18<6:18:53, 102.40s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:13:57<6:13:05, 101.29s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:16:46<7:26:00, 121.64s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:18:27<7:01:22, 115.44s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:20:14<6:50:22, 112.95s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:21:55<6:35:45, 109.43s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:23:40<6:29:10, 108.11s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:25:18<6:15:54, 104.90s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:27:01<6:12:29, 104.44s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:28:39<6:04:19, 102.63s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:30:13<5:53:22, 100.01s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:31:53<5:51:10, 99.86s/it] 
[36m(TaskRunner pid=2605172)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:34:42<7:02:45, 120.79s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:36:23<6:39:21, 114.65s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:37:57<6:16:40, 108.66s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:39:36<6:04:03, 105.53s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:41:22<6:02:45, 105.66s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:42:57<5:50:08, 102.48s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:44:38<5:47:10, 102.11s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:46:19<5:44:35, 101.85s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:47:58<5:39:48, 100.93s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:49:37<5:36:12, 100.36s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:52:27<6:43:53, 121.17s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:54:00<6:13:47, 112.70s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:55:36<5:55:46, 107.81s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:57:17<5:47:06, 105.72s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:59:02<5:44:25, 105.44s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:00:42<5:37:37, 103.88s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:02:23<5:33:23, 103.11s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:04:06<5:31:20, 103.01s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:05:48<5:28:34, 102.68s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:07:25<5:21:57, 101.14s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:10:18<6:27:50, 122.48s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:11:55<6:02:13, 114.99s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:13:33<5:44:12, 109.85s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:15:10<5:30:17, 105.97s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:16:52<5:24:57, 104.83s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:18:33<5:19:21, 103.58s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:20:15<5:15:59, 103.04s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:21:56<5:12:38, 102.50s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:23:37<5:09:20, 101.98s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:25:19<5:07:33, 101.95s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 22:32:15,088:Timeout during comparison
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608719)[0m   warnings.warn(
[36m(TaskRunner pid=2605172)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:28:31<6:27:30, 129.17s/it]
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:30:12<5:59:31, 120.51s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:31:51<5:38:20, 114.05s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:33:35<5:28:12, 111.26s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:35:16<5:16:54, 108.04s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:36:52<5:04:42, 104.47s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:38:34<5:00:26, 103.60s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:40:12<4:54:39, 102.19s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:41:52<4:50:46, 101.43s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:43:39<4:53:29, 102.98s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:46:30<5:49:29, 123.35s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:48:09<5:27:07, 116.14s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:49:51<5:13:05, 111.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:51:34<5:04:00, 109.22s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:53:23<5:01:54, 109.13s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:55:10<4:58:22, 108.50s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:57:03<5:00:07, 109.80s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 23:03:56,558:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:58:45<4:51:54, 107.45s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [10:00:26<4:45:09, 105.61s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:02:11<4:42:41, 105.35s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:05:04<5:35:07, 125.67s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:06:47<5:15:20, 119.00s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 23:13:51,352:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 23:13:56,390:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 23:14:01,431:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:08:54<5:19:23, 121.29s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:10:32<4:59:25, 114.43s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:12:27<4:57:57, 114.60s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:14:12<4:48:40, 111.75s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:15:56<4:40:36, 109.33s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:17:42<4:35:58, 108.23s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:19:26<4:31:33, 107.20s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:21:07<4:25:00, 105.30s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:24:03<5:16:13, 126.49s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:25:39<4:51:37, 117.43s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-13 23:32:32,866:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:27:22<4:38:46, 113.01s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:29:14<4:35:45, 112.55s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:30:52<4:23:15, 108.19s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:32:34<4:16:58, 106.33s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:34:15<4:11:16, 104.69s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:36:01<4:10:45, 105.21s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:37:46<4:09:01, 105.22s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:39:25<4:03:01, 103.41s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:42:19<4:50:12, 124.37s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:44:04<4:34:59, 118.70s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:45:46<4:21:17, 113.61s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:47:26<4:09:57, 109.47s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:49:02<3:58:51, 105.38s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:50:44<3:55:20, 104.59s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:52:28<3:52:53, 104.28s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:54:10<3:49:52, 103.70s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:55:52<3:47:02, 103.20s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:57:28<3:40:27, 100.98s/it]
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608719)[0m   warnings.warn(
[36m(TaskRunner pid=2605172)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [11:00:42<4:38:56, 128.75s/it]
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:02:23<4:18:59, 120.46s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:04:11<4:08:54, 116.68s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:05:55<3:59:13, 113.02s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:07:46<3:56:05, 112.43s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:09:30<3:49:00, 109.93s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:11:10<3:40:39, 106.77s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:12:53<3:36:51, 105.79s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:14:33<3:31:21, 103.94s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:16:23<3:33:30, 105.87s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:19:15<4:11:17, 125.65s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:21:03<3:58:58, 120.49s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:22:48<3:47:37, 115.74s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:24:33<3:39:24, 112.52s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:26:12<3:29:57, 108.60s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:27:50<3:21:56, 105.36s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:29:26<3:14:46, 102.51s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:31:01<3:08:32, 100.11s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:32:43<3:08:00, 100.72s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:34:22<3:05:47, 100.43s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:37:15<3:43:36, 121.97s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:38:55<3:29:58, 115.58s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:40:36<3:20:13, 111.24s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:42:23<3:15:48, 109.80s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:43:57<3:05:33, 105.03s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:45:38<3:01:58, 103.99s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:47:20<2:59:05, 103.32s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:48:59<2:54:55, 101.90s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:50:38<2:52:00, 101.18s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:52:18<2:49:23, 100.63s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:55:07<3:21:58, 121.18s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:56:50<3:11:11, 115.87s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:58:33<3:03:03, 112.08s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [12:00:17<2:57:15, 109.64s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-14 01:07:15,241:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [12:02:09<2:56:33, 110.35s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:03:50<2:49:52, 107.29s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:05:31<2:45:10, 105.43s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:07:15<2:43:06, 105.23s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:08:54<2:38:17, 103.24s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:10:38<2:36:53, 103.45s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:13:30<3:06:15, 124.17s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:15:12<2:54:18, 117.51s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:16:51<2:44:11, 111.94s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:18:27<2:35:20, 107.13s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:20:08<2:30:49, 105.23s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:21:55<2:29:53, 105.81s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:23:32<2:24:17, 103.06s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:25:14<2:22:09, 102.77s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:26:59<2:21:24, 103.47s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:28:40<2:18:48, 102.83s/it]
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608719)[0m   warnings.warn(
[36m(TaskRunner pid=2605172)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:31:50<2:51:56, 128.96s/it]
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:33:36<2:40:43, 122.07s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:35:23<2:32:49, 117.56s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:37:10<2:26:44, 114.34s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:38:51<2:19:37, 110.23s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:40:31<2:13:57, 107.16s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-14 01:47:26,851:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:42:16<2:11:25, 106.56s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-14 01:49:15,659:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:44:06<2:11:00, 107.68s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:45:49<2:07:18, 106.09s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:47:31<2:04:07, 104.89s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:50:25<2:26:34, 125.64s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:52:05<2:15:44, 118.04s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:53:43<2:07:02, 112.09s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:55:25<2:01:42, 108.99s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:57:09<1:58:07, 107.38s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:58:50<1:54:15, 105.47s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [13:00:29<1:50:26, 103.53s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [13:02:16<1:49:58, 104.75s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:03:57<1:46:52, 103.43s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:05:39<1:44:43, 103.01s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:08:34<2:04:45, 124.77s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:10:11<1:54:34, 116.51s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:12:05<1:51:37, 115.47s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:13:44<1:45:10, 110.71s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:15:27<1:41:08, 108.37s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:17:10<1:37:58, 106.89s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:18:54<1:35:11, 105.78s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:20:33<1:31:48, 103.94s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:22:18<1:30:09, 104.03s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:23:56<1:26:58, 102.32s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:26:46<1:42:11, 122.62s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:28:26<1:34:41, 115.95s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:30:05<1:28:44, 110.94s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:31:56<1:26:53, 110.93s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:33:35<1:22:09, 107.17s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:35:15<1:18:46, 105.02s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:36:57<1:16:22, 104.15s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:38:41<1:14:33, 104.02s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:40:22<1:12:14, 103.20s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:42:10<1:11:25, 104.52s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:45:03<1:23:26, 125.16s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:46:44<1:16:39, 117.94s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:48:28<1:12:00, 113.71s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:50:10<1:08:00, 110.29s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:51:52<1:04:37, 107.71s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:53:33<1:01:45, 105.86s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-14 03:00:28,161:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:55:18<59:45, 105.46s/it]  
[36m(TaskRunner pid=2605172)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:56:57<57:02, 103.70s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:58:38<54:50, 102.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [14:00:21<53:08, 102.85s/it]
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608719)[0m   warnings.warn(
[36m(TaskRunner pid=2605172)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:03:30<1:04:18, 128.63s/it]
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2605172)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:05:13<58:28, 120.99s/it]  
[36m(TaskRunner pid=2605172)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:06:51<53:11, 113.98s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:08:36<50:06, 111.35s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:10:18<47:00, 108.48s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:11:55<43:49, 105.19s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:13:39<41:55, 104.82s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:15:27<40:31, 105.70s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:17:14<38:55, 106.16s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:18:58<36:57, 105.60s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:21:54<42:12, 126.63s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:23:44<38:30, 121.61s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:25:27<34:46, 115.93s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:27:08<31:37, 111.59s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:28:52<29:10, 109.38s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:30:34<26:47, 107.17s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:32:22<25:01, 107.22s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:34:05<22:57, 105.99s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:35:48<21:00, 105.04s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:37:30<19:07, 104.34s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:40:37<21:31, 129.11s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:42:18<18:05, 120.66s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:44:04<15:28, 116.06s/it]
[36m(TaskRunner pid=2605172)[0m WARNING:2025-12-14 03:51:01,962:Timeout during comparison
[36m(TaskRunner pid=2605172)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:45:55<13:22, 114.59s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:47:37<11:05, 110.89s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:49:17<08:57, 107.56s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:51:00<07:04, 106.23s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:52:39<05:12, 104.14s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:54:27<03:30, 105.38s/it]
[36m(TaskRunner pid=2605172)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:56:16<01:46, 106.41s/it]
[36m(WorkerDict pid=2608719)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2608719)[0m   warnings.warn(
[36m(TaskRunner pid=2605172)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:59:32<01:52, 112.68s/it]
[36m(WorkerDict pid=2608925)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2608925)[0m   warnings.warn([32m [repeated 3x across cluster][0m
+ ISODES
./scripts/train_1_5b.sh: line 73: ISODES: command not found
