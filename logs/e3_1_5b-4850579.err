
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_0.00005_2sub_half/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_0.00005_2sub_half//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.00005_2sub_half//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.00005_2sub_half//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_0.00005_2sub_half/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-16 22:22:16,764	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=2244325)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-16 22:22:37,008:Waiting for register center actor 53VFO2_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2248074)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2248074)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=2248074)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=2248074)[0m [rank1]:[W1116 22:22:54.904289219 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=2247898)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2247898)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2247898)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2247898)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m [rank3]:[W1116 22:22:54.137810434 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248074)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2248075)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2248077)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(WorkerDict pid=2247898)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:   0%|          | 1/480 [01:59<15:52:17, 119.29s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   0%|          | 2/480 [03:59<15:55:19, 119.91s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   1%|          | 3/480 [06:04<16:12:23, 122.31s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   1%|          | 4/480 [08:02<15:55:14, 120.41s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   1%|          | 5/480 [10:01<15:51:00, 120.13s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   1%|â–         | 6/480 [12:04<15:55:01, 120.89s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   1%|â–         | 7/480 [14:06<15:56:45, 121.37s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   2%|â–         | 8/480 [16:07<15:54:37, 121.35s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   2%|â–         | 9/480 [18:07<15:47:22, 120.68s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-16 22:44:31,604:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:   2%|â–         | 10/480 [21:35<19:18:05, 147.84s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   2%|â–         | 11/480 [23:32<18:00:51, 138.28s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   2%|â–Ž         | 12/480 [25:30<17:10:30, 132.12s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   3%|â–Ž         | 13/480 [27:28<16:35:00, 127.84s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   3%|â–Ž         | 14/480 [29:29<16:16:33, 125.74s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   3%|â–Ž         | 15/480 [31:24<15:50:05, 122.59s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   3%|â–Ž         | 16/480 [33:24<15:40:37, 121.63s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   4%|â–Ž         | 17/480 [35:21<15:28:19, 120.30s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   4%|â–         | 18/480 [37:17<15:18:06, 119.23s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   4%|â–         | 19/480 [39:17<15:17:09, 119.37s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   4%|â–         | 20/480 [42:38<18:23:33, 143.94s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   4%|â–         | 21/480 [44:38<17:26:21, 136.78s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   5%|â–         | 22/480 [46:38<16:45:01, 131.66s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   5%|â–         | 23/480 [48:36<16:10:56, 127.48s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   5%|â–Œ         | 24/480 [50:31<15:40:32, 123.75s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   5%|â–Œ         | 25/480 [52:26<15:18:34, 121.13s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   5%|â–Œ         | 26/480 [54:23<15:06:09, 119.76s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   6%|â–Œ         | 27/480 [56:24<15:08:54, 120.38s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   6%|â–Œ         | 28/480 [58:16<14:47:45, 117.84s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:14<14:44:38, 117.69s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:23<17:24:44, 139.30s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:14<16:18:16, 130.73s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:01<15:22:39, 123.57s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:56<15:01:52, 121.06s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:46<14:34:59, 117.71s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:36<14:16:33, 115.49s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:26<14:02:20, 113.83s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:17<13:54:07, 112.97s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:13<13:57:45, 113.72s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   8%|â–Š         | 39/480 [1:19:57<13:35:51, 111.00s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:06<16:25:12, 134.35s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   9%|â–Š         | 41/480 [1:24:54<15:23:52, 126.27s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   9%|â–‰         | 42/480 [1:26:49<14:58:47, 123.12s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:37<14:22:22, 118.40s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:28<14:04:47, 116.26s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:12<13:37:07, 112.71s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:02<13:28:06, 111.72s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:52<13:23:33, 111.35s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:43<13:20:32, 111.19s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:39<13:27:47, 112.45s/it]
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(TaskRunner pid=2244325)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:42:58<16:32:54, 138.55s/it]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:46<15:25:35, 129.45s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:34<14:37:32, 123.02s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:16<13:49:59, 116.63s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:05<13:31:12, 114.25s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:51:48<13:05:13, 110.86s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:35<12:55:48, 109.78s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:24<12:52:19, 109.55s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:07<12:37:30, 107.70s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:58:49<12:23:14, 105.93s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:01:43<14:44:04, 126.30s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:03:29<13:58:37, 120.09s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:12<13:21:21, 115.03s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:06:55<12:55:12, 111.54s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:08:46<12:52:03, 111.36s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:10:26<12:26:32, 107.93s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:12:13<12:23:44, 107.79s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:13:59<12:17:26, 107.14s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:15:42<12:07:46, 105.99s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:17:30<12:08:45, 106.39s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:20:30<14:38:54, 128.62s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:22:14<13:46:15, 121.21s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:23:57<13:06:39, 115.68s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:25:39<12:36:53, 111.58s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:27:25<12:24:45, 110.06s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:29:11<12:13:00, 108.59s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:30:57<12:07:40, 108.07s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:32:45<12:04:05, 107.80s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:34:29<11:55:32, 106.80s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:36:17<11:55:25, 107.05s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 01:02:28,863:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 01:02:34,501:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:39:24<14:33:40, 131.05s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:41:06<13:34:14, 122.44s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:42:50<12:55:31, 116.91s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:44:35<12:29:22, 113.26s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:46:19<12:09:57, 110.60s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:48:04<11:55:47, 108.73s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:49:49<11:48:16, 107.86s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:51:35<11:41:51, 107.15s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:53:20<11:35:43, 106.49s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:55:00<11:21:30, 104.58s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:57:58<13:42:44, 126.58s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [2:59:36<12:46:07, 118.17s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 01:25:48,217:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 01:25:55,512:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:01:29<12:32:23, 116.35s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:03:11<12:04:19, 112.30s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 01:29:27,306:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:05:03<12:01:31, 112.15s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:06:43<11:35:03, 108.32s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:08:29<11:29:56, 107.80s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:10:10<11:15:22, 105.80s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:11:48<10:58:22, 103.41s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:13:37<11:07:33, 105.13s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 01:39:48,795:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 01:39:56,327:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 01:41:34,512:Timeout during comparison
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(WorkerDict pid=2247898)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2247898)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=2244325)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:17:06<14:22:07, 136.12s/it]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:18:42<13:04:03, 124.12s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 01:44:52,946:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:20:34<12:38:52, 120.46s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:22:11<11:53:13, 113.51s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:23:47<11:19:08, 108.37s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:25:35<11:14:48, 107.97s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:27:14<10:56:44, 105.36s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 01:53:31,063:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:29:05<11:05:54, 107.12s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:30:43<10:47:28, 104.43s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:32:35<10:58:58, 106.57s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:35:31<13:06:36, 127.56s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:37:15<12:20:21, 120.38s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:38:49<11:30:12, 112.53s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:40:30<11:06:28, 108.96s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:42:12<10:52:03, 106.89s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:43:44<10:23:44, 102.53s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:45:23<10:15:24, 101.44s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:47:05<10:14:01, 101.49s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:48:44<10:08:45, 100.90s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:50:25<10:07:15, 100.93s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:53:24<12:25:44, 124.29s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:54:57<11:27:47, 114.95s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:56:42<11:08:18, 112.01s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 02:22:53,175:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:58:26<10:52:13, 109.62s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:00:13<10:44:21, 108.60s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:01:50<10:22:35, 105.23s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:03:28<10:09:03, 103.23s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:05:05<9:55:47, 101.27s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:06:44<9:49:17, 100.45s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:08:21<9:42:06, 99.51s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:11:11<11:43:32, 120.61s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:12:51<11:06:05, 114.51s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:14:25<10:27:38, 108.21s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:16:04<10:09:42, 105.43s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:17:42<9:55:22, 103.24s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:19:22<9:49:11, 102.47s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:21:02<9:42:52, 101.66s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:22:40<9:35:03, 100.59s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 02:48:52,581:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:24:26<9:42:14, 102.15s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:26:04<9:34:00, 101.00s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:28:53<11:27:27, 121.32s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:30:31<10:46:21, 114.40s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:32:06<10:10:45, 108.42s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:33:45<9:53:24, 105.65s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:35:21<9:35:12, 102.72s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 03:01:31,659:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:37:04<9:34:02, 102.81s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:38:35<9:12:50, 99.31s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:40:09<9:01:26, 97.56s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:41:45<8:57:52, 97.21s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:43:29<9:07:39, 99.27s/it]
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(TaskRunner pid=2244325)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:46:34<11:26:37, 124.84s/it]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:48:11<10:39:38, 116.65s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:49:49<10:06:55, 111.02s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:51:25<9:40:36, 106.53s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:53:04<9:25:56, 104.16s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:54:41<9:12:49, 102.06s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:56:13<8:55:41, 99.20s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [4:57:47<8:45:42, 97.66s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [4:59:28<8:49:10, 98.60s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 03:25:38,448:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:01:12<8:55:58, 100.18s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:04:00<10:41:58, 120.37s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:05:43<10:13:21, 115.37s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:07:23<9:47:11, 110.79s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:09:00<9:23:41, 106.69s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:10:34<9:01:38, 102.84s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:12:08<8:44:44, 99.95s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:13:45<8:38:56, 99.16s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:15:19<8:29:11, 97.61s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:16:59<8:31:38, 98.39s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:18:33<8:22:50, 97.01s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:21:21<10:11:34, 118.37s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:22:59<9:37:22, 112.11s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:24:34<9:10:30, 107.24s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:26:12<8:54:03, 104.37s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:27:46<8:36:39, 101.31s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:29:25<8:30:49, 100.49s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:31:03<8:25:36, 99.79s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:32:41<8:21:37, 99.33s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:34:20<8:18:28, 99.03s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:35:59<8:17:04, 99.08s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:38:54<10:09:48, 121.96s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 04:05:04,450:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 04:05:10,297:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:40:44<9:50:23, 118.47s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:42:23<9:18:41, 112.49s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:44:03<8:57:46, 108.64s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:45:36<8:33:12, 104.03s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:47:20<8:30:49, 103.90s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:48:55<8:17:25, 101.51s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:50:34<8:11:38, 100.68s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:52:16<8:10:54, 100.87s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:53:55<8:07:42, 100.56s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [5:56:47<9:49:40, 122.00s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [5:58:24<9:10:58, 114.39s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:00:00<8:41:49, 108.71s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:01:38<8:24:46, 105.53s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:03:17<8:14:25, 103.73s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:04:53<8:01:31, 101.37s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:06:35<8:01:22, 101.70s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:08:12<7:52:17, 100.13s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:09:53<7:52:25, 100.52s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:11:31<7:46:14, 99.55s/it] 
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(TaskRunner pid=2244325)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:14:42<9:53:22, 127.15s/it]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:16:20<9:10:46, 118.45s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:18:01<8:43:38, 113.02s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:19:39<8:21:55, 108.72s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:21:16<8:03:33, 105.12s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:22:56<7:55:16, 103.70s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:24:38<7:50:39, 103.07s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:26:22<7:50:17, 103.36s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:27:55<7:34:34, 100.27s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:29:33<7:29:26, 99.51s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:32:30<9:12:30, 122.78s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:34:08<8:36:37, 115.23s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:35:49<8:15:41, 110.98s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:37:29<7:59:26, 107.74s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:39:12<7:51:16, 106.30s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:40:49<7:37:17, 103.54s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:42:26<7:27:11, 101.63s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:44:08<7:25:35, 101.65s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:45:44<7:16:22, 99.93s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:47:30<7:22:50, 101.80s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:50:22<8:53:01, 123.01s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:52:02<8:20:11, 115.87s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:53:45<8:01:45, 112.04s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:55:18<7:36:02, 106.47s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [6:56:59<7:27:25, 104.87s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [6:58:38<7:17:49, 103.02s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:00:15<7:08:05, 101.12s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:02:03<7:15:32, 103.29s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:03:42<7:08:25, 102.00s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:05:24<7:06:56, 102.06s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:08:18<8:34:57, 123.59s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:09:54<7:59:05, 115.44s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:11:32<7:35:20, 110.16s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:13:13<7:21:54, 107.35s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:14:48<7:05:11, 103.70s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:16:26<6:56:21, 101.96s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:18:04<6:49:24, 100.67s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:19:39<6:41:19, 99.09s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:21:21<6:43:22, 100.01s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:22:58<6:37:46, 99.03s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:25:52<8:05:37, 121.40s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 05:52:02,350:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:27:45<7:53:38, 118.91s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:29:22<7:25:34, 112.33s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:31:01<7:08:00, 108.36s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:32:38<6:52:19, 104.83s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:34:17<6:44:24, 103.25s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:35:55<6:36:38, 101.70s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:37:33<6:30:48, 100.64s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:39:13<6:27:26, 100.20s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:40:53<6:25:45, 100.20s/it]
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(TaskRunner pid=2244325)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:44:01<8:05:20, 126.61s/it]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:45:35<7:26:05, 116.88s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:47:13<7:02:26, 111.17s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:48:49<6:43:39, 106.69s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:50:26<6:31:03, 103.82s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:51:59<6:17:19, 100.62s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:53:38<6:12:56, 99.89s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:55:13<6:06:34, 98.63s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:56:53<6:06:16, 98.99s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [7:58:26<5:58:09, 97.24s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:01:18<7:18:05, 119.48s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:02:57<6:53:42, 113.35s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:04:38<6:38:11, 109.60s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:06:19<6:27:58, 107.28s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:08:04<6:22:52, 106.35s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:09:40<6:09:54, 103.23s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:11:17<6:02:12, 101.55s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:12:55<5:56:03, 100.30s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:14:28<5:47:09, 98.25s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:16:05<5:44:35, 97.99s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 06:42:14,985:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:19:07<7:10:26, 122.99s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:20:49<6:46:18, 116.64s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:22:24<6:22:13, 110.26s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:24:05<6:10:29, 107.39s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:25:46<6:02:40, 105.64s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:27:23<5:51:58, 103.02s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:29:06<5:49:44, 102.87s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:30:51<5:50:06, 103.48s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:32:31<5:45:37, 102.66s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:34:14<5:43:41, 102.59s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:37:10<6:55:38, 124.69s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:38:46<6:24:31, 115.94s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:40:27<6:08:06, 111.55s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:42:10<5:58:01, 109.04s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:43:57<5:54:39, 108.57s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:45:41<5:47:52, 107.04s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:47:21<5:39:46, 105.09s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 07:13:32,778:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:49:08<5:39:35, 105.57s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:50:51<5:35:32, 104.86s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:52:33<5:30:19, 103.77s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:55:40<6:48:27, 128.99s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:57:23<6:21:12, 121.02s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [8:59:07<6:03:15, 115.93s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:00:47<5:46:14, 111.10s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:02:29<5:36:20, 108.50s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:04:16<5:33:10, 108.06s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:06:05<5:31:45, 108.18s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:07:45<5:23:12, 105.97s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:09:33<5:23:10, 106.54s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:11:17<5:18:44, 105.66s/it]
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(TaskRunner pid=2244325)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:14:32<6:37:00, 132.34s/it]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:16:16<6:10:10, 124.08s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:18:00<5:50:11, 118.04s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:19:47<5:38:07, 114.62s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:21:31<5:27:12, 111.55s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:23:12<5:15:53, 108.31s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:24:55<5:09:36, 106.76s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:26:36<5:02:52, 105.05s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:28:21<5:00:31, 104.83s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:30:08<5:01:02, 105.63s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 07:57:56,640:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:33:11<6:05:11, 128.89s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:34:56<5:42:27, 121.58s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:36:39<5:24:41, 115.96s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:38:22<5:12:34, 112.30s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:40:08<5:04:51, 110.19s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:41:53<4:58:44, 108.63s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:43:42<4:57:33, 108.86s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 08:09:52,917:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:45:26<4:51:30, 107.31s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:47:09<4:46:47, 106.22s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 08:13:18,671:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 08:13:23,722:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 08:13:29,687:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 08:13:36,882:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:49:12<4:58:26, 111.22s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:52:12<5:51:44, 131.90s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:53:58<5:28:23, 123.92s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 08:20:06,191:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 08:20:13,022:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:55:48<5:15:08, 119.68s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:57:28<4:58:15, 113.99s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:59:16<4:51:23, 112.07s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:01:00<4:43:27, 109.73s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:02:45<4:38:15, 108.41s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:04:32<4:35:10, 107.91s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:06:16<4:30:38, 106.83s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:07:56<4:23:19, 104.63s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:10:53<5:15:41, 126.28s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:12:31<4:52:37, 117.83s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:14:08<4:35:15, 111.59s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:15:53<4:28:37, 109.64s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:17:31<4:18:27, 106.22s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:19:10<4:11:23, 104.02s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:20:51<4:07:29, 103.12s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:22:35<4:06:16, 103.33s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:24:16<4:03:10, 102.75s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:25:55<3:58:36, 101.53s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:28:52<4:49:39, 124.14s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:30:34<4:32:11, 117.49s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:32:18<4:20:45, 113.37s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:33:59<4:10:49, 109.85s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:35:36<3:59:45, 105.78s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 09:01:48,057:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:37:23<3:59:00, 106.23s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:39:03<3:53:01, 104.34s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:40:44<3:48:57, 103.29s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 09:06:55,810:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:42:33<3:50:54, 104.96s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:44:11<3:44:47, 102.96s/it]
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(TaskRunner pid=2244325)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:47:21<4:39:36, 129.05s/it]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:49:01<4:18:49, 120.38s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:50:44<4:05:48, 115.23s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 09:16:53,101:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:52:31<3:58:33, 112.70s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:54:15<3:50:57, 109.98s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:55:55<3:42:54, 107.00s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:57:34<3:36:27, 104.73s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:59:14<3:31:38, 103.24s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:00:50<3:25:50, 101.23s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:02:37<3:27:19, 102.80s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:05:28<4:06:21, 123.18s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:07:09<3:51:07, 116.53s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:08:49<3:39:39, 111.69s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:10:26<3:28:58, 107.17s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:12:02<3:20:49, 103.87s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:13:38<3:14:52, 101.67s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:15:13<3:09:20, 99.65s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:16:48<3:05:01, 98.25s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:18:27<3:03:31, 98.32s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:20:03<3:00:35, 97.62s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 09:47:52,566:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:23:06<3:45:57, 123.25s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:24:43<3:30:01, 115.61s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:26:24<3:20:06, 111.17s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:28:06<3:13:05, 108.27s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:29:41<3:04:35, 104.49s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:31:21<3:00:24, 103.09s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:32:59<2:55:58, 101.53s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:34:37<2:52:33, 100.52s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:36:16<2:49:44, 99.84s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:37:52<2:46:26, 98.88s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:40:44<3:21:06, 120.67s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:42:24<3:08:50, 114.45s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:44:05<3:00:25, 110.46s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:45:45<2:53:22, 107.24s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:47:39<2:54:59, 109.37s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:49:17<2:47:50, 106.00s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:50:54<2:41:53, 103.34s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:52:36<2:39:33, 102.94s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 10:18:45,091:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:54:20<2:38:22, 103.29s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:56:01<2:35:24, 102.47s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:58:55<3:06:02, 124.02s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:00:34<2:52:33, 116.34s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:02:11<2:42:28, 110.78s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:03:45<2:33:12, 105.66s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:05:22<2:27:35, 102.98s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:07:06<2:26:15, 103.24s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:08:41<2:21:12, 100.86s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:10:18<2:18:07, 99.84s/it] 
[36m(TaskRunner pid=2244325)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:11:58<2:16:18, 99.74s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:13:34<2:13:19, 98.77s/it]
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(TaskRunner pid=2244325)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:16:44<2:48:04, 126.05s/it]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:18:25<2:36:01, 118.50s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:20:09<2:28:30, 114.24s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:21:50<2:21:22, 110.16s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 10:48:00,710:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:23:34<2:17:07, 108.26s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:25:10<2:10:40, 104.54s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:26:51<2:07:49, 103.64s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 10:53:01,031:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:28:39<2:07:47, 105.03s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:30:22<2:05:10, 104.31s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:32:02<2:02:02, 103.14s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:35:01<2:26:47, 125.83s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:36:40<2:15:30, 117.83s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:38:20<2:07:16, 112.30s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:40:00<2:01:13, 108.56s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:41:43<1:57:43, 107.02s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:43:21<1:52:49, 104.15s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:45:02<1:50:22, 103.47s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:46:48<1:49:19, 104.12s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:48:32<1:47:25, 103.96s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:50:16<1:45:55, 104.18s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:53:20<2:08:06, 128.11s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:55:03<1:58:34, 120.58s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:56:54<1:53:41, 117.61s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:58:37<1:47:36, 113.28s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:00:23<1:43:45, 111.18s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:02:09<1:40:20, 109.47s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:03:51<1:36:29, 107.21s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:05:35<1:33:51, 106.26s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:07:21<1:32:06, 106.28s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:09:04<1:29:32, 105.35s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 11:35:19,076:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:12:07<1:47:13, 128.67s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:13:52<1:39:11, 121.47s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:15:35<1:32:36, 115.76s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:17:26<1:29:45, 114.59s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:19:09<1:25:05, 110.98s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:20:51<1:21:10, 108.23s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:22:35<1:18:31, 107.07s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:24:19<1:16:02, 106.10s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:26:02<1:13:35, 105.12s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:27:48<1:12:05, 105.49s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:30:47<1:24:59, 127.48s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:32:29<1:17:55, 119.90s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:34:14<1:13:07, 115.45s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:35:57<1:08:52, 111.69s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:37:40<1:05:23, 108.98s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:39:24<1:02:41, 107.48s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 12:05:35,443:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:41:10<1:00:39, 107.05s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:42:50<57:48, 105.11s/it]  
[36m(TaskRunner pid=2244325)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:44:29<55:01, 103.18s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:46:15<53:41, 103.93s/it]
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(TaskRunner pid=2244325)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:49:29<1:05:27, 130.92s/it]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2244325)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:51:11<59:11, 122.46s/it]  
[36m(TaskRunner pid=2244325)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:52:52<54:01, 115.78s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:54:38<50:47, 112.87s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:56:22<47:46, 110.26s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:57:59<44:19, 106.36s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:59:43<42:14, 105.58s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:01:33<40:56, 106.79s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:03:17<38:53, 106.07s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:05:00<36:46, 105.09s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:07:59<42:27, 127.40s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:09:45<38:17, 120.90s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:11:27<34:36, 115.34s/it]
[36m(TaskRunner pid=2244325)[0m WARNING:2025-11-17 12:37:39,906:Timeout during comparison
[36m(TaskRunner pid=2244325)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:13:16<32:04, 113.20s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:14:57<29:15, 109.71s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:16:40<26:55, 107.72s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:18:25<24:57, 106.95s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:20:05<22:43, 104.91s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:21:49<20:55, 104.63s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:23:30<18:56, 103.29s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:26:32<21:10, 127.00s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:28:11<17:47, 118.62s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:29:52<15:07, 113.45s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:31:32<12:45, 109.42s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:33:13<10:40, 106.72s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:34:50<08:39, 103.86s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:36:31<06:52, 103.06s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:38:10<05:05, 101.85s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:39:58<03:27, 103.50s/it]
[36m(TaskRunner pid=2244325)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:41:46<01:45, 105.07s/it]
[36m(WorkerDict pid=2247898)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2247898)[0m   warnings.warn(
[36m(TaskRunner pid=2244325)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:44:59<01:50, 110.86s/it]
[36m(WorkerDict pid=2248077)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2248077)[0m   warnings.warn([32m [repeated 3x across cluster][0m
