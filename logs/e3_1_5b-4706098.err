
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_div_grpo_0.00008/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_div_grpo_0.00008//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_div_grpo_0.00008//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_div_grpo_0.00008//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_div_grpo_0.00008/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-09 18:29:36,464	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=1589581)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 18:30:17,616:Waiting for register center actor M5qR9r_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=1594371)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1594371)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=1594371)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=1594162)[0m [rank0]:[W1109 18:30:37.099913918 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=1594162)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1594162)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1594370)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594162)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m [rank1]:[W1109 18:30:37.336009362 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594371)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1594371)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1594371)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1594371)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1594373)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(WorkerDict pid=1594162)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:   0%|          | 1/480 [02:04<16:36:04, 124.77s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   0%|          | 2/480 [04:06<16:21:53, 123.25s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   1%|          | 3/480 [06:14<16:33:46, 125.00s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   1%|          | 4/480 [08:12<16:10:08, 122.29s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   1%|          | 5/480 [10:12<16:03:26, 121.70s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   1%|â–         | 6/480 [12:15<16:04:37, 122.10s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   1%|â–         | 7/480 [14:20<16:09:07, 122.93s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   2%|â–         | 8/480 [16:22<16:05:29, 122.73s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   2%|â–         | 9/480 [18:22<15:55:43, 121.75s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   2%|â–         | 10/480 [21:45<19:11:05, 146.95s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   2%|â–         | 11/480 [23:43<17:59:04, 138.05s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   2%|â–Ž         | 12/480 [25:41<17:08:27, 131.85s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   3%|â–Ž         | 13/480 [27:41<16:39:04, 128.36s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   3%|â–Ž         | 14/480 [29:41<16:16:20, 125.71s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   3%|â–Ž         | 15/480 [31:37<15:52:57, 122.96s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   3%|â–Ž         | 16/480 [33:35<15:38:21, 121.34s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   4%|â–Ž         | 17/480 [35:36<15:35:05, 121.18s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   4%|â–         | 18/480 [37:33<15:24:53, 120.11s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   4%|â–         | 19/480 [39:33<15:22:00, 120.00s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   4%|â–         | 20/480 [42:54<18:26:08, 144.28s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   4%|â–         | 21/480 [44:53<17:26:29, 136.80s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   5%|â–         | 22/480 [46:53<16:44:50, 131.64s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   5%|â–         | 23/480 [48:51<16:12:03, 127.62s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   5%|â–Œ         | 24/480 [50:45<15:39:01, 123.56s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   5%|â–Œ         | 25/480 [52:38<15:13:40, 120.49s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   5%|â–Œ         | 26/480 [54:32<14:56:24, 118.47s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   6%|â–Œ         | 27/480 [56:33<15:00:10, 119.23s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   6%|â–Œ         | 28/480 [58:24<14:40:03, 116.82s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:22<14:40:22, 117.12s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:29<17:15:36, 138.08s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:13<15:57:08, 127.90s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:57<15:01:16, 120.71s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:53<14:48:24, 119.25s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:46<14:31:56, 117.30s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:38<14:17:47, 115.66s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:26<13:59:33, 113.45s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:18<13:54:20, 113.00s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:15<14:02:18, 114.34s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:02<13:43:53, 112.09s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:08<16:23:27, 134.11s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   9%|â–Š         | 41/480 [1:24:56<15:25:29, 126.49s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   9%|â–‰         | 42/480 [1:26:47<14:48:01, 121.65s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:34<14:15:07, 117.41s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:23<13:53:44, 114.73s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:04<13:22:53, 110.74s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  10%|â–‰         | 46/480 [1:33:54<13:19:37, 110.55s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:42<13:11:11, 109.63s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:33<13:12:06, 110.02s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:24<13:13:46, 110.50s/it]
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(TaskRunner pid=1589581)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:42:42<16:19:14, 136.64s/it]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:28<15:11:02, 127.42s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:14<14:24:21, 121.17s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:47:57<13:42:59, 115.64s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:49:46<13:25:23, 113.44s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:51:29<13:03:00, 110.54s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:14<12:49:23, 108.88s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:02<12:44:31, 108.44s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:56:45<12:32:32, 107.00s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 20:30:45,699:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:58:32<12:31:01, 107.03s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 20:32:29,844:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:01:32<15:01:50, 128.83s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:03:17<14:10:02, 121.72s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:01<13:31:02, 116.42s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:06:44<13:00:41, 112.33s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:08:33<12:51:25, 111.26s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:10:15<12:30:15, 108.47s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:12:03<12:28:26, 108.47s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:13:46<12:14:36, 106.72s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:15:29<12:04:42, 105.54s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:17:15<12:05:08, 105.86s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:20:15<14:35:11, 128.08s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:21:58<13:40:16, 120.33s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:23:41<13:04:07, 115.31s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:25:25<12:39:40, 111.99s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:27:12<12:27:52, 110.52s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:28:56<12:11:22, 108.35s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:30:45<12:10:24, 108.48s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:32:31<12:04:03, 107.80s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:34:17<11:58:30, 107.24s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:36:04<11:57:25, 107.35s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:38:59<14:11:19, 127.70s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:40:48<13:31:29, 122.03s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:42:34<12:56:59, 117.13s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:44:24<12:40:20, 114.91s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:46:11<12:23:41, 112.68s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:47:57<12:07:41, 110.54s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:49:43<11:58:06, 109.36s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:51:31<11:53:34, 108.94s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 21:25:34,896:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:53:28<12:06:39, 111.22s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:55:11<11:48:50, 108.77s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:58:09<14:02:15, 129.58s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [2:59:52<13:07:41, 121.50s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 21:33:50,975:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:01:39<12:37:27, 117.13s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:03:25<12:14:58, 113.95s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:05:13<12:00:44, 112.03s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 21:39:15,064:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:07:01<11:52:33, 111.05s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:08:50<11:46:23, 110.37s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:10:32<11:27:51, 107.76s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:12:07<11:02:32, 104.06s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:13:58<11:13:28, 106.06s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 21:48:00,419:Timeout during comparison
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(WorkerDict pid=1594162)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1594162)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=1589581)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:17:19<14:12:46, 134.65s/it]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:19:00<13:05:59, 124.43s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:20:43<12:24:14, 118.13s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:22:24<11:49:06, 112.86s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:24:07<11:28:34, 109.88s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:25:52<11:18:24, 108.55s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:27:32<10:59:23, 105.78s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:29:20<11:01:37, 106.43s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:30:59<10:47:11, 104.39s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:32:53<11:02:40, 107.17s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:35:53<13:15:30, 129.00s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:37:38<12:30:12, 121.98s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:39:15<11:41:43, 114.41s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:41:00<11:22:59, 111.66s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:42:48<11:13:24, 110.40s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:44:23<10:44:19, 105.92s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:46:04<10:32:56, 104.33s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:47:48<10:30:15, 104.17s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:49:31<10:27:30, 104.01s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:51:12<10:18:42, 102.83s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:54:13<12:38:18, 126.39s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:55:50<11:43:52, 117.64s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:57:38<11:25:12, 114.84s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 22:31:38,938:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 22:31:43,954:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 22:31:50,091:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:59:36<11:28:34, 115.73s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:01:28<11:19:03, 114.45s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:03:07<10:51:09, 110.05s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:04:50<10:36:08, 107.82s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:06:29<10:17:47, 105.01s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:08:10<10:10:42, 104.10s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:09:53<10:05:52, 103.57s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:12:50<12:13:45, 125.79s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:14:33<11:31:49, 118.94s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:16:11<10:52:21, 112.47s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-09 22:50:12,576:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:17:58<10:41:37, 110.94s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:19:39<10:22:42, 107.98s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:21:22<10:12:04, 106.45s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:23:04<10:02:29, 105.08s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:24:45<9:54:10, 103.94s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:26:28<9:50:45, 103.64s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:28:12<9:49:58, 103.81s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:31:05<11:45:08, 124.44s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:32:46<11:02:35, 117.27s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:34:22<10:25:38, 111.06s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:36:02<10:05:18, 107.77s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:37:39<9:44:25, 104.36s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:39:17<9:32:30, 102.54s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:40:50<9:15:04, 99.71s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:42:25<9:06:12, 98.42s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:44:03<9:03:10, 98.17s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:45:45<9:07:40, 99.28s/it]
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(TaskRunner pid=1589581)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:48:51<11:28:51, 125.25s/it]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:50:34<10:49:50, 118.51s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:52:12<10:14:31, 112.41s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:53:49<9:48:14, 107.94s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:55:31<9:36:18, 106.07s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:57:06<9:16:48, 102.79s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:58:42<9:03:32, 100.66s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:00:16<8:51:44, 98.78s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:01:56<8:51:42, 99.08s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:03:33<8:47:12, 98.54s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:06:24<10:40:56, 120.18s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:08:09<10:15:03, 115.68s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:09:49<9:48:21, 111.01s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:11:23<9:19:48, 105.96s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:12:59<9:01:25, 102.80s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:14:37<8:51:48, 101.30s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:16:16<8:47:51, 100.87s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:17:51<8:36:11, 98.95s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:19:32<8:38:05, 99.63s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:21:07<8:28:24, 98.09s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:23:57<10:19:06, 119.83s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:25:36<9:44:01, 113.40s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:27:14<9:18:36, 108.82s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:28:51<8:58:35, 105.26s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:30:26<8:41:24, 102.24s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:32:05<8:35:45, 101.46s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:33:46<8:33:03, 101.26s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:35:26<8:28:53, 100.77s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:37:08<8:29:33, 101.24s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:38:47<8:24:10, 100.50s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:41:43<10:15:01, 123.00s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 00:15:38,680:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:43:28<9:46:17, 117.65s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:45:07<9:17:24, 112.23s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:46:48<8:58:37, 108.81s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:48:26<8:40:24, 105.49s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:50:13<8:41:28, 106.06s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:51:54<8:32:09, 104.52s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 00:25:47,617:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 00:25:59,127:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:53:43<8:36:12, 105.71s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:55:23<8:27:20, 104.25s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:57:08<8:26:02, 104.34s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:00:00<10:02:57, 124.75s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:01:36<9:18:49, 116.02s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:03:14<8:51:00, 110.63s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:04:54<8:33:10, 107.29s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:06:36<8:24:32, 105.85s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:08:16<8:14:47, 104.17s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:09:58<8:08:59, 103.31s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:11:35<7:58:34, 101.47s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:13:18<8:00:01, 102.13s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:14:59<7:56:17, 101.70s/it]
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(TaskRunner pid=1589581)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:18:13<10:03:59, 129.43s/it]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:19:55<9:23:41, 121.22s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:21:39<8:56:33, 115.80s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:23:17<8:30:34, 110.60s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 00:57:14,740:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:25:03<8:21:55, 109.11s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:26:43<8:08:31, 106.59s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:28:27<8:02:41, 105.70s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:30:12<8:00:13, 105.54s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:31:48<7:44:44, 102.52s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:33:27<7:38:12, 101.45s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:36:24<9:19:24, 124.31s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:38:07<8:48:13, 117.82s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:39:49<8:25:18, 113.13s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:41:32<8:09:27, 109.99s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:43:13<7:55:56, 107.36s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:44:52<7:43:07, 104.86s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:46:32<7:35:38, 103.55s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:48:10<7:26:16, 101.81s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:49:45<7:15:49, 99.81s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:51:30<7:20:49, 101.34s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:54:20<8:48:29, 121.96s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:55:59<8:16:29, 115.02s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:57:42<7:58:18, 111.23s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:59:13<7:30:55, 105.28s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:00:54<7:23:17, 103.90s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:02:32<7:14:04, 102.14s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:04:08<7:04:37, 100.31s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:05:49<7:04:12, 100.60s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:07:27<6:59:45, 99.94s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:09:07<6:57:22, 99.77s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:11:57<8:23:30, 120.84s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:13:32<7:49:25, 113.12s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:15:10<7:29:03, 108.64s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:16:48<7:13:47, 105.37s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:18:23<6:59:01, 102.20s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:19:58<6:49:30, 100.29s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:21:33<6:41:29, 98.73s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:23:08<6:35:03, 97.54s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:24:51<6:39:37, 99.08s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:26:27<6:34:50, 98.30s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:29:21<8:03:11, 120.80s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:31:11<7:48:47, 117.69s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:32:52<7:27:06, 112.72s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:34:33<7:10:43, 109.05s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:36:12<6:56:54, 105.99s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:37:55<6:51:43, 105.12s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:39:32<6:40:50, 102.78s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:41:12<6:35:37, 101.88s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:42:55<6:35:58, 102.41s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:44:34<6:29:25, 101.15s/it]
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(TaskRunner pid=1589581)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:47:42<8:07:53, 127.28s/it]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:49:19<7:31:22, 118.26s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:50:55<7:04:06, 111.61s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:52:32<6:45:42, 107.24s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 02:26:26,731:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:54:13<6:36:10, 105.18s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:55:47<6:22:37, 102.03s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:57:27<6:18:33, 101.40s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:59:03<6:10:13, 99.61s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:00:44<6:10:32, 100.15s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 02:34:38,275:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 02:34:44,781:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:02:27<6:12:25, 101.11s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:05:16<7:24:54, 121.34s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:06:54<6:57:46, 114.46s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 02:40:54,196:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:08:39<6:45:12, 111.52s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:10:19<6:30:41, 108.03s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:12:00<6:21:55, 106.09s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:13:36<6:08:41, 102.89s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:15:14<6:01:45, 101.43s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:16:50<5:54:39, 99.90s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:18:23<5:45:34, 97.80s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:20:01<5:43:44, 97.75s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 02:53:58,890:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 02:54:04,626:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 02:54:09,639:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:23:06<7:14:26, 124.12s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:24:45<6:45:59, 116.55s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:26:20<6:21:18, 109.99s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:27:56<6:04:51, 105.75s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:29:37<5:58:32, 104.43s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:31:12<5:47:02, 101.57s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:32:53<5:44:40, 101.38s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:34:35<5:43:44, 101.60s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:36:12<5:36:59, 100.09s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:37:50<5:33:28, 99.54s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:40:40<6:42:25, 120.73s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:42:11<6:10:23, 111.68s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:43:48<5:54:18, 107.37s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:45:25<5:41:57, 104.15s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:47:08<5:39:21, 103.88s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:48:47<5:32:41, 102.37s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:50:24<5:26:23, 100.95s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:52:05<5:24:09, 100.77s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:53:44<5:21:24, 100.44s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:55:22<5:17:10, 99.64s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:58:17<6:26:42, 122.12s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:59:52<5:59:33, 114.14s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:01:30<5:42:17, 109.24s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:03:06<5:27:34, 105.11s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:04:43<5:18:51, 102.86s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:06:20<5:11:32, 101.04s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:08:00<5:09:21, 100.88s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:09:35<5:01:57, 99.00s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:11:15<5:00:47, 99.16s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:12:50<4:55:22, 97.92s/it]
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(TaskRunner pid=1589581)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:15:57<6:14:15, 124.75s/it]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:17:38<5:51:09, 117.71s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:19:16<5:31:04, 111.60s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:20:56<5:19:12, 108.20s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:22:35<5:09:49, 105.62s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:24:11<4:59:08, 102.56s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:25:50<4:54:04, 101.41s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:27:22<4:44:48, 98.78s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:29:00<4:42:13, 98.45s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:30:42<4:43:23, 99.44s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:33:32<5:41:33, 120.55s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:35:09<5:20:02, 113.62s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:36:50<5:07:15, 109.73s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:38:26<4:54:02, 105.64s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:40:06<4:47:34, 103.94s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 04:14:05,076:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:41:53<4:48:48, 105.02s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:43:37<4:46:11, 104.70s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 04:17:29,073:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 04:17:35,415:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:45:19<4:42:11, 103.87s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:46:59<4:37:27, 102.76s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:48:40<4:33:53, 102.07s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:51:35<5:30:34, 123.96s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:53:15<5:09:18, 116.72s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 04:27:11,481:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:54:57<4:56:04, 112.43s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:56:35<4:42:38, 108.02s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:58:20<4:38:56, 107.28s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:00:07<4:36:50, 107.16s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:01:50<4:31:56, 105.95s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:03:35<4:28:59, 105.49s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:05:16<4:23:52, 104.16s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:06:53<4:17:08, 102.18s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:09:46<5:07:55, 123.17s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:11:21<4:44:53, 114.72s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:12:57<4:29:08, 109.11s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:14:43<4:25:13, 108.25s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:16:22<4:16:41, 105.49s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:18:00<4:09:27, 103.22s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:19:41<4:06:19, 102.64s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:21:23<4:04:18, 102.50s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:23:06<4:02:44, 102.57s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:24:44<3:57:47, 101.19s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:27:37<4:46:28, 122.77s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 05:01:36,072:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:29:23<4:32:37, 117.68s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:31:06<4:20:19, 113.18s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:32:46<4:09:25, 109.24s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:34:23<3:59:41, 105.75s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:36:07<3:56:50, 105.26s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:37:47<3:51:16, 103.56s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 05:11:44,666:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:39:34<3:51:44, 104.54s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:41:16<3:48:46, 103.99s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:42:53<3:42:16, 101.81s/it]
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(TaskRunner pid=1589581)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:46:06<4:39:42, 129.10s/it]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:47:49<4:20:38, 121.23s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:49:31<4:06:14, 115.43s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:51:17<3:58:40, 112.76s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:53:00<3:50:48, 109.91s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:54:43<3:44:33, 107.79s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:56:24<3:38:17, 105.63s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:58:07<3:34:51, 104.81s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:59:46<3:29:26, 103.01s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:01:34<3:31:07, 104.69s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:04:24<4:08:23, 124.20s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:06:04<3:52:14, 117.10s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 05:40:05,539:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:07:53<3:45:23, 114.61s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:09:32<3:34:24, 109.95s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:11:10<3:25:19, 106.20s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 05:45:05,436:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:12:50<3:20:19, 104.52s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:14:27<3:14:13, 102.22s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:16:05<3:09:45, 100.76s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:17:45<3:07:39, 100.53s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 05:51:39,172:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:19:25<3:05:45, 100.41s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:22:23<3:46:40, 123.64s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:24:01<3:30:43, 116.00s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:25:42<3:20:40, 111.49s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:27:25<3:14:22, 109.00s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:29:00<3:05:20, 104.91s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:30:40<3:00:42, 103.26s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:32:16<2:55:34, 101.29s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:33:56<2:53:05, 100.83s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:35:35<2:50:21, 100.21s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:37:15<2:48:25, 100.06s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:40:04<3:21:33, 120.93s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:41:45<3:09:19, 114.74s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:43:23<2:59:17, 109.77s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:45:04<2:53:16, 107.18s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:46:52<2:52:02, 107.52s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:48:28<2:44:29, 103.89s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:50:03<2:38:59, 101.48s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:51:42<2:36:05, 100.70s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:53:15<2:30:55, 98.43s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:54:54<2:29:32, 98.60s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:57:44<2:59:56, 119.97s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:59:23<2:48:22, 113.51s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:00:57<2:38:04, 107.78s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:02:29<2:29:14, 102.92s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:04:05<2:24:28, 100.80s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:05:46<2:22:56, 100.90s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:07:19<2:18:09, 98.68s/it] 
[36m(TaskRunner pid=1589581)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:08:57<2:16:10, 98.44s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:10:36<2:14:48, 98.64s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:12:12<2:12:02, 97.81s/it]
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(TaskRunner pid=1589581)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:15:18<2:45:30, 124.13s/it]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:16:56<2:33:12, 116.36s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:18:38<2:25:50, 112.18s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:20:18<2:19:19, 108.56s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:21:56<2:13:25, 105.34s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:23:29<2:06:59, 101.59s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:25:10<2:05:01, 101.37s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:26:51<2:03:24, 101.43s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:28:32<2:01:13, 101.03s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:30:10<1:58:32, 100.17s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:33:04<2:22:41, 122.31s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:34:42<2:12:29, 115.20s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:36:21<2:04:52, 110.19s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:38:00<1:59:31, 107.03s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:39:41<1:55:37, 105.12s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:41:14<1:49:58, 101.51s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:42:53<1:47:23, 100.69s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:44:35<1:46:04, 101.03s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:46:15<1:44:09, 100.80s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:47:55<1:42:09, 100.48s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:50:51<2:03:05, 123.09s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:52:30<1:54:10, 116.11s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:54:17<1:49:20, 113.11s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:55:55<1:43:20, 108.78s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:57:38<1:39:46, 106.90s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:59:21<1:36:51, 105.66s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:01:01<1:33:49, 104.25s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:02:40<1:30:39, 102.63s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:04:26<1:29:40, 103.46s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:06:07<1:27:28, 102.90s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:09:03<1:43:52, 124.64s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:10:45<1:36:13, 117.84s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:12:25<1:30:01, 112.54s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:14:13<1:27:12, 111.34s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:15:55<1:23:01, 108.28s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:17:34<1:19:18, 105.75s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:19:16<1:16:43, 104.62s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:21:03<1:15:22, 105.17s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:22:45<1:13:04, 104.40s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:24:28<1:11:02, 103.97s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:27:28<1:24:20, 126.52s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:29:08<1:17:11, 118.75s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:30:52<1:12:20, 114.23s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:32:34<1:08:09, 110.52s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:34:20<1:05:30, 109.18s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:36:05<1:02:58, 107.95s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:37:45<59:49, 105.57s/it]  
[36m(TaskRunner pid=1589581)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:39:26<57:23, 104.36s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:41:05<54:49, 102.79s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:42:51<53:29, 103.52s/it]
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(TaskRunner pid=1589581)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:46:08<1:05:48, 131.63s/it]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1589581)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:47:51<59:25, 122.94s/it]  
[36m(TaskRunner pid=1589581)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:49:30<54:01, 115.76s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:51:16<50:49, 112.93s/it]
[36m(TaskRunner pid=1589581)[0m WARNING:2025-11-10 08:25:14,187:Timeout during comparison
[36m(TaskRunner pid=1589581)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:53:07<48:38, 112.24s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:54:47<45:20, 108.81s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:56:31<42:57, 107.38s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:58:21<41:25, 108.05s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:00:06<39:19, 107.23s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:01:50<37:10, 106.21s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:04:49<42:39, 127.95s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:06:36<38:34, 121.82s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:08:19<34:50, 116.16s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:10:04<31:56, 112.75s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:11:47<29:16, 109.78s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:13:31<27:00, 108.06s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:15:16<25:00, 107.15s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:17:01<23:02, 106.35s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:18:48<21:20, 106.67s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:20:32<19:25, 105.99s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:23:38<21:38, 129.83s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:25:21<18:17, 121.96s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:27:06<15:35, 116.89s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:28:52<13:13, 113.34s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:30:37<11:05, 110.97s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:32:19<09:01, 108.36s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:34:06<07:12, 108.01s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:35:50<05:20, 106.76s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:37:38<03:34, 107.19s/it]
[36m(TaskRunner pid=1589581)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:39:31<01:48, 108.67s/it]
[36m(WorkerDict pid=1594162)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1594162)[0m   warnings.warn(
[36m(TaskRunner pid=1589581)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:42:52<01:50, 110.59s/it]
[36m(WorkerDict pid=1594370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1594370)[0m   warnings.warn([32m [repeated 3x across cluster][0m
