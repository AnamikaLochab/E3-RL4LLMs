
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.8/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_covvar_kappa_0.8//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.8//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.8//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_covvar_kappa_0.8/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-09 21:45:45,895	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=733489)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-09 21:46:16,051:Waiting for register center actor 6sfKE8_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=734736)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=734735)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=734735)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=734553)[0m [rank0]:[W1109 21:46:35.850110064 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=734553)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=734553)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=734553)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734736)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734736)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m [rank3]:[W1109 21:46:35.216263013 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=734736)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=734553)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=734735)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(WorkerDict pid=734553)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:   0%|          | 1/480 [01:59<15:52:35, 119.32s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   0%|          | 2/480 [03:59<15:52:37, 119.58s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   1%|          | 3/480 [06:03<16:08:19, 121.80s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   1%|          | 4/480 [08:00<15:50:34, 119.82s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   1%|          | 5/480 [09:59<15:45:53, 119.48s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   1%|â–         | 6/480 [12:00<15:48:09, 120.02s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   1%|â–         | 7/480 [14:02<15:52:04, 120.77s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   2%|â–         | 8/480 [16:03<15:49:41, 120.72s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   2%|â–         | 9/480 [18:04<15:48:55, 120.88s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   2%|â–         | 10/480 [21:25<19:00:10, 145.55s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-09 22:11:30,365:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:   2%|â–         | 11/480 [23:28<18:03:57, 138.67s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   2%|â–Ž         | 12/480 [25:26<17:12:28, 132.37s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   3%|â–Ž         | 13/480 [27:25<16:38:21, 128.27s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   3%|â–Ž         | 14/480 [29:24<16:15:07, 125.55s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   3%|â–Ž         | 15/480 [31:22<15:55:20, 123.27s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   3%|â–Ž         | 16/480 [33:22<15:44:57, 122.19s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   4%|â–Ž         | 17/480 [35:21<15:35:45, 121.26s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   4%|â–         | 18/480 [37:18<15:25:17, 120.17s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-09 22:27:28,761:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:   4%|â–         | 19/480 [39:22<15:30:50, 121.15s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   4%|â–         | 20/480 [42:42<18:30:04, 144.79s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   4%|â–         | 21/480 [44:39<17:24:33, 136.54s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   5%|â–         | 22/480 [46:38<16:42:17, 131.30s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   5%|â–         | 23/480 [48:35<16:08:09, 127.11s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   5%|â–Œ         | 24/480 [50:31<15:40:48, 123.79s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   5%|â–Œ         | 25/480 [52:24<15:12:46, 120.36s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-09 22:42:29,849:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:   5%|â–Œ         | 26/480 [54:24<15:10:33, 120.34s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   6%|â–Œ         | 27/480 [56:24<15:06:48, 120.11s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   6%|â–Œ         | 28/480 [58:15<14:45:59, 117.61s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:14<14:45:21, 117.79s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:19<17:14:57, 138.00s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-09 22:53:20,964:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:12<16:16:57, 130.55s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:58<15:19:55, 123.20s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:05<15:25:51, 124.28s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:03<15:11:02, 122.56s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:57<14:49:37, 119.95s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:46<14:23:37, 116.71s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:39<14:12:28, 115.46s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:36<14:14:05, 115.94s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:23<13:53:11, 113.36s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:32<16:36:51, 135.94s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:21<15:36:34, 128.01s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:17<15:07:52, 124.37s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   9%|â–‰         | 43/480 [1:29:06<14:32:23, 119.78s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:57<14:09:48, 116.95s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:42<13:43:28, 113.58s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:36<13:41:03, 113.51s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-09 23:24:41,738:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:32<13:44:39, 114.27s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:25<13:39:56, 113.88s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:21<13:42:27, 114.50s/it]
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(TaskRunner pid=733489)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:42<16:46:35, 140.46s/it]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:30<15:35:55, 130.90s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:47:18<14:44:53, 124.05s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:49:01<13:56:31, 117.54s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:51<13:38:35, 115.29s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:37<13:18:27, 112.72s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:24<13:02:31, 110.73s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:56:13<12:58:18, 110.40s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:59<12:46:10, 108.93s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-09 23:48:03,076:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:59:51<12:50:41, 109.84s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:43<15:00:33, 128.65s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:33<14:17:56, 122.86s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:06:18<13:39:22, 117.61s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-09 23:56:20,913:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:08:08<13:21:38, 115.34s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:09:58<13:08:16, 113.69s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:11:41<12:44:09, 110.48s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:13:31<12:41:23, 110.35s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:15:16<12:27:57, 108.66s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:17:01<12:19:15, 107.66s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:18:47<12:14:33, 107.23s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:21:49<14:45:20, 129.56s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:23:34<13:52:34, 122.14s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:25:18<13:13:22, 116.67s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:27:03<12:47:52, 113.20s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:28:51<12:36:43, 111.83s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 00:18:48,993:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:30:40<12:28:42, 110.92s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:32:27<12:19:14, 109.79s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:34:13<12:09:24, 108.60s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:36:00<12:04:48, 108.18s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:37:49<12:04:55, 108.47s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:40:44<14:16:25, 128.46s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:42:31<13:30:22, 121.86s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:44:18<12:58:16, 117.33s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:46:04<12:33:48, 113.93s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:47:50<12:16:01, 111.52s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:49:34<11:59:22, 109.27s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:51:19<11:50:02, 108.13s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:53:06<11:45:30, 107.71s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:54:54<11:45:16, 107.95s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:56:39<11:36:22, 106.86s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:59:36<13:51:08, 127.87s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:01:16<12:56:07, 119.71s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:02:57<12:17:21, 114.02s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:04:44<12:01:02, 111.79s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 00:54:44,605:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:06:36<12:00:37, 112.01s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:08:17<11:37:43, 108.74s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:10:04<11:33:10, 108.31s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:11:46<11:19:19, 106.42s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:13:23<10:58:37, 103.45s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:15:12<11:06:39, 104.99s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 01:05:08,609:Timeout during comparison
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(WorkerDict pid=734553)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=734553)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=733489)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:18:29<14:00:07, 132.65s/it]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:20:09<12:56:50, 122.98s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 01:10:10,019:Timeout during comparison
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 01:10:16,584:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:22:03<12:38:07, 120.34s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:23:43<11:57:24, 114.18s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:25:21<11:24:16, 109.19s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:27:06<11:14:48, 107.97s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:28:45<10:55:41, 105.19s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:30:30<10:54:14, 105.24s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:32:07<10:36:58, 102.74s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:33:57<10:49:13, 105.00s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:36:55<13:02:24, 126.88s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:38:39<12:17:38, 119.94s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:40:15<11:31:37, 112.77s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:41:57<11:10:49, 109.67s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:43:46<11:06:49, 109.31s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:45:19<10:35:20, 104.44s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:46:58<10:24:49, 102.99s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:48:39<10:18:00, 102.15s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:50:19<10:14:02, 101.78s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:52:01<10:11:04, 101.56s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:54:57<12:23:17, 123.88s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:56:33<11:32:04, 115.67s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:58:18<11:11:17, 112.51s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 01:48:14,275:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:00:01<10:52:51, 109.72s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:01:52<10:52:50, 110.03s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:03:32<10:32:20, 106.88s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:05:11<10:17:24, 104.65s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:06:48<10:02:13, 102.36s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:08:28<9:55:45, 101.55s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:10:07<9:49:13, 100.72s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:12:59<11:52:19, 122.11s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:14:40<11:14:37, 115.98s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:16:16<10:37:07, 109.85s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:17:56<10:18:29, 106.94s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:19:37<10:05:48, 105.05s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:21:16<9:53:48, 103.27s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:22:56<9:47:38, 102.50s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:24:34<9:37:51, 101.08s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:26:14<9:34:28, 100.79s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:27:54<9:31:24, 100.54s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 02:19:19,028:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:30:47<11:32:56, 122.28s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:32:26<10:50:43, 115.17s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:34:01<10:15:09, 109.20s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:35:44<10:02:44, 107.31s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:37:20<9:41:22, 103.82s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:38:56<9:27:20, 101.61s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:40:28<9:08:55, 98.61s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:42:03<9:01:03, 97.49s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:43:39<8:56:47, 97.01s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:45:21<9:04:19, 98.67s/it]
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(TaskRunner pid=733489)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:48:24<11:21:22, 123.89s/it]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:50:01<10:35:22, 115.88s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:51:41<10:06:45, 110.99s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:53:19<9:45:03, 107.35s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:54:58<9:29:43, 104.86s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:56:36<9:15:40, 102.59s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:58:08<8:57:19, 99.51s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [4:59:45<8:50:59, 98.64s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:01:26<8:53:00, 99.32s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:03:05<8:51:15, 99.30s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:05:53<10:40:02, 120.01s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:07:37<10:12:45, 115.25s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:09:20<9:50:47, 111.47s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:10:57<9:26:01, 107.14s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:12:33<9:05:55, 103.66s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:14:09<8:52:53, 101.50s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:15:48<8:47:11, 100.74s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:17:21<8:33:12, 98.38s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:19:01<8:33:36, 98.77s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:20:35<8:24:36, 97.35s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 03:11:56,599:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:23:25<10:15:51, 119.20s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:25:01<9:38:17, 112.29s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:26:36<9:09:30, 107.05s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:28:11<8:49:10, 103.42s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:29:43<8:30:12, 100.04s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:31:19<8:22:56, 98.94s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:32:57<8:19:33, 98.60s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:34:31<8:11:35, 97.35s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:36:09<8:10:59, 97.55s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:37:45<8:07:01, 97.08s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:40:35<9:54:08, 118.83s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 03:30:32,381:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:42:19<9:30:23, 114.46s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:43:55<9:00:26, 108.81s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:45:32<8:41:19, 105.32s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:47:06<8:23:24, 102.04s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:48:47<8:19:12, 101.53s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:50:23<8:10:09, 100.03s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:51:58<8:00:05, 98.31s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:53:33<7:54:15, 97.45s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:55:13<7:55:39, 98.07s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 03:46:35,922:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [5:58:02<9:37:11, 119.42s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [5:59:35<8:57:33, 111.60s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:01:08<8:28:21, 105.91s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:02:44<8:12:04, 102.87s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:04:19<7:59:18, 100.56s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:05:52<7:46:44, 98.26s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:07:30<7:45:24, 98.32s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:09:02<7:35:07, 96.49s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:10:38<7:32:10, 96.21s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:12:13<7:28:47, 95.83s/it]
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(TaskRunner pid=733489)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:15:23<9:38:50, 124.04s/it]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:16:58<8:57:22, 115.56s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:18:35<8:29:14, 109.91s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:20:12<8:09:13, 105.97s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:21:50<7:56:36, 103.61s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 04:11:43,341:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:23:32<7:52:22, 103.06s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:25:11<7:45:42, 101.98s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:26:54<7:45:08, 102.23s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:28:28<7:32:41, 99.86s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:30:04<7:25:29, 98.63s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:32:59<9:07:04, 121.57s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 04:22:54,384:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:34:41<8:38:44, 115.71s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:36:19<8:12:50, 110.34s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:37:59<7:57:02, 107.20s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:39:40<7:46:26, 105.21s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:41:15<7:31:16, 102.18s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:42:51<7:21:48, 100.41s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:44:28<7:15:25, 99.34s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:46:04<7:09:03, 98.26s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:47:49<7:16:44, 100.40s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:50:41<8:48:38, 122.00s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:52:18<8:13:57, 114.43s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:53:58<7:53:31, 110.12s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:55:33<7:31:37, 105.44s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [6:57:12<7:22:20, 103.68s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [6:58:51<7:13:50, 102.08s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:00:26<7:04:00, 100.16s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:02:07<7:02:55, 100.30s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:03:45<6:58:12, 99.57s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:05:27<6:59:36, 100.31s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 04:55:22,140:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:08:27<8:37:56, 124.31s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:10:04<8:02:00, 116.15s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:11:45<7:40:46, 111.48s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:13:26<7:25:46, 108.29s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:15:04<7:11:31, 105.25s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:16:46<7:05:32, 104.21s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:18:24<6:56:43, 102.47s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:20:04<6:52:11, 101.78s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:21:53<6:59:01, 103.89s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:23:37<6:57:34, 103.96s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 05:13:40,017:Timeout during comparison
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 05:13:45,282:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:26:54<8:47:05, 131.77s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:28:46<8:22:04, 126.04s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:30:31<7:53:56, 119.48s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:32:17<7:35:59, 115.44s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:33:59<7:18:41, 111.53s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:35:45<7:10:31, 109.92s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 05:25:43,590:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:37:31<7:04:10, 108.76s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:39:15<6:56:31, 107.26s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:41:00<6:51:46, 106.49s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:42:47<6:50:30, 106.63s/it]
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(TaskRunner pid=733489)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:46:08<8:37:48, 135.08s/it]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:47:49<7:56:52, 124.95s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:49:30<7:27:14, 117.69s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:51:12<7:07:25, 112.97s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:52:51<6:49:36, 108.75s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:54:32<6:38:35, 106.29s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:56:15<6:33:55, 105.52s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:57:56<6:26:14, 103.92s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:59:40<6:25:00, 104.06s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 05:49:36,776:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:01:26<6:25:24, 104.64s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 05:53:04,453:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:04:32<7:52:54, 128.98s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:06:15<7:23:04, 121.39s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:08:02<7:05:04, 116.99s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:09:46<6:49:01, 113.10s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:11:32<6:38:52, 110.80s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:13:11<6:24:48, 107.39s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:14:52<6:15:45, 105.35s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:16:32<6:08:39, 103.85s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:18:09<5:59:37, 101.78s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:19:49<5:56:13, 101.30s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 06:11:26,013:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:22:53<7:21:34, 126.16s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:24:36<6:55:13, 119.21s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:26:14<6:30:53, 112.76s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:27:53<6:15:01, 108.70s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:29:37<6:08:39, 107.37s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:31:16<5:58:13, 104.84s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:32:57<5:52:31, 103.69s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:34:40<5:50:06, 103.48s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:36:20<5:44:56, 102.46s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:38:01<5:41:29, 101.94s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:40:58<6:54:51, 124.46s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:42:32<6:22:08, 115.22s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:44:10<6:02:56, 109.98s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:45:50<5:51:29, 107.05s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:47:31<5:44:01, 105.31s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:49:12<5:37:49, 103.94s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:50:50<5:30:18, 102.16s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:52:28<5:25:02, 101.05s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:54:06<5:20:21, 100.11s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:55:42<5:14:56, 98.94s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:58:41<6:29:25, 122.97s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:00:18<6:02:21, 115.04s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:01:55<5:43:34, 109.65s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:03:31<5:28:33, 105.42s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:05:09<5:20:32, 103.40s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:06:48<5:14:08, 101.88s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:08:28<5:10:45, 101.33s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:10:02<5:02:51, 99.30s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:11:43<5:02:41, 99.79s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:13:18<4:56:43, 98.36s/it]
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(TaskRunner pid=733489)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:16:28<6:17:09, 125.72s/it]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:18:05<5:49:59, 117.32s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:19:41<5:28:26, 110.71s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:21:20<5:16:05, 107.15s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:22:59<5:07:08, 104.71s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:24:34<4:57:01, 101.84s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:26:11<4:51:41, 100.58s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:27:44<4:43:23, 98.28s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:29:20<4:39:27, 97.49s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:31:01<4:41:16, 98.69s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:33:57<5:44:39, 121.64s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:35:33<5:21:12, 114.04s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:37:10<5:05:27, 109.09s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:38:47<4:53:03, 105.29s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:40:27<4:47:17, 103.84s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:42:11<4:45:33, 103.84s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:43:58<4:46:16, 104.73s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 07:33:50,663:Timeout during comparison
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 07:33:56,350:Timeout during comparison
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 07:34:02,558:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:45:51<4:51:34, 107.33s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:47:31<4:43:50, 105.12s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 07:37:27,329:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:49:18<4:43:11, 105.54s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:52:16<5:39:16, 127.23s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:53:54<5:14:00, 118.49s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 07:43:50,826:Timeout during comparison
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 07:43:56,411:Timeout during comparison
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 07:44:01,427:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:55:47<5:08:03, 116.98s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:57:25<4:51:09, 111.27s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:59:10<4:44:26, 109.40s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:00:51<4:35:40, 106.71s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:02:32<4:29:42, 105.08s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:04:13<4:25:05, 103.96s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:05:57<4:23:24, 103.97s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:07:36<4:17:27, 102.30s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:10:37<5:14:42, 125.88s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:12:14<4:51:04, 117.21s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:13:51<4:34:41, 111.36s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:15:35<4:27:18, 109.11s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:17:15<4:19:03, 106.46s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:18:54<4:11:29, 104.07s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:20:34<4:07:06, 102.96s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:22:15<4:03:40, 102.24s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:23:55<4:00:32, 101.64s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:25:33<3:56:15, 100.54s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:28:38<4:53:46, 125.90s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:30:21<4:35:44, 119.02s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:32:02<4:21:08, 113.54s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:33:41<4:09:33, 109.29s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:35:16<3:57:37, 104.83s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:36:58<3:54:20, 104.15s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:38:39<3:50:17, 103.12s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:40:20<3:47:01, 102.42s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:42:01<3:44:23, 101.99s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:43:36<3:38:27, 100.06s/it]
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(TaskRunner pid=733489)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:46:50<4:37:45, 128.19s/it]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:48:32<4:18:35, 120.28s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:50:13<4:04:31, 114.62s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:51:55<3:54:34, 110.82s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:53:38<3:47:55, 108.53s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:55:18<3:40:43, 105.95s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:56:55<3:32:58, 103.06s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:58:33<3:28:22, 101.65s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:00:11<3:24:11, 100.42s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:01:58<3:26:24, 102.35s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:04:48<4:05:41, 122.84s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:06:26<3:48:43, 115.33s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:08:07<3:38:25, 111.07s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:09:43<3:27:59, 106.66s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:11:18<3:18:54, 102.88s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:12:52<3:12:17, 100.33s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:14:26<3:06:57, 98.40s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:15:59<3:02:10, 96.73s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:17:36<3:00:55, 96.92s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 09:07:27,184:Timeout during comparison
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 09:07:34,165:Timeout during comparison
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 09:07:39,908:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:19:23<3:05:06, 100.06s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 09:09:20,048:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:22:22<3:46:32, 123.56s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:23:58<3:29:40, 115.42s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:25:37<3:19:02, 110.58s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:27:15<3:10:11, 106.65s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:28:47<3:00:36, 102.23s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:30:23<2:55:28, 100.27s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:31:57<2:51:01, 98.66s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:33:34<2:48:21, 98.07s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:35:08<2:44:29, 96.76s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:36:44<2:42:25, 96.49s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:39:33<3:16:57, 118.18s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:41:08<3:03:51, 111.43s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 09:31:05,847:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:42:51<2:57:48, 108.86s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:44:29<2:50:52, 105.69s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 09:34:31,164:Timeout during comparison
[36m(TaskRunner pid=733489)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:46:19<2:50:47, 106.75s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:47:53<2:43:10, 103.05s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:49:27<2:37:20, 100.43s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:51:06<2:34:45, 99.84s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:52:40<2:30:29, 98.14s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:54:17<2:28:23, 97.84s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:57:09<3:00:08, 120.10s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:58:46<2:47:59, 113.25s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:00:20<2:37:16, 107.23s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:01:52<2:29:01, 102.78s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:03:28<2:24:24, 100.75s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:05:10<2:23:10, 101.07s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:06:41<2:17:20, 98.10s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:08:17<2:14:46, 97.43s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:09:54<2:13:07, 97.41s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:11:29<2:10:26, 96.63s/it]
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(TaskRunner pid=733489)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:14:37<2:45:17, 123.97s/it]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:16:14<2:32:37, 115.92s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:17:54<2:24:40, 111.29s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:19:29<2:16:32, 106.40s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:21:04<2:10:09, 102.75s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:22:35<2:04:19, 99.46s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:24:11<2:01:11, 98.27s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:25:51<2:00:21, 98.92s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:27:27<1:57:36, 98.00s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:29:02<1:54:47, 97.01s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:31:55<2:19:57, 119.97s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:33:33<2:10:13, 113.24s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:35:07<2:01:51, 107.53s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:36:42<1:55:58, 103.86s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:38:19<1:51:48, 101.64s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:39:48<1:46:06, 97.95s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:41:24<1:43:38, 97.16s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:43:02<1:42:27, 97.59s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:44:38<1:40:10, 96.95s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:46:12<1:37:54, 96.30s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:49:04<1:58:47, 118.78s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:50:40<1:50:07, 112.00s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:52:24<1:45:56, 109.60s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:54:00<1:40:14, 105.52s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:55:38<1:36:24, 103.30s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:57:16<1:33:19, 101.80s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:58:53<1:30:10, 100.19s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:00:29<1:27:23, 98.93s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:02:11<1:26:32, 99.86s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:03:46<1:23:36, 98.36s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:06:32<1:38:59, 118.79s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:08:08<1:31:21, 111.86s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:09:43<1:25:24, 106.75s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:11:27<1:23:05, 106.08s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:13:02<1:18:52, 102.88s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:14:37<1:15:16, 100.37s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:16:14<1:12:50, 99.34s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:17:51<1:10:36, 98.53s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:19:28<1:08:41, 98.14s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:21:05<1:06:48, 97.77s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:23:55<1:19:36, 119.42s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:25:33<1:13:29, 113.07s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:27:16<1:09:40, 110.02s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:28:52<1:05:21, 105.99s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:30:30<1:02:08, 103.57s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:32:09<59:29, 101.99s/it]  
[36m(TaskRunner pid=733489)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:33:42<56:24, 99.56s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:35:16<53:41, 97.62s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:36:49<51:21, 96.29s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:38:28<50:11, 97.16s/it]
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(TaskRunner pid=733489)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:41:37<1:02:22, 124.76s/it]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=733489)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:43:15<56:24, 116.69s/it]  
[36m(TaskRunner pid=733489)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:44:48<51:09, 109.63s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:46:26<47:43, 106.05s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:48:05<45:03, 103.97s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:49:37<41:50, 100.43s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:51:12<39:29, 98.72s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:52:56<38:30, 100.48s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:54:36<36:42, 100.13s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:56:13<34:42, 99.19s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [13:59:05<40:19, 120.98s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:00:44<36:18, 114.63s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:02:17<32:24, 108.05s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:03:53<29:36, 104.53s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:05:28<27:05, 101.62s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:07:03<24:53, 99.55s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:08:42<23:13, 99.53s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:10:20<21:24, 98.80s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:11:58<19:43, 98.59s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:13:34<17:56, 97.82s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:16:28<20:07, 120.79s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:18:04<16:59, 113.24s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:19:42<14:30, 108.78s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:21:18<12:14, 104.94s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:22:55<10:14, 102.47s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:24:26<08:15, 99.15s/it] 
[36m(TaskRunner pid=733489)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:26:02<06:32, 98.22s/it]
[36m(TaskRunner pid=733489)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:27:33<04:47, 95.98s/it]
[36m(TaskRunner pid=733489)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:29:09<03:11, 95.86s/it]
[36m(TaskRunner pid=733489)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:30:48<01:36, 96.90s/it]
[36m(TaskRunner pid=733489)[0m WARNING:2025-11-10 12:22:14,025:Timeout during comparison
[36m(WorkerDict pid=734553)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=734553)[0m   warnings.warn(
[36m(TaskRunner pid=733489)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:33:58<01:49, 109.47s/it]
[36m(WorkerDict pid=734737)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=734737)[0m   warnings.warn([32m [repeated 3x across cluster][0m
