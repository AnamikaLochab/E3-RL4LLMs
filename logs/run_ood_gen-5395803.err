The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a3/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a3//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a3//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a3//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a3/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-19 16:02:47,213	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=3032440)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 16:03:07,529:Waiting for register center actor qcVg2d_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=3036197)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3036197)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=3036197)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=3036021)[0m [rank0]:[W1219 16:03:25.617617239 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=3036197)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3036197)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3036021)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036021)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m [rank3]:[W1219 16:03:25.849566041 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036195)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=3036021)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3036195)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3036195)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3036197)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(WorkerDict pid=3036195)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=3032440)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3032440)[0m /scratch/gautschi/alochab/E3-RL4LLMs/verl/verl/trainer/ppo/core_algos.py:744: RuntimeWarning: divide by zero encountered in log
[36m(TaskRunner pid=3032440)[0m   print(f"    Entropy H(q):   {Hq.item():.4f} (Max possible: {np.log(corr_mask.sum().item()):.4f})")
[36m(TaskRunner pid=3032440)[0m Training Progress:   0%|          | 1/480 [02:02<16:16:06, 122.27s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   0%|          | 2/480 [04:05<16:16:21, 122.55s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   1%|          | 3/480 [06:10<16:23:18, 123.69s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   1%|          | 4/480 [08:09<16:09:20, 122.19s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   1%|          | 5/480 [10:10<16:02:00, 121.52s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   1%|â–         | 6/480 [12:13<16:05:37, 122.23s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   1%|â–         | 7/480 [14:17<16:07:31, 122.73s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   2%|â–         | 8/480 [16:19<16:03:19, 122.46s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 16:23:10,151:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:   2%|â–         | 9/480 [18:27<16:15:37, 124.28s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   2%|â–         | 10/480 [21:52<19:27:40, 149.06s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   2%|â–         | 11/480 [23:52<18:15:32, 140.15s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   2%|â–Ž         | 12/480 [25:52<17:25:48, 134.08s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   3%|â–Ž         | 13/480 [27:52<16:50:52, 129.88s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   3%|â–Ž         | 14/480 [29:55<16:32:26, 127.78s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   3%|â–Ž         | 15/480 [31:55<16:10:57, 125.28s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   3%|â–Ž         | 16/480 [33:56<16:00:14, 124.17s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   4%|â–Ž         | 17/480 [35:58<15:53:06, 123.51s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   4%|â–         | 18/480 [37:57<15:39:31, 122.02s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   4%|â–         | 19/480 [39:56<15:32:00, 121.30s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   4%|â–         | 20/480 [43:24<18:47:53, 147.12s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   4%|â–         | 21/480 [45:28<17:52:37, 140.21s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   5%|â–         | 22/480 [47:31<17:11:06, 135.08s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   5%|â–         | 23/480 [49:30<16:33:21, 130.42s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   5%|â–Œ         | 24/480 [51:31<16:09:08, 127.52s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   5%|â–Œ         | 25/480 [53:26<15:37:25, 123.62s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   5%|â–Œ         | 26/480 [55:26<15:27:15, 122.54s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   6%|â–Œ         | 27/480 [57:28<15:25:17, 122.56s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   6%|â–Œ         | 28/480 [59:23<15:05:38, 120.22s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   6%|â–Œ         | 29/480 [1:01:25<15:07:39, 120.75s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   6%|â–‹         | 30/480 [1:04:34<17:39:29, 141.27s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   6%|â–‹         | 31/480 [1:06:23<16:23:24, 131.41s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   7%|â–‹         | 32/480 [1:08:10<15:28:12, 124.31s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   7%|â–‹         | 33/480 [1:10:16<15:28:05, 124.58s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   7%|â–‹         | 34/480 [1:12:12<15:07:02, 122.02s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   7%|â–‹         | 35/480 [1:14:04<14:43:35, 119.14s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:55<14:24:26, 116.82s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   8%|â–Š         | 37/480 [1:17:55<14:28:11, 117.59s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   8%|â–Š         | 38/480 [1:19:55<14:31:13, 118.27s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   8%|â–Š         | 39/480 [1:21:45<14:12:18, 115.96s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   8%|â–Š         | 40/480 [1:24:58<16:59:11, 138.98s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   9%|â–Š         | 41/480 [1:26:50<15:57:13, 130.83s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   9%|â–‰         | 42/480 [1:28:47<15:24:35, 126.66s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   9%|â–‰         | 43/480 [1:30:35<14:41:55, 121.09s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   9%|â–‰         | 44/480 [1:32:27<14:20:05, 118.36s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:   9%|â–‰         | 45/480 [1:34:15<13:56:31, 115.38s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  10%|â–‰         | 46/480 [1:36:13<13:59:00, 115.99s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  10%|â–‰         | 47/480 [1:38:09<13:57:58, 116.12s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:40:05<13:56:09, 116.13s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:42:05<14:01:09, 117.10s/it]
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(TaskRunner pid=3032440)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:45:26<17:00:45, 142.43s/it]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3032440)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:47:19<15:55:37, 133.65s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:49:12<15:08:49, 127.41s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:51:02<14:28:39, 122.06s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:52:56<14:09:34, 119.66s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:54:44<13:43:08, 116.21s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:56:31<13:22:53, 113.62s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:58:24<13:19:17, 113.37s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [2:00:12<13:05:51, 111.73s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 18:06:55,620:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:02:04<13:04:47, 111.85s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:04:59<15:14:25, 130.63s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:06:52<14:34:57, 125.29s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:08:39<13:54:44, 119.82s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:10:25<13:23:56, 115.67s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:12:21<13:22:28, 115.74s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:14:10<13:06:32, 113.72s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:16:03<13:03:19, 113.53s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:17:57<13:02:31, 113.68s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:19:45<12:48:50, 111.97s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:21:35<12:44:06, 111.55s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:24:40<15:12:24, 133.52s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:26:32<14:27:03, 127.20s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:28:20<13:45:18, 121.37s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:30:07<13:14:01, 117.06s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:31:59<13:00:55, 115.41s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 18:38:37,921:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 18:38:45,870:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:33:53<12:57:14, 115.15s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 18:40:38,010:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:35:50<12:59:25, 115.76s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:37:40<12:44:42, 113.85s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:39:33<12:41:01, 113.58s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 18:46:15,372:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:41:29<12:43:41, 114.27s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:44:27<14:49:59, 133.50s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:46:18<14:03:00, 126.77s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:48:08<13:27:28, 121.73s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:49:59<13:04:32, 118.57s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:51:50<12:46:20, 116.11s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:53:40<12:33:47, 114.50s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:55:30<12:21:59, 112.99s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:57:24<12:22:14, 113.32s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:59:18<12:21:49, 113.55s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [3:01:06<12:09:53, 112.00s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:04:06<14:19:03, 132.16s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:05:53<13:28:43, 124.74s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 19:12:33,501:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 19:12:38,535:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 19:12:43,595:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:07:55<13:21:35, 123.96s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:09:45<12:52:22, 119.75s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:11:36<12:33:30, 117.13s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:13:27<12:19:16, 115.21s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:15:22<12:17:37, 115.25s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:17:08<11:58:20, 112.53s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:18:52<11:39:56, 109.94s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:20:52<11:56:49, 112.89s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 19:27:34,256:Timeout during comparison
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(WorkerDict pid=3036021)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3036021)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=3032440)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:24:16<14:47:06, 140.07s/it]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 19:30:55,911:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:26:05<13:47:35, 131.02s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:27:55<13:04:04, 124.46s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:29:39<12:24:46, 118.53s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:31:24<11:55:54, 114.24s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:33:14<11:47:13, 113.16s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:34:56<11:24:13, 109.77s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:36:45<11:21:26, 109.62s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:38:31<11:12:17, 108.43s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:40:33<11:35:14, 112.44s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:43:34<13:40:13, 133.01s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:45:23<12:54:58, 126.01s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:47:02<12:03:10, 117.91s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:48:52<11:46:25, 115.49s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:50:44<11:37:01, 114.27s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:52:23<11:07:20, 109.70s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:54:04<10:49:53, 107.12s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:55:52<10:49:40, 107.38s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:57:43<10:55:22, 108.63s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:59:29<10:47:19, 107.59s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 20:06:11,857:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [4:02:38<13:13:21, 132.23s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:04:24<12:23:53, 124.33s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:06:16<11:59:14, 120.54s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:08:05<11:36:27, 117.05s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:10:11<11:51:11, 119.86s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:12:02<11:33:46, 117.26s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:13:54<11:21:00, 115.43s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:15:41<11:05:28, 113.11s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:17:32<10:58:57, 112.32s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:19:23<10:55:35, 112.07s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:22:29<13:02:21, 134.12s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:24:19<12:18:46, 127.01s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:26:07<11:43:05, 121.22s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:27:58<11:23:15, 118.14s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:29:45<11:01:34, 114.72s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:31:32<10:46:46, 112.48s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:33:21<10:39:15, 111.50s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:35:05<10:24:54, 109.31s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:36:52<10:18:22, 108.49s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:38:40<10:15:08, 108.23s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:41:34<12:06:21, 128.18s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:43:22<11:29:05, 121.96s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:45:04<10:54:08, 116.12s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:46:52<10:38:32, 113.69s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:48:36<10:19:15, 110.58s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:50:24<10:13:39, 109.91s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:52:04<9:56:09, 107.09s/it] 
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 20:58:42,770:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:53:52<9:55:03, 107.22s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:55:37<9:49:29, 106.54s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:57:32<10:01:46, 109.08s/it]
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(TaskRunner pid=3032440)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [5:00:47<12:21:29, 134.82s/it]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3032440)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [5:02:36<11:36:30, 127.02s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [5:04:24<11:03:33, 121.38s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [5:06:07<10:32:11, 116.00s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [5:07:55<10:17:05, 113.58s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:09:39<9:58:49, 110.55s/it] 
[36m(TaskRunner pid=3032440)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:11:18<9:39:38, 107.34s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:13:03<9:33:38, 106.56s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:14:51<9:33:56, 106.95s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:16:38<9:32:38, 107.04s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:19:38<11:27:01, 128.82s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:21:31<10:59:50, 124.11s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:23:18<10:30:59, 119.06s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:25:04<10:07:57, 115.07s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:26:45<9:43:09, 110.73s/it] 
[36m(TaskRunner pid=3032440)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:28:31<9:33:39, 109.27s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:30:16<9:26:20, 108.22s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:31:59<9:15:43, 106.53s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:33:45<9:13:19, 106.41s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:35:27<9:03:55, 104.94s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:38:21<10:50:22, 125.88s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:40:03<10:11:33, 118.75s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:41:47<9:46:06, 114.18s/it] 
[36m(TaskRunner pid=3032440)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:43:28<9:24:03, 110.24s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:45:09<9:08:05, 107.47s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:46:56<9:05:07, 107.24s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:48:44<9:05:10, 107.60s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:50:25<8:53:17, 105.60s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:52:12<8:53:05, 105.91s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:53:57<8:50:45, 105.80s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:56:55<10:36:56, 127.39s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 22:03:35,879:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-19 22:03:40,923:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:58:53<10:20:08, 124.44s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [6:00:35<9:45:39, 117.92s/it] 
[36m(TaskRunner pid=3032440)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [6:02:24<9:30:48, 115.32s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [6:04:05<9:07:40, 111.01s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [6:05:58<9:07:38, 111.39s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [6:07:43<8:56:21, 109.46s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:09:23<8:41:32, 106.80s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:11:09<8:37:45, 106.39s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:12:57<8:39:13, 107.06s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:15:56<10:21:10, 128.52s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:17:37<9:39:52, 120.39s/it] 
[36m(TaskRunner pid=3032440)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:19:23<9:16:11, 115.87s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:21:04<8:53:39, 111.57s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:22:49<8:42:41, 109.66s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:24:33<8:31:35, 107.70s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:26:20<8:29:29, 107.64s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:28:00<8:16:26, 105.25s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:29:46<8:15:36, 105.45s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:31:23<8:02:38, 103.06s/it]
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(TaskRunner pid=3032440)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:34:36<10:06:18, 129.92s/it]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3032440)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:36:19<9:27:05, 121.96s/it] 
[36m(TaskRunner pid=3032440)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:38:02<8:58:24, 116.20s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:39:42<8:34:23, 111.42s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:41:26<8:22:22, 109.21s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:43:09<8:12:16, 107.41s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:44:55<8:08:11, 106.90s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:46:45<8:10:02, 107.70s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:48:22<7:54:01, 104.56s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:50:01<7:45:28, 103.06s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:52:59<9:24:04, 125.35s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:54:42<8:52:11, 118.70s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:56:23<8:26:36, 113.42s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:58:15<8:22:25, 112.90s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:59:57<8:06:50, 109.81s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [7:01:40<7:55:24, 107.64s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [7:03:22<7:45:53, 105.89s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [7:05:02<7:36:46, 104.21s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [7:06:40<7:27:06, 102.39s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [7:08:27<7:30:50, 103.64s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:11:18<8:57:34, 124.05s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:12:59<8:25:35, 117.12s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:14:42<8:04:34, 112.69s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:16:17<7:40:37, 107.54s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:18:04<7:38:24, 107.44s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:19:46<7:28:47, 105.60s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:21:24<7:18:03, 103.48s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:23:08<7:16:37, 103.55s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:24:52<7:15:06, 103.60s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:26:34<7:11:13, 103.08s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:29:26<8:36:33, 123.98s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:31:08<8:07:08, 117.38s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:32:49<7:44:23, 112.35s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:34:29<7:27:25, 108.69s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:36:06<7:10:45, 105.06s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:37:42<6:58:27, 102.48s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:39:21<6:52:38, 101.47s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:40:56<6:42:56, 99.49s/it] 
[36m(TaskRunner pid=3032440)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:42:41<6:48:00, 101.16s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:44:20<6:43:08, 100.37s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:47:16<8:13:07, 123.28s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:49:07<7:55:25, 119.35s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:50:48<7:32:32, 114.09s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:52:29<7:14:56, 110.11s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:54:09<7:01:19, 107.12s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:55:57<6:59:57, 107.22s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:57:36<6:48:08, 104.65s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:59:15<6:40:38, 103.17s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [8:00:59<6:39:17, 103.27s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [8:02:42<6:37:29, 103.25s/it]
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(TaskRunner pid=3032440)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [8:05:51<8:14:19, 128.95s/it]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3032440)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [8:07:29<7:37:04, 119.76s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:09:09<7:11:51, 113.65s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:10:47<6:52:28, 109.03s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:12:28<6:42:06, 106.75s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:14:06<6:30:25, 104.12s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:15:51<6:29:09, 104.24s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:17:30<6:21:59, 102.78s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:19:16<6:23:44, 103.71s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:20:56<6:17:48, 102.57s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:23:48<7:32:48, 123.49s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:25:32<7:08:58, 117.53s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:27:23<7:00:04, 115.62s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:29:03<6:41:45, 111.08s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:30:48<6:32:52, 109.13s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:32:30<6:23:41, 107.08s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:34:15<6:19:36, 106.43s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:35:59<6:15:06, 105.66s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:37:36<6:04:05, 103.04s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:39:19<6:02:36, 103.11s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:42:13<7:15:18, 124.37s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:43:55<6:49:07, 117.45s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:45:32<6:26:37, 111.53s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:47:12<6:12:02, 107.84s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:48:56<6:06:44, 106.82s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:50:32<5:54:20, 103.71s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:52:14<5:50:40, 103.14s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:53:56<5:47:54, 102.83s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:55:36<5:43:24, 102.00s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:57:19<5:42:01, 102.10s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [9:00:12<6:51:18, 123.39s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [9:01:43<6:17:31, 113.83s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [9:03:22<6:00:07, 109.13s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [9:05:00<5:48:02, 106.00s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [9:06:43<5:43:22, 105.11s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:08:27<5:40:03, 104.63s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:10:06<5:32:56, 102.97s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:11:50<5:32:02, 103.22s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:13:34<5:31:42, 103.66s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:15:12<5:24:26, 101.92s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:18:07<6:32:22, 123.91s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:19:47<6:07:16, 116.60s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:21:24<5:47:17, 110.84s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:23:06<5:36:32, 107.98s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:24:46<5:27:51, 105.76s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:26:29<5:23:36, 104.95s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:28:13<5:20:51, 104.63s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:29:57<5:18:04, 104.29s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:31:41<5:16:23, 104.30s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:33:21<5:11:01, 103.10s/it]
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(TaskRunner pid=3032440)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:36:31<6:27:22, 129.12s/it]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3032440)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:38:12<5:59:45, 120.59s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:39:52<5:39:40, 114.50s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:41:37<5:29:39, 111.75s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:43:18<5:17:45, 108.32s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:44:53<5:04:14, 104.31s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:46:37<5:02:14, 104.22s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:48:14<4:54:16, 102.06s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:49:51<4:48:42, 100.71s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:51:36<4:50:40, 101.99s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:54:30<5:49:54, 123.50s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:56:10<5:27:35, 116.30s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:57:54<5:15:39, 112.74s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:59:35<5:03:37, 109.09s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [10:01:19<4:57:36, 107.57s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [10:03:01<4:51:42, 106.08s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [10:04:48<4:50:24, 106.25s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-20 02:11:22,250:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [10:06:27<4:43:05, 104.21s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [10:08:07<4:37:32, 102.79s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-20 02:14:44,194:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:09:55<4:40:10, 104.41s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:12:50<5:35:00, 125.63s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:14:33<5:14:59, 118.86s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-20 02:21:10,746:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:16:19<5:02:45, 114.97s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:17:56<4:46:55, 109.65s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:19:42<4:42:10, 108.53s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:21:23<4:34:37, 106.31s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:23:10<4:32:57, 106.34s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:24:52<4:28:15, 105.20s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:26:39<4:27:25, 105.56s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:28:16<4:19:13, 103.01s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:31:09<5:10:05, 124.04s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:32:46<4:48:18, 116.09s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:34:25<4:33:27, 110.86s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:36:14<4:30:12, 110.29s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:37:54<4:21:10, 107.33s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:39:36<4:14:53, 105.47s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:41:15<4:08:37, 103.60s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:42:58<4:06:22, 103.37s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:44:43<4:06:09, 104.01s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:46:24<4:02:22, 103.14s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:49:19<4:51:04, 124.75s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:51:05<4:36:01, 119.15s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:52:49<4:23:02, 114.37s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:54:31<4:12:46, 110.70s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:56:10<4:03:02, 107.23s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:57:55<4:00:00, 106.67s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:59:39<3:56:04, 105.70s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [11:01:21<3:52:00, 104.66s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [11:03:05<3:49:40, 104.40s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [11:04:45<3:44:53, 103.00s/it]
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(TaskRunner pid=3032440)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [11:08:01<4:43:59, 131.07s/it]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3032440)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:09:45<4:24:30, 123.03s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:11:33<4:12:28, 118.34s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:13:18<4:02:18, 114.47s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:15:10<3:58:32, 113.59s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:16:54<3:50:39, 110.72s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:18:35<3:42:51, 107.83s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:20:21<3:40:18, 107.47s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:22:03<3:34:51, 105.66s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:23:54<3:36:18, 107.26s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:26:46<4:13:20, 126.67s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:28:34<4:00:19, 121.17s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:30:18<3:48:05, 115.98s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:31:59<3:37:17, 111.43s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:33:39<3:29:07, 108.17s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:35:17<3:21:06, 104.93s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:36:52<3:13:35, 101.89s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:38:32<3:11:06, 101.48s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:40:14<3:09:54, 101.73s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:41:51<3:05:18, 100.16s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:44:51<3:47:33, 124.12s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:46:34<3:33:51, 117.72s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:48:15<3:23:13, 112.90s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:50:05<3:19:39, 111.96s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:51:42<3:09:57, 107.52s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:53:24<3:05:05, 105.77s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:55:04<3:00:26, 104.10s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:56:46<2:57:25, 103.35s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:58:25<2:53:22, 101.98s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [12:00:05<2:50:36, 101.35s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [12:02:58<3:25:01, 123.01s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [12:04:40<3:12:20, 116.57s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-20 04:11:17,594:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [12:06:28<3:06:15, 114.03s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [12:08:11<2:59:05, 110.78s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [12:09:57<2:55:12, 109.50s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:11:38<2:49:16, 106.91s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:13:17<2:43:39, 104.46s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:14:59<2:40:41, 103.67s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-20 04:21:37,400:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:16:44<2:39:26, 103.99s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:18:25<2:36:37, 103.27s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:21:20<3:07:17, 124.86s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:23:00<2:54:06, 117.37s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:24:41<2:44:46, 112.35s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:26:16<2:35:27, 107.21s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:28:02<2:33:07, 106.84s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:29:50<2:31:43, 107.11s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:31:29<2:26:29, 104.63s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:33:12<2:24:18, 104.32s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:34:55<2:22:03, 103.95s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:36:38<2:19:56, 103.66s/it]
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(TaskRunner pid=3032440)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:39:50<2:53:20, 130.01s/it]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3032440)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:41:32<2:40:00, 121.53s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:43:19<2:32:32, 117.34s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:45:02<2:25:01, 113.00s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:46:44<2:18:52, 109.63s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:48:24<2:13:25, 106.75s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:50:05<2:09:26, 104.96s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:51:49<2:07:31, 104.82s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:53:34<2:05:41, 104.74s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:55:17<2:03:19, 104.21s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:58:21<2:29:31, 128.17s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [13:00:01<2:17:37, 119.67s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [13:01:41<2:09:10, 113.98s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [13:03:23<2:03:01, 110.16s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [13:05:04<1:58:25, 107.66s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [13:06:38<1:52:07, 103.50s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [13:08:22<1:50:27, 103.55s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [13:10:09<1:49:46, 104.55s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:11:49<1:46:46, 103.33s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:13:33<1:45:11, 103.46s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:16:29<2:05:18, 125.32s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:18:09<1:55:39, 117.61s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:19:55<1:50:17, 114.09s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:21:33<1:43:47, 109.26s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:23:16<1:40:17, 107.45s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:24:59<1:37:19, 106.17s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:26:41<1:34:17, 104.77s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:28:23<1:31:56, 104.09s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:30:09<1:30:34, 104.51s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:31:49<1:27:48, 103.30s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:34:44<1:44:02, 124.86s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:36:26<1:36:11, 117.78s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:38:07<1:30:24, 113.01s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:39:56<1:27:25, 111.61s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:41:36<1:23:01, 108.29s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:43:12<1:18:26, 104.59s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:44:52<1:15:41, 103.21s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:46:36<1:14:01, 103.30s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:48:17<1:11:58, 102.82s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:50:02<1:10:40, 103.42s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:53:00<1:23:51, 125.79s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:54:43<1:17:17, 118.92s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:56:27<1:12:28, 114.42s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:58:08<1:08:01, 110.30s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:59:53<1:05:18, 108.84s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [14:01:35<1:02:19, 106.83s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-20 06:08:14,405:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [14:03:22<1:00:33, 106.87s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [14:05:03<57:40, 104.86s/it]  
[36m(TaskRunner pid=3032440)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [14:06:45<55:37, 104.29s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [14:08:29<53:48, 104.14s/it]
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(TaskRunner pid=3032440)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:11:39<1:04:51, 129.71s/it]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3032440)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:13:22<58:51, 121.77s/it]  
[36m(TaskRunner pid=3032440)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:14:58<53:14, 114.10s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:16:43<50:05, 111.33s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:18:26<47:08, 108.80s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:20:06<44:12, 106.10s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:21:45<41:37, 104.06s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:23:32<40:15, 105.01s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:25:15<38:13, 104.25s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:26:55<36:04, 103.05s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:29:51<41:40, 125.04s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:31:42<38:14, 120.74s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:33:24<34:34, 115.24s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:35:06<31:28, 111.08s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:36:48<28:56, 108.55s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:38:30<26:35, 106.40s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:40:16<24:47, 106.26s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:41:59<22:50, 105.39s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:43:40<20:47, 103.97s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:45:21<18:55, 103.19s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:48:32<21:36, 129.61s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:50:17<18:18, 122.06s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:52:02<15:36, 117.10s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-20 06:58:40,536:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-20 06:58:45,563:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-20 06:58:50,744:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:54:02<13:44, 117.82s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:55:44<11:18, 113.15s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:57:23<09:04, 108.86s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:59:06<07:08, 107.07s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [15:00:47<05:16, 105.38s/it]
[36m(TaskRunner pid=3032440)[0m WARNING:2025-12-20 07:07:28,000:Timeout during comparison
[36m(TaskRunner pid=3032440)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [15:02:39<03:34, 107.19s/it]
[36m(TaskRunner pid=3032440)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:04:32<01:49, 109.12s/it]
[36m(WorkerDict pid=3036021)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3036021)[0m   warnings.warn(
[36m(TaskRunner pid=3032440)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:07:51<01:53, 113.72s/it]
[36m(WorkerDict pid=3036198)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3036198)[0m   warnings.warn([32m [repeated 3x across cluster][0m
