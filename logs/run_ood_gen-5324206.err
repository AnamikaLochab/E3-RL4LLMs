The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_r_norm_dyn_clamp_2.5/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_r_norm_dyn_clamp_2.5//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_r_norm_dyn_clamp_2.5//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_r_norm_dyn_clamp_2.5//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_r_norm_dyn_clamp_2.5/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-14 21:23:09,055	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=646610)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-14 21:23:30,605:Waiting for register center actor nxtlsW_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=650370)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=650370)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=650370)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=650163)[0m [rank0]:[W1214 21:23:49.823581287 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=650370)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=650370)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=650163)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650163)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m [rank1]:[W1214 21:23:49.044867389 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=650368)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=650163)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650368)[0m   warnings.warn(
[36m(WorkerDict pid=650371)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=650371)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650371)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:   0%|          | 1/480 [02:06<16:49:25, 126.44s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   0%|          | 2/480 [04:08<16:29:01, 124.15s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   1%|          | 3/480 [06:16<16:38:20, 125.58s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   1%|          | 4/480 [08:17<16:23:58, 124.03s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   1%|          | 5/480 [10:19<16:15:25, 123.21s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   1%|â–         | 6/480 [12:25<16:20:58, 124.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   1%|â–         | 7/480 [14:31<16:22:15, 124.60s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   2%|â–         | 8/480 [16:36<16:22:51, 124.94s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   2%|â–         | 9/480 [18:40<16:18:18, 124.63s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   2%|â–         | 10/480 [22:12<19:47:54, 151.65s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   2%|â–         | 11/480 [24:15<18:36:02, 142.78s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   2%|â–Ž         | 12/480 [26:21<17:53:07, 137.58s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   3%|â–Ž         | 13/480 [28:28<17:26:32, 134.46s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   3%|â–Ž         | 14/480 [30:35<17:07:09, 132.25s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   3%|â–Ž         | 15/480 [32:43<16:54:36, 130.92s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   3%|â–Ž         | 16/480 [34:49<16:41:57, 129.56s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   4%|â–Ž         | 17/480 [36:59<16:39:16, 129.50s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   4%|â–         | 18/480 [39:06<16:31:23, 128.75s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   4%|â–         | 19/480 [41:17<16:34:05, 129.38s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   4%|â–         | 20/480 [44:59<20:05:47, 157.28s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   4%|â–         | 21/480 [47:15<19:14:48, 150.96s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   5%|â–         | 22/480 [49:26<18:26:27, 144.95s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   5%|â–         | 23/480 [51:37<17:51:59, 140.74s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   5%|â–Œ         | 24/480 [53:50<17:31:44, 138.39s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   5%|â–Œ         | 25/480 [55:59<17:08:42, 135.65s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   5%|â–Œ         | 26/480 [58:13<17:02:38, 135.15s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   6%|â–Œ         | 27/480 [1:00:31<17:05:37, 135.85s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   6%|â–Œ         | 28/480 [1:02:42<16:52:11, 134.36s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   6%|â–Œ         | 29/480 [1:04:58<16:54:40, 134.99s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   6%|â–‹         | 30/480 [1:08:38<20:03:01, 160.40s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   6%|â–‹         | 31/480 [1:10:49<18:54:47, 151.64s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   7%|â–‹         | 32/480 [1:13:00<18:06:45, 145.55s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   7%|â–‹         | 33/480 [1:15:19<17:48:39, 143.44s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   7%|â–‹         | 34/480 [1:17:34<17:27:16, 140.89s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   7%|â–‹         | 35/480 [1:19:48<17:09:15, 138.78s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   8%|â–Š         | 36/480 [1:22:03<16:59:34, 137.78s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   8%|â–Š         | 37/480 [1:24:19<16:52:39, 137.15s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   8%|â–Š         | 38/480 [1:26:38<16:55:01, 137.79s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   8%|â–Š         | 39/480 [1:28:55<16:50:40, 137.51s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   8%|â–Š         | 40/480 [1:32:40<20:01:16, 163.81s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   9%|â–Š         | 41/480 [1:34:54<18:52:52, 154.84s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   9%|â–‰         | 42/480 [1:37:11<18:11:28, 149.52s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   9%|â–‰         | 43/480 [1:39:24<17:33:42, 144.67s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   9%|â–‰         | 44/480 [1:41:40<17:12:09, 142.04s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:   9%|â–‰         | 45/480 [1:43:55<16:54:36, 139.95s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  10%|â–‰         | 46/480 [1:46:13<16:46:53, 139.20s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  10%|â–‰         | 47/480 [1:48:29<16:37:01, 138.16s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:50:43<16:25:51, 136.92s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:52:58<16:21:04, 136.58s/it]
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650163)[0m   warnings.warn(
[36m(TaskRunner pid=646610)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:57:00<20:04:38, 168.09s/it]
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:59:17<18:55:24, 158.80s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  11%|â–ˆ         | 52/480 [2:01:32<18:01:35, 151.62s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  11%|â–ˆ         | 53/480 [2:03:46<17:22:29, 146.49s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [2:06:04<17:01:46, 143.91s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [2:08:20<16:41:33, 141.40s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [2:10:36<16:27:35, 139.75s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [2:12:52<16:17:22, 138.63s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [2:15:05<16:04:31, 137.14s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-14 23:42:30,530:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:17:24<16:04:17, 137.43s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-14 23:44:44,815:Timeout during comparison
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-14 23:44:49,893:Timeout during comparison
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-14 23:44:58,824:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:21:19<19:28:21, 166.91s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:23:34<18:17:32, 157.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:25:48<17:27:58, 150.43s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:28:04<16:54:35, 145.98s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:30:23<16:37:42, 143.90s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:32:37<16:15:03, 140.97s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:34:52<16:00:28, 139.20s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:37:08<15:50:54, 138.15s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:39:25<15:46:37, 137.86s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:41:41<15:41:05, 137.39s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:45:26<18:38:14, 163.64s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:47:42<17:37:46, 155.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:49:58<16:57:29, 149.63s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:52:15<16:27:17, 145.55s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:54:30<16:04:10, 142.49s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:56:45<15:46:23, 140.21s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:59:01<15:37:04, 139.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [3:01:17<15:28:00, 138.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [3:03:33<15:20:44, 137.42s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [3:05:50<15:17:26, 137.27s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [3:09:33<18:06:03, 162.91s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [3:11:47<17:07:01, 154.44s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [3:14:03<16:27:28, 148.87s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [3:16:20<16:00:28, 145.16s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [3:18:35<15:38:39, 142.22s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [3:20:52<15:24:59, 140.51s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [3:23:07<15:12:59, 139.03s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [3:25:24<15:06:31, 138.40s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [3:27:41<15:01:00, 137.91s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [3:29:57<14:55:16, 137.38s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:33:40<17:39:31, 163.00s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:35:56<16:44:23, 154.92s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:38:13<16:06:41, 149.49s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:40:28<15:37:09, 145.30s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 01:07:52,207:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:42:50<15:27:22, 144.15s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:45:07<15:10:59, 141.97s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:47:24<15:00:17, 140.67s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:49:41<14:50:06, 139.44s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:51:56<14:39:37, 138.16s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:54:13<14:35:50, 137.93s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 01:21:36,889:Timeout during comparison
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650163)[0m   warnings.warn(
[36m(WorkerDict pid=650163)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=650163)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=646610)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:58:18<17:57:19, 170.10s/it]
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [4:00:35<16:51:23, 160.11s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [4:02:51<16:03:23, 152.92s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [4:05:08<15:29:11, 147.88s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 01:32:35,614:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [4:07:29<15:14:42, 145.96s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [4:09:45<14:53:15, 142.92s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [4:12:00<14:37:07, 140.72s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [4:14:16<14:25:45, 139.26s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [4:16:31<14:14:32, 137.83s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [4:18:46<14:07:02, 136.99s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [4:22:29<16:43:30, 162.73s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [4:24:46<15:54:01, 155.13s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [4:27:01<15:13:30, 148.94s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [4:29:18<14:49:28, 145.42s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [4:31:35<14:33:01, 143.12s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [4:33:51<14:17:16, 140.92s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [4:36:07<14:05:37, 139.39s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [4:38:22<13:54:41, 137.97s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [4:40:37<13:46:39, 137.02s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [4:42:52<13:41:28, 136.53s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 02:10:15,987:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [4:46:38<16:19:29, 163.25s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [4:48:53<15:26:32, 154.85s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:51:10<14:52:02, 149.51s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:53:25<14:24:16, 145.26s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:55:41<14:05:33, 142.51s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:57:57<13:51:42, 140.57s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [5:00:12<13:39:05, 138.83s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [5:02:27<13:29:51, 137.65s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [5:04:43<13:24:42, 137.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [5:06:57<13:17:04, 136.25s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [5:10:38<15:42:36, 161.59s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [5:12:52<14:52:44, 153.48s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [5:15:07<14:16:40, 147.70s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [5:17:23<13:54:13, 144.25s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [5:19:39<13:37:09, 141.70s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [5:21:54<13:23:36, 139.76s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [5:24:10<13:15:25, 138.74s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [5:26:26<13:07:40, 137.79s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [5:28:41<13:01:20, 137.08s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [5:30:57<12:56:57, 136.71s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [5:34:35<15:13:31, 161.21s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [5:36:52<14:29:56, 153.97s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [5:39:07<13:54:06, 148.07s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [5:41:23<13:30:57, 144.38s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [5:43:38<13:13:00, 141.61s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [5:45:53<12:59:33, 139.62s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [5:48:07<12:48:59, 138.14s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [5:50:24<12:44:18, 137.71s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [5:52:40<12:39:04, 137.18s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [5:54:55<12:33:12, 136.53s/it]
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650163)[0m   warnings.warn(
[36m(TaskRunner pid=646610)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [5:58:52<15:17:32, 166.83s/it]
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [6:01:08<14:23:23, 157.46s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [6:03:24<13:44:53, 150.90s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [6:05:41<13:20:09, 146.82s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [6:07:56<12:58:54, 143.36s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [6:10:12<12:44:18, 141.10s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [6:12:28<12:33:48, 139.59s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [6:14:44<12:25:37, 138.51s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [6:16:59<12:18:02, 137.52s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [6:19:15<12:12:22, 136.89s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [6:22:56<14:24:26, 162.08s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [6:25:13<13:41:45, 154.56s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [6:27:29<13:10:23, 149.13s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [6:29:46<12:48:20, 145.43s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [6:32:03<12:32:07, 142.81s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [6:34:18<12:18:47, 140.72s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [6:36:36<12:11:14, 139.73s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [6:38:52<12:03:00, 138.60s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [6:41:09<11:59:09, 138.30s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [6:43:25<11:53:04, 137.57s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [6:47:06<14:00:01, 162.59s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [6:49:21<13:14:49, 154.33s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [6:51:37<12:43:43, 148.78s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [6:53:54<12:23:28, 145.30s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [6:56:10<12:06:17, 142.41s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [6:58:27<11:55:50, 140.82s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [7:00:44<11:46:49, 139.50s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [7:02:59<11:39:00, 138.42s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [7:05:16<11:33:20, 137.75s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [7:07:32<11:28:43, 137.29s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [7:11:13<13:32:27, 162.49s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 04:38:37,610:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [7:13:33<12:56:22, 155.79s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [7:15:50<12:25:54, 150.18s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [7:18:07<12:03:31, 146.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [7:20:24<11:46:55, 143.30s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [7:22:41<11:35:01, 141.36s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [7:24:58<11:27:03, 140.22s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 04:52:30,544:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [7:27:25<11:33:39, 142.05s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [7:29:42<11:24:22, 140.62s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [7:31:59<11:16:56, 139.58s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [7:35:40<13:13:23, 164.15s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [7:37:57<12:31:16, 155.97s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [7:40:14<12:01:31, 150.32s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [7:42:30<11:38:03, 145.93s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [7:44:47<11:22:36, 143.20s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [7:47:04<11:10:51, 141.23s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [7:49:21<11:03:03, 140.08s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [7:51:37<10:55:20, 138.94s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [7:53:55<10:51:00, 138.51s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [7:56:13<10:48:04, 138.38s/it]
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650163)[0m   warnings.warn(
[36m(TaskRunner pid=646610)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [8:00:13<13:07:33, 168.76s/it]
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [8:02:30<12:20:28, 159.24s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [8:04:46<11:46:30, 152.48s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [8:07:03<11:22:03, 147.74s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [8:09:21<11:05:44, 144.73s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [8:11:39<10:55:10, 142.95s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [8:13:57<10:45:43, 141.40s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [8:16:14<10:36:33, 139.90s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [8:18:31<10:30:19, 139.04s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [8:20:48<10:26:14, 138.65s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 05:48:14,479:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [8:24:35<12:22:22, 164.97s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [8:26:51<11:40:40, 156.28s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [8:29:07<11:11:45, 150.39s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [8:31:25<10:52:01, 146.52s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [8:33:43<10:38:56, 144.12s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [8:36:01<10:27:19, 142.04s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [8:38:19<10:19:50, 140.87s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [8:40:35<10:11:54, 139.60s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [8:42:54<10:07:50, 139.20s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [8:45:14<10:07:02, 139.55s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [8:48:56<11:51:40, 164.23s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [8:51:13<11:14:25, 156.24s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [8:53:34<10:51:00, 151.40s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [8:55:51<10:30:43, 147.25s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [8:58:12<10:19:38, 145.23s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [9:00:30<10:08:31, 143.18s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [9:02:48<9:59:42, 141.66s/it] 
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 06:30:10,467:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [9:05:15<10:03:22, 143.09s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [9:07:33<9:54:28, 141.54s/it] 
[36m(TaskRunner pid=646610)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [9:09:53<9:50:22, 141.13s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [9:13:35<11:29:39, 165.52s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [9:15:52<10:51:44, 157.05s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [9:18:10<10:24:51, 151.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [9:20:28<10:06:34, 147.35s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [9:22:46<9:52:07, 144.42s/it] 
[36m(TaskRunner pid=646610)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [9:25:04<9:41:37, 142.44s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [9:27:21<9:33:22, 140.99s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [9:29:40<9:27:56, 140.23s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [9:31:58<9:23:00, 139.59s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [9:34:16<9:19:01, 139.18s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 07:03:44,437:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [9:38:07<11:06:25, 166.61s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [9:40:26<10:30:42, 158.34s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [9:42:43<10:03:06, 152.04s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [9:45:01<9:43:57, 147.84s/it] 
[36m(TaskRunner pid=646610)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [9:47:21<9:32:03, 145.44s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [9:49:40<9:22:17, 143.56s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [9:51:59<9:14:01, 142.06s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [9:54:18<9:08:58, 141.37s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [9:56:36<9:02:16, 140.25s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [9:58:54<8:57:16, 139.55s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 07:26:20,740:Timeout during comparison
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650163)[0m   warnings.warn(
[36m(TaskRunner pid=646610)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [10:03:02<10:59:05, 171.94s/it]
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [10:05:20<10:18:21, 162.01s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [10:07:39<9:48:42, 154.92s/it] 
[36m(TaskRunner pid=646610)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [10:10:01<9:32:13, 151.25s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 07:37:26,192:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [10:12:26<9:21:45, 149.14s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [10:14:44<9:06:48, 145.82s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [10:17:02<8:55:29, 143.43s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [10:19:20<8:47:19, 141.88s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [10:21:38<8:40:48, 140.76s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 07:49:04,819:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [10:24:01<8:41:22, 141.55s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [10:27:48<10:12:08, 166.95s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [10:30:08<9:40:03, 158.92s/it] 
[36m(TaskRunner pid=646610)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [10:32:28<9:17:26, 153.42s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [10:34:49<9:00:47, 149.53s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [10:37:10<8:49:11, 147.00s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [10:39:29<8:38:25, 144.68s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [10:41:49<8:30:57, 143.26s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [10:44:09<8:24:50, 142.21s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [10:46:28<8:19:06, 141.26s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [10:48:48<8:15:48, 140.99s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [10:52:32<9:40:13, 165.78s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [10:54:53<9:11:38, 158.36s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [10:57:12<8:48:24, 152.42s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [10:59:31<8:32:47, 148.64s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [11:01:50<8:20:11, 145.69s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [11:04:10<8:11:20, 143.81s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [11:06:29<8:04:09, 142.40s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [11:08:49<7:59:32, 141.74s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [11:11:07<7:53:46, 140.73s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [11:13:27<7:50:07, 140.33s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [11:17:10<9:10:31, 165.16s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [11:19:27<8:40:19, 156.88s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [11:21:46<8:19:24, 151.34s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [11:24:05<8:05:01, 147.72s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [11:26:25<7:54:41, 145.31s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [11:28:44<7:46:04, 143.41s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [11:31:04<7:40:24, 142.39s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [11:33:23<7:35:09, 141.50s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [11:35:42<7:30:44, 140.85s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 09:03:08,098:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [11:38:06<7:31:24, 141.81s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 09:05:30,351:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [11:41:56<8:52:46, 168.24s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [11:44:17<8:23:50, 159.95s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [11:46:40<8:04:56, 154.77s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [11:49:00<7:49:17, 150.57s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [11:51:22<7:38:11, 147.80s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [11:53:42<7:28:56, 145.60s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [11:56:04<7:22:57, 144.44s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [11:58:27<7:19:04, 143.96s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [12:00:52<7:18:00, 144.40s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [12:03:12<7:11:49, 143.15s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 09:30:40,827:Timeout during comparison
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 09:30:45,968:Timeout during comparison
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650163)[0m   warnings.warn(
[36m(TaskRunner pid=646610)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [12:07:23<8:46:13, 175.41s/it]
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [12:09:44<8:11:56, 164.90s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [12:12:06<7:49:14, 158.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [12:14:29<7:33:20, 153.67s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [12:16:53<7:21:45, 150.60s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [12:19:15<7:12:12, 148.19s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [12:21:37<7:04:05, 146.24s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [12:23:58<6:56:51, 144.58s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [12:26:20<6:52:22, 143.85s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [12:28:40<6:46:49, 142.74s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [12:32:25<7:54:27, 167.46s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [12:34:47<7:30:13, 159.84s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [12:37:10<7:13:41, 154.89s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [12:39:32<6:59:35, 150.75s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [12:41:51<6:47:52, 147.43s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 10:09:21,405:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [12:44:16<6:43:13, 146.63s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [12:46:37<6:35:54, 144.84s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [12:48:56<6:28:46, 143.11s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [12:51:15<6:23:28, 142.03s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 10:18:38,899:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [12:53:41<6:23:50, 143.05s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [12:57:25<7:26:19, 167.37s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [12:59:46<7:02:51, 159.57s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [13:02:04<6:43:18, 153.15s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [13:04:24<6:29:59, 149.04s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [13:06:42<6:19:27, 145.95s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [13:09:01<6:11:05, 143.65s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [13:11:19<6:04:35, 142.05s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [13:13:37<5:59:05, 140.82s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [13:15:56<5:55:19, 140.26s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [13:18:14<5:51:39, 139.73s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [13:21:58<6:52:19, 164.93s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [13:24:16<6:29:13, 156.74s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [13:26:33<6:11:51, 150.75s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [13:28:52<6:00:43, 147.23s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [13:31:10<5:51:37, 144.50s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 10:58:34,830:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [13:33:32<5:47:52, 143.95s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [13:35:51<5:41:40, 142.36s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [13:38:09<5:36:16, 141.10s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [13:40:28<5:32:02, 140.30s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [13:43:52<6:14:54, 159.53s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [13:47:34<6:55:59, 178.28s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [13:49:51<6:24:12, 165.85s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [13:52:09<6:02:34, 157.64s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [13:54:26<5:45:43, 151.41s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [13:56:43<5:33:31, 147.14s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [13:59:01<5:24:25, 144.19s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [14:01:19<5:18:15, 142.50s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [14:03:36<5:11:55, 140.72s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [14:05:54<5:07:45, 139.89s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [14:08:12<5:04:12, 139.33s/it]
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650163)[0m   warnings.warn(
[36m(TaskRunner pid=646610)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [14:12:11<6:06:30, 169.16s/it]
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [14:14:27<5:42:41, 159.39s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [14:16:44<5:25:18, 152.49s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [14:19:00<5:12:50, 147.80s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [14:21:17<5:03:19, 144.44s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [14:23:34<4:56:29, 142.31s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [14:25:52<4:50:55, 140.77s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [14:28:08<4:46:07, 139.58s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [14:30:25<4:41:52, 138.63s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [14:32:44<4:39:50, 138.77s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [14:36:25<5:27:00, 163.50s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [14:38:42<5:08:22, 155.48s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [14:40:59<4:54:45, 149.88s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [14:43:15<4:44:34, 145.93s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [14:45:32<4:36:36, 143.07s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 12:12:59,102:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [14:47:53<4:33:06, 142.49s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [14:50:09<4:27:15, 140.66s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [14:52:26<4:22:35, 139.43s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [14:54:43<4:18:59, 138.75s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 12:22:05,430:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [14:57:05<4:18:15, 139.60s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [15:00:56<5:06:13, 167.03s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [15:03:13<4:47:20, 158.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [15:05:30<4:33:03, 151.70s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [15:07:47<4:22:57, 147.45s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [15:10:03<4:14:23, 143.99s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [15:12:20<4:08:02, 141.73s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [15:14:37<4:03:36, 140.54s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [15:16:58<4:01:17, 140.56s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [15:19:16<3:57:31, 139.72s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [15:21:32<3:53:29, 138.71s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [15:25:18<4:34:41, 164.81s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [15:27:35<4:18:16, 156.53s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [15:29:53<4:06:18, 150.81s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [15:32:09<3:56:48, 146.48s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [15:34:33<3:53:00, 145.63s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [15:36:50<3:46:44, 143.20s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [15:39:07<3:41:13, 141.20s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [15:41:24<3:37:03, 140.03s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [15:43:41<3:33:30, 139.24s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [15:46:00<3:30:52, 139.03s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [15:49:43<4:06:13, 164.15s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [15:52:00<3:51:38, 156.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [15:54:19<3:41:29, 151.02s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [15:56:36<3:32:35, 146.62s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [15:58:57<3:27:44, 144.94s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [16:01:15<3:22:22, 142.85s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [16:03:31<3:17:28, 141.06s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [16:05:49<3:13:41, 140.02s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [16:08:06<3:10:15, 139.22s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [16:10:25<3:07:33, 138.94s/it]
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650163)[0m   warnings.warn(
[36m(TaskRunner pid=646610)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [16:14:29<3:47:28, 170.60s/it]
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [16:16:48<3:32:02, 161.04s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [16:19:05<3:20:01, 153.86s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [16:21:23<3:11:17, 149.06s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [16:23:40<3:04:09, 145.39s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [16:25:56<2:58:27, 142.77s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [16:28:14<2:54:10, 141.22s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [16:30:33<2:50:57, 140.51s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [16:32:49<2:47:08, 139.29s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [16:35:06<2:44:03, 138.64s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [16:38:47<3:10:29, 163.28s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [16:41:03<2:58:17, 155.04s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [16:43:20<2:49:44, 149.77s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [16:45:37<2:42:56, 145.91s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [16:47:55<2:37:41, 143.36s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [16:50:11<2:33:04, 141.30s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [16:52:28<2:29:18, 139.97s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [16:54:45<2:25:58, 139.03s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [16:57:02<2:23:02, 138.43s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [16:59:21<2:20:47, 138.48s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [17:03:03<2:43:38, 163.63s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [17:05:20<2:33:03, 155.66s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 14:32:50,439:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [17:07:46<2:27:40, 152.76s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [17:10:02<2:20:25, 147.82s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [17:12:20<2:15:02, 144.68s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [17:14:36<2:10:14, 142.08s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [17:16:52<2:06:25, 140.48s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 14:44:15,153:Timeout during comparison
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 14:44:20,194:Timeout during comparison
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 14:44:25,230:Timeout during comparison
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 14:44:30,275:Timeout during comparison
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 14:44:35,289:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [17:19:35<2:10:03, 147.23s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [17:21:55<2:05:37, 144.95s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [17:24:13<2:01:33, 143.01s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 14:51:39,677:Timeout during comparison
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 14:51:44,703:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [17:28:08<2:22:01, 170.42s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [17:30:25<2:10:56, 160.34s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [17:32:41<2:02:37, 153.29s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [17:35:00<1:56:31, 148.75s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [17:37:19<1:51:59, 146.07s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 15:04:42,699:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [17:39:42<1:48:47, 145.05s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [17:41:59<1:44:28, 142.47s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [17:44:15<1:40:50, 140.72s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [17:46:31<1:37:29, 139.28s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [17:48:48<1:34:42, 138.61s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [17:52:29<1:48:46, 163.16s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [17:54:48<1:41:30, 156.16s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [17:57:08<1:35:48, 151.26s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [17:59:26<1:30:48, 147.26s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [18:01:43<1:26:27, 144.09s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [18:03:59<1:22:37, 141.65s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [18:06:16<1:19:25, 140.17s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [18:08:33<1:16:39, 139.37s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [18:10:50<1:13:55, 138.61s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [18:13:07<1:11:20, 138.08s/it]
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650163)[0m   warnings.warn(
[36m(TaskRunner pid=646610)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [18:17:07<1:24:21, 168.71s/it]
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=646610)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [18:19:24<1:16:55, 159.16s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [18:21:41<1:11:10, 152.50s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [18:23:57<1:06:26, 147.65s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [18:26:15<1:02:46, 144.85s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [18:28:32<59:19, 142.39s/it]  
[36m(TaskRunner pid=646610)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [18:30:48<56:14, 140.59s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [18:33:05<53:25, 139.37s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [18:35:22<50:47, 138.53s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [18:37:39<48:20, 138.10s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [18:41:24<54:44, 164.22s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [18:43:41<49:25, 156.06s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [18:45:57<45:01, 150.08s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [18:48:15<41:28, 146.37s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [18:50:32<38:17, 143.59s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [18:52:51<35:34, 142.32s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [18:55:09<32:55, 141.07s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 16:22:32,240:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [18:57:30<30:33, 141.06s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [18:59:47<27:58, 139.88s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [19:02:05<25:31, 139.23s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 16:31:34,133:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [19:05:57<27:50, 167.00s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [19:08:16<23:46, 158.54s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [19:10:34<20:20, 152.60s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 16:37:58,749:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [19:12:58<17:29, 149.87s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [19:15:15<14:36, 146.12s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [19:17:32<11:56, 143.24s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [19:19:49<09:25, 141.45s/it]
[36m(TaskRunner pid=646610)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [19:22:07<07:01, 140.49s/it]
[36m(TaskRunner pid=646610)[0m WARNING:2025-12-15 16:49:34,741:Timeout during comparison
[36m(TaskRunner pid=646610)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [19:24:32<04:43, 141.71s/it]
[36m(TaskRunner pid=646610)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [19:26:51<02:21, 141.03s/it]
[36m(WorkerDict pid=650163)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=650163)[0m   warnings.warn(
[36m(TaskRunner pid=646610)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [19:30:53<02:26, 146.67s/it]
[36m(WorkerDict pid=650368)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=650368)[0m   warnings.warn([32m [repeated 3x across cluster][0m
