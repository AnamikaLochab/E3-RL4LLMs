
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_tw_covvar_0.0009/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_tw_covvar_0.0009//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_tw_covvar_0.0009//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_tw_covvar_0.0009//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_tw_covvar_0.0009/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-15 14:00:33,684	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8266 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=2464803)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 14:00:54,068:Waiting for register center actor 5pigrY_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2468579)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2468577)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=2468577)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=2468354)[0m [rank0]:[W1115 14:01:11.009551512 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=2468354)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2468354)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2468354)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468354)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m [rank2]:[W1115 14:01:12.121739241 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2468579)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2468354)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2468577)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(WorkerDict pid=2468354)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:   0%|          | 1/480 [01:58<15:49:08, 118.89s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   0%|          | 2/480 [03:57<15:45:24, 118.67s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   1%|          | 3/480 [06:01<16:04:15, 121.29s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   1%|          | 4/480 [07:58<15:49:01, 119.62s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   1%|          | 5/480 [09:58<15:46:05, 119.51s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   1%|â–         | 6/480 [12:00<15:50:48, 120.35s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   1%|â–         | 7/480 [14:01<15:52:03, 120.77s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   2%|â–         | 8/480 [16:01<15:48:32, 120.58s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   2%|â–         | 9/480 [18:00<15:40:58, 119.87s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   2%|â–         | 10/480 [21:19<18:50:36, 144.33s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   2%|â–         | 11/480 [23:15<17:39:32, 135.55s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   2%|â–Ž         | 12/480 [25:11<16:53:01, 129.87s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   3%|â–Ž         | 13/480 [27:09<16:20:43, 126.00s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   3%|â–Ž         | 14/480 [29:06<15:59:35, 123.55s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   3%|â–Ž         | 15/480 [31:02<15:38:17, 121.07s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   3%|â–Ž         | 16/480 [32:59<15:27:06, 119.88s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   4%|â–Ž         | 17/480 [34:58<15:23:31, 119.68s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   4%|â–         | 18/480 [36:54<15:12:01, 118.45s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   4%|â–         | 19/480 [38:51<15:07:57, 118.17s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   4%|â–         | 20/480 [42:10<18:10:58, 142.30s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   4%|â–         | 21/480 [44:08<17:13:15, 135.07s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   5%|â–         | 22/480 [46:07<16:33:46, 130.19s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   5%|â–         | 23/480 [48:04<16:02:38, 126.39s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   5%|â–Œ         | 24/480 [49:59<15:34:26, 122.95s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   5%|â–Œ         | 25/480 [51:53<15:10:50, 120.11s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   5%|â–Œ         | 26/480 [53:47<14:56:15, 118.45s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   6%|â–Œ         | 27/480 [55:47<14:56:27, 118.74s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   6%|â–Œ         | 28/480 [57:38<14:36:44, 116.38s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   6%|â–Œ         | 29/480 [59:34<14:36:01, 116.54s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   6%|â–‹         | 30/480 [1:02:39<17:06:00, 136.80s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 15:07:04,792:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:   6%|â–‹         | 31/480 [1:04:29<16:04:42, 128.92s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:14<15:09:38, 121.83s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 15:10:48,556:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:16<15:06:53, 121.73s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:09<14:44:47, 119.03s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:00<14:25:33, 116.71s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   8%|â–Š         | 36/480 [1:13:49<14:05:48, 114.30s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   8%|â–Š         | 37/480 [1:15:40<13:57:08, 113.38s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   8%|â–Š         | 38/480 [1:17:36<14:00:52, 114.14s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   8%|â–Š         | 39/480 [1:19:23<13:44:35, 112.19s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   8%|â–Š         | 40/480 [1:22:30<16:26:17, 134.49s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   9%|â–Š         | 41/480 [1:24:19<15:29:30, 127.04s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   9%|â–‰         | 42/480 [1:26:13<14:56:43, 122.84s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:00<14:21:47, 118.32s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   9%|â–‰         | 44/480 [1:29:48<13:57:21, 115.23s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:   9%|â–‰         | 45/480 [1:31:33<13:31:28, 111.93s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  10%|â–‰         | 46/480 [1:33:23<13:26:30, 111.50s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:11<13:17:40, 110.53s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:02<13:17:02, 110.70s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:38:57<13:22:49, 111.76s/it]
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(TaskRunner pid=2464803)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:42:13<16:22:01, 137.03s/it]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:00<15:16:08, 128.13s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:45:46<14:26:14, 121.44s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:47:28<13:43:34, 115.72s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:49:16<13:24:49, 113.36s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:51:01<13:06:03, 110.97s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:52:48<12:54:15, 109.57s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:54:37<12:51:56, 109.50s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:56:19<12:35:00, 107.35s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:58:03<12:25:11, 106.20s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:00:55<14:42:38, 126.09s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:02:43<14:02:08, 120.59s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:04:27<13:25:57, 115.69s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:06:12<13:00:43, 112.33s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:08:04<12:58:07, 112.23s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:09:49<12:40:26, 109.94s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:11:36<12:33:26, 109.19s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:13:20<12:21:35, 107.74s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:15:05<12:14:16, 106.93s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:16:53<12:14:18, 107.20s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:19:52<14:39:29, 128.71s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:21:39<13:52:12, 122.08s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:23:22<13:11:31, 116.40s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:25:08<12:47:46, 113.19s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:26:55<12:34:30, 111.50s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:28:38<12:15:40, 108.99s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:30:28<12:15:28, 109.23s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:32:16<12:11:12, 108.86s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:34:06<12:11:02, 109.11s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:35:54<12:08:13, 108.96s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:38:48<14:15:28, 128.32s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:40:33<13:27:03, 121.36s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:42:18<12:52:09, 116.41s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:44:04<12:29:38, 113.30s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:45:51<12:15:12, 111.39s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:47:38<12:04:28, 110.05s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:49:23<11:52:32, 108.51s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:51:11<11:50:20, 108.45s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:52:58<11:45:11, 107.94s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:54:40<11:32:38, 106.29s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:57:36<13:45:34, 127.01s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [2:59:17<12:53:45, 119.34s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:01:00<12:19:12, 114.31s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:02:44<11:58:55, 111.46s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 17:07:07,741:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 17:07:14,450:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:04:44<12:12:08, 113.81s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:06:27<11:50:17, 110.69s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 17:10:53,310:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:08:21<11:53:45, 111.53s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:10:01<11:30:45, 108.21s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:11:39<11:09:19, 105.13s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:13:30<11:17:55, 106.76s/it]
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(WorkerDict pid=2468354)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2468354)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=2464803)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:16:46<14:06:01, 133.58s/it]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:18:24<12:56:08, 122.87s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:20:06<12:14:59, 116.66s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:21:45<11:39:45, 111.37s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:23:25<11:17:00, 108.03s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:25:10<11:08:37, 106.98s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:26:50<10:54:54, 105.06s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:28:37<10:56:03, 105.53s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:30:18<10:46:08, 104.22s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:32:11<11:00:57, 106.89s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 17:38:10,392:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:35:14<13:19:10, 129.60s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:37:00<12:33:48, 122.57s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:38:38<11:46:57, 115.26s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:40:20<11:20:03, 111.18s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:42:04<11:06:22, 109.24s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:43:40<10:39:24, 105.11s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 17:48:03,303:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:45:26<10:39:02, 105.34s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:47:09<10:34:23, 104.86s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:48:53<10:31:02, 104.59s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:50:36<10:25:45, 104.00s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:53:33<12:35:01, 125.84s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:55:09<11:40:29, 117.07s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:56:57<11:22:07, 114.32s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 18:01:19,382:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:58:45<11:07:54, 112.25s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:00:42<11:14:00, 113.60s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:02:23<10:49:50, 109.83s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:04:05<10:35:11, 107.66s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:05:46<10:20:41, 105.50s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:07:31<10:18:14, 105.38s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:09:13<10:11:04, 104.46s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:12:07<12:11:22, 125.38s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:13:53<11:34:48, 119.45s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:15:33<10:59:20, 113.68s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:17:16<10:39:06, 110.51s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:19:00<10:25:40, 108.50s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:20:43<10:15:14, 107.00s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:22:26<10:06:22, 105.76s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:24:06<9:53:59, 103.90s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:25:50<9:53:03, 104.04s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:27:33<9:49:31, 103.73s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:30:28<11:49:09, 125.15s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:32:14<11:13:21, 119.18s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:33:54<10:40:04, 113.62s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:35:41<10:27:02, 111.64s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:37:24<10:10:18, 108.98s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:39:06<9:57:24, 107.00s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:40:44<9:39:51, 104.17s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:42:25<9:32:17, 103.11s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:44:07<9:29:39, 102.95s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:45:58<9:40:09, 105.16s/it]
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(TaskRunner pid=2464803)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:49:12<12:05:54, 131.98s/it]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:50:56<11:17:56, 123.64s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:52:41<10:44:12, 117.84s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:54:23<10:17:33, 113.31s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:56:11<10:05:53, 111.52s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:57:56<9:53:35, 109.59s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:59:36<9:35:55, 106.65s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:01:17<9:25:02, 104.96s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:03:04<9:27:44, 105.79s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:04:50<9:26:10, 105.83s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:07:48<11:18:50, 127.28s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:09:37<10:48:53, 122.05s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:11:23<10:20:25, 117.06s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:13:07<9:58:07, 113.21s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:14:49<9:37:39, 109.68s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:16:30<9:22:54, 107.22s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:18:14<9:16:01, 106.25s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:19:56<9:07:09, 104.89s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:21:42<9:08:03, 105.39s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:23:23<8:58:23, 103.87s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:26:20<10:51:04, 126.01s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:28:03<10:13:07, 119.05s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:29:44<9:43:55, 113.75s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:31:28<9:26:12, 110.66s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:33:08<9:07:46, 107.41s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:34:54<9:04:57, 107.21s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:36:40<9:00:45, 106.73s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:38:25<8:56:46, 106.29s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:40:12<8:55:24, 106.37s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:41:58<8:53:51, 106.42s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:45:00<10:44:42, 128.94s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 19:49:28,424:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:46:54<10:20:01, 124.42s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:48:39<9:48:59, 118.59s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:50:26<9:30:29, 115.25s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:52:07<9:07:43, 111.03s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:53:58<9:05:35, 110.97s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:55:42<8:53:09, 108.81s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:57:24<8:41:33, 106.80s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:59:11<8:40:13, 106.90s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:00:59<8:39:04, 107.03s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:03:58<10:21:43, 128.63s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:05:41<9:42:29, 120.93s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:07:23<9:13:47, 115.37s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:09:08<8:57:22, 112.34s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:10:50<8:40:55, 109.29s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:12:32<8:27:35, 106.86s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:14:20<8:28:08, 107.35s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:16:02<8:18:49, 105.76s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:17:47<8:15:21, 105.40s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:19:28<8:08:17, 104.26s/it]
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(TaskRunner pid=2464803)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:22:47<10:18:59, 132.64s/it]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:24:30<9:35:32, 123.77s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:26:15<9:07:27, 118.16s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:27:59<8:44:47, 113.67s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:29:39<8:25:04, 109.80s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:31:23<8:15:04, 108.01s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:33:09<8:10:13, 107.35s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:34:56<8:08:29, 107.36s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:36:33<7:52:08, 104.15s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:38:14<7:46:10, 103.21s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:41:13<9:26:11, 125.82s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:42:55<8:52:26, 118.76s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:44:38<8:29:24, 114.05s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:46:22<8:14:48, 111.19s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:48:06<8:02:29, 108.83s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:49:46<7:49:31, 106.31s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:51:26<7:39:00, 104.32s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:53:08<7:34:22, 103.66s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:54:44<7:22:47, 101.40s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:56:31<7:28:45, 103.16s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:59:25<8:58:40, 124.31s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:01:06<8:26:07, 117.25s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:02:49<8:05:42, 112.96s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:04:26<7:42:59, 108.09s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:06:09<7:35:03, 106.66s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:07:48<7:24:12, 104.52s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:09:25<7:12:02, 102.06s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 21:13:53,102:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:11:15<7:21:27, 104.69s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:12:56<7:14:15, 103.40s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:14:43<7:17:41, 104.63s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:17:40<8:45:46, 126.19s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:19:16<8:06:52, 117.32s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:20:56<7:43:14, 112.07s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:22:40<7:30:29, 109.43s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:24:16<7:13:16, 105.68s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:25:57<7:05:05, 104.10s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:27:34<6:54:40, 101.97s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:29:13<6:49:24, 101.09s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:30:57<6:51:03, 101.92s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:32:36<6:46:17, 101.15s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:35:32<8:14:08, 123.54s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:37:23<7:57:38, 119.91s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:39:03<7:31:51, 113.91s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:40:49<7:19:52, 111.36s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:42:30<7:06:30, 108.43s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:44:13<6:57:59, 106.72s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:45:52<6:46:57, 104.35s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:47:33<6:42:01, 103.53s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:49:15<6:37:42, 102.86s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:50:58<6:35:59, 102.85s/it]
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(TaskRunner pid=2464803)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:54:14<8:21:49, 130.91s/it]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:55:51<7:40:55, 120.77s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:57:31<7:15:24, 114.58s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:59:12<6:57:39, 110.39s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:00:52<6:43:41, 107.18s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:02:30<6:32:23, 104.64s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:04:12<6:27:36, 103.82s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:05:50<6:18:50, 101.93s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:07:31<6:16:42, 101.81s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:09:07<6:08:11, 99.96s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:12:00<7:27:22, 122.01s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:13:43<7:03:40, 116.08s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:15:25<6:46:28, 111.88s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:17:07<6:34:20, 109.04s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:18:52<6:28:35, 107.94s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:20:31<6:17:15, 105.28s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:22:13<6:11:01, 104.02s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:23:52<6:04:33, 102.69s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:25:29<5:57:08, 101.08s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:27:09<5:53:53, 100.63s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:30:05<7:11:14, 123.21s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:31:51<6:50:56, 117.97s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:33:27<6:26:50, 111.59s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:35:08<6:14:02, 108.42s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:36:51<6:06:39, 106.79s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:38:31<5:57:47, 104.72s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:40:16<5:55:46, 104.64s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:42:03<5:56:33, 105.38s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:43:45<5:51:23, 104.38s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:45:29<5:49:23, 104.30s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:48:27<7:00:57, 126.29s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:50:04<6:30:06, 117.62s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:51:45<6:11:13, 112.49s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:53:28<6:00:25, 109.77s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:55:14<5:54:39, 108.57s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:56:58<5:49:07, 107.43s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:58:39<5:41:07, 105.50s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:00:22<5:36:09, 104.51s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:02:04<5:32:27, 103.89s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:03:46<5:29:09, 103.40s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:06:49<6:42:54, 127.23s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:08:30<6:15:51, 119.32s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:10:13<5:58:53, 114.54s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:11:53<5:43:03, 110.07s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:13:32<5:31:12, 106.84s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:15:16<5:26:48, 105.99s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:17:03<5:25:34, 106.17s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:18:40<5:15:22, 103.40s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:20:23<5:13:00, 103.19s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:22:06<5:11:00, 103.10s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 23:26:26,723:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 23:26:33,768:Timeout during comparison
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(TaskRunner pid=2464803)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:25:27<6:37:44, 132.58s/it]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:27:10<6:08:52, 123.64s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:28:49<5:44:48, 116.23s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:30:31<5:30:34, 112.06s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:32:13<5:19:47, 109.02s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:33:51<5:08:41, 105.84s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:35:31<5:01:46, 104.06s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:37:11<4:55:56, 102.64s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:38:50<4:51:39, 101.74s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:40:33<4:50:54, 102.07s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:43:28<5:51:05, 123.92s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:45:09<5:29:45, 117.08s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:46:51<5:15:04, 112.53s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:48:33<5:04:24, 109.37s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:50:18<4:59:06, 108.11s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:52:02<4:54:03, 106.93s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:53:51<4:53:22, 107.33s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-15 23:58:14,782:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:55:35<4:49:36, 106.61s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:57:17<4:43:59, 105.18s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-16 00:01:39,826:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:59:06<4:44:55, 106.18s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:02:05<5:41:33, 128.08s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:03:51<5:21:55, 121.48s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-16 00:08:13,590:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-16 00:08:18,615:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:05:41<5:10:30, 117.91s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:07:22<4:55:41, 113.00s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:09:11<4:50:46, 111.84s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:10:57<4:44:21, 110.07s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:12:43<4:39:16, 108.81s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:14:29<4:35:26, 108.02s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:16:16<4:32:19, 107.50s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:17:57<4:26:14, 105.79s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:20:56<5:18:43, 127.49s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:22:34<4:55:06, 118.84s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:24:14<4:39:12, 113.19s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:26:00<4:32:14, 111.12s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:27:41<4:22:49, 108.01s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:29:22<4:15:44, 105.83s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:31:05<4:11:43, 104.88s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:32:50<4:10:27, 105.09s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:34:32<4:06:13, 104.04s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:36:10<4:00:30, 102.34s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:39:06<4:50:32, 124.52s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:40:48<4:32:42, 117.71s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:42:34<4:22:45, 114.24s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:44:18<4:13:33, 111.05s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:45:56<4:02:29, 106.98s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:47:38<3:57:51, 105.71s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:49:20<3:53:28, 104.54s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:51:03<3:50:36, 104.03s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:52:48<3:49:13, 104.20s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:54:25<3:43:23, 102.32s/it]
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(TaskRunner pid=2464803)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:57:39<4:41:02, 129.71s/it]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:59:24<4:23:01, 122.34s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:01:09<4:10:04, 117.22s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:02:56<4:01:29, 114.09s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:04:40<3:53:01, 110.97s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:06:23<3:46:12, 108.58s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:08:05<3:40:10, 106.53s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:09:47<3:35:30, 105.13s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:11:28<3:31:16, 103.90s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:13:17<3:32:40, 105.45s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:16:13<4:13:07, 126.56s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:17:56<3:57:01, 119.51s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:19:40<3:46:11, 115.01s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:21:20<3:35:26, 110.48s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:23:00<3:27:33, 107.36s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:24:38<3:20:15, 104.48s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:26:15<3:14:37, 102.44s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:27:54<3:10:57, 101.39s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:29:36<3:09:22, 101.45s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-16 01:34:00,528:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:31:22<3:10:01, 102.71s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:34:20<3:50:08, 125.53s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:36:03<3:35:17, 118.51s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:37:47<3:25:42, 114.28s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:39:32<3:18:39, 111.40s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:41:08<3:08:48, 106.87s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:42:51<3:04:48, 105.61s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:44:30<2:59:55, 103.81s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:46:12<2:56:55, 103.06s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:47:52<2:53:46, 102.22s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:49:31<2:50:36, 101.35s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:52:25<3:25:13, 123.14s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:54:07<3:12:48, 116.85s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:55:50<3:03:50, 112.56s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:57:33<2:57:36, 109.86s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:59:25<2:56:42, 110.44s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:01:07<2:50:35, 107.75s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:02:48<2:46:00, 105.96s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:04:35<2:44:25, 106.08s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-16 02:08:58,596:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:06:22<2:43:12, 106.43s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:08:08<2:41:08, 106.25s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:11:04<3:10:51, 127.24s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:12:47<2:57:52, 119.92s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:14:27<2:47:06, 113.94s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:16:04<2:37:47, 108.82s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:17:43<2:31:53, 105.97s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:19:31<2:30:52, 106.50s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:21:09<2:25:25, 103.88s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:22:48<2:21:42, 102.44s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:24:28<2:19:08, 101.81s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:26:08<2:16:36, 101.19s/it]
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(TaskRunner pid=2464803)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:29:19<2:51:06, 128.33s/it]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:31:02<2:38:36, 120.47s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:32:47<2:30:37, 115.86s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:34:31<2:24:03, 112.25s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:36:13<2:18:18, 109.19s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:37:50<2:12:02, 105.63s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:39:34<2:09:53, 105.32s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:41:18<2:07:32, 104.83s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:43:03<2:05:46, 104.81s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:44:44<2:02:50, 103.81s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:47:43<2:27:09, 126.14s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:49:24<2:16:23, 118.60s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:51:04<2:08:14, 113.15s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:52:42<2:01:22, 108.70s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:54:25<1:57:29, 106.80s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:56:01<1:52:14, 103.60s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:57:40<1:49:07, 102.30s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:59:25<1:48:09, 103.00s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:01:08<1:46:25, 102.99s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:02:51<1:44:47, 103.07s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:05:53<2:06:45, 126.76s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:07:33<1:56:44, 118.73s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:09:22<1:51:57, 115.83s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:11:02<1:45:32, 111.09s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:12:47<1:41:52, 109.15s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:14:29<1:38:00, 106.92s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:16:08<1:34:19, 104.80s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:17:51<1:31:57, 104.11s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:19:34<1:30:04, 103.92s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:21:14<1:27:21, 102.77s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:24:10<1:43:51, 124.63s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:25:51<1:36:01, 117.58s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:27:29<1:29:25, 111.77s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:29:16<1:26:16, 110.13s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:30:55<1:21:59, 106.94s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:32:35<1:18:39, 104.88s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:34:17<1:16:13, 103.95s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:35:57<1:13:34, 102.67s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:37:39<1:11:52, 102.67s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:39:22<1:10:01, 102.48s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:42:14<1:22:23, 123.58s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-16 03:46:38,151:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:44:00<1:16:55, 118.35s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:45:46<1:12:35, 114.61s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:47:26<1:07:59, 110.25s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:49:07<1:04:29, 107.50s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:50:48<1:01:31, 105.48s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:52:25<58:12, 102.71s/it]  
[36m(TaskRunner pid=2464803)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:54:00<55:20, 100.61s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:55:36<52:53, 99.19s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:57:19<51:50, 100.35s/it]
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(TaskRunner pid=2464803)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:00:26<1:03:09, 126.30s/it]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2464803)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:02:07<57:25, 118.80s/it]  
[36m(TaskRunner pid=2464803)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:03:43<52:16, 112.02s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:05:25<48:57, 108.80s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:07:02<45:42, 105.47s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:08:36<42:30, 102.00s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:10:13<40:10, 100.42s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:11:59<39:06, 102.02s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:13:38<37:03, 101.07s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:15:14<34:49, 99.52s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:18:10<40:51, 122.59s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:19:48<36:30, 115.26s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:21:27<33:04, 110.27s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:23:07<30:20, 107.10s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:24:45<27:50, 104.39s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:26:28<25:59, 104.00s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:28:06<23:52, 102.32s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:29:42<21:45, 100.43s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:31:22<20:01, 100.12s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:32:58<18:07, 98.88s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:35:55<20:24, 122.45s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:37:31<17:11, 114.66s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:39:10<14:38, 109.87s/it]
[36m(TaskRunner pid=2464803)[0m WARNING:2025-11-16 04:43:33,779:Timeout during comparison
[36m(TaskRunner pid=2464803)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:40:55<12:38, 108.36s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:42:35<10:35, 105.93s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:44:10<08:32, 102.48s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:45:48<06:45, 101.38s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:47:25<04:59, 99.96s/it] 
[36m(TaskRunner pid=2464803)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:49:10<03:22, 101.47s/it]
[36m(TaskRunner pid=2464803)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:50:56<01:42, 102.73s/it]
[36m(WorkerDict pid=2468354)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2468354)[0m   warnings.warn(
[36m(TaskRunner pid=2464803)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:54:09<01:52, 112.00s/it]
[36m(WorkerDict pid=2468578)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2468578)[0m   warnings.warn([32m [repeated 3x across cluster][0m
