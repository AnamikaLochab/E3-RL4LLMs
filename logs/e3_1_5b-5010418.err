
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_grpo_3/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_grpo_3//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_grpo_3//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_grpo_3//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=grpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_grpo_3/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-28 15:17:34,409	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=3897637)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 15:17:54,774:Waiting for register center actor 8yHTvA_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=3901399)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3901399)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=3901399)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=3901191)[0m [rank0]:[W1128 15:18:13.582993617 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=3901191)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3901191)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3901400)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m [rank2]:[W1128 15:18:13.810389993 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=3901191)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3901399)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3901399)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3901399)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=3901399)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901399)[0m   warnings.warn(
[36m(WorkerDict pid=3901400)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:   0%|          | 1/480 [01:58<15:45:12, 118.40s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   0%|          | 2/480 [03:56<15:43:04, 118.38s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   1%|          | 3/480 [06:00<16:00:22, 120.80s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   1%|          | 4/480 [07:56<15:44:13, 119.02s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   1%|          | 5/480 [09:55<15:42:15, 119.02s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   1%|â–         | 6/480 [11:56<15:44:54, 119.61s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   1%|â–         | 7/480 [13:59<15:52:17, 120.80s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   2%|â–         | 8/480 [15:59<15:47:51, 120.49s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   2%|â–         | 9/480 [17:59<15:44:56, 120.37s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 15:39:38,968:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:   2%|â–         | 10/480 [21:32<19:26:16, 148.89s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   2%|â–         | 11/480 [23:30<18:10:24, 139.50s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   2%|â–Ž         | 12/480 [25:26<17:12:35, 132.38s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   3%|â–Ž         | 13/480 [27:24<16:36:11, 127.99s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   3%|â–Ž         | 14/480 [29:24<16:14:04, 125.42s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   3%|â–Ž         | 15/480 [31:19<15:49:30, 122.52s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   3%|â–Ž         | 16/480 [33:18<15:37:15, 121.20s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   4%|â–Ž         | 17/480 [35:16<15:28:51, 120.37s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   4%|â–         | 18/480 [37:12<15:17:06, 119.10s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   4%|â–         | 19/480 [39:10<15:12:41, 118.79s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   4%|â–         | 20/480 [42:33<18:25:09, 144.15s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   4%|â–         | 21/480 [44:31<17:20:51, 136.06s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   5%|â–         | 22/480 [46:29<16:37:22, 130.66s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   5%|â–         | 23/480 [48:25<16:03:27, 126.49s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 16:10:01,519:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:   5%|â–Œ         | 24/480 [50:24<15:43:55, 124.20s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   5%|â–Œ         | 25/480 [52:17<15:15:59, 120.79s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   5%|â–Œ         | 26/480 [54:12<15:00:00, 118.94s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   6%|â–Œ         | 27/480 [56:14<15:04:48, 119.84s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   6%|â–Œ         | 28/480 [58:05<14:44:02, 117.35s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:02<14:40:39, 117.16s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:10<17:18:31, 138.47s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   6%|â–‹         | 31/480 [1:04:55<16:01:19, 128.46s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:42<15:10:29, 121.94s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:36<14:50:55, 119.59s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:30<14:35:48, 117.82s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:21<14:18:42, 115.78s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:10<14:01:03, 113.66s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:01<13:53:30, 112.89s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   8%|â–Š         | 38/480 [1:17:58<14:00:35, 114.11s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   8%|â–Š         | 39/480 [1:19:44<13:40:40, 111.66s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   8%|â–Š         | 40/480 [1:22:50<16:23:28, 134.11s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   9%|â–Š         | 41/480 [1:24:38<15:24:48, 126.40s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   9%|â–‰         | 42/480 [1:26:31<14:53:26, 122.39s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:19<14:19:25, 118.00s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:09<13:58:24, 115.38s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:   9%|â–‰         | 45/480 [1:31:53<13:32:07, 112.02s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  10%|â–‰         | 46/480 [1:33:44<13:29:29, 111.91s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:32<13:17:35, 110.52s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:25<13:20:51, 111.23s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:18<13:22:49, 111.76s/it]
[36m(WorkerDict pid=3901191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901191)[0m   warnings.warn(
[36m(TaskRunner pid=3897637)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:42:37<16:29:57, 138.13s/it]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:25<15:23:08, 129.11s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:14<14:37:59, 123.08s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:47:57<13:52:44, 117.01s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:49:45<13:32:15, 114.40s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:51:30<13:10:09, 111.55s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:17<12:58:01, 110.10s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:05<12:52:06, 109.52s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:56:49<12:39:02, 107.92s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:58:38<12:38:22, 108.08s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:01:30<14:51:41, 127.38s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:03:17<14:06:09, 121.17s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:01<13:28:52, 116.11s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:06:44<13:00:06, 112.25s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 17:28:19,118:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:08:40<13:04:58, 113.22s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:10:22<12:39:47, 109.85s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:12:11<12:36:58, 109.71s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:13:54<12:20:46, 107.62s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:15:40<12:16:29, 107.26s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:17:26<12:11:24, 106.77s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 17:38:56,959:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:20:31<14:50:04, 130.25s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:22:18<14:00:22, 123.28s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:24:03<13:19:41, 117.60s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:25:47<12:50:19, 113.56s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:27:36<12:40:15, 112.35s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:29:21<12:23:01, 110.08s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:31:09<12:16:50, 109.43s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:32:56<12:09:23, 108.59s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:34:41<12:02:19, 107.81s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:36:28<11:58:35, 107.52s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:39:24<14:12:32, 127.88s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:41:09<13:25:11, 121.08s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:42:55<12:53:14, 116.57s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:44:41<12:29:33, 113.28s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:46:27<12:13:42, 111.17s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:48:12<11:59:39, 109.32s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:49:56<11:47:47, 107.79s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:51:43<11:44:34, 107.57s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:53:30<11:41:37, 107.39s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:55:12<11:29:09, 105.75s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:58:06<13:40:53, 126.29s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [2:59:48<12:50:17, 118.81s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 18:21:12,958:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 18:21:18,929:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 18:21:24,694:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:01:43<12:41:47, 117.80s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:03:28<12:14:57, 113.95s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:05:16<12:02:29, 112.30s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:07:00<11:43:25, 109.62s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:08:48<11:38:46, 109.18s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:10:29<11:21:10, 106.71s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 18:31:54,308:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:12:10<11:08:49, 105.05s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:14:04<11:23:47, 107.68s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 18:35:32,548:Timeout during comparison
[36m(WorkerDict pid=3901191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901191)[0m   warnings.warn(
[36m(WorkerDict pid=3901191)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=3901191)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=3897637)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:17:21<14:12:04, 134.54s/it]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:19:03<13:07:44, 124.71s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:20:48<12:27:42, 118.68s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:22:29<11:53:25, 113.54s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:24:09<11:26:31, 109.55s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:25:55<11:17:33, 108.41s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:27:34<10:57:49, 105.53s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:29:21<10:59:06, 106.02s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:31:02<10:47:25, 104.42s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:32:54<11:00:25, 106.81s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:35:50<13:06:48, 127.59s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:37:35<12:21:53, 120.63s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:39:11<11:35:06, 113.33s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:40:55<11:15:54, 110.50s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:42:41<11:06:24, 109.25s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:44:16<10:38:16, 104.92s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:45:55<10:25:40, 103.13s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:47:37<10:22:31, 102.90s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:49:22<10:24:28, 103.51s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 19:10:50,031:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:51:09<10:28:26, 104.45s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:54:06<12:37:19, 126.22s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:55:44<11:44:22, 117.72s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:57:30<11:21:12, 114.17s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 19:18:56,893:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:59:17<11:07:42, 112.22s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:01:16<11:17:03, 114.11s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:02:59<10:55:11, 110.74s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:04:41<10:38:07, 108.16s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:06:22<10:23:12, 105.93s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:08:05<10:17:49, 105.31s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:09:49<10:12:24, 104.69s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:12:40<12:07:08, 124.65s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:14:24<11:30:00, 118.63s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 19:35:50,523:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:16:08<11:01:10, 114.00s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:17:51<10:41:30, 110.93s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:19:34<10:25:29, 108.47s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:21:18<10:16:21, 107.19s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:23:01<10:06:09, 105.73s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:24:42<9:56:24, 104.33s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:26:26<9:54:37, 104.32s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:28:11<9:53:23, 104.41s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:31:01<11:44:16, 124.28s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:32:42<11:03:02, 117.35s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:34:21<10:28:40, 111.60s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:36:04<10:12:34, 109.06s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:37:42<9:51:56, 105.70s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:39:21<9:39:09, 103.73s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:40:56<9:23:39, 101.26s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:42:33<9:14:09, 99.85s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:44:13<9:13:37, 100.05s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:45:58<9:19:37, 101.44s/it]
[36m(WorkerDict pid=3901191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901191)[0m   warnings.warn(
[36m(TaskRunner pid=3897637)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:49:07<11:42:41, 127.76s/it]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:50:52<11:02:53, 120.89s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:52:37<10:34:24, 116.05s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:54:17<10:07:02, 111.38s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:56:02<9:55:01, 109.51s/it] 
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 20:17:30,944:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:57:49<9:48:10, 108.58s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:59:28<9:31:30, 105.83s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:01:10<9:22:28, 104.48s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:02:56<9:22:56, 104.90s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:04:38<9:16:49, 104.08s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:07:33<11:09:13, 125.48s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:09:22<10:41:25, 120.64s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:11:09<10:17:04, 116.43s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:12:47<9:46:17, 110.97s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:14:27<9:27:26, 107.74s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:16:09<9:15:06, 105.74s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:17:52<9:10:17, 105.15s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:19:30<8:57:11, 102.98s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:21:15<8:58:43, 103.60s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:22:53<8:47:24, 101.75s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:25:47<10:37:23, 123.37s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:27:30<10:03:53, 117.26s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:29:11<9:37:42, 112.54s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:30:52<9:17:15, 108.91s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 20:52:15,787:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:32:35<9:06:29, 107.15s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:34:17<8:57:16, 105.69s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:35:59<8:50:46, 104.76s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:37:43<8:47:45, 104.51s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:39:27<8:44:05, 104.12s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:41:08<8:38:53, 103.43s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:44:10<10:33:50, 126.77s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:45:53<9:57:11, 119.84s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:47:34<9:26:15, 114.01s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:49:16<9:07:01, 110.51s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:50:54<8:46:59, 106.82s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:52:42<8:46:16, 107.04s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:54:24<8:37:15, 105.56s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 21:15:45,400:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:56:07<8:31:51, 104.82s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:57:49<8:26:24, 104.05s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:59:35<8:27:10, 104.57s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:02:29<10:05:23, 125.25s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:04:07<9:24:03, 117.10s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:05:45<8:54:30, 111.36s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:07:23<8:34:41, 107.60s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:09:05<8:24:32, 105.85s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:10:44<8:13:12, 103.83s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:12:28<8:10:40, 103.66s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:14:05<8:00:31, 101.88s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:15:47<7:58:31, 101.81s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:17:26<7:52:48, 100.96s/it]
[36m(WorkerDict pid=3901191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901191)[0m   warnings.warn(
[36m(TaskRunner pid=3897637)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:20:37<9:57:55, 128.13s/it]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:22:20<9:19:26, 120.31s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:24:04<8:55:13, 115.52s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:25:45<8:33:11, 111.16s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:27:26<8:17:19, 108.11s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:29:07<8:06:06, 106.06s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:30:52<8:03:04, 105.78s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 21:52:25,701:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:32:46<8:12:02, 108.14s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:34:26<7:59:12, 105.71s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:36:06<7:50:08, 104.09s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:39:07<9:31:55, 127.10s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:40:50<8:56:43, 119.72s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 22:02:19,737:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:42:41<8:44:11, 117.36s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:44:26<8:25:03, 113.50s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:46:08<8:07:37, 109.99s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:47:47<7:51:11, 106.69s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:49:27<7:41:36, 104.91s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:51:06<7:32:06, 103.14s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:52:43<7:22:14, 101.28s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:54:32<7:30:28, 103.56s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:57:25<8:58:56, 124.37s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:59:05<8:25:17, 117.06s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:00:50<8:07:45, 113.43s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:02:22<7:38:41, 107.09s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:04:02<7:27:21, 104.85s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:05:42<7:19:08, 103.33s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:07:21<7:11:36, 101.95s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:09:03<7:10:33, 102.11s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:10:43<7:06:01, 101.43s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:12:25<7:04:51, 101.56s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:15:16<8:29:39, 122.32s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:16:51<7:54:41, 114.38s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:18:30<7:33:37, 109.75s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:20:09<7:18:19, 106.48s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:21:45<7:03:45, 103.36s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:23:22<6:54:16, 101.46s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:24:58<6:45:10, 99.63s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:26:34<6:39:56, 98.75s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:28:19<6:45:24, 100.52s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:29:56<6:39:12, 99.39s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:32:48<8:05:19, 121.33s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:34:36<7:46:39, 117.15s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:36:20<7:29:54, 113.42s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:38:01<7:12:45, 109.56s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:39:42<7:00:53, 107.01s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:41:25<6:55:00, 105.96s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:43:04<6:44:56, 103.83s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:44:43<6:37:39, 102.40s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:46:28<6:38:05, 102.96s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:48:08<6:33:10, 102.12s/it]
[36m(WorkerDict pid=3901191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901191)[0m   warnings.warn(
[36m(TaskRunner pid=3897637)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:51:17<8:11:13, 128.14s/it]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:52:55<7:34:41, 119.13s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:54:32<7:07:21, 112.46s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:56:08<6:47:17, 107.65s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 23:17:30,414:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:57:48<6:36:16, 105.21s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:59:23<6:23:52, 102.36s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:01:03<6:19:11, 101.57s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:02:38<6:10:17, 99.63s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:04:20<6:11:06, 100.30s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 23:25:44,198:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:06:00<6:08:50, 100.14s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:08:45<7:18:29, 119.59s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:10:22<6:52:13, 112.94s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:12:01<6:34:27, 108.56s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:13:40<6:22:36, 105.79s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:15:23<6:17:29, 104.86s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:17:01<6:08:39, 102.88s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:18:38<6:01:09, 101.26s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:20:17<5:56:49, 100.51s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:21:51<5:48:24, 98.61s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:23:30<5:46:30, 98.53s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 23:44:54,382:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-28 23:44:59,391:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:26:29<7:09:18, 122.66s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:28:08<6:43:17, 115.78s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:29:42<6:18:35, 109.21s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:31:18<6:02:53, 105.19s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:32:59<5:57:00, 103.98s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:34:35<5:46:42, 101.48s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:36:15<5:43:29, 101.03s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:37:55<5:40:46, 100.72s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:39:32<5:36:04, 99.82s/it] 
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 00:00:56,805:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:41:19<5:41:17, 101.88s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:44:08<6:46:28, 121.94s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:45:40<6:14:24, 112.89s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:47:18<5:57:44, 108.41s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 00:08:41,585:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:49:02<5:51:45, 107.13s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:50:50<5:50:56, 107.43s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:52:32<5:43:50, 105.80s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:54:10<5:34:31, 103.46s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:55:51<5:30:34, 102.77s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:57:33<5:28:22, 102.62s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:59:12<5:22:45, 101.39s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:02:08<6:31:52, 123.75s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:03:47<6:06:39, 116.40s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:05:27<5:49:11, 111.45s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:07:05<5:34:44, 107.40s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:08:47<5:28:07, 105.85s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:10:29<5:22:56, 104.74s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:12:14<5:21:36, 104.87s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:13:52<5:13:06, 102.66s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:15:35<5:11:36, 102.73s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:17:14<5:06:59, 101.76s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 00:38:39,333:Timeout during comparison
[36m(WorkerDict pid=3901191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901191)[0m   warnings.warn(
[36m(TaskRunner pid=3897637)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:20:27<6:27:27, 129.15s/it]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:22:12<6:03:07, 121.72s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:23:51<5:41:26, 115.09s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:25:35<5:29:10, 111.59s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:27:18<5:19:40, 108.98s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:28:55<5:07:54, 105.57s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:30:36<5:02:06, 104.18s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:32:12<4:53:24, 101.76s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:33:52<4:50:11, 101.23s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:35:37<4:51:25, 102.25s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:38:28<5:48:08, 122.87s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:40:05<5:24:15, 115.12s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:41:46<5:10:22, 110.85s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:43:25<4:58:32, 107.26s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:45:04<4:50:17, 104.93s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:46:48<4:47:13, 104.45s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:48:34<4:47:17, 105.10s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:50:07<4:35:39, 101.47s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:51:47<4:32:39, 100.98s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:53:26<4:29:14, 100.34s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:56:16<5:23:44, 121.40s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:57:56<5:04:15, 114.82s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 01:19:18,543:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 01:19:24,293:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 01:19:29,316:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 01:19:36,014:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:59:55<5:05:29, 116.01s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:01:31<4:47:42, 109.95s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:03:13<4:40:14, 107.78s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:04:53<4:31:56, 105.27s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:06:35<4:27:55, 104.38s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:08:16<4:23:42, 103.42s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:09:57<4:19:57, 102.62s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:11:33<4:13:04, 100.56s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:14:22<5:03:05, 121.24s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:15:57<4:41:13, 113.25s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:17:32<4:26:16, 107.95s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:19:18<4:22:38, 107.20s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:20:55<4:13:55, 104.35s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:22:32<4:06:29, 102.00s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:24:12<4:03:20, 101.39s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:25:51<4:00:13, 100.79s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:27:34<3:59:37, 101.25s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:29:11<3:55:04, 100.03s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:32:07<4:46:43, 122.88s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:33:51<4:31:16, 117.10s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:35:32<4:18:30, 112.40s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:37:12<4:08:16, 108.74s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:38:49<3:58:09, 105.07s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:40:33<3:55:34, 104.70s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:42:15<3:52:09, 103.95s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:43:56<3:48:29, 103.08s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:45:39<3:46:40, 103.03s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:47:18<3:42:11, 101.77s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 02:10:19,134:Timeout during comparison
[36m(WorkerDict pid=3901191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901191)[0m   warnings.warn(
[36m(TaskRunner pid=3897637)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:50:37<4:44:14, 131.19s/it]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:52:24<4:26:27, 123.93s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:54:12<4:13:52, 119.00s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:55:58<4:03:52, 115.22s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:57:46<3:57:27, 113.07s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:59:30<3:49:48, 110.31s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:01:11<3:42:08, 107.49s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:02:56<3:38:27, 106.57s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:04:33<3:31:03, 103.80s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:06:23<3:33:14, 105.74s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:09:22<4:15:22, 127.69s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:11:07<3:59:31, 120.77s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:12:51<3:47:40, 115.77s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:14:37<3:40:00, 112.82s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:16:15<3:29:39, 108.45s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 02:37:39,021:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:17:59<3:25:18, 107.12s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:19:37<3:18:19, 104.38s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:21:13<3:11:47, 101.84s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:22:55<3:10:12, 101.90s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 02:44:18,895:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:24:37<3:08:30, 101.89s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:27:35<3:48:53, 124.85s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:29:15<3:33:22, 117.45s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:30:56<3:22:05, 112.27s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 02:52:23,756:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:32:46<3:18:55, 111.55s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:34:21<3:08:30, 106.70s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:36:02<3:03:55, 105.10s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:37:40<2:58:35, 103.03s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:39:19<2:54:45, 101.80s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:40:59<2:51:53, 101.12s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:42:33<2:46:30, 98.91s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:45:20<3:19:13, 119.54s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:46:59<3:06:59, 113.33s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 03:08:21,095:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 03:08:26,862:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:48:48<3:02:39, 111.83s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:50:28<2:55:26, 108.52s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:52:12<2:51:28, 107.18s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:53:47<2:43:58, 103.56s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:55:23<2:38:36, 101.24s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:57:04<2:36:47, 101.15s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:58:40<2:32:34, 99.50s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:00:18<2:30:21, 99.13s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:03:08<3:00:31, 120.35s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:04:48<2:49:25, 114.22s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:06:24<2:39:40, 108.86s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:07:56<2:30:19, 103.67s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:09:31<2:24:55, 101.11s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:11:13<2:23:37, 101.39s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:12:47<2:18:43, 99.09s/it] 
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 03:34:10,595:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:14:27<2:17:34, 99.45s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:16:05<2:15:28, 99.13s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:17:43<2:13:05, 98.59s/it]
[36m(WorkerDict pid=3901191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901191)[0m   warnings.warn(
[36m(TaskRunner pid=3897637)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:20:47<2:45:40, 124.26s/it]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:22:24<2:32:54, 116.14s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:24:03<2:24:13, 110.95s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:25:41<2:17:34, 107.21s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:27:17<2:11:26, 103.77s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:28:48<2:04:49, 99.85s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:30:25<2:02:02, 98.95s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:32:04<2:00:20, 98.91s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:33:41<1:58:09, 98.47s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:35:17<1:55:35, 97.69s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:38:10<2:20:15, 120.22s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:39:46<2:09:58, 113.02s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:41:21<2:01:57, 107.61s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:42:57<1:56:24, 104.24s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:44:36<1:52:42, 102.46s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:46:03<1:46:12, 98.03s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:47:39<1:43:57, 97.47s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:49:17<1:42:20, 97.47s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:50:52<1:40:02, 96.82s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:52:28<1:38:04, 96.47s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:55:19<1:58:50, 118.83s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:56:56<1:50:21, 112.23s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:58:38<1:45:43, 109.37s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:00:14<1:40:06, 105.38s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:01:51<1:35:50, 102.68s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:03:29<1:32:51, 101.30s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:05:05<1:29:39, 99.61s/it] 
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 04:26:24,019:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:06:44<1:28:00, 99.64s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:08:26<1:26:51, 100.22s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:10:04<1:24:32, 99.46s/it] 
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 04:31:24,181:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:12:54<1:40:44, 120.89s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:14:29<1:32:20, 113.07s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:16:03<1:25:50, 107.30s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:17:44<1:22:38, 105.51s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:19:17<1:17:57, 101.69s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:20:51<1:14:31, 99.37s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:22:26<1:11:52, 98.00s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:24:01<1:09:34, 97.07s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:25:37<1:07:41, 96.70s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:27:12<1:05:50, 96.35s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:29:59<1:18:21, 117.54s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:31:33<1:11:44, 110.37s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:33:11<1:07:34, 106.69s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:34:48<1:04:03, 103.87s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:36:26<1:01:10, 101.95s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:38:03<58:36, 100.47s/it]  
[36m(TaskRunner pid=3897637)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:39:34<55:24, 97.78s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:41:07<52:52, 96.13s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:42:41<50:58, 95.56s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:44:18<49:40, 96.14s/it]
[36m(WorkerDict pid=3901191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901191)[0m   warnings.warn(
[36m(TaskRunner pid=3897637)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:47:22<1:01:15, 122.52s/it]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=3897637)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:48:58<55:18, 114.44s/it]  
[36m(TaskRunner pid=3897637)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:50:30<50:18, 107.79s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:52:07<46:57, 104.37s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:53:42<44:04, 101.73s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:55:13<41:05, 98.60s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:56:47<38:47, 96.99s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:58:27<37:33, 97.96s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:00:06<36:00, 98.20s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:01:41<34:03, 97.29s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:04:29<39:32, 118.62s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:06:08<35:43, 112.81s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:07:43<32:13, 107.40s/it]
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 05:29:05,187:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m WARNING:2025-11-29 05:29:11,179:Timeout during comparison
[36m(TaskRunner pid=3897637)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:09:28<30:13, 106.68s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:11:00<27:16, 102.30s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:12:38<25:12, 100.82s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:14:14<23:13, 99.56s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:15:51<21:24, 98.80s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:17:28<19:38, 98.25s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:19:03<17:50, 97.34s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:21:57<20:03, 120.30s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:23:33<16:56, 112.99s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:25:11<14:28, 108.53s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:26:47<12:13, 104.74s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:28:23<10:11, 101.88s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:29:56<08:17, 99.49s/it] 
[36m(TaskRunner pid=3897637)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:31:34<06:35, 98.94s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:33:08<04:52, 97.38s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:34:48<03:16, 98.17s/it]
[36m(TaskRunner pid=3897637)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:36:30<01:39, 99.34s/it]
[36m(WorkerDict pid=3901191)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3901191)[0m   warnings.warn(
[36m(TaskRunner pid=3897637)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:39:43<01:50, 110.19s/it]
[36m(WorkerDict pid=3901400)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3901400)[0m   warnings.warn([32m [repeated 3x across cluster][0m
