
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_covvar_kappa_1.0/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_covvar_kappa_1.0//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa_1.0//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa_1.0//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_covvar_kappa_1.0/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-09 18:39:02,299	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8266 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=1617478)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 18:39:41,538:Waiting for register center actor jsLJtz_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=1620966)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=1620750)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=1620750)[0m [rank0]:[W1109 18:40:10.053990785 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=1620750)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1620750)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620965)[0m [rank1]:[W1109 18:40:10.385132783 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620750)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1620967)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1620750)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1620750)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1620965)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1620966)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620966)[0m   warnings.warn(
[36m(WorkerDict pid=1620967)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:   0%|          | 1/480 [02:00<15:59:49, 120.23s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   0%|          | 2/480 [03:59<15:51:32, 119.44s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   1%|          | 3/480 [06:03<16:07:07, 121.65s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   1%|          | 4/480 [08:00<15:50:09, 119.77s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   1%|          | 5/480 [10:01<15:53:02, 120.38s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   1%|â–         | 6/480 [12:03<15:55:15, 120.92s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   1%|â–         | 7/480 [14:06<15:57:10, 121.42s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   2%|â–         | 8/480 [16:05<15:50:46, 120.86s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   2%|â–         | 9/480 [18:05<15:44:41, 120.34s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   2%|â–         | 10/480 [21:26<18:59:18, 145.44s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   2%|â–         | 11/480 [23:23<17:49:17, 136.80s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   2%|â–Ž         | 12/480 [25:22<17:02:46, 131.12s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   3%|â–Ž         | 13/480 [27:21<16:33:19, 127.62s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   3%|â–Ž         | 14/480 [29:22<16:15:55, 125.65s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   3%|â–Ž         | 15/480 [31:18<15:51:14, 122.74s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   3%|â–Ž         | 16/480 [33:16<15:38:08, 121.31s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   4%|â–Ž         | 17/480 [35:17<15:34:08, 121.06s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   4%|â–         | 18/480 [37:14<15:24:01, 120.00s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   4%|â–         | 19/480 [39:14<15:21:06, 119.88s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   4%|â–         | 20/480 [42:36<18:29:01, 144.65s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   4%|â–         | 21/480 [44:36<17:30:01, 137.26s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   5%|â–         | 22/480 [46:37<16:49:40, 132.27s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   5%|â–         | 23/480 [48:35<16:14:34, 127.95s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   5%|â–Œ         | 24/480 [50:32<15:48:09, 124.76s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   5%|â–Œ         | 25/480 [52:28<15:26:15, 122.14s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   5%|â–Œ         | 26/480 [54:24<15:10:26, 120.32s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   6%|â–Œ         | 27/480 [56:26<15:11:42, 120.76s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   6%|â–Œ         | 28/480 [58:17<14:47:43, 117.84s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:14<14:43:14, 117.50s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:22<17:20:43, 138.76s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:09<16:06:58, 129.22s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:55<15:12:52, 122.26s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:52<14:58:46, 120.64s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:51<14:52:55, 120.13s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:40<14:26:49, 116.87s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:30<14:10:29, 114.93s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:26<14:09:13, 115.02s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:23<14:12:18, 115.70s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:12<13:56:09, 113.76s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 20:03:53,395:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:24<16:46:07, 137.20s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:12<15:39:43, 128.44s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:05<15:03:31, 123.77s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:53<14:27:39, 119.13s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:43<14:05:53, 116.41s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:27<13:37:01, 112.69s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:17<13:29:28, 111.91s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:05<13:18:34, 110.66s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:55<13:15:01, 110.42s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:52<13:26:12, 112.23s/it]
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620750)[0m   warnings.warn(
[36m(TaskRunner pid=1617478)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:10<16:30:37, 138.23s/it]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:59<15:24:08, 129.25s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:48<14:40:15, 123.40s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:32<13:55:04, 117.34s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:23<13:39:34, 115.43s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:08<13:16:38, 112.47s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:54<13:00:18, 110.42s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:43<12:55:23, 109.98s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:27<12:40:35, 108.14s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:59:11<12:30:51, 107.01s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:05<14:49:13, 127.03s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:03:54<14:09:26, 121.64s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:39<13:33:09, 116.72s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:07:23<13:04:56, 112.94s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:09:17<13:04:14, 113.11s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:10:59<12:40:51, 110.00s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:12:48<12:36:27, 109.63s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:14:35<12:29:14, 108.85s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:16:20<12:19:02, 107.63s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:18:08<12:17:10, 107.62s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:21:06<14:41:27, 128.99s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:22:52<13:52:20, 122.10s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:24:38<13:17:02, 117.21s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:26:24<12:52:34, 113.89s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:28:13<12:39:20, 112.22s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:29:58<12:22:24, 109.99s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:31:51<12:27:13, 110.97s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:33:38<12:18:36, 109.97s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:35:25<12:09:48, 108.93s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:37:19<12:17:22, 110.33s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:40:15<14:27:54, 130.19s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:42:02<13:40:06, 123.32s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:43:48<13:02:40, 117.99s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:45:34<12:37:35, 114.50s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:47:21<12:20:21, 112.17s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:49:06<12:05:12, 110.16s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:50:53<11:55:53, 109.02s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:52:40<11:50:50, 108.53s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:54:27<11:45:57, 108.05s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:56:11<11:35:24, 106.71s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:59:06<13:47:07, 127.25s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:00:47<12:54:22, 119.44s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 21:44:18,871:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 21:44:23,911:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 21:44:28,929:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 21:44:34,718:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 21:44:41,328:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:02:54<13:07:23, 121.76s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:04:39<12:32:12, 116.62s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:06:26<12:11:37, 113.72s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:08:09<11:49:45, 110.61s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:09:58<11:43:29, 109.92s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:11:40<11:26:24, 107.53s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:13:17<11:05:59, 104.61s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:15:08<11:16:06, 106.47s/it]
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620750)[0m   warnings.warn(
[36m(WorkerDict pid=1620750)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1620750)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=1617478)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:18:23<14:01:50, 132.92s/it]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:20:02<12:55:50, 122.82s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 22:03:35,940:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:21:50<12:25:16, 118.30s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:23:28<11:45:51, 112.34s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:25:08<11:20:47, 108.64s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:26:53<11:11:35, 107.45s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:28:30<10:50:18, 104.33s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:30:15<10:49:04, 104.41s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:31:52<10:34:08, 102.28s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:33:39<10:41:29, 103.75s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 22:18:46,543:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:36:40<13:02:25, 126.88s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:38:22<12:15:12, 119.55s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:39:56<11:26:34, 111.94s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 22:23:28,248:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:41:45<11:18:35, 110.94s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:43:29<11:04:44, 108.98s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:45:03<10:35:06, 104.40s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 22:28:34,153:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:46:45<10:28:49, 103.65s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:48:23<10:16:15, 101.86s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:50:05<10:14:56, 101.92s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:51:41<10:03:34, 100.32s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 22:35:15,431:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:54:41<12:25:09, 124.19s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:56:18<11:33:46, 115.95s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:58:03<11:11:29, 112.54s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:59:44<10:50:25, 109.32s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:01:36<10:52:20, 109.95s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:03:15<10:30:59, 106.65s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:04:55<10:18:00, 104.75s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:06:35<10:07:58, 103.34s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:08:15<9:59:40, 102.22s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:09:57<9:57:39, 102.17s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:12:50<12:00:40, 123.55s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:14:34<11:23:16, 117.47s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:16:12<10:47:25, 111.62s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:17:52<10:26:56, 108.40s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:19:35<10:14:27, 106.55s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:21:16<10:02:52, 104.85s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:22:58<9:56:37, 104.06s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:24:36<9:44:42, 102.28s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:26:18<9:43:21, 102.34s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:28:00<9:40:03, 102.06s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:30:50<11:33:52, 122.45s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:32:33<10:59:59, 116.81s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:34:11<10:25:49, 111.09s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:35:52<10:06:09, 107.92s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:37:29<9:45:44, 104.60s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:39:10<9:38:22, 103.59s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:40:45<9:22:06, 100.98s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:42:21<9:12:45, 99.60s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:43:58<9:06:21, 98.74s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:45:41<9:12:50, 100.21s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 23:30:48,356:Timeout during comparison
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620750)[0m   warnings.warn(
[36m(TaskRunner pid=1617478)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:48:58<11:50:27, 129.17s/it]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:50:40<11:02:57, 120.90s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:52:21<10:28:27, 114.96s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 23:35:52,774:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:54:04<10:07:27, 111.46s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:55:46<9:50:09, 108.62s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:57:26<9:34:08, 106.00s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-09 23:40:57,053:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:59:09<9:27:38, 105.12s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:00:49<9:17:32, 103.57s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:02:36<9:21:02, 104.54s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:04:15<9:10:24, 102.88s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:07:11<11:05:25, 124.77s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:08:59<10:37:42, 119.95s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:10:43<10:09:15, 114.95s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:12:20<9:39:41, 109.72s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:13:59<9:20:59, 106.52s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:15:39<9:08:55, 104.56s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:17:18<8:58:28, 102.89s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:18:56<8:48:46, 101.36s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:20:38<8:48:25, 101.62s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:22:16<8:40:53, 100.49s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:25:14<10:39:17, 123.73s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:26:54<10:00:48, 116.66s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:28:34<9:33:25, 111.70s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:30:14<9:12:36, 108.00s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:31:51<8:54:48, 104.87s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:33:33<8:48:25, 103.95s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:35:16<8:44:45, 103.57s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:36:54<8:35:16, 102.04s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:38:38<8:36:08, 102.54s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:40:21<8:35:02, 102.67s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:43:20<10:27:10, 125.43s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 00:26:52,474:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 00:26:58,150:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:45:12<10:06:18, 121.67s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:46:52<9:30:49, 114.93s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:48:32<9:06:46, 110.46s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:50:09<8:45:42, 106.56s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:51:55<8:43:36, 106.50s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:53:37<8:34:15, 104.95s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 00:37:13,126:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:55:24<8:36:08, 105.69s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:57:06<8:29:21, 104.66s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:58:51<8:27:07, 104.56s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:01:42<10:02:40, 124.69s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:03:20<9:20:42, 116.41s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:04:58<8:52:54, 111.02s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:06:38<8:34:40, 107.60s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:08:19<8:24:38, 105.87s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:09:57<8:11:27, 103.47s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:11:38<8:06:25, 102.77s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:13:15<7:55:55, 100.90s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:14:56<7:53:56, 100.84s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:16:33<7:46:42, 99.65s/it] 
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620750)[0m   warnings.warn(
[36m(TaskRunner pid=1617478)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:19:43<9:52:05, 126.88s/it]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:21:22<9:11:48, 118.67s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:23:02<8:43:46, 113.05s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:24:40<8:21:05, 108.54s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:26:19<8:05:56, 105.64s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:27:59<7:55:49, 103.82s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:29:43<7:54:06, 103.82s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:31:28<7:54:54, 104.38s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:33:02<7:39:03, 101.26s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:34:39<7:31:32, 99.97s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:37:39<9:17:36, 123.91s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:39:20<8:44:42, 117.03s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:40:59<8:18:52, 111.69s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:42:43<8:05:45, 109.16s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:44:22<7:51:28, 106.35s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:45:59<7:36:58, 103.47s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:47:36<7:27:13, 101.64s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:49:13<7:18:21, 100.01s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:50:47<7:08:41, 98.17s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:52:33<7:17:57, 100.68s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:55:23<8:46:37, 121.53s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:57:02<8:14:51, 114.64s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:58:44<7:56:42, 110.86s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:00:17<7:31:46, 105.47s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:01:57<7:22:51, 103.80s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:03:32<7:09:53, 101.15s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:05:06<6:59:24, 99.07s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:06:46<6:58:38, 99.28s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:08:23<6:55:00, 98.81s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:10:08<7:00:31, 100.52s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:12:56<8:23:42, 120.89s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:14:32<7:49:53, 113.23s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:16:08<7:26:45, 108.09s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:17:43<7:08:46, 104.16s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:19:16<6:53:10, 100.77s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:20:50<6:43:31, 98.82s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:22:24<6:36:15, 97.44s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:23:57<6:29:37, 96.20s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:25:39<6:34:10, 97.73s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:27:15<6:31:01, 97.35s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:30:08<8:00:09, 120.04s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:31:53<7:39:30, 115.36s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:33:30<7:16:10, 109.96s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:35:08<6:59:57, 106.32s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:36:44<6:46:55, 103.45s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:38:26<6:42:55, 102.88s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:40:01<6:32:00, 100.51s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:41:38<6:25:46, 99.34s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:43:16<6:22:40, 98.97s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:44:53<6:19:27, 98.56s/it]
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620750)[0m   warnings.warn(
[36m(TaskRunner pid=1617478)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:48:01<7:59:45, 125.15s/it]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:49:34<7:21:44, 115.74s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:51:10<6:57:27, 109.86s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:52:44<6:37:36, 105.09s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:54:19<6:24:31, 102.08s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:55:54<6:14:00, 99.73s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:57:33<6:11:34, 99.53s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:59:07<6:03:40, 97.85s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:00:44<6:01:43, 97.76s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:02:17<5:54:01, 96.12s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:05:05<7:11:45, 117.75s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:06:44<6:49:03, 112.07s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:08:24<6:34:38, 108.62s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 02:51:54,301:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:10:08<6:28:07, 107.31s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:11:50<6:20:28, 105.69s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:13:25<6:06:32, 102.29s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:15:03<6:00:46, 101.15s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:16:39<5:53:48, 99.66s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:18:12<5:45:11, 97.70s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:19:48<5:41:22, 97.07s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 03:03:20,200:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:22:42<7:00:49, 120.24s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:24:21<6:36:27, 113.82s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:25:54<6:12:25, 107.43s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:27:29<5:57:50, 103.72s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:29:08<5:51:45, 102.45s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:30:44<5:43:00, 100.39s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:32:26<5:42:43, 100.80s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:34:07<5:41:41, 100.99s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:35:47<5:38:41, 100.60s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:37:25<5:34:50, 99.95s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:40:18<6:46:04, 121.82s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:41:50<6:14:15, 112.84s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:43:27<5:57:10, 108.23s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:45:08<5:47:43, 105.91s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:46:51<5:43:34, 105.18s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:48:34<5:39:11, 104.37s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:50:12<5:31:29, 102.52s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:51:53<5:28:04, 101.99s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:53:36<5:27:10, 102.24s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:55:14<5:21:40, 101.05s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:58:12<6:33:19, 124.21s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:59:51<6:07:08, 116.55s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:01:30<5:49:04, 111.40s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:03:10<5:36:00, 107.81s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:04:50<5:27:31, 105.65s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:06:34<5:23:29, 104.92s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:08:19<5:21:54, 104.97s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:09:56<5:13:34, 102.81s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:11:38<5:10:35, 102.39s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:13:15<5:04:22, 100.90s/it]
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620750)[0m   warnings.warn(
[36m(TaskRunner pid=1617478)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:16:24<6:22:01, 127.34s/it]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:18:06<5:57:05, 119.69s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:19:47<5:38:19, 114.04s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:21:29<5:25:48, 110.44s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:23:12<5:17:16, 108.16s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:24:49<5:05:50, 104.86s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:26:32<5:02:24, 104.28s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:28:06<4:52:15, 101.36s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:29:47<4:50:04, 101.19s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:31:31<4:50:57, 102.09s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:34:25<5:49:44, 123.44s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:36:04<5:27:13, 116.18s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:37:47<5:13:54, 112.11s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:39:27<5:02:21, 108.63s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:41:09<4:54:46, 106.55s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:42:53<4:51:11, 105.89s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:44:38<4:48:54, 105.70s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 04:28:07,832:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:46:23<4:46:24, 105.43s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:48:05<4:41:36, 104.30s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:49:47<4:38:26, 103.77s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:52:44<5:35:23, 125.77s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:54:25<5:13:17, 118.22s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:56:03<4:54:55, 112.00s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:57:41<4:42:42, 108.04s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:59:26<4:38:27, 107.10s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:01:09<4:33:34, 105.90s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:02:53<4:30:05, 105.23s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:04:35<4:25:57, 104.30s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:06:18<4:23:12, 103.90s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:07:56<4:16:56, 102.10s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:10:46<5:06:21, 122.54s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:12:23<4:45:28, 114.96s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:14:00<4:29:54, 109.42s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:15:45<4:24:43, 108.05s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:17:25<4:17:31, 105.83s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:19:04<4:10:18, 103.57s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:20:42<4:05:03, 102.11s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:22:24<4:02:37, 101.80s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:24:05<4:00:53, 101.79s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:25:46<3:58:09, 101.34s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:28:42<4:48:42, 123.73s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:30:26<4:32:56, 117.82s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:32:07<4:19:23, 112.78s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:33:48<4:09:54, 109.45s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:35:27<4:00:55, 106.29s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:37:12<3:57:50, 105.71s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:38:54<3:54:12, 104.87s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:40:38<3:51:32, 104.45s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:42:21<3:49:09, 104.16s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:43:59<3:43:13, 102.24s/it]
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620750)[0m   warnings.warn(
[36m(TaskRunner pid=1617478)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:47:14<4:41:39, 130.00s/it]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:48:58<4:22:55, 122.29s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:50:43<4:09:34, 116.99s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:52:31<4:01:55, 114.29s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:54:17<3:55:01, 111.92s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:56:02<3:48:33, 109.71s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:57:43<3:41:21, 107.11s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:59:25<3:36:45, 105.74s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:01:06<3:31:39, 104.09s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:02:56<3:33:52, 106.06s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:05:48<4:11:40, 125.84s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 05:49:22,997:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:07:34<3:57:52, 119.94s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:09:19<3:46:46, 115.31s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:10:58<3:35:15, 110.39s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:12:37<3:26:36, 106.87s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:14:14<3:19:31, 104.10s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:15:50<3:13:14, 101.71s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:17:27<3:08:55, 100.31s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:19:11<3:08:51, 101.18s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:20:46<3:04:06, 99.52s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:23:42<3:44:08, 122.26s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:25:23<3:30:38, 115.95s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:27:05<3:21:23, 111.89s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:28:50<3:15:36, 109.69s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:30:25<3:06:06, 105.34s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:32:06<3:02:04, 104.04s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:33:44<2:57:27, 102.38s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:35:25<2:54:49, 101.84s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:37:03<2:51:15, 100.74s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:38:40<2:47:45, 99.66s/it] 
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 06:22:13,841:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:41:38<3:25:00, 123.01s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:43:19<3:12:04, 116.41s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:45:01<3:03:03, 112.08s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:46:46<2:58:00, 110.11s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:48:44<2:59:52, 112.42s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:50:24<2:52:15, 108.79s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:52:06<2:46:50, 106.50s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:53:50<2:43:55, 105.76s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:55:28<2:38:52, 103.62s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:57:11<2:36:48, 103.39s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:00:06<3:07:18, 124.87s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:01:47<2:54:24, 117.58s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:03:23<2:43:14, 111.31s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:05:00<2:35:07, 106.98s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:06:40<2:30:03, 104.69s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:08:27<2:29:36, 105.60s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:10:03<2:23:41, 102.64s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:11:43<2:20:47, 101.77s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:13:22<2:17:58, 100.95s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:15:02<2:15:54, 100.68s/it]
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620750)[0m   warnings.warn(
[36m(TaskRunner pid=1617478)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:18:12<2:50:09, 127.61s/it]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:19:53<2:37:20, 119.51s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:21:38<2:29:34, 115.05s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:23:18<2:22:05, 110.73s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:24:56<2:15:26, 106.93s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:26:32<2:09:36, 103.69s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:28:14<2:07:13, 103.15s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:29:58<2:05:49, 103.42s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:31:38<2:02:52, 102.40s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:33:16<1:59:31, 101.00s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:36:15<2:25:00, 124.29s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:37:55<2:14:42, 117.14s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:39:34<2:06:21, 111.49s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:41:13<2:00:34, 107.98s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:42:52<1:55:37, 105.11s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:44:23<1:49:18, 100.90s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:46:00<1:46:33, 99.90s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:47:42<1:45:35, 100.56s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:49:22<1:43:39, 100.31s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:51:01<1:41:37, 99.96s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:53:57<2:02:46, 122.78s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:55:36<1:53:38, 115.56s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:57:20<1:48:23, 112.12s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:58:57<1:42:09, 107.54s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:00:37<1:38:21, 105.38s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:02:18<1:35:13, 103.88s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:03:57<1:32:09, 102.39s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:05:35<1:29:26, 101.25s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:07:16<1:27:43, 101.22s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:08:57<1:25:47, 100.93s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:11:46<1:41:20, 121.60s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:13:25<1:33:35, 114.59s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:15:02<1:27:35, 109.48s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:16:48<1:24:56, 108.43s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:18:27<1:20:51, 105.46s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:20:04<1:17:14, 103.00s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:21:42<1:14:23, 101.44s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:23:22<1:12:29, 101.16s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:25:01<1:10:21, 100.52s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:26:40<1:08:16, 99.92s/it] 
[36m(TaskRunner pid=1617478)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:29:34<1:21:21, 122.04s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:31:14<1:15:05, 115.52s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:32:55<1:10:22, 111.11s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:34:37<1:06:56, 108.56s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:36:19<1:03:49, 106.38s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:38:00<1:01:13, 104.94s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:39:38<58:17, 102.87s/it]  
[36m(TaskRunner pid=1617478)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:41:15<55:32, 101.00s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:42:53<53:22, 100.07s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:44:37<52:17, 101.19s/it]
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620750)[0m   warnings.warn(
[36m(TaskRunner pid=1617478)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:47:45<1:03:44, 127.48s/it]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1617478)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:49:28<57:56, 119.88s/it]  
[36m(TaskRunner pid=1617478)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:51:04<52:36, 112.73s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:52:45<49:09, 109.25s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:54:27<46:22, 107.02s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:56:02<43:07, 103.52s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:57:40<40:43, 101.82s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:59:27<39:40, 103.50s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:01:07<37:35, 102.53s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:02:46<35:26, 101.26s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:05:38<40:52, 122.65s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:07:20<36:52, 116.43s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:08:57<33:11, 110.64s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 08:52:27,854:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:10:40<30:39, 108.23s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:12:16<27:52, 104.56s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:13:53<25:34, 102.32s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:15:35<23:50, 102.19s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 08:59:07,697:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:17:22<22:28, 103.70s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:19:03<20:32, 102.72s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:20:43<18:41, 101.98s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:23:41<20:47, 124.77s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:25:20<17:34, 117.21s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:27:01<14:59, 112.38s/it]
[36m(TaskRunner pid=1617478)[0m WARNING:2025-11-10 09:10:32,841:Timeout during comparison
[36m(TaskRunner pid=1617478)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:28:46<12:50, 110.08s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:30:24<10:39, 106.50s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:32:01<08:38, 103.68s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:33:43<06:51, 102.91s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:35:26<05:09, 103.04s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:37:10<03:26, 103.41s/it]
[36m(TaskRunner pid=1617478)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:38:56<01:44, 104.02s/it]
[36m(WorkerDict pid=1620750)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1620750)[0m   warnings.warn(
[36m(TaskRunner pid=1617478)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:42:07<01:50, 110.50s/it]
[36m(WorkerDict pid=1620967)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1620967)[0m   warnings.warn([32m [repeated 3x across cluster][0m
