
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_0.00003/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_0.00003//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.00003//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_0.00003//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_0.00003/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-16 22:03:09,406	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=2002449)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-16 22:03:29,923:Waiting for register center actor 3dMpR3_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2006179)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2006179)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=2006179)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=2006000)[0m [rank0]:[W1116 22:03:47.138362767 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=2006000)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2006000)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2006000)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006000)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m [rank2]:[W1116 22:03:47.208547851 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2006179)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2006178)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(WorkerDict pid=2006177)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=2002449)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2002449)[0m Training Progress:   0%|          | 1/480 [01:59<15:50:20, 119.04s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   0%|          | 2/480 [04:04<16:19:34, 122.96s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   1%|          | 3/480 [06:07<16:17:05, 122.90s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   1%|          | 4/480 [08:06<16:02:10, 121.28s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   1%|          | 5/480 [10:07<16:00:58, 121.39s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   1%|â–         | 6/480 [12:09<15:58:51, 121.37s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   1%|â–         | 7/480 [14:11<15:59:36, 121.73s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   2%|â–         | 8/480 [16:11<15:52:29, 121.08s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   2%|â–         | 9/480 [18:09<15:43:41, 120.22s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   2%|â–         | 10/480 [21:31<18:58:49, 145.38s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   2%|â–         | 11/480 [23:27<17:45:59, 136.37s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   2%|â–Ž         | 12/480 [25:25<17:01:00, 130.90s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   3%|â–Ž         | 13/480 [27:24<16:31:11, 127.35s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   3%|â–Ž         | 14/480 [29:25<16:13:53, 125.39s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   3%|â–Ž         | 15/480 [31:22<15:51:20, 122.75s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   3%|â–Ž         | 16/480 [33:22<15:42:00, 121.81s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   4%|â–Ž         | 17/480 [35:20<15:31:35, 120.72s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   4%|â–         | 18/480 [37:16<15:19:19, 119.39s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   4%|â–         | 19/480 [39:14<15:14:45, 119.06s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   4%|â–         | 20/480 [42:37<18:24:51, 144.11s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   4%|â–         | 21/480 [44:35<17:22:14, 136.24s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   5%|â–         | 22/480 [46:36<16:45:47, 131.76s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   5%|â–         | 23/480 [48:32<16:07:03, 126.97s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   5%|â–Œ         | 24/480 [50:28<15:39:19, 123.59s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   5%|â–Œ         | 25/480 [52:22<15:16:55, 120.91s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   5%|â–Œ         | 26/480 [54:20<15:06:34, 119.81s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   6%|â–Œ         | 27/480 [56:20<15:06:07, 120.02s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   6%|â–Œ         | 28/480 [58:13<14:48:28, 117.94s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:09<14:40:49, 117.18s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:19<17:22:56, 139.06s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:07<16:12:11, 129.92s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:55<15:19:25, 123.14s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:50<14:59:15, 120.71s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:42<14:39:21, 118.30s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:35<14:24:53, 116.61s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:26<14:09:34, 114.81s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:17<14:01:04, 113.92s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:16<14:09:09, 115.27s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:01<13:45:39, 112.33s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:11<16:35:08, 135.70s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:02<15:38:27, 128.26s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:00<15:12:22, 124.98s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:49<14:35:51, 120.26s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:40<14:13:51, 117.50s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:25<13:44:46, 113.76s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:18<13:41:11, 113.53s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:11<13:38:47, 113.46s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:04<13:35:26, 113.26s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:01<13:41:29, 114.36s/it]
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(TaskRunner pid=2002449)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:23<16:47:42, 140.61s/it]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2002449)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:15<15:43:57, 132.02s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:47:05<14:53:57, 125.32s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:52<14:12:47, 119.83s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:43<13:52:56, 117.32s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:31<13:30:39, 114.45s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:20<13:18:27, 112.99s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:56:14<13:17:21, 113.10s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:58:00<13:00:41, 111.00s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 00:05:06,689:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:59:53<13:02:37, 111.54s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 00:06:57,553:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:55<15:29:25, 132.77s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:46<14:42:32, 126.38s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:06:34<14:01:14, 120.75s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:08:21<13:31:22, 116.75s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:10:19<13:30:24, 116.89s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:12:04<13:05:24, 113.55s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:13:56<12:59:53, 113.03s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:15:44<12:46:16, 111.32s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:17:31<12:35:23, 110.01s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:19:19<12:30:31, 109.57s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:22:24<15:03:37, 132.24s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:24:11<14:09:43, 124.65s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:25:58<13:32:10, 119.44s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:27:45<13:04:15, 115.61s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:29:35<12:51:39, 114.04s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:31:25<12:39:39, 112.54s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:33:16<12:36:30, 112.35s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:35:09<12:34:11, 112.29s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:36:59<12:27:41, 111.60s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:38:50<12:26:14, 111.66s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:41:51<14:43:18, 132.50s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:43:39<13:51:24, 125.02s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:45:29<13:18:25, 120.37s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:47:17<12:52:40, 116.78s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:49:05<12:33:58, 114.24s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:50:51<12:15:36, 111.74s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:52:41<12:09:55, 111.16s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:54:30<12:03:01, 110.38s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:56:19<11:59:09, 110.07s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:58:02<11:44:30, 108.11s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:01:03<14:04:55, 129.99s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:02:45<13:07:29, 121.46s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:04:28<12:30:28, 116.05s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:06:15<12:10:47, 113.30s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:08:06<12:03:36, 112.48s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:09:48<11:41:12, 109.28s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:11:37<11:39:39, 109.32s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:13:19<11:24:24, 107.22s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:14:57<11:03:22, 104.20s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:16:47<11:12:56, 105.98s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 01:23:51,505:Timeout during comparison
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(WorkerDict pid=2006000)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2006000)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=2002449)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:20:06<14:08:52, 134.03s/it]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2002449)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:21:46<13:02:25, 123.87s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:23:31<12:24:00, 118.10s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:25:11<11:47:14, 112.56s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:26:49<11:18:00, 108.19s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:28:36<11:14:44, 107.96s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:30:17<10:59:11, 105.75s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:32:03<10:58:17, 105.89s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:33:45<10:49:53, 104.82s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:35:39<11:04:36, 107.48s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:38:40<13:18:54, 129.55s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:40:27<12:35:11, 122.79s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:42:06<11:49:22, 115.66s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:43:52<11:30:12, 112.84s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:45:39<11:18:03, 111.16s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:47:15<10:47:15, 106.40s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:48:56<10:35:13, 104.71s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:50:41<10:34:13, 104.83s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:52:23<10:27:30, 104.01s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:54:07<10:26:13, 104.08s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:57:05<12:37:02, 126.17s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:58:42<11:43:16, 117.54s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:00:30<11:24:33, 114.73s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 02:07:32,366:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:02:17<11:08:05, 112.28s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:04:10<11:07:16, 112.46s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:05:50<10:44:23, 108.91s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:07:31<10:27:51, 106.42s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:09:08<10:09:43, 103.64s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:10:52<10:08:07, 103.66s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:12:31<9:58:15, 102.27s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:15:21<11:54:43, 122.52s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:17:03<11:18:08, 116.59s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:18:38<10:37:38, 109.94s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:20:17<10:17:43, 106.81s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:21:59<10:06:55, 105.25s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:23:41<9:59:56, 104.34s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:25:21<9:50:15, 102.95s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:27:00<9:42:02, 101.82s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:28:39<9:35:39, 100.99s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:30:20<9:33:07, 100.84s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:33:09<11:27:22, 121.30s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 02:40:08,590:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:34:53<10:57:25, 116.36s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:36:31<10:23:07, 110.61s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:38:11<10:03:40, 107.48s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:39:46<9:41:02, 103.76s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:41:24<9:29:43, 102.04s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:42:56<9:11:45, 99.12s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:44:32<9:03:52, 98.00s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:46:08<8:59:04, 97.42s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:47:51<9:06:48, 99.12s/it]
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(TaskRunner pid=2002449)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:50:57<11:28:51, 125.25s/it]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2002449)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:52:36<10:43:28, 117.35s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 02:59:40,117:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:54:22<10:22:28, 113.87s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:56:00<9:54:53, 109.16s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:57:41<9:39:44, 106.70s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:59:19<9:24:17, 104.18s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:00:52<9:03:45, 100.70s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:02:28<8:54:55, 99.37s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:04:11<8:58:32, 100.35s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:05:49<8:54:25, 99.89s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:08:37<10:41:21, 120.25s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:10:21<10:13:55, 115.47s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:12:03<9:50:24, 111.40s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:13:41<9:27:07, 107.34s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:15:17<9:06:54, 103.84s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:16:53<8:53:32, 101.63s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:18:33<8:49:10, 101.12s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:20:08<8:37:08, 99.13s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:21:46<8:33:34, 98.77s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:23:21<8:26:31, 97.72s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:26:10<10:15:05, 119.05s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:27:46<9:38:28, 112.33s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:29:24<9:14:27, 108.01s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:31:03<8:58:48, 105.31s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:32:37<8:38:54, 101.75s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:34:17<8:34:57, 101.30s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:35:55<8:28:12, 100.30s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:37:33<8:23:35, 99.72s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:39:12<8:20:51, 99.51s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:40:51<8:17:48, 99.23s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 03:49:25,687:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:43:49<10:14:05, 122.82s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 03:50:50,983:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 03:50:56,805:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:45:39<9:53:11, 119.04s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:47:18<9:21:01, 112.96s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:48:56<8:57:43, 108.63s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:50:29<8:31:57, 103.78s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:52:11<8:28:07, 103.35s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:53:45<8:12:46, 100.57s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 04:00:46,646:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:55:24<8:08:24, 100.01s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:57:04<8:06:04, 99.88s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:58:43<8:04:18, 99.86s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:01:32<9:42:02, 120.42s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:03:05<9:00:21, 112.18s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:04:38<8:31:04, 106.48s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:06:16<8:16:51, 103.87s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:07:52<8:04:18, 101.60s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:09:27<7:53:13, 99.63s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:11:08<7:53:00, 99.93s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:12:42<7:44:02, 98.38s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:14:21<7:42:00, 98.30s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:15:55<7:35:04, 97.17s/it]
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(TaskRunner pid=2002449)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:19:03<9:40:26, 124.38s/it]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2002449)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:20:42<9:02:37, 116.69s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:22:21<8:35:52, 111.34s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:23:57<8:12:58, 106.78s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:25:34<7:57:46, 103.87s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:27:12<7:48:50, 102.29s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:28:53<7:44:59, 101.82s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:30:34<7:42:35, 101.67s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:32:06<7:27:47, 98.78s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:33:43<7:23:35, 98.21s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:36:35<9:00:43, 120.16s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:38:12<8:27:21, 113.16s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:39:49<8:04:57, 108.57s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:41:29<7:51:27, 105.94s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:43:08<7:39:30, 103.65s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:44:42<7:25:23, 100.84s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:46:16<7:14:31, 98.76s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:47:54<7:12:16, 98.62s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:49:27<7:02:41, 96.80s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:51:10<7:09:35, 98.75s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:53:56<8:35:41, 119.01s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:55:32<8:04:23, 112.22s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:57:11<7:44:42, 108.07s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:58:42<7:20:56, 102.94s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:00:21<7:14:24, 101.81s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:01:57<7:04:37, 99.91s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:03:30<6:54:47, 97.98s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:05:11<6:57:28, 99.01s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:06:49<6:53:40, 98.49s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:08:31<6:56:33, 99.58s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:11:18<8:19:04, 119.78s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:12:52<7:45:42, 112.22s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:14:29<7:24:50, 107.62s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:16:07<7:10:53, 104.67s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:17:40<6:54:28, 101.09s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:19:15<6:45:16, 99.25s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:20:50<6:38:53, 98.09s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:22:24<6:31:45, 96.73s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:24:03<6:33:57, 97.68s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:25:39<6:29:39, 97.01s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:28:26<7:52:35, 118.15s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:30:10<7:32:47, 113.67s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:31:47<7:11:54, 108.89s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:33:26<6:57:49, 105.78s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:35:03<6:45:32, 103.11s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:36:41<6:38:29, 101.74s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:38:17<6:29:38, 99.91s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:39:53<6:23:55, 98.86s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:41:31<6:21:18, 98.62s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:43:11<6:20:27, 98.82s/it]
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(TaskRunner pid=2002449)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:46:17<7:58:59, 124.95s/it]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2002449)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:47:50<7:20:33, 115.43s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:49:26<6:56:44, 109.67s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:51:02<6:39:51, 105.69s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:52:37<6:25:49, 102.43s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:54:10<6:13:22, 99.57s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:55:48<6:09:25, 98.95s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:57:19<5:59:32, 96.74s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:58:59<6:01:25, 97.68s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:00:30<5:52:11, 95.62s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:03:14<7:06:13, 116.24s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:04:53<6:44:43, 110.88s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:06:32<6:30:26, 107.46s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:08:09<6:17:22, 104.34s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:09:48<6:09:56, 102.76s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:11:22<5:58:34, 100.07s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:13:05<5:59:23, 100.76s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:14:37<5:48:59, 98.31s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:16:07<5:38:06, 95.69s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:17:43<5:36:46, 95.77s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:20:30<6:50:39, 117.33s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:22:09<6:29:26, 111.80s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:23:41<6:06:54, 105.84s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:25:16<5:54:21, 102.71s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:26:56<5:49:43, 101.86s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:28:29<5:38:38, 99.11s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:30:07<5:36:02, 98.84s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 06:37:10,858:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:31:53<5:41:30, 100.94s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:33:28<5:33:46, 99.14s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:35:06<5:30:45, 98.74s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:37:53<6:37:05, 119.13s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:39:23<6:06:57, 110.64s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:40:58<5:49:15, 105.83s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:42:34<5:38:06, 102.98s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:44:16<5:35:25, 102.68s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:45:54<5:29:02, 101.25s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:47:31<5:23:01, 99.90s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:49:08<5:18:51, 99.13s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:50:45<5:15:12, 98.50s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:52:21<5:10:59, 97.70s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:55:13<6:19:40, 119.90s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:56:50<5:55:46, 112.94s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [8:58:29<5:40:50, 108.78s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:00:04<5:26:15, 104.68s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:01:41<5:17:48, 102.52s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:03:21<5:13:36, 101.71s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:05:03<5:12:20, 101.85s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:06:38<5:03:48, 99.61s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:08:17<5:02:01, 99.57s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:09:54<4:57:56, 98.76s/it]
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(TaskRunner pid=2002449)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:12:54<6:09:40, 123.23s/it]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2002449)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:14:31<5:43:35, 115.17s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:16:08<5:25:40, 109.78s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:17:46<5:13:30, 106.27s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:19:24<5:04:18, 103.74s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:20:58<4:54:15, 100.89s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:22:38<4:51:37, 100.56s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 07:29:36,561:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:24:18<4:49:13, 100.31s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:25:57<4:46:53, 100.08s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:27:37<4:44:47, 99.93s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:30:23<5:39:43, 119.90s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:32:00<5:18:07, 112.94s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:33:37<5:03:04, 108.24s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:35:16<4:53:16, 105.37s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:36:55<4:46:47, 103.66s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:38:36<4:42:35, 102.76s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:40:18<4:40:30, 102.63s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 07:47:18,685:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 07:47:24,363:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 07:47:29,394:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:42:09<4:45:02, 104.92s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:43:47<4:38:04, 102.99s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 07:50:47,301:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:45:31<4:37:22, 103.37s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 07:52:32,520:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:48:26<5:32:44, 124.78s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:50:07<5:11:41, 117.62s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 07:57:05,406:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 07:57:11,766:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 07:57:16,781:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 07:57:23,049:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:52:03<5:08:29, 117.15s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:53:42<4:52:19, 111.71s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:55:26<4:44:34, 109.46s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [9:57:07<4:35:47, 106.76s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [9:58:49<4:30:51, 105.53s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:00:32<4:26:55, 104.67s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 08:07:36,732:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:02:19<4:26:33, 105.22s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:03:56<4:18:59, 102.91s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:06:45<5:06:56, 122.77s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:08:21<4:44:54, 114.73s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:09:57<4:28:49, 108.98s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:11:41<4:23:31, 107.56s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:13:18<4:13:37, 104.23s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:14:54<4:05:58, 101.78s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:16:34<4:03:00, 101.25s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:18:15<4:01:32, 101.35s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:19:55<3:58:29, 100.77s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:21:32<3:54:34, 99.82s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:24:22<4:42:11, 120.94s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:26:03<4:26:10, 114.90s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:27:48<4:17:14, 111.84s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:29:27<4:06:43, 108.05s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:31:01<3:55:00, 103.68s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:32:43<3:52:28, 103.32s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:34:23<3:48:40, 102.39s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 08:41:24,484:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:36:10<3:49:28, 103.52s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:37:52<3:47:17, 103.31s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:39:27<3:40:07, 100.82s/it]
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(TaskRunner pid=2002449)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:42:35<4:34:42, 126.79s/it]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2002449)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:44:17<4:16:45, 119.43s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:46:02<4:05:40, 115.16s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:47:48<3:57:32, 112.23s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:49:32<3:50:54, 109.96s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:51:13<3:43:17, 107.18s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:52:53<3:36:49, 104.91s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:54:34<3:32:41, 103.75s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:56:12<3:27:36, 102.11s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:57:58<3:28:32, 103.41s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:00:47<4:05:59, 123.00s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:02:28<3:50:44, 116.34s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:04:11<3:41:17, 112.52s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:05:49<3:30:47, 108.10s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:07:28<3:23:44, 105.38s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 09:14:29,204:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:09:10<3:19:42, 104.19s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:10:44<3:12:21, 101.25s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:12:20<3:07:36, 99.61s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:14:01<3:06:33, 99.95s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 09:21:01,705:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:15:42<3:05:45, 100.41s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:18:30<3:41:08, 120.62s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:20:08<3:26:42, 113.79s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:21:48<3:17:38, 109.80s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:23:29<3:10:47, 106.99s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:25:03<3:02:15, 103.16s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:26:41<2:57:42, 101.55s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:28:17<2:53:06, 99.87s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:29:58<2:52:01, 100.21s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:31:33<2:48:09, 98.92s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:33:09<2:44:39, 97.81s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:35:56<3:17:58, 118.79s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:37:35<3:05:56, 112.70s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 09:44:37,421:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:39:20<3:00:32, 110.54s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:41:03<2:54:40, 108.04s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:42:50<2:52:45, 107.97s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:44:28<2:46:14, 104.99s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:46:06<2:41:08, 102.86s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:47:48<2:38:53, 102.51s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 09:54:51,551:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:49:33<2:38:09, 103.15s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:51:14<2:35:27, 102.50s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:54:05<3:04:36, 123.07s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:55:44<2:52:07, 116.04s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:57:22<2:41:54, 110.39s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [11:58:56<2:33:15, 105.69s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:00:34<2:27:59, 103.25s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:02:20<2:27:20, 104.00s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:03:55<2:22:01, 101.44s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:05:32<2:18:31, 100.14s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:07:12<2:16:32, 99.91s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:08:49<2:13:58, 99.24s/it]
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(TaskRunner pid=2002449)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:11:54<2:46:27, 124.85s/it]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 10:18:54,843:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:13:38<2:36:12, 118.64s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:15:20<2:27:45, 113.67s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:17:01<2:21:00, 109.88s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:18:40<2:15:03, 106.62s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:20:15<2:08:48, 103.05s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:21:57<2:06:35, 102.64s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:23:38<2:04:25, 102.26s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:25:19<2:02:17, 101.91s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:26:58<1:59:25, 100.92s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:29:50<2:22:41, 122.30s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:31:27<2:11:59, 114.78s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:33:05<2:04:32, 109.88s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:34:44<1:58:58, 106.54s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:36:25<1:55:12, 104.73s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:37:57<1:49:27, 101.04s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:39:34<1:46:26, 99.79s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:41:15<1:45:00, 100.01s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:42:54<1:43:10, 99.85s/it] 
[36m(TaskRunner pid=2002449)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:44:32<1:41:02, 99.39s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:47:28<2:02:07, 122.13s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:49:07<1:53:23, 115.31s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:50:53<1:48:43, 112.47s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:52:29<1:42:20, 107.72s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:54:12<1:39:01, 106.10s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 11:01:12,575:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:55:58<1:37:13, 106.07s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:57:36<1:33:29, 103.88s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [12:59:17<1:30:57, 102.97s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:01:00<1:29:16, 103.00s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:02:40<1:26:38, 101.94s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 11:09:43,312:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:05:36<1:43:26, 124.14s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:07:16<1:35:31, 116.96s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:08:54<1:29:00, 111.25s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:10:43<1:26:41, 110.66s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:12:24<1:22:27, 107.54s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:14:03<1:18:51, 105.14s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 11:21:04,422:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:15:49<1:17:19, 105.43s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:17:33<1:15:12, 104.93s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:19:14<1:12:40, 103.83s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:20:57<1:10:38, 103.38s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:23:50<1:22:58, 124.46s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:25:33<1:16:46, 118.12s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:27:19<1:12:22, 114.27s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:29:00<1:08:06, 110.44s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:30:41<1:04:33, 107.59s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:32:24<1:01:51, 106.04s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 11:39:27,102:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:34:08<59:53, 105.68s/it]  
[36m(TaskRunner pid=2002449)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:35:48<57:10, 103.97s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:37:26<54:27, 102.10s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:39:11<53:11, 102.95s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 11:46:12,780:Timeout during comparison
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(TaskRunner pid=2002449)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:42:33<1:06:18, 132.62s/it]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2002449)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:44:16<59:45, 123.65s/it]  
[36m(TaskRunner pid=2002449)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:45:54<54:07, 115.99s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:47:39<50:42, 112.68s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:49:23<47:43, 110.13s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:51:01<44:21, 106.46s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 11:58:03,833:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:52:49<42:47, 107.00s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:54:37<41:04, 107.15s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:56:20<38:55, 106.15s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:58:02<36:42, 104.90s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:01:02<42:24, 127.22s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:02:47<38:11, 120.61s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:04:29<34:28, 114.94s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:06:11<31:29, 111.17s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:07:52<28:48, 108.05s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:09:34<26:34, 106.30s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:11:18<24:37, 105.56s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:13:00<22:39, 104.57s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:14:42<20:45, 103.80s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:16:23<18:51, 102.84s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:19:20<20:50, 125.08s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:20:59<17:36, 117.39s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 12:28:02,904:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:22:46<15:14, 114.36s/it]
[36m(TaskRunner pid=2002449)[0m WARNING:2025-11-17 12:29:50,697:Timeout during comparison
[36m(TaskRunner pid=2002449)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:24:34<13:05, 112.23s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:26:14<10:52, 108.67s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:27:50<08:44, 104.82s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:29:29<06:52, 103.23s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:31:10<05:07, 102.54s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:32:57<03:27, 103.76s/it]
[36m(TaskRunner pid=2002449)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:34:45<01:45, 105.05s/it]
[36m(WorkerDict pid=2006000)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2006000)[0m   warnings.warn(
[36m(TaskRunner pid=2002449)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:37:58<01:49, 109.98s/it]
[36m(WorkerDict pid=2006178)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2006178)[0m   warnings.warn([32m [repeated 3x across cluster][0m
+ ISODES
./scripts/train_1_5b.sh: line 73: ISODES: command not found
