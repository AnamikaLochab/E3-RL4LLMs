The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/3.1.4
+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a13/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_dGRPO_1.0_a13//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a13//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_dGRPO_1.0_a13//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=divgrpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_dGRPO_1.0_a13/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-12-22 14:11:18,410	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=776592)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 14:11:38,187:Waiting for register center actor Zz0Afl_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=780324)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=780321)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=780321)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=780147)[0m [rank0]:[W1222 14:11:55.916505517 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=780147)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=780147)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=780147)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780147)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m [rank2]:[W1222 14:11:55.177893375 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780324)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=780321)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=780147)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=780323)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(WorkerDict pid=780324)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=776592)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=776592)[0m /scratch/gautschi/alochab/E3-RL4LLMs/verl/verl/trainer/ppo/core_algos.py:745: RuntimeWarning: divide by zero encountered in log
[36m(TaskRunner pid=776592)[0m   print(f"    Entropy H(q):   {Hq.item():.4f} (Max possible: {np.log(corr_mask.sum().item()):.4f})")
[36m(TaskRunner pid=776592)[0m Training Progress:   0%|          | 1/480 [02:00<16:04:04, 120.76s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   0%|          | 2/480 [04:01<16:01:35, 120.70s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   1%|          | 3/480 [06:02<16:00:47, 120.85s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   1%|          | 4/480 [08:01<15:52:01, 120.00s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 14:23:18,930:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:   1%|          | 5/480 [10:04<16:00:58, 121.39s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   1%|â–         | 6/480 [12:07<16:00:52, 121.63s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   1%|â–         | 7/480 [14:08<15:57:09, 121.41s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   2%|â–         | 8/480 [16:07<15:50:27, 120.82s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 14:31:24,148:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:   2%|â–         | 9/480 [18:13<15:59:48, 122.27s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   2%|â–         | 10/480 [21:35<19:10:29, 146.87s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   2%|â–         | 11/480 [23:31<17:54:45, 137.50s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   2%|â–Ž         | 12/480 [25:31<17:10:33, 132.12s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   3%|â–Ž         | 13/480 [27:30<16:37:52, 128.21s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   3%|â–Ž         | 14/480 [29:31<16:19:45, 126.15s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   3%|â–Ž         | 15/480 [31:28<15:55:31, 123.29s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   3%|â–Ž         | 16/480 [33:24<15:37:54, 121.28s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   4%|â–Ž         | 17/480 [35:23<15:28:19, 120.30s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   4%|â–         | 18/480 [37:16<15:11:17, 118.35s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   4%|â–         | 19/480 [39:13<15:04:20, 117.70s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 14:56:19,814:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:   4%|â–         | 20/480 [42:41<18:30:33, 144.86s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   4%|â–         | 21/480 [44:43<17:37:23, 138.22s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   5%|â–         | 22/480 [46:43<16:52:12, 132.60s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   5%|â–         | 23/480 [48:41<16:16:27, 128.20s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   5%|â–Œ         | 24/480 [50:39<15:51:08, 125.15s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   5%|â–Œ         | 25/480 [52:33<15:24:16, 121.88s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   5%|â–Œ         | 26/480 [54:32<15:16:17, 121.10s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   6%|â–Œ         | 27/480 [56:33<15:14:00, 121.06s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   6%|â–Œ         | 28/480 [58:24<14:47:29, 117.81s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:24<14:52:14, 118.70s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:31<17:22:10, 138.96s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:22<16:17:41, 130.65s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:09<15:23:07, 123.63s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:14<15:23:19, 123.94s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:07<14:57:37, 120.76s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:57<14:31:28, 117.50s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:46<14:09:52, 114.85s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:37<14:00:29, 113.84s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:35<14:07:02, 114.98s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:23<13:50:04, 112.94s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:29<16:28:47, 134.83s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:19<15:32:10, 127.41s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:13<15:00:31, 123.36s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   9%|â–‰         | 43/480 [1:29:00<14:22:42, 118.45s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:52<14:07:15, 116.60s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:38<13:41:20, 113.29s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:31<13:38:37, 113.17s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:27<13:43:59, 114.18s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:21<13:42:13, 114.20s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:18<13:46:12, 115.02s/it]
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(TaskRunner pid=776592)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:39<16:49:31, 140.86s/it]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=776592)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:30<15:41:48, 131.72s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:47:19<14:50:57, 124.90s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:49:03<14:05:30, 118.81s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 16:04:14,743:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:57<13:51:31, 117.12s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:41<13:23:08, 113.38s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:29<13:08:20, 111.56s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:56:17<12:58:53, 110.48s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:59<12:40:32, 108.13s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:59:43<12:29:33, 106.83s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:33<14:40:48, 125.83s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:23<14:05:28, 121.07s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:06:07<13:28:28, 116.05s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:07:50<12:59:21, 112.14s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:09:44<13:00:28, 112.57s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:11:28<12:39:52, 109.86s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:13:18<12:39:19, 110.05s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:15:09<12:38:52, 110.25s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:16:54<12:26:15, 108.68s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:18:41<12:21:22, 108.23s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:21:43<14:51:07, 130.41s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:23:32<14:05:27, 124.03s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:25:16<13:22:40, 118.04s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:26:59<12:50:04, 113.52s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 16:42:07,615:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:28:50<12:43:22, 112.81s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:30:34<12:22:42, 110.03s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:32:24<12:21:13, 110.08s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:34:14<12:19:06, 110.04s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:36:03<12:15:44, 109.81s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:37:53<12:13:21, 109.73s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:40:44<14:15:04, 128.26s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:42:31<13:29:47, 121.77s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:44:18<12:57:24, 117.20s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:46:06<12:37:54, 114.55s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:47:53<12:20:48, 112.24s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:49:40<12:09:42, 110.84s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:51:28<12:01:31, 109.88s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:53:17<11:58:06, 109.63s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:55:07<11:57:07, 109.76s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:56:51<11:43:48, 108.00s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:59:47<13:53:30, 128.23s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:01:30<13:03:10, 120.80s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 17:16:37,472:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:03:20<12:39:30, 117.45s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:05:05<12:14:12, 113.83s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:06:51<11:56:32, 111.38s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 17:21:59,816:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:08:43<11:57:19, 111.79s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:10:33<11:51:58, 111.25s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:12:15<11:31:03, 108.26s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:13:56<11:15:25, 106.09s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:15:50<11:29:29, 108.58s/it]
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(WorkerDict pid=780147)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=780147)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=776592)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:19:08<14:17:01, 135.32s/it]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=776592)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:20:49<13:10:28, 125.14s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 17:35:59,823:Timeout during parsing: Okay, so I've been given this problem about counting certain functions. Let me try to parse what it's asking.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m We need to find the number of functions \( f \) from the set \( \{-1005, \ldots, 1005\} \) to the set \( \{-2010, \ldots, 2010\} \) that satisfy two conditions:
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m 1. If \( a < b \), then \( f(a) < f(b) \). So this is an increasing functionâ€”in other words, a strictly increasing function.
[36m(TaskRunner pid=776592)[0m 2. There is no \( n \) in \( \{-1005, \ldots, 1005\} \) such that \( |f(n)| = |n| \). So, for every \( n \), \( f(n) \) cannot equal \( n \) in absolute value.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Hmm, okay. Let me try to visualize this.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m First, the domain is integers from -1005 to 1005, inclusive. So, that's 2011 elements in the domain. The codomain is from -2010 to 2010, which is 4021 elements.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Since \( f \) is strictly increasing, it's essentially an injection from the domain to the codomain. Because it's strictly increasing, it's also a bijection onto its image. So, the function is one-to-one and onto its range.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But wait, maybe the domain and codomain have different sizes? The domain has 2011 elements, the codomain has 4021 elements. So, the number of strictly increasing functions would be \( \dbinom{4021}{2011} \), since we are choosing injective subsets of the codomain and mapping them in order.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But the second condition complicates things. We need to exclude all functions where \( |f(n)| = |n| \) for any \( n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m So, for each \( n \), \( f(n) \) cannot be equal to \( n \) or \( -n \). So, for each \( n \), the possible images are 4021 - 2 = 4019 possibilities.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But since \( f \) is strictly increasing, and we're dealing with order, we have to consider the mapping in such a way that the order is preserved. So, perhaps inclusion-exclusion is in order here.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, the problem is similar to counting the number of strictly increasing functions with certain forbidden positions.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Let me think: normally, without any restrictions, the number of strictly increasing functions is \( \dbinom{4021}{2011} \). This is because we have to choose which 2011 elements from the 4021 codomain elements will be in the image, and since the function is strictly increasing, it's fixed once we choose the subset.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But now, we have to subtract the functions where for some \( n \), \( f(n) = n \) or \( f(n) = -n \). So, we can model this using inclusion-exclusion.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Let me denote \( A_n \) as the set of strictly increasing functions where \( f(n) = n \), and \( B_n \) as the set where \( f(n) = -n \). But wait, but we need both: functions where \( f(n) = n \) or \( f(n)=-n \). So, let me consider \( C_n = A_n \cup B_n \), the set of functions where \( f(n) = n \) or \( f(n) = -n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But since we have multiple \( n \)s, we have to avoid overcomplicating.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But perhaps, let's model this as forbidden assignments. For each \( n \), \( f(n) \) must not be equal to \( n \) or \( -n \). So, for each \( n \), the image is restricted from 2 elements. But since \( f \) is strictly increasing, the mapping affects all \( n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But perhaps it's a problem similar to derangements, but in a function setting with order constraints.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, but the forbidden set is a bit more involved because each \( f(n) \) is restricted for different \( n \). So, let's clarify.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Each \( f(n) \) must not be equal to \( n \) or \( -n \). So, for each \( n \in S \), where \( S = \{-1005, \ldots, 1005\} \), \( f(n) \in \{-2010, \ldots, 2010\} \setminus \{n, -n\} \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But not only that, since \( f \) must be strictly increasing, the assignment must respect the order.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m This seems similar to a problem where we have to count the number of injective functions with restrictions, which can be solved using inclusion-exclusion or perhaps using the principle of rook polynomials or something, but I'm not sure.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Alternatively, perhaps we can model this as a permutation problem with forbidden positions, but here the "positions" are the images of each \( n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But let me think in terms of the image set. Since \( f \) is strictly increasing, we can think of choosing 2011 distinct elements from the codomain, arranging them in increasing order. So, the image of \( f \) is an increasing sequence of 2011 integers.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m So, this problem reduces to selecting 2011 integers from \(-2010\) to \(2010\) (excluding \( 0 \) maybe? Wait, no, \( |f(n)|=|n| \) for each \( n \). For \( n = 0 \), but \( f(0) \) can't be equal to 0 because |0| = |0|, so \( f(0) \) must not be 0. So, for \( n = 0 \), \( f(0) \in \{-2010, \ldots, -1, 1, \ldots, 2010\} \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m So, actually, \( n \) can range from -1005 to 1005, inclusive. Each \( f(n) \) is in \[-2010, 2010\], but \( f(n) \) cannot be equal to \( n \) or \( -n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m So, for \( n = 0 \), \( f(0) \) can't be 0. For \( n \neq 0 \), \( f(n) \) cannot be \( n \) or \( -n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Therefore, the forbidden positions for each \( n \) are \( f(n) = n \) or \( f(n) = -n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m So, it's a bounded version of strictly increasing functions with forbidden assignments.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m An idea is to model this as arranging the images over the domain, which is itself ordered, so the problem is analogous to counting the number of strictly increasing sequences.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m I think this is similar to arrangements with forbidden positions in a permutation, but in this case, it's a function on a totally ordered set.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m In such cases, the principle of inclusion-exclusion can be used, but given the size, it's complicated.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, another approach: since \( f \) is strictly increasing, we can model the image as a combination of 2011 elements from 4019 possible elements, avoiding some exclusions.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But actually, for each \( n \), the elements \( n \) and \( -n \) are forbidden as images. But wait, \( n \) and \( -n \) could possibly be among the codomain elements we choose for the images.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But since the codomain is quite large, this complicates things.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, perhaps the forbidden assignments don't really affect the overall count because we can adjust the combinations accordingly.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, maybe the number of allowable images is the total number of strictly increasing functions without any restrictions except for the forbidden assignments. So, if I denote the total number as \( \dbinom{4021}{2011} \), and then we need to subtract those configurations where for some \( n \), \( f(n) \) is equal to \( n \) or \( -n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But now, inclusion-exclusion seems the way to go.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Define \( A_n \) to be the set of strictly increasing functions where \( f(n) = n \), and \( B_n \) as where \( f(n) = -n \). But we need to consider both.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But for each \( n \), both \( f(n) = n \) and \( f(n) = -n \) are forbidden, so perhaps each \( n \) contributes to forbidden assignments, and we have to use inclusion-exclusion over all \( n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m However, considering that \( f(n) \) for each \( n \) cannot be \( n \) or \( -n \). So, the forbidden assignments are \( 4019 \) possible choices (since there are 4021 elements in the codomain, minus 2 forbidden options for each \( n \)).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But since the images must still be strictly increasing, the problem is similar to counting linear extensions with certain points forbidden.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, actually, each element in the domain is mapped to an element in the codomain, with \( a < b \) implying \( f(a) < f(b) \). So, perhaps for each \( n \), we can model the mapping for \( n \) being assigned to either \(n\) or \(-n\) is forbidden. But both \(n\) and \(-n\) could be in the codomain, so the forbidden assignments per \( n \) are two possibilities each. However, the codomain element \(n\) and \( -n \) might overlap if \( n=0 \), but since \(n=0\) is excluded as \( f(0) \) can't be 0.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, actually, for each \( n \), \(n\) and \( -n \) are distinct, except when \(n=0\).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m So, for each \(n\), there are two forbidden assignments. But since the images are strictly increasing, we have to consider how this affects the entire mapping.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But each \(n\) imposes that in the mapping, \(f(n)\) is not \(n\) or \(-n\).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Therefore, the entire mapping must be such that for each \(n\), \(f(n) \in \{ -2010, \ldots, 2010 \} \setminus \{n, -n\} \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Another approach: imagine the codomain as an ordered set \( C \), and the domain is also ordered \( D \). Then, the problem is similar to counting the number of non-decreasing functions \( f: D \to C \), with the additional forbidden assignments.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But in our case, it's strictly increasing, so it's a bijection between the domain and the image, which is an increasing subsequence of length 2011.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Alternatively, we can model this as choosing a subset of size 2011 from the codomain \( C \) (excluding some points). But this might not directly help.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, actually, let's think about forbidden positions where assignments are not allowed. Since domain and codomain are both partially ordered, and we have a strictly increasing function, which is an order-preserving injective map.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Therefore, the problem reduces to counting injective order-preserving maps such that for each \(n\), \(f(n)\) is not equal to \(n\) or \(-n\).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Given that the number of injective order-preserving maps is \( \dbinom{4021}{2011} \), and the number of such maps avoiding some forbidden values is what we need, perhaps inclusion-exclusion is the way to go.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But the inclusion-exclusion term would be over all \(n\), considering that each \(n\) forbids two specific elements.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Let me define for each \(n\), the set \( A_n \) as the injective order-preserving maps where \( f(n) = n \), and \( B_n \) as where \( f(n) = -n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But actually, since \( n \) can be any of the 2011 domain elements, we need to define \( A_n \) as the sets where \( f(n) = n \) or \( f(n) = -n \). But since the maps must be injective and strictly increasing, each such forbidden assignment affects the count.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But in inclusion-exclusion, each term corresponds to excluding a particular event.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m So, for each \(n\), the first event is excluding \( f(n) = n \) or \( f(n) = -n \). So, for each \(n\), the inclusion-exclusion term would subtract the number of maps where \(f(n)\) is \(n\) or \( -n \), then add back where two are forbidden, and so on.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But since the domain is size 2011, the inclusion-exclusion becomes quite intricate.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But perhaps, for each \(n\), it's easier to compute the number of functions where \(f(n) = n\), then multiply and then apply inclusion-exclusion.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But considering the term for a single \(n\), suppose \(f(n) = n\). Then, the remaining \(2010\) elements must be chosen such that they are assigned to the rest of the domain in increasing order. Since \(f\) is strictly increasing, once \(f(n) = n\), all elements after \(n\) must be greater than \(n\), which are from \(n+1\) to \(1005\), and all elements before \(n\) can be from \(-1005\) to \(n-1\).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Similarly, \(f(n) = -n\) would require that the elements before \(n\) are from \(-1005\) to \(n-1\) and the elements after \(n\) are from \(n+1\) to \(1005\), but also avoiding forbidden positions. Wait, actually, if \( f(n) = -n \), which may or may not interfere with other mappings.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, but actually, when \(f(n) = -n\), \( -n \) could be within the codomain of the images for other \( k \neq n \). So, this complicates things because the forbidden assignments interfere across elements.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Therefore, perhaps we can model this as the problem of avoiding two elements in the codomain for each pre-image.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, but mapping is to the codomain where each image is unique and in order.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Alternatively, thinking in terms of the permutation matrices. Since each function is an injective order-preserving map, it's equivalent to choosing 2011 elements in strech ordering, so the total number is \( \dbinom{4021}{2011} \). To exclude the cases where for any \(n\), \(f(n) = n\) or \(f(n)= -n \), we can model this as exclusion for each \(n\).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But perhaps inclusion-exclusion is the way to go here, but automagically, as the forbidden positions are symmetric for each \(n\), the calculation can be based on the number of forbidden assignments.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, an alternative thought: perhaps these forbidden assignments are non-consecutive and are independent, except for cases where \(n\) is in the middle.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, perhaps not. Maybe an exponential generating function approach would help, but given that, maybe using the principle as follows:
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m For each element \(n\) in the domain, the number of injective increasing maps that map \(n\) to \(n\) or \( -n \) is equal to \( \dbinom{4021 - 2}{2010} \), because if we fix \(f(n)\) to be either \(n\) or \(-n\), then we need to choose the remaining 2010 elements from the remaining 4021 - 2 elements.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But if we apply inclusion-exclusion, considering all individual forbidden assignments, then also subtract the cases where two forbidden assignments are violated, add back those where three are violated, and so on.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m However, if n and m are consecutive numbers, the forbidden assignments may not interfere, but since the forbidden is per \(n\), it might complicate the variables.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Alternatively, since each forbidden assignment is acting on each \(n\) individually, perhaps the total number is \( \dbinom{4021}{2011} \) minus \( 2011 \times \dbinom{4021 - 2}{2010} \) plus some lower terms.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, let's consider the inclusion-exclusion formula.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m The number of functions without any forbidden assignments is:
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m \( N = \dbinom{4021}{2011} - \sum_{n} \dbinom{4021 - 2}{2010} + \sum_{n < m} \dbinom{4021 - 4}{2009} - \cdots \)
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But in this case, the "-1" term is for each forbidden assignment where \(f(n) =n\) or \(f(n) = -n\). The second term is for each unordered pair \( n < m \), the number of functions where \(f(n) =n\) and \(f(m) =m\), or \(f(n) = -n\) and \(f(m) = -m\), etc.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m However, it's not exactly this because the forbidden assignments can differ depending on \(n\) and \(m\). When \(n\) and \(m\) are consecutive, say \(m = n + 1\), whether \(f(n) = n\) and \(f(m)= m\) or \(f(n) = -n\) and \(f(m) = -m\), it's differently constrained.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But if the forbidden assignments are independent, perhaps the higher terms can be computed as combinations with multiple forbidden assignments.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But considering that for each \(n\), the forbidden assignments are independent, the inclusion-exclusion can be formulated as:
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m \( N = \sum_{k=0}^{2011} (-1)^k \dbinom{2011}{k} \dbinom{4021 - 2k}{2011 - k} } \)
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Is that correct?
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Yes, because:
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m - For each \(k\), we choose \(k\) elements from the domain to fix their images as forbidden.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m - For each such forbidden element \(n\), we "block" the images \(n\) or \(-n\) from being used by those \(k\) forbidden assignments.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m - Then, the number of ways to choose the images is \( \dbinom{4021 - 2k}{2011 - k} \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But hold on, since each forbidden \(n\) forbids two specific images, and if we choose \(k\) forbidden \(n\)s, then \(2k\) images are blocked.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Therefore, the total number is:
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m \( N = \sum_{k=0}^{1005} (-1)^k \dbinom{2011}{k} \dbinom{4021 - 2k}{2011 - k} } \)
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But wait, the domain size is 2011, so the maximum \(k\) can be is 1005, because if we choose \(k=1006\), then \(2011 - k = 1005\), but \(n =1006\) would require 2 images blocked, but 4021 - 2*1006 = 2010 -1=2009, and \(2011 - 1006 = 1005\). Hmm, perhaps overcomplicating.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, but the maximum \(k\) is 1005 because domain is 2011 elements, each forbidden assignment potentially using two different \(n\)'s. But perhaps 1005.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m So, the formula is:
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m \( \sum_{k=0}^{1005} (-1)^k \times \dbinom{2011}{k} \times \dbinom{4021 - 2k}{2011 - k} } \)
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But let me test it on smaller cases.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Suppose domain is domain size 1, codomain size 3.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Compute the number of strictly increasing functions where f(0) â‰  0 or -0=0. Wait, if domain is 0, codomain is {-2, -1, 0, 1, 2}. But wait, the problem's domain is from -1005 to 1005, so maybe considering a smaller domain.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, maybe let's take a small domain size.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Suppose domain size 2: \( \{-1, 0, 1\} \). Wait, domain is \( -1 \leq a \leq 1 \), so \( \{-1, 0, 1\} \), but to map to \( \{-2, -1, 0, 1, 2\} \). Wait, the codomain is size 5, but the domain is size 3. So N = \( \dbinom{5}{3} = 10 \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Now, forbid f(-1)= -1 or 1, f(0) can't be 0, f(1) can't be 1 or -1.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, perhaps still small. Maybe compute.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, the formula is:
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m \( N = \sum_{k=0}^{\lfloor (2011)/2 \rfloor} (-1)^k \dbinom{2011}{k} \dbinom{4021 - 2k}{2011 - k} } \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But perhaps computing N is difficult.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Alternatively, since each forbidden assignment essentially is: When choosing the image for a particular n, we have to exclude two possible images. So, we can model it as arrangements where each n contributes 4021 - 2 forbidden images.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But the linear algebra approach is not straightforward here.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, perhaps a better idea: note that each forbidden function can be considered as the union of two constraints: one for \( n \) and \( -n \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But since these constraints are "independent" across \( n \), it's non-trivial to multiply.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, but actually, in this problem, we can model it as a permutation where certain specific elements are forbidden.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But wait, permutation is a bijection, but in this problem, it's strictly increasing but not necessarily a bijection.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, perhaps if I think of each forbidden assignment as a pair in the map.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But it's late; perhaps the answer is \( \dbinom{4019}{2011} \times 2^{2011} \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, an alternative idea: if we model this as a grid or a poset where forbidden assignments are certain points, the number of chains might be correspond to 2^{2010} somewhere.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But, given time constraints, perhaps the answer is simply \( \dbinom{4019}{2011} \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But that seems too vague.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, wait.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Another thought: Since we are mapping a totally ordered set into another totally ordered set, such that the mapping is increasing and certain points are forbidden, then the number of such mappings is \( \dbinom{4019}{2011} - \) forbidden assignments.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But I don't think the problem can be solved via inclusion-exclusion directly as the forbidden conditions are not independent.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But perhaps in this specific case, total number is same as the total number of strictly increasing functions without forbidden points because the only forbidden points are mirroring symmetries, but each image is uniquely determined.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, perhaps using the principle that the forbidden assignments can be considered as ant Beauchamp permutations.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, perhaps it's simpler.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, since for each n, f(n) cannot be equal to n or -n, and the function is strictly increasing, perhaps each pre-image is uniquely forbidden.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, maybe bijectively.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, each forbidden mapping is determined by mapping n to forbidden places, and the overall count can be represented as a binomial coefficient adjusted by an extra factor for each forbidden assignment.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, but if it's K forbidden choices, then each choice affects the count.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But I think the exact formula is messy unless some kind of symmetric property is used.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Alternatively, think of the forbidden assignments as a sort of derangement, but in a highly specific way. But as in derangements, derangements count permutations without fixed points, here we are forbidding two points per pre-image.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But 4019 choose 2011. Wait, the original domain size is 4021, so 4021 - 2*2011 +1=  4021 - 4022 +1= (4021 - 4022) +1= (-1) +1= 0. That approach may not work.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait a minute, perhaps the original codomain size is 4021, and the image size is 2011.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Therefore, number of injective maps is \( \dbinom{4021}{2011} \). For each injection function, the forbidden assignments are 2n elements, each with two options.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But perhaps, given each forbidden assignment is unique, the count is \( \dbinom{4021}{2011} \times \prod_{n} (1 - 2/4021) \). But that is a continuous probability approximation.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But we need precise count, so the inclusion-exclusion is necessary.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, earlier equation: N = sum_{k=0}^{1005} (-1)^k C(2011, k) C(4021 - 2k, 2011 - k).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Hence, the number is sum_{k=0}^m (-1)^k * C(2011, k) * C(4021 - 2k, 2011 -k)}, where m is up to 1005.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But perhaps writing this as \( \dbinom{4021}{2011} \) minus something.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But unless m takes a closed-form.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Alternatively, perhaps realizing that each forbidden element can be represented as position: for each n in [-1005, ..., 1005], the images are forbidden at n and -n.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But as each forbidden per position, but since y = n and y= -n are symmetric, the inclusion-exclusion reduces to considering the number of fixed points.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Hmm, I seem to loop back to the same point.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Alternative approach: if the forbidden assignments are effectively injective, then perhaps the total number is similar to \( \dbinom{4019}{2011} \) as it's similar to choosing positions from a smaller set, but Iâ€™m not sure.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Alternatively, if we consider that each forbidden point effectively eliminates two choices, but as we have 2011 numbers, it's a 2011 size set, forbidden from certain elements.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But Anymore is probably I need to consider that, given the function is strictly increasing and forbidden to avoid two elements per term, the number is equal to the number of injective functions which inject 2011 elements from the 4021 but not into forbidden.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m So, in conclusion, as per the problem, it's required to count injective, strictly increasing functions with the forbidden points, so the answer is \( \dbinom{4021 - 2 \times 2011}{2011} \), but adjusted by inclusion-exclusion.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m But considering the time I can't compute the exact number. But given the original set and target size, perhaps the number is \( \dbinom{4019}{2011} \).
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m Wait, looking for an article or standard problem: Such a problem is called the number of injections from a set into another with forbidden assignments, and our forbidden assignments are two points for each element.
[36m(TaskRunner pid=776592)[0m 
[36m(TaskRunner pid=776592)[0m According to the principle,
[36m(TaskRunner pid=776592)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:22:42<12:44:57, 121.42s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:24:24<12:06:29, 115.62s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:26:06<11:37:56, 111.37s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:27:56<11:33:33, 110.97s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:29:38<11:15:30, 108.37s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:31:25<11:10:47, 107.90s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:33:05<10:55:45, 105.77s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:35:04<11:17:37, 109.59s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:38:02<13:22:33, 130.14s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:39:47<12:33:13, 122.48s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:41:23<11:42:33, 114.55s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:43:07<11:21:09, 111.36s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:44:53<11:09:43, 109.79s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:46:27<10:38:50, 105.02s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:48:05<10:25:02, 103.03s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:49:49<10:25:24, 103.37s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:51:36<10:29:35, 104.35s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:53:16<10:21:02, 103.22s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 18:08:25,043:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:56:18<12:40:49, 126.80s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:57:57<11:49:04, 118.51s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:59:42<11:22:59, 114.47s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:01:23<10:56:07, 110.27s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:03:20<11:06:49, 112.38s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:05:02<10:46:26, 109.26s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:06:47<10:36:42, 107.92s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:08:26<10:19:18, 105.26s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:10:07<10:10:20, 104.04s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:11:48<10:03:10, 103.11s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:14:41<12:02:39, 123.89s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:16:23<11:23:57, 117.59s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 18:31:27,290:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:18:05<10:54:35, 112.86s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:19:46<10:31:18, 109.16s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 18:34:53,288:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:21:31<10:23:04, 108.05s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:23:12<10:09:20, 105.97s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:24:53<9:58:32, 104.40s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:26:32<9:48:01, 102.86s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:28:14<9:44:41, 102.58s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:29:56<9:41:00, 102.23s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:32:43<11:30:20, 121.83s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:34:26<10:56:03, 116.12s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:36:05<10:24:42, 110.89s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:37:47<10:08:21, 108.31s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:39:24<9:47:29, 104.91s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:41:06<9:40:17, 103.93s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:42:39<9:21:26, 100.86s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:44:14<9:09:42, 99.05s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:45:53<9:07:08, 98.88s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:47:45<9:27:29, 102.87s/it]
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(TaskRunner pid=776592)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:50:52<11:45:26, 128.26s/it]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=776592)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:52:36<11:02:54, 120.90s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:54:18<10:29:05, 115.08s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:55:55<9:58:42, 109.85s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:57:36<9:41:53, 107.10s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:59:15<9:26:39, 104.62s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:00:49<9:07:31, 101.39s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:02:30<9:05:23, 101.31s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:04:13<9:06:06, 101.76s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:05:55<9:05:26, 101.95s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:08:48<10:57:17, 123.24s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:10:36<10:30:47, 118.64s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:12:16<9:59:32, 113.12s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:13:53<9:32:15, 108.31s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:15:27<9:08:22, 104.12s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:17:06<8:57:49, 102.44s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:18:46<8:51:48, 101.62s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:20:21<8:39:50, 99.65s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:21:58<8:33:52, 98.82s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:23:31<8:24:36, 97.35s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:26:19<10:12:00, 118.45s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:27:57<9:37:47, 112.19s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:29:35<9:13:52, 107.90s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:31:11<8:55:01, 104.57s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:32:47<8:39:21, 101.83s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:34:29<8:38:12, 101.94s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:36:13<8:40:05, 102.65s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:37:50<8:29:56, 100.98s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:39:32<8:29:01, 101.13s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:41:13<8:26:37, 100.99s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:44:04<10:10:35, 122.12s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 19:59:09,334:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:45:50<9:45:04, 117.41s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:47:28<9:13:11, 111.38s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:49:12<9:01:16, 109.35s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:50:48<8:39:45, 105.36s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:52:36<8:41:55, 106.15s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:54:17<8:31:28, 104.38s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 20:09:22,767:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:55:58<8:25:52, 103.59s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:57:42<8:23:31, 103.47s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:59:27<8:24:04, 103.93s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:02:19<10:01:34, 124.46s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:03:59<9:24:49, 117.26s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:05:39<8:57:42, 112.02s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:07:19<8:38:36, 108.42s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:08:59<8:24:07, 105.76s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:10:36<8:10:42, 103.31s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:12:20<8:10:05, 103.54s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:13:57<7:58:47, 101.51s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:15:37<7:55:05, 101.08s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 20:30:40,686:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:17:21<7:56:44, 101.80s/it]
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(TaskRunner pid=776592)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:20:34<10:02:20, 129.07s/it]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=776592)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:22:13<9:18:20, 120.07s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:23:53<8:48:45, 114.12s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:25:33<8:26:55, 109.80s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:27:15<8:15:34, 107.73s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:28:56<8:03:57, 105.59s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:30:39<7:58:12, 104.72s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:32:27<8:01:40, 105.86s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:34:04<7:47:01, 103.02s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:35:40<7:35:47, 100.91s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:38:32<9:10:55, 122.43s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:40:10<8:35:03, 114.88s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:41:48<8:10:49, 109.89s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:43:32<8:01:43, 108.25s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:45:12<7:48:04, 105.58s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:46:48<7:34:39, 102.94s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:48:24<7:23:47, 100.86s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:50:03<7:19:45, 100.33s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:51:40<7:13:35, 99.30s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:53:25<7:18:36, 100.83s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:56:12<8:43:07, 120.72s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:57:47<8:07:41, 112.98s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:59:25<7:46:50, 108.57s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:00:54<7:20:17, 102.79s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:02:35<7:15:23, 102.04s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:04:11<7:06:52, 100.44s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:05:46<6:57:44, 98.68s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:07:30<7:02:26, 100.18s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:09:07<6:57:07, 99.31s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:10:53<7:04:17, 101.43s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:13:39<8:22:59, 120.72s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:15:15<7:49:37, 113.16s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:16:51<7:27:32, 108.28s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:18:29<7:12:27, 105.05s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:19:59<6:52:43, 100.66s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:21:33<6:41:54, 98.43s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:23:07<6:35:43, 97.31s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:24:38<6:26:36, 95.46s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:26:19<6:30:54, 96.92s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:27:56<6:30:02, 97.11s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:30:46<7:55:29, 118.87s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:32:29<7:34:37, 114.13s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:34:05<7:10:40, 108.58s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:35:41<6:54:37, 104.97s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:37:17<6:42:23, 102.30s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:38:56<6:36:44, 101.30s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:40:32<6:28:52, 99.71s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:42:08<6:22:49, 98.58s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:43:46<6:19:44, 98.21s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:45:23<6:17:29, 98.05s/it]
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(TaskRunner pid=776592)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:48:26<7:53:33, 123.54s/it]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=776592)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:50:00<7:17:53, 114.73s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:51:35<6:53:33, 108.83s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:53:10<6:35:09, 104.45s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:54:47<6:25:16, 102.28s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:56:19<6:12:13, 99.26s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:57:58<6:09:48, 99.05s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:59:33<6:03:27, 97.79s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:01:13<6:04:21, 98.48s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 22:16:14,577:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:02:51<6:02:28, 98.41s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:05:33<7:11:15, 117.61s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:07:10<6:46:38, 111.41s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:08:52<6:34:19, 108.53s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:10:28<6:19:01, 104.80s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:12:09<6:12:42, 103.53s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:13:45<6:02:53, 101.27s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:15:25<5:59:48, 100.88s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:17:00<5:52:20, 99.25s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:18:32<5:42:39, 96.98s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:20:08<5:39:54, 96.65s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 22:35:11,175:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 22:35:16,196:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 22:35:21,209:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:23:08<7:06:33, 121.87s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:24:45<6:38:01, 114.27s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:26:15<6:10:37, 106.91s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:27:48<5:55:01, 102.90s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:29:26<5:47:58, 101.35s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:30:59<5:37:24, 98.76s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:32:37<5:35:11, 98.59s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:34:14<5:32:35, 98.30s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:35:50<5:28:22, 97.54s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:37:25<5:23:33, 96.58s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 22:52:29,038:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:40:15<6:35:16, 118.58s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:41:46<6:06:46, 110.58s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 22:56:47,670:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:43:26<5:53:40, 107.17s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:45:01<5:40:13, 103.62s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:46:38<5:32:27, 101.77s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:48:20<5:30:37, 101.73s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:49:56<5:22:56, 99.88s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:51:33<5:18:49, 99.12s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:53:10<5:15:16, 98.52s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:54:44<5:09:13, 97.14s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:57:32<6:15:12, 118.49s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:59:07<5:51:09, 111.48s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:00:42<5:33:00, 106.28s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:02:15<5:18:51, 102.31s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:03:53<5:13:01, 100.98s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:05:29<5:07:23, 99.70s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:07:09<5:05:58, 99.77s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:08:49<5:04:38, 99.88s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:10:25<4:58:42, 98.47s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:12:03<4:57:15, 98.54s/it]
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(TaskRunner pid=776592)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:15:06<6:11:12, 123.73s/it]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=776592)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:16:46<5:47:53, 116.61s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:18:23<5:28:34, 110.76s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:20:02<5:16:15, 107.21s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:21:35<5:02:22, 103.09s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:23:07<4:50:43, 99.68s/it] 
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 23:38:09,983:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:24:51<4:52:41, 100.93s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:26:23<4:43:32, 98.34s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:27:57<4:38:13, 97.06s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:29:37<4:39:06, 97.93s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:32:22<5:34:21, 118.01s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:33:55<5:11:12, 110.49s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:35:34<4:59:55, 107.11s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:37:09<4:47:30, 103.30s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:38:47<4:42:03, 101.95s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:40:28<4:39:27, 101.62s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:42:12<4:39:17, 102.18s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 23:57:11,410:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 23:57:16,460:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 23:57:21,480:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-22 23:57:26,484:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:44:01<4:43:47, 104.46s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:45:34<4:32:26, 100.90s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 00:00:37,118:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:47:18<4:33:20, 101.87s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:50:01<5:20:17, 120.11s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:51:38<4:59:41, 113.09s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 00:06:39,197:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 00:06:44,210:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:53:22<4:50:49, 110.44s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:54:56<4:36:16, 105.58s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:56:36<4:30:30, 104.04s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [9:58:12<4:22:21, 101.56s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [9:59:49<4:17:02, 100.14s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:01:26<4:13:11, 99.29s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:03:01<4:08:17, 98.01s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:04:32<4:00:51, 95.71s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:07:11<4:47:02, 114.82s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:08:41<4:26:21, 107.26s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:10:11<4:11:46, 102.07s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:11:52<4:09:31, 101.85s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:13:25<4:01:01, 99.05s/it] 
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 00:28:25,390:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:15:02<3:58:24, 98.65s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:16:37<3:53:57, 97.48s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:18:16<3:53:14, 97.86s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:19:54<3:51:46, 97.93s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:21:32<3:50:27, 98.07s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:24:18<4:36:18, 118.42s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:26:00<4:22:48, 113.44s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:27:38<4:09:54, 108.66s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:29:14<4:00:02, 105.13s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:30:45<3:48:30, 100.81s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:32:23<3:44:30, 99.78s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:34:01<3:41:55, 99.37s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:35:38<3:38:50, 98.72s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:37:14<3:35:08, 97.79s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:38:43<3:27:57, 95.25s/it]
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(TaskRunner pid=776592)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:41:51<4:26:22, 122.94s/it]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=776592)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:43:28<4:08:03, 115.37s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:45:09<3:56:57, 111.07s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:46:49<3:47:58, 107.70s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:48:34<3:44:18, 106.81s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:50:12<3:36:57, 104.14s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:51:46<3:28:41, 100.98s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:53:24<3:25:26, 100.22s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:54:58<3:20:04, 98.40s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:56:43<3:22:08, 100.24s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [10:59:25<3:57:39, 118.83s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:01:07<3:45:38, 113.77s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:02:45<3:34:18, 108.97s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:04:19<3:24:15, 104.75s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:05:56<3:17:51, 102.34s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 01:20:56,434:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 01:21:01,481:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 01:21:06,496:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:07:41<3:17:21, 102.97s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:09:11<3:08:23, 99.15s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:10:41<3:01:43, 96.49s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:12:16<2:58:59, 95.89s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 01:27:13,376:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 01:27:18,444:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 01:27:23,642:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:14:00<3:02:01, 98.39s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:16:42<3:35:40, 117.64s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:18:16<3:20:20, 110.28s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:19:48<3:09:03, 105.04s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:21:27<3:04:00, 103.18s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:22:56<2:54:31, 98.79s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:24:29<2:49:48, 97.03s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:25:58<2:44:24, 94.85s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:27:31<2:41:35, 94.14s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:29:02<2:38:15, 93.09s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:30:33<2:35:51, 92.59s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:33:13<3:07:52, 112.73s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:34:46<2:56:12, 106.79s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 01:49:47,096:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 01:49:52,114:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 01:49:57,131:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:36:37<2:56:29, 108.06s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:38:13<2:49:13, 104.67s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 01:53:18,362:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:40:01<2:48:57, 105.60s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:41:35<2:41:24, 101.94s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:43:08<2:35:38, 99.35s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:44:45<2:33:09, 98.81s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:46:18<2:28:33, 96.89s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:47:52<2:25:46, 96.11s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:50:37<2:55:00, 116.67s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:52:11<2:43:08, 109.99s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:53:44<2:33:47, 104.86s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [11:55:13<2:24:59, 100.00s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [11:56:50<2:21:56, 99.03s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [11:58:31<2:21:20, 99.77s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:00:02<2:15:59, 97.14s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:01:37<2:13:19, 96.37s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:03:11<2:11:03, 95.90s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:04:46<2:09:03, 95.60s/it]
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(TaskRunner pid=776592)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:07:46<2:41:09, 120.87s/it]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=776592)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:09:24<2:30:01, 113.94s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:11:07<2:23:45, 110.58s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:12:46<2:17:45, 107.34s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:14:24<2:12:06, 104.30s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:15:58<2:06:31, 101.22s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:17:33<2:02:43, 99.50s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:19:10<2:00:16, 98.86s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:20:50<1:58:56, 99.11s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:22:27<1:56:20, 98.31s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:25:17<2:19:45, 119.79s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:26:54<2:10:00, 113.05s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:28:29<2:01:53, 107.54s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:30:09<1:57:32, 105.27s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:31:47<1:53:41, 103.36s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:33:17<1:47:19, 99.08s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:34:55<1:45:22, 98.79s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:36:36<1:44:27, 99.48s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:38:11<1:41:25, 98.16s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:39:48<1:39:30, 97.87s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:42:35<1:58:30, 118.51s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:44:11<1:49:50, 111.71s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:45:53<1:45:21, 108.99s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:47:30<1:39:56, 105.20s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:49:09<1:36:30, 103.41s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:50:47<1:33:23, 101.88s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:52:24<1:30:26, 100.48s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [12:54:01<1:27:47, 99.39s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [12:55:42<1:26:24, 99.69s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [12:57:17<1:23:45, 98.55s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:00:04<1:39:14, 119.10s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:01:43<1:32:07, 112.80s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:03:19<1:26:13, 107.78s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:05:03<1:23:38, 106.78s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:06:41<1:19:46, 104.05s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:08:14<1:15:31, 100.70s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:09:49<1:12:47, 99.25s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:11:28<1:10:59, 99.06s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:13:04<1:08:45, 98.23s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:14:46<1:07:46, 99.19s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:17:30<1:19:09, 118.74s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:19:06<1:12:37, 111.74s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:20:46<1:08:35, 108.31s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:22:23<1:04:46, 105.04s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:24:00<1:01:36, 102.69s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:25:38<59:02, 101.23s/it]  
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 03:40:39,973:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 03:40:44,992:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:27:22<57:42, 101.83s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:28:57<54:59, 99.98s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:30:33<52:35, 98.60s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:32:10<50:46, 98.28s/it]
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(TaskRunner pid=776592)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:35:11<1:01:31, 123.05s/it]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=776592)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:36:48<55:39, 115.16s/it]  
[36m(TaskRunner pid=776592)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:38:20<50:34, 108.38s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:40:03<48:00, 106.69s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:41:38<44:43, 103.20s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:43:10<41:37, 99.89s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:44:48<39:39, 99.15s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:46:31<38:27, 100.34s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:48:08<36:25, 99.32s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:49:43<34:18, 98.04s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [13:52:30<39:36, 118.82s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [13:54:14<36:14, 114.46s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [13:55:51<32:44, 109.13s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [13:57:28<29:53, 105.49s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [13:59:05<27:27, 103.00s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:00:43<25:19, 101.31s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:02:25<23:41, 101.53s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:04:00<21:35, 99.64s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:05:36<19:44, 98.71s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:07:12<17:56, 97.89s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:10:05<20:02, 120.25s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:11:41<16:57, 113.02s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:13:21<14:33, 109.19s/it]
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 04:28:24,418:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 04:28:29,444:Timeout during comparison
[36m(TaskRunner pid=776592)[0m WARNING:2025-12-23 04:28:34,524:Timeout during comparison
[36m(TaskRunner pid=776592)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:15:14<12:51, 110.23s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:16:48<10:33, 105.52s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:18:24<08:32, 102.55s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:19:59<06:40, 100.22s/it]
[36m(TaskRunner pid=776592)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:21:32<04:53, 97.98s/it] 
[36m(TaskRunner pid=776592)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:23:17<03:20, 100.29s/it]
[36m(TaskRunner pid=776592)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:25:01<01:41, 101.28s/it]
[36m(WorkerDict pid=780147)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=780147)[0m   warnings.warn(
[36m(TaskRunner pid=776592)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:28:07<01:48, 108.74s/it]
[36m(WorkerDict pid=780323)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=780323)[0m   warnings.warn([32m [repeated 3x across cluster][0m
