
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=8
+ n_rollout_min=8
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=0
+ enable_temperature_scheduler=False
+ enable_annealing=False
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.1/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_covvar_kappa_0.1//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.1//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_covvar_kappa_0.1//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=covvar data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=8 actor_rollout_ref.rollout.n_high=8 actor_rollout_ref.rollout.n_update=0 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=False actor_rollout_ref.rollout.enable_annealing=False actor_rollout_ref.rollout.max_steps=480 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_covvar_kappa_0.1/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-09 18:50:09,266	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=79845)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 18:50:34,323:Waiting for register center actor llWZj9_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=83615)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=83410)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=83410)[0m [rank0]:[W1109 18:50:53.005697356 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=83615)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=83615)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=83410)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m [rank1]:[W1109 18:50:53.344112482 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83410)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=83615)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=83410)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=83617)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(WorkerDict pid=83410)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:   0%|          | 1/480 [02:00<16:01:41, 120.46s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   0%|          | 2/480 [04:00<15:59:12, 120.40s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   1%|          | 3/480 [06:06<16:15:25, 122.70s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   1%|          | 4/480 [08:04<15:58:50, 120.86s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   1%|          | 5/480 [10:04<15:56:18, 120.80s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   1%|â–         | 6/480 [12:06<15:57:09, 121.16s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   1%|â–         | 7/480 [14:09<15:58:02, 121.53s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   2%|â–         | 8/480 [16:10<15:54:29, 121.33s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   2%|â–         | 9/480 [18:12<15:55:04, 121.67s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 19:14:38,537:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:   2%|â–         | 10/480 [21:42<19:28:01, 149.11s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   2%|â–         | 11/480 [23:42<18:15:15, 140.12s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   2%|â–Ž         | 12/480 [25:40<17:19:38, 133.29s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   3%|â–Ž         | 13/480 [27:47<17:01:59, 131.31s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   3%|â–Ž         | 14/480 [29:47<16:34:39, 128.07s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   3%|â–Ž         | 15/480 [31:45<16:09:23, 125.08s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   3%|â–Ž         | 16/480 [33:44<15:53:21, 123.28s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   4%|â–Ž         | 17/480 [35:42<15:38:40, 121.64s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   4%|â–         | 18/480 [37:40<15:28:36, 120.60s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   4%|â–         | 19/480 [39:40<15:23:57, 120.25s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   4%|â–         | 20/480 [43:02<18:30:43, 144.88s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 19:37:38,801:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:   4%|â–         | 21/480 [45:09<17:46:19, 139.39s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   5%|â–         | 22/480 [47:10<17:01:58, 133.88s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   5%|â–         | 23/480 [49:10<16:27:20, 129.63s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   5%|â–Œ         | 24/480 [51:06<15:54:35, 125.60s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   5%|â–Œ         | 25/480 [52:59<15:24:35, 121.93s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   5%|â–Œ         | 26/480 [54:56<15:10:33, 120.34s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   6%|â–Œ         | 27/480 [56:58<15:11:50, 120.77s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   6%|â–Œ         | 28/480 [58:48<14:47:19, 117.79s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:47<14:46:15, 117.91s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 19:56:55,870:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:   6%|â–‹         | 30/480 [1:04:01<17:37:20, 140.98s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:48<16:18:31, 130.76s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:34<15:20:41, 123.31s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:31<15:04:51, 121.46s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:29<14:54:16, 120.31s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:21<14:34:16, 117.88s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   8%|â–Š         | 36/480 [1:15:12<14:17:32, 115.88s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   8%|â–Š         | 37/480 [1:17:02<14:02:33, 114.12s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:59<14:07:07, 114.99s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:47<13:49:02, 112.79s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:57<16:35:56, 135.81s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:46<15:35:02, 127.80s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:38<14:59:54, 123.28s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   9%|â–‰         | 43/480 [1:29:27<14:24:45, 118.73s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   9%|â–‰         | 44/480 [1:31:17<14:04:08, 116.17s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:   9%|â–‰         | 45/480 [1:33:01<13:35:23, 112.47s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:52<13:30:54, 112.11s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:40<13:19:46, 110.82s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:31<13:19:05, 110.98s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:24<13:20:32, 111.45s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 20:36:27,419:Timeout during comparison
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(TaskRunner pid=79845)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:49<16:40:03, 139.54s/it]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:37<15:30:06, 130.09s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 20:40:03,314:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:47:27<14:44:58, 124.06s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:49:11<14:00:50, 118.15s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:51:03<13:46:22, 116.39s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:51<13:26:10, 113.81s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:38<13:10:29, 111.86s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:56:31<13:09:27, 111.98s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:58:16<12:53:38, 110.00s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [2:00:01<12:41:48, 108.57s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 20:54:23,711:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:59<15:05:41, 129.38s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:45<14:14:41, 122.39s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:06:33<13:41:58, 117.99s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:08:22<13:20:14, 115.14s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:10:19<13:23:04, 115.83s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:12:03<12:56:01, 112.20s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:13:54<12:52:17, 111.93s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:15:38<12:34:14, 109.57s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:17:23<12:23:02, 108.21s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:19:11<12:20:27, 108.10s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:22:16<14:56:45, 131.23s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:24:00<13:58:25, 123.00s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:25:43<13:15:24, 116.97s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:27:28<12:49:48, 113.49s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:29:18<12:39:40, 112.27s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:31:01<12:19:27, 109.55s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:32:50<12:17:13, 109.49s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:34:40<12:15:25, 109.49s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:36:27<12:08:55, 108.79s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 21:30:55,389:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:38:23<12:21:15, 110.91s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 21:32:48,560:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:41:29<14:50:46, 133.62s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:43:16<13:55:06, 125.58s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:45:03<13:16:46, 120.12s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:46:53<12:54:22, 117.03s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:48:42<12:36:18, 114.59s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:50:31<12:22:57, 112.85s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:52:23<12:20:15, 112.73s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:54:13<12:12:01, 111.76s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:56:04<12:07:59, 111.43s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:57:51<11:57:54, 110.16s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [3:01:00<14:29:47, 133.81s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 21:55:26,474:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:02:52<13:45:19, 127.30s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 21:57:17,320:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:04:43<13:11:59, 122.47s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:06:32<12:43:06, 118.31s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:08:24<12:30:05, 116.60s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:10:10<12:07:57, 113.45s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:12:03<12:04:54, 113.27s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:13:52<11:53:32, 111.78s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:15:30<11:26:06, 107.77s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:17:21<11:31:13, 108.86s/it]
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(WorkerDict pid=83410)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=83410)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=79845)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:20:41<14:21:18, 136.00s/it]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:22:20<13:10:20, 125.12s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:24:05<12:29:20, 118.94s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:25:44<11:50:26, 113.07s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:27:25<11:24:52, 109.29s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:29:13<11:21:30, 109.04s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:30:55<11:05:54, 106.83s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:32:43<11:05:47, 107.10s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:34:25<10:56:02, 105.81s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:36:20<11:09:46, 108.32s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:39:21<13:23:32, 130.31s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:41:09<12:39:50, 123.55s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:42:48<11:51:50, 116.06s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:44:31<11:26:25, 112.22s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:46:16<11:11:22, 110.06s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:47:51<10:43:02, 105.71s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:49:33<10:33:03, 104.35s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:51:16<10:29:08, 103.99s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:52:57<10:21:59, 103.09s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:54:39<10:18:14, 102.75s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:57:36<12:31:20, 125.22s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:59:12<11:36:07, 116.34s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 22:53:37,116:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:01:05<11:27:35, 115.24s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 22:55:25,059:Timeout during comparison
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 22:55:31,288:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:02:54<11:14:57, 113.44s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 22:57:22,214:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:04:50<11:16:58, 114.10s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:06:31<10:52:00, 110.20s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:08:15<10:40:17, 108.53s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:09:53<10:18:52, 105.19s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:11:34<10:10:12, 104.01s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:13:14<10:00:57, 102.73s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:16:05<11:59:59, 123.43s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:17:48<11:21:25, 117.15s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:19:24<10:42:29, 110.78s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:21:04<10:21:56, 107.54s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:22:44<10:07:05, 105.28s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:24:23<9:54:58, 103.47s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:26:02<9:44:52, 102.01s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:27:40<9:36:24, 100.83s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:29:18<9:30:48, 100.14s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:30:57<9:25:59, 99.59s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:33:46<11:23:16, 120.58s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-09 23:28:06,796:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:35:31<10:55:22, 116.00s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:37:09<10:23:07, 110.61s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:38:52<10:07:02, 108.08s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:40:28<9:46:20, 104.70s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:42:05<9:30:31, 102.18s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:43:37<9:12:21, 99.22s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:45:13<9:04:43, 98.15s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:46:52<9:05:40, 98.62s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:48:36<9:12:19, 100.12s/it]
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(TaskRunner pid=79845)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:51:40<11:29:15, 125.32s/it]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:53:18<10:41:39, 117.02s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:54:55<10:07:52, 111.20s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:56:33<9:42:57, 106.96s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:58:13<9:31:20, 105.15s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:59:51<9:17:23, 102.90s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:01:24<8:59:36, 99.93s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:02:57<8:46:22, 97.78s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:04:38<8:50:36, 98.87s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:06:16<8:47:32, 98.60s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:09:08<10:43:30, 120.66s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:11:01<10:28:41, 118.25s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:12:42<9:59:12, 113.06s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:14:19<9:31:22, 108.15s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:15:54<9:08:58, 104.23s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:17:27<8:50:35, 101.07s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:19:04<8:41:49, 99.71s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:20:36<8:28:40, 97.51s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:22:15<8:28:18, 97.75s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:23:49<8:21:17, 96.71s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:26:38<10:11:19, 118.32s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:28:15<9:36:21, 111.91s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:29:50<9:09:12, 106.99s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:31:27<8:51:42, 103.92s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:32:59<8:31:31, 100.30s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:34:38<8:28:25, 100.02s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:36:16<8:23:20, 99.34s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:37:54<8:19:58, 99.01s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:39:33<8:18:12, 98.98s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:41:12<8:16:20, 98.94s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:44:05<10:06:16, 121.25s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:45:44<9:31:21, 114.66s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:47:21<9:02:47, 109.29s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:49:02<8:48:15, 106.72s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:50:34<8:25:00, 102.37s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:52:14<8:19:31, 101.60s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:53:50<8:09:16, 99.85s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:55:26<8:01:58, 98.70s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:57:06<8:02:56, 99.24s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:58:46<8:01:31, 99.28s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:01:35<9:41:21, 120.28s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:03:11<9:03:42, 112.88s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:04:43<8:32:54, 106.86s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:06:20<8:16:49, 103.87s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:07:56<8:02:51, 101.30s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:09:31<7:53:26, 99.67s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:11:12<7:52:50, 99.90s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:12:46<7:43:25, 98.25s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:14:25<7:43:03, 98.52s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:16:03<7:39:26, 98.10s/it]
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(TaskRunner pid=79845)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:19:13<9:46:58, 125.78s/it]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:20:49<9:03:59, 116.99s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:22:28<8:36:25, 111.46s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:24:06<8:15:28, 107.32s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:25:40<7:55:47, 103.43s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:27:19<7:47:28, 101.99s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:28:58<7:42:47, 101.34s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:30:42<7:43:56, 101.96s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:32:13<7:27:12, 98.65s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:33:50<7:24:04, 98.32s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:36:43<9:02:13, 120.49s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:38:20<8:29:06, 113.55s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:39:58<8:06:09, 108.84s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:41:37<7:51:06, 105.87s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:43:16<7:40:32, 103.88s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:44:48<7:23:30, 100.42s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:46:22<7:13:22, 98.49s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:48:00<7:10:19, 98.17s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:49:31<6:59:55, 96.17s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 01:43:55,315:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:51:19<7:13:37, 99.68s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:54:07<8:41:18, 120.30s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:55:44<8:08:09, 113.09s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:57:23<7:48:27, 108.95s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:58:53<7:22:13, 103.24s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:00:30<7:12:24, 101.35s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:02:05<7:02:13, 99.35s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:03:38<6:52:37, 97.47s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:05:19<6:56:27, 98.77s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:06:55<6:51:02, 97.87s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:08:38<6:55:50, 99.41s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 02:04:26,670:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:11:32<8:27:31, 121.81s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:13:06<7:50:15, 113.32s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:14:39<7:23:57, 107.41s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:16:17<7:09:48, 104.41s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:17:50<6:53:58, 100.97s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:19:27<6:47:14, 99.73s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:21:02<6:40:03, 98.38s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:22:35<6:32:09, 96.83s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:24:15<6:33:55, 97.67s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:25:50<6:29:03, 96.86s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:28:40<7:55:12, 118.80s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:30:29<7:41:36, 115.88s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:32:06<7:17:32, 110.30s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:33:46<7:03:09, 107.13s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:35:23<6:49:19, 104.06s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:37:02<6:42:23, 102.74s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:38:38<6:32:07, 100.54s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:40:15<6:26:27, 99.52s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:41:55<6:25:06, 99.60s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:43:33<6:21:40, 99.14s/it]
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(TaskRunner pid=79845)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:46:43<8:05:04, 126.54s/it]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:48:19<7:27:31, 117.25s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:49:54<7:00:18, 110.61s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:51:29<6:40:36, 105.89s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:53:05<6:27:31, 102.88s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:54:37<6:14:34, 99.89s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:56:15<6:10:00, 99.11s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:57:46<5:59:20, 96.68s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:59:25<6:00:01, 97.30s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 02:53:39,511:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:01:01<5:57:31, 97.07s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:03:47<7:11:40, 117.73s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:05:24<6:47:31, 111.65s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:07:05<6:33:18, 108.25s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:08:43<6:20:08, 105.11s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:10:24<6:14:34, 104.05s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:11:58<6:01:24, 100.86s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:13:33<5:54:22, 99.36s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:15:07<5:46:17, 97.55s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:16:37<5:36:44, 95.30s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:18:13<5:36:32, 95.70s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:21:03<6:52:37, 117.89s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:22:42<6:30:36, 112.14s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:24:14<6:07:56, 106.14s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:25:55<6:00:37, 104.53s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:27:35<5:54:07, 103.14s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:29:09<5:43:08, 100.43s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:30:50<5:42:29, 100.73s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:32:31<5:40:58, 100.78s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:34:08<5:35:16, 99.59s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:35:46<5:32:02, 99.12s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:38:38<6:43:20, 121.00s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:40:11<6:13:30, 112.61s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:41:48<5:55:47, 107.82s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:43:25<5:43:19, 104.57s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:45:07<5:39:02, 103.79s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:46:46<5:32:46, 102.39s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:48:24<5:27:22, 101.25s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:50:03<5:23:18, 100.51s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:51:42<5:19:57, 99.99s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:53:20<5:16:20, 99.37s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:56:16<6:27:57, 122.51s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:57:56<6:03:56, 115.54s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [8:59:36<5:47:43, 110.98s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:01:11<5:30:56, 106.18s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:02:49<5:21:30, 103.71s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:04:29<5:16:40, 102.71s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:06:12<5:14:54, 102.69s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:07:47<5:05:56, 100.31s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:09:27<5:04:46, 100.47s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:11:05<5:00:18, 99.55s/it] 
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(TaskRunner pid=79845)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:14:13<6:18:21, 126.12s/it]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:15:51<5:51:12, 117.72s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:17:28<5:30:38, 111.45s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:19:09<5:19:31, 108.32s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:20:49<5:10:42, 105.92s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:22:26<5:00:30, 103.03s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:24:03<4:53:38, 101.26s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:25:38<4:47:04, 99.56s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:27:17<4:44:55, 99.39s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:29:00<4:45:50, 100.30s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:31:53<5:46:20, 122.24s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:33:31<5:23:57, 115.01s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:35:10<5:08:28, 110.17s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:36:48<4:56:46, 106.62s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:38:30<4:50:23, 104.96s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:40:09<4:43:51, 103.22s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:41:55<4:44:48, 104.20s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 04:36:13,063:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:43:34<4:38:54, 102.67s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:45:14<4:34:26, 101.64s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:46:54<4:31:24, 101.14s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:49:48<5:28:04, 123.03s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:51:28<5:08:23, 116.38s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:53:03<4:49:13, 109.83s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:54:39<4:36:40, 105.74s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [9:56:24<4:33:55, 105.36s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [9:58:04<4:28:37, 103.98s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [9:59:47<4:26:04, 103.66s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:01:31<4:24:22, 103.68s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:03:12<4:20:21, 102.77s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:04:50<4:15:37, 101.57s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:07:42<5:06:07, 122.45s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:09:16<4:43:16, 114.07s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:10:52<4:28:08, 108.71s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:12:35<4:22:07, 106.99s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:14:13<4:13:11, 104.05s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:15:49<4:05:38, 101.65s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:17:28<4:02:40, 101.12s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:19:11<4:01:44, 101.43s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:20:51<3:59:29, 101.19s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:22:28<3:54:54, 99.96s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:25:22<4:44:50, 122.07s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 05:19:41,413:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:27:07<4:30:53, 116.93s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:28:49<4:18:45, 112.51s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:30:31<4:09:40, 109.35s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:32:06<3:58:15, 105.12s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:33:47<3:53:33, 103.80s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:35:27<3:48:57, 102.52s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:37:08<3:46:10, 102.04s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:38:50<3:44:59, 102.27s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:40:25<3:38:23, 100.03s/it]
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(TaskRunner pid=79845)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:43:32<4:33:10, 126.08s/it]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:45:16<4:16:37, 119.36s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:47:00<4:04:48, 114.75s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:48:43<3:55:49, 111.41s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:50:25<3:47:53, 108.52s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:52:06<3:41:09, 106.15s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:53:44<3:34:47, 103.93s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:55:25<3:30:57, 102.91s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [10:57:00<3:24:36, 100.62s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [10:58:47<3:26:18, 102.30s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:01:37<4:05:35, 122.80s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:03:14<3:48:14, 115.08s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:04:57<3:38:50, 111.27s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:06:33<3:28:04, 106.71s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:08:10<3:21:04, 104.00s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 06:02:27,799:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:09:50<3:16:39, 102.60s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:11:23<3:09:25, 99.70s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:12:58<3:05:27, 98.47s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:14:37<3:03:56, 98.54s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:16:13<3:01:08, 97.92s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 06:10:33,969:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:19:13<3:44:42, 122.57s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:20:50<3:28:13, 114.61s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:22:30<3:18:25, 110.23s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:24:11<3:11:42, 107.50s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:25:44<3:02:24, 103.25s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:27:21<2:57:25, 101.39s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:28:56<2:52:27, 99.49s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:30:37<2:51:25, 99.86s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:32:13<2:47:57, 98.79s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:33:49<2:44:59, 98.02s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:36:41<3:20:13, 120.14s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:38:20<3:07:35, 113.70s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 06:32:38,205:Timeout during comparison
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 06:32:44,247:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:40:08<3:02:54, 111.98s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:41:47<2:54:40, 108.04s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 06:36:10,727:Timeout during comparison
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 06:36:20,216:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:43:45<2:58:04, 111.30s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:45:25<2:50:35, 107.74s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:47:03<2:44:12, 104.82s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:48:46<2:41:26, 104.16s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 06:43:05,872:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:50:28<2:39:01, 103.71s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:52:07<2:35:05, 102.26s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:55:03<3:06:41, 124.46s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [11:56:41<2:52:50, 116.52s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [11:58:16<2:41:26, 110.07s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [11:59:48<2:31:42, 104.62s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:01:22<2:25:10, 101.28s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:03:05<2:24:13, 101.80s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:04:37<2:18:21, 98.83s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:06:12<2:15:14, 97.77s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:07:45<2:11:51, 96.48s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:09:20<2:09:25, 95.87s/it]
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(TaskRunner pid=79845)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:12:27<2:44:10, 123.13s/it]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:14:02<2:31:02, 114.72s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:15:42<2:23:36, 110.47s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:17:22<2:17:34, 107.20s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:19:00<2:12:16, 104.43s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:20:33<2:06:13, 100.98s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:22:10<2:03:09, 99.86s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:23:49<2:01:13, 99.63s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:25:30<1:59:58, 99.98s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:27:07<1:57:21, 99.17s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:30:03<2:22:43, 122.33s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:31:41<2:12:12, 114.96s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:33:18<2:04:10, 109.56s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:34:55<1:57:54, 105.58s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:36:34<1:54:13, 103.84s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:38:07<1:48:53, 100.51s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:39:45<1:46:28, 99.83s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:41:28<1:45:41, 100.66s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:43:09<1:44:06, 100.75s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:44:50<1:42:30, 100.83s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:47:48<2:04:01, 124.03s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:49:27<1:54:39, 116.60s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:51:13<1:49:30, 113.29s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:52:51<1:43:14, 108.67s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:54:34<1:39:50, 106.97s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [12:56:14<1:36:19, 105.08s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [12:57:53<1:32:41, 103.00s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [12:59:35<1:30:44, 102.73s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:01:19<1:29:27, 103.23s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:02:58<1:26:35, 101.86s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 07:57:19,383:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:05:56<1:43:53, 124.67s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:07:36<1:35:46, 117.28s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:09:14<1:29:12, 111.51s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:10:57<1:25:19, 108.92s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:12:35<1:21:01, 105.69s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:14:12<1:17:23, 103.19s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:15:53<1:15:06, 102.42s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:17:31<1:12:32, 101.23s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:19:13<1:10:55, 101.33s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:20:53<1:09:02, 101.03s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:23:47<1:21:55, 122.88s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:25:27<1:15:25, 116.03s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:27:11<1:11:09, 112.35s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:28:50<1:06:57, 108.57s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:30:30<1:03:27, 105.77s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:32:11<1:00:57, 104.51s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 08:26:31,176:Timeout during comparison
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 08:26:36,866:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:33:58<59:36, 105.20s/it]  
[36m(TaskRunner pid=79845)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:35:34<56:20, 102.43s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:37:09<53:26, 100.22s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:38:50<51:53, 100.42s/it]
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(TaskRunner pid=79845)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:42:05<1:04:27, 128.91s/it]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=79845)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:43:44<57:56, 119.88s/it]  
[36m(TaskRunner pid=79845)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:45:18<52:18, 112.08s/it]
[36m(TaskRunner pid=79845)[0m WARNING:2025-11-10 08:39:40,575:Timeout during comparison
[36m(TaskRunner pid=79845)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:47:03<49:30, 110.03s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:48:42<46:14, 106.71s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:50:15<42:45, 102.62s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:51:52<40:20, 100.87s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:53:37<39:06, 102.02s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:55:16<37:05, 101.18s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [13:56:52<34:52, 99.65s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [13:59:47<40:46, 122.32s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:01:29<36:43, 115.97s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:03:05<33:02, 110.12s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:04:45<30:20, 107.11s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:06:24<27:55, 104.70s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:08:06<25:59, 103.97s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:09:45<23:52, 102.32s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:11:23<21:53, 101.01s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:13:02<20:05, 100.49s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:14:40<18:15, 99.56s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:17:37<20:28, 122.81s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:19:14<17:16, 115.21s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:20:53<14:42, 110.27s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:22:31<12:27, 106.75s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:24:09<10:24, 104.07s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:25:44<08:27, 101.44s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:27:22<06:41, 100.37s/it]
[36m(TaskRunner pid=79845)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:28:58<04:57, 99.01s/it] 
[36m(TaskRunner pid=79845)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:30:41<03:20, 100.27s/it]
[36m(TaskRunner pid=79845)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:32:28<01:42, 102.16s/it]
[36m(WorkerDict pid=83410)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=83410)[0m   warnings.warn(
[36m(TaskRunner pid=79845)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:35:42<01:49, 109.69s/it]
[36m(WorkerDict pid=83614)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=83614)[0m   warnings.warn([32m [repeated 3x across cluster][0m
