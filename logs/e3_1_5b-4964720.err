
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=12
+ n_rollout_min=4
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=2
+ enable_temperature_scheduler=True
+ enable_annealing=True
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_e3/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_e3//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_e3//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_e3//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=grpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=4 actor_rollout_ref.rollout.n_high=12 actor_rollout_ref.rollout.n_update=2 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=True actor_rollout_ref.rollout.enable_annealing=True actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_e3/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-24 13:54:31,857	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=1638129)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 13:54:52,918:Waiting for register center actor f4vjBV_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=1641886)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=1641886)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=1641680)[0m [rank0]:[W1124 13:55:11.859017171 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=1641680)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1641680)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1641680)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641680)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m [rank3]:[W1124 13:55:11.045697177 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1641886)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=1641884)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(WorkerDict pid=1641680)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:   0%|          | 1/480 [01:59<15:57:58, 120.00s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   0%|          | 2/480 [04:01<16:04:50, 121.11s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   1%|          | 3/480 [06:10<16:29:21, 124.45s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   1%|          | 4/480 [08:11<16:16:20, 123.07s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   1%|          | 5/480 [10:14<16:13:54, 123.02s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   1%|â–         | 6/480 [12:18<16:14:35, 123.37s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   1%|â–         | 7/480 [14:27<16:28:21, 125.37s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   2%|â–         | 8/480 [16:35<16:31:37, 126.05s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   2%|â–         | 9/480 [18:37<16:20:47, 124.94s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   2%|â–         | 10/480 [22:05<19:39:28, 150.57s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   2%|â–         | 11/480 [24:09<18:32:34, 142.33s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   2%|â–Ž         | 12/480 [26:13<17:47:01, 136.80s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   3%|â–Ž         | 13/480 [28:15<17:09:28, 132.27s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   3%|â–Ž         | 14/480 [30:19<16:48:05, 129.80s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   3%|â–Ž         | 15/480 [32:21<16:28:46, 127.58s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   3%|â–Ž         | 16/480 [34:27<16:21:05, 126.86s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   4%|â–Ž         | 17/480 [36:26<16:00:38, 124.49s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   4%|â–         | 18/480 [38:22<15:39:33, 122.02s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   4%|â–         | 19/480 [40:18<15:24:28, 120.32s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   4%|â–         | 20/480 [43:37<18:22:53, 143.86s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   4%|â–         | 21/480 [45:33<17:16:56, 135.55s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   5%|â–         | 22/480 [47:31<16:33:39, 130.17s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   5%|â–         | 23/480 [49:28<16:01:16, 126.21s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   5%|â–Œ         | 24/480 [51:22<15:32:57, 122.76s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   5%|â–Œ         | 25/480 [53:15<15:07:06, 119.62s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   5%|â–Œ         | 26/480 [55:08<14:49:44, 117.59s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   6%|â–Œ         | 27/480 [57:06<14:49:51, 117.86s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   6%|â–Œ         | 28/480 [58:56<14:30:21, 115.53s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:51<14:27:00, 115.34s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:57<17:04:22, 136.58s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 15:02:26,462:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:46<15:59:59, 128.28s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:30<15:02:21, 120.85s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:25<14:47:12, 119.09s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   7%|â–‹         | 34/480 [1:11:15<14:26:39, 116.59s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   7%|â–‹         | 35/480 [1:13:06<14:11:01, 114.74s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:53<13:52:20, 112.48s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:41<13:41:00, 111.20s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:35<13:45:01, 111.99s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:20<13:28:13, 109.96s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:23<16:07:01, 131.87s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:09<15:08:27, 124.16s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:01<14:39:54, 120.53s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:46<14:02:29, 115.67s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:32<13:38:58, 112.70s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:13<13:13:25, 109.44s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:10<13:27:36, 111.65s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:57<13:14:54, 110.15s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:44<13:05:44, 109.13s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:36<13:09:56, 109.97s/it]
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(TaskRunner pid=1638129)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:42:49<16:07:00, 134.93s/it]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:32<14:56:26, 125.38s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:17<14:10:21, 119.21s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:47:57<13:27:31, 113.47s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:49:43<13:10:46, 111.38s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:51:27<12:52:27, 109.05s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:10<12:38:41, 107.36s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:54:55<12:32:13, 106.70s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:56:36<12:18:07, 104.95s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 15:55:02,978:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:58:22<12:17:31, 105.11s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 15:56:45,530:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 15:56:52,184:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:01:20<14:50:26, 127.21s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:03:04<13:58:08, 120.02s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:04:44<13:15:20, 114.17s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:06:25<12:46:28, 110.28s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:08:11<12:34:52, 108.88s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:09:50<12:11:56, 105.82s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:11:35<12:08:05, 105.52s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:13:15<11:55:34, 103.96s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:14:56<11:48:37, 103.20s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:16:40<11:47:01, 103.22s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:19:36<14:14:22, 125.03s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:21:16<13:22:15, 117.69s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:23:10<13:12:05, 116.48s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:24:52<12:40:47, 112.16s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:26:36<12:23:29, 109.88s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:28:19<12:06:54, 107.69s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:30:04<12:00:25, 106.99s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:31:46<11:48:55, 105.55s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:33:30<11:42:16, 104.82s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:35:14<11:38:50, 104.56s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:38:04<13:48:00, 124.20s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:39:48<13:06:44, 118.31s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:41:30<12:32:28, 113.44s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:43:15<12:13:33, 110.86s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:44:59<11:57:23, 108.70s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:46:41<11:43:52, 106.92s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:48:26<11:36:58, 106.14s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:50:11<11:33:42, 105.91s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:51:59<11:36:32, 106.61s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:53:40<11:23:51, 104.94s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:56:33<13:33:13, 125.11s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [2:58:14<12:45:18, 118.04s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 16:56:40,324:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 16:56:46,225:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 16:56:51,246:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:00:08<12:35:58, 116.90s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:01:52<12:08:24, 112.93s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 17:00:21,573:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:03:42<12:01:16, 112.11s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:05:23<11:38:19, 108.83s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:07:08<11:28:46, 107.62s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:08:47<11:09:19, 104.86s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:10:21<10:46:30, 101.55s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:12:08<10:56:08, 103.33s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 17:10:36,314:Timeout during comparison
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(WorkerDict pid=1641680)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=1641680)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=1638129)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:15:24<13:49:59, 131.05s/it]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:17:02<12:46:24, 121.33s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:18:49<12:17:13, 117.02s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:20:28<11:41:16, 111.61s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:22:05<11:12:08, 107.26s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:23:48<11:02:12, 105.95s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:25:24<10:40:53, 102.82s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:27:08<10:42:12, 103.30s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:28:45<10:27:28, 101.20s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:30:39<10:50:42, 105.24s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:33:34<12:57:07, 126.02s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:35:16<12:11:04, 118.88s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:36:48<11:20:37, 110.97s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:38:30<11:00:59, 108.07s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:40:13<10:51:10, 106.75s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:41:46<10:22:38, 102.35s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 17:40:08,629:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 17:40:14,337:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:43:31<10:26:28, 103.27s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:45:09<10:16:09, 101.84s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:46:49<10:09:25, 101.01s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:48:25<9:58:54, 99.54s/it]  
[36m(TaskRunner pid=1638129)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:51:16<12:07:04, 121.18s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:52:51<11:18:19, 113.37s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:54:34<10:56:25, 110.02s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [3:56:13<10:35:10, 106.75s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 17:54:46,928:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [3:58:09<10:49:32, 109.47s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [3:59:48<10:28:59, 106.31s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:01:28<10:16:20, 104.46s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:03:04<10:01:02, 102.16s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:04:43<9:53:29, 101.16s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:06:23<9:49:06, 100.70s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:09:14<11:50:40, 121.83s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:10:55<11:12:49, 115.67s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:12:29<10:33:02, 109.14s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:14:08<10:13:11, 106.03s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 18:12:36,469:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:15:53<10:08:59, 105.61s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:17:33<9:57:49, 103.97s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:19:12<9:48:38, 102.67s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:20:47<9:33:36, 100.34s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:22:28<9:32:42, 100.48s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:24:09<9:30:55, 100.46s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:26:58<11:25:50, 121.03s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:28:38<10:48:15, 114.73s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:30:13<10:12:56, 108.81s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:31:52<9:54:49, 105.90s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:33:28<9:36:09, 102.89s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:35:05<9:26:02, 101.38s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:36:38<9:09:03, 98.63s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:38:11<8:58:13, 96.98s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:39:47<8:54:33, 96.61s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:41:29<9:02:36, 98.36s/it]
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(TaskRunner pid=1638129)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:44:38<11:30:03, 125.47s/it]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:46:18<10:45:59, 117.81s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:48:00<10:18:34, 113.15s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:49:37<9:50:00, 108.26s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:51:19<9:37:46, 106.34s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:52:57<9:23:14, 103.98s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [4:54:30<9:03:59, 100.74s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [4:56:07<8:56:32, 99.67s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [4:57:50<9:00:02, 100.63s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [4:59:30<8:56:03, 100.20s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:02:21<10:49:10, 121.72s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:04:09<10:24:57, 117.55s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:05:55<10:04:08, 113.99s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:07:34<9:38:30, 109.50s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:09:19<9:28:52, 108.02s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:11:00<9:16:13, 105.95s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:12:43<9:11:10, 105.32s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:14:20<8:55:37, 102.68s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:16:05<8:57:44, 103.41s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:17:45<8:50:54, 102.43s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:20:39<10:39:14, 123.72s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:22:20<10:02:30, 116.99s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:24:00<9:34:43, 111.96s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:25:40<9:14:19, 108.34s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:27:17<8:55:29, 105.00s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:28:59<8:49:08, 104.09s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:30:42<8:44:58, 103.61s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:32:24<8:41:01, 103.17s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:34:09<8:41:55, 103.69s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:35:53<8:40:51, 103.83s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 19:34:23,444:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:38:57<10:38:54, 127.78s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 19:37:26,403:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 19:37:31,420:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 19:37:37,211:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:40:56<10:24:21, 125.29s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:42:39<9:48:43, 118.54s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:44:23<9:25:15, 114.20s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:46:00<8:58:08, 109.08s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:47:48<8:54:49, 108.78s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:49:28<8:39:38, 106.05s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:51:07<8:27:45, 103.98s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:52:50<8:25:21, 103.84s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [5:54:35<8:25:03, 104.13s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [5:57:28<10:02:08, 124.58s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [5:59:08<9:24:50, 117.27s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:00:44<8:52:52, 111.02s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:02:25<8:36:44, 108.03s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:04:05<8:22:58, 105.52s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:05:44<8:11:44, 103.52s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:07:30<8:14:22, 104.45s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:09:06<8:00:01, 101.77s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:10:47<7:57:42, 101.64s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:12:25<7:49:59, 100.35s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 20:12:24,396:Timeout during comparison
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(TaskRunner pid=1638129)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:15:40<10:01:03, 128.80s/it]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:17:21<9:20:18, 120.49s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:19:00<8:48:14, 114.01s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:20:40<8:26:59, 109.82s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:22:19<8:10:45, 106.69s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:24:01<8:02:04, 105.18s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:25:43<7:56:19, 104.31s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:27:29<7:56:25, 104.71s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:29:05<7:43:29, 102.24s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:30:43<7:36:04, 100.98s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:33:39<9:14:45, 123.28s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:35:20<8:42:44, 116.60s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:37:03<8:22:32, 112.51s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:38:47<8:09:14, 109.94s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:40:29<7:57:15, 107.65s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:42:07<7:43:20, 104.91s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:43:47<7:34:03, 103.19s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:45:25<7:26:38, 101.89s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:47:00<7:15:21, 99.70s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:48:49<7:26:02, 102.54s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:51:41<8:54:29, 123.34s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:53:21<8:22:07, 116.32s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [6:55:04<8:02:33, 112.22s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [6:56:37<7:36:29, 106.57s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [6:58:17<7:25:58, 104.53s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [6:59:55<7:16:10, 102.63s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:01:35<7:10:35, 101.72s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:03:16<7:08:39, 101.66s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:04:56<7:04:12, 101.00s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:06:40<7:06:27, 101.94s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:09:29<8:29:02, 122.17s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:11:08<7:57:26, 115.05s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:12:47<7:36:16, 110.39s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:14:25<7:19:05, 106.66s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:16:01<7:04:44, 103.59s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:17:40<6:56:24, 101.98s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:19:17<6:48:38, 100.49s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:20:55<6:44:38, 99.91s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:22:39<6:47:33, 101.05s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:24:18<6:43:11, 100.38s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:27:10<8:08:16, 122.07s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 21:25:45,198:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:29:07<7:59:29, 120.37s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:30:48<7:35:11, 114.76s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:32:29<7:16:32, 110.52s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:34:10<7:03:55, 107.78s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:35:56<6:59:02, 106.99s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:37:37<6:50:06, 105.15s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:39:18<6:43:52, 104.00s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:41:00<6:39:44, 103.38s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:42:45<6:39:49, 103.85s/it]
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(TaskRunner pid=1638129)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:45:53<8:14:47, 129.08s/it]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:47:32<7:38:42, 120.19s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:49:11<7:11:55, 113.66s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:50:49<6:52:59, 109.16s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:52:27<6:38:07, 105.70s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:54:04<6:27:20, 103.29s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [7:55:44<6:21:29, 102.19s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [7:57:20<6:13:13, 100.42s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [7:59:03<6:14:05, 101.10s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:00:39<6:06:17, 99.45s/it] 
[36m(TaskRunner pid=1638129)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:03:27<7:20:41, 120.19s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:05:09<6:58:09, 114.56s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:06:52<6:44:28, 111.32s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:08:35<6:32:51, 108.62s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:10:21<6:27:59, 107.78s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:11:59<6:15:54, 104.90s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:13:41<6:10:56, 104.00s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:15:21<6:04:47, 102.76s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:16:56<5:55:45, 100.69s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:18:36<5:53:13, 100.44s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:21:29<7:07:41, 122.20s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:23:13<6:46:31, 116.71s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:24:53<6:26:48, 111.58s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:26:34<6:14:34, 108.57s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:28:20<6:09:51, 107.73s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:30:00<6:00:16, 105.45s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:31:45<5:57:53, 105.26s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:33:31<5:57:03, 105.54s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:35:11<5:49:59, 103.96s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:36:55<5:48:09, 103.93s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:39:48<6:55:18, 124.59s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:41:24<6:24:49, 116.03s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:43:07<6:09:24, 111.94s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:44:50<5:58:49, 109.29s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:46:36<5:54:01, 108.38s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:48:22<5:49:37, 107.58s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:50:04<5:42:30, 105.93s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:51:45<5:36:03, 104.47s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:53:27<5:31:49, 103.70s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:55:09<5:28:21, 103.15s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [8:58:07<6:38:14, 125.76s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [8:59:48<6:12:58, 118.41s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:01:30<5:55:36, 113.49s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:03:11<5:41:44, 109.65s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:04:56<5:35:10, 108.12s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:06:42<5:31:21, 107.47s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:08:30<5:30:03, 107.63s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:10:10<5:21:25, 105.39s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:11:56<5:20:26, 105.64s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:13:36<5:13:46, 104.02s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 23:12:04,873:Timeout during comparison
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(TaskRunner pid=1638129)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:16:51<6:33:34, 131.19s/it]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:18:34<6:06:38, 122.90s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:20:16<5:45:19, 116.40s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:21:59<5:32:11, 112.61s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:23:43<5:22:09, 109.82s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:25:23<5:12:21, 107.10s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:27:08<5:08:08, 106.26s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:28:46<4:59:12, 103.77s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:30:28<4:56:17, 103.36s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:32:14<4:56:53, 104.17s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:35:05<5:51:41, 124.13s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:36:45<5:29:41, 117.05s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:38:27<5:14:46, 112.42s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:40:08<5:03:28, 109.03s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:41:52<4:57:27, 107.52s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:43:39<4:54:49, 107.21s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:45:28<4:55:05, 107.96s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 23:43:58,566:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 23:44:05,077:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:47:22<4:58:05, 109.73s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:49:05<4:51:05, 107.81s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:50:52<4:48:30, 107.52s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:53:46<5:39:42, 127.39s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:55:30<5:19:15, 120.47s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 23:53:59,181:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 23:54:04,193:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-24 23:54:10,675:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:57:30<5:16:31, 120.20s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [9:59:15<5:02:20, 115.54s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:01:04<4:55:33, 113.68s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:02:52<4:48:58, 111.86s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:04:38<4:42:45, 110.17s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:06:23<4:37:08, 108.68s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:08:11<4:34:49, 108.48s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:09:53<4:28:17, 106.60s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:12:52<5:20:37, 128.25s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:14:32<4:57:43, 119.89s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:16:14<4:42:01, 114.34s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:18:00<4:34:23, 111.99s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:19:43<4:25:27, 109.09s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:21:26<4:19:17, 107.29s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:23:11<4:15:52, 106.61s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:24:54<4:12:00, 105.74s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:26:40<4:10:00, 105.64s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:28:26<4:08:30, 105.75s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:31:21<4:55:31, 126.65s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:33:08<4:39:34, 120.68s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:34:49<4:23:44, 114.67s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:36:33<4:14:33, 111.48s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:38:11<4:03:43, 107.52s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:39:57<4:01:13, 107.21s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:41:45<3:59:53, 107.41s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:43:30<3:56:27, 106.67s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:45:16<3:53:59, 106.36s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:46:58<3:49:29, 105.11s/it]
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(TaskRunner pid=1638129)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:50:09<4:43:12, 130.71s/it]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:51:54<4:24:43, 123.13s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:53:39<4:10:50, 117.58s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:55:25<4:01:45, 114.22s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:57:11<3:54:59, 111.90s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:58:56<3:48:30, 109.68s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:00:40<3:42:53, 107.85s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:02:22<3:37:58, 106.33s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:04:03<3:32:59, 104.75s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:05:52<3:33:15, 105.75s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:08:40<4:09:18, 124.66s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:10:24<3:54:59, 118.48s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-25 01:08:58,049:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:12:18<3:50:01, 116.96s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:13:59<3:38:52, 112.24s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:15:40<3:30:41, 108.98s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:17:21<3:23:51, 106.36s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:19:00<3:17:53, 104.16s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:20:39<3:13:24, 102.70s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:22:21<3:11:29, 102.59s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:23:58<3:06:44, 100.94s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:26:55<3:46:36, 123.61s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:28:38<3:33:08, 117.33s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:30:23<3:24:56, 113.86s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:32:13<3:20:41, 112.54s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:33:53<3:12:09, 108.77s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:35:36<3:07:28, 107.13s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:37:18<3:02:55, 105.54s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:39:00<2:59:41, 104.68s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:40:46<2:58:35, 105.06s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:42:30<2:55:52, 104.48s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:45:23<3:28:48, 125.28s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:47:11<3:18:01, 120.02s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-25 01:45:39,849:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-25 01:45:46,926:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-25 01:45:53,674:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:49:15<3:17:55, 121.17s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:51:01<3:08:23, 116.53s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:52:55<3:05:11, 115.75s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:54:40<2:58:27, 112.71s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:56:24<2:52:17, 109.98s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:58:13<2:50:00, 109.68s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:59:58<2:46:00, 108.27s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:01:44<2:43:12, 107.61s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:04:42<3:13:03, 128.70s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:06:31<3:02:26, 123.00s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:08:13<2:51:08, 116.69s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:09:55<2:42:34, 112.12s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:11:37<2:36:35, 109.24s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:13:28<2:35:09, 109.52s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:15:07<2:29:00, 106.44s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:16:50<2:25:50, 105.42s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:18:36<2:24:27, 105.70s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:20:23<2:23:01, 105.95s/it]
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(TaskRunner pid=1638129)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:23:40<2:57:43, 133.29s/it]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:25:28<2:45:42, 125.86s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:27:17<2:36:43, 120.55s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:29:03<2:29:11, 116.25s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:30:47<2:22:35, 112.57s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:32:30<2:17:09, 109.72s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:34:15<2:13:47, 108.48s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:36:07<2:13:10, 109.46s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:37:52<2:09:35, 108.00s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:39:36<2:06:21, 106.78s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:42:30<2:28:20, 127.15s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:44:19<2:19:59, 121.74s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:46:05<2:12:20, 116.77s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:47:49<2:06:09, 112.97s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:49:35<2:02:04, 110.97s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:51:13<1:55:57, 107.04s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:52:56<1:52:54, 105.85s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:54:42<1:51:05, 105.81s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:56:23<1:47:59, 104.51s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:58:06<1:45:36, 103.87s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:01:04<2:06:11, 126.18s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:02:47<1:57:17, 119.27s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:04:36<1:52:20, 116.22s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:06:18<1:46:27, 112.07s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:08:03<1:42:31, 109.84s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:09:47<1:39:09, 108.18s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:11:31<1:36:12, 106.89s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:13:15<1:33:40, 106.06s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:15:02<1:32:04, 106.23s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:16:43<1:28:55, 104.61s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-25 03:15:07,593:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:19:37<1:44:27, 125.36s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:21:18<1:36:28, 118.13s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:22:59<1:30:19, 112.91s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:24:45<1:27:01, 111.10s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:26:25<1:22:25, 107.51s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:28:08<1:19:43, 106.30s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:29:52<1:17:30, 105.70s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:31:35<1:15:07, 104.82s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:33:16<1:12:26, 103.48s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:34:55<1:09:58, 102.41s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-25 03:33:25,060:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:37:50<1:22:48, 124.20s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:39:32<1:16:20, 117.45s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:41:16<1:11:47, 113.36s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:42:58<1:07:49, 109.98s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:44:38<1:04:08, 106.90s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:46:18<1:01:11, 104.89s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-25 03:44:42,387:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-25 03:44:48,103:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:48:05<59:45, 105.45s/it]  
[36m(TaskRunner pid=1638129)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:49:43<56:52, 103.41s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:51:21<54:11, 101.62s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:53:02<52:27, 101.55s/it]
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(TaskRunner pid=1638129)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:56:05<1:02:53, 125.79s/it]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=1638129)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:57:43<56:51, 117.65s/it]  
[36m(TaskRunner pid=1638129)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:59:20<51:59, 111.43s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:01:02<48:52, 108.63s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:02:43<46:01, 106.20s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:04:19<43:03, 103.33s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-25 04:02:44,663:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:06:04<41:25, 103.56s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:07:49<39:57, 104.22s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:09:31<37:59, 103.62s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:11:12<35:59, 102.83s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:14:03<41:01, 123.08s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:15:44<36:51, 116.41s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:17:23<33:21, 111.19s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:19:05<30:42, 108.39s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:20:43<28:08, 105.56s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:22:28<26:16, 105.11s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:24:11<24:24, 104.62s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:25:54<22:32, 104.07s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:27:33<20:32, 102.74s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:29:15<18:47, 102.51s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:32:11<20:44, 124.45s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:34:02<18:04, 120.48s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:35:47<15:27, 115.90s/it]
[36m(TaskRunner pid=1638129)[0m WARNING:2025-11-25 04:34:17,783:Timeout during comparison
[36m(TaskRunner pid=1638129)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:37:36<13:15, 113.59s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:39:18<11:01, 110.19s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:41:00<08:59, 107.90s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:42:44<07:05, 106.44s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:44:28<05:17, 105.82s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:46:12<03:30, 105.43s/it]
[36m(TaskRunner pid=1638129)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:48:03<01:47, 107.03s/it]
[36m(WorkerDict pid=1641680)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1641680)[0m   warnings.warn(
[36m(TaskRunner pid=1638129)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:51:24<01:51, 111.66s/it]
[36m(WorkerDict pid=1641886)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=1641886)[0m   warnings.warn([32m [repeated 3x across cluster][0m
