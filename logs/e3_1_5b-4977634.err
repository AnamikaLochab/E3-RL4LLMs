
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=12
+ n_rollout_min=4
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=2
+ enable_temperature_scheduler=True
+ enable_annealing=True
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_e3_2/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_e3_2//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_e3_2//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_e3_2//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=grpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=4 actor_rollout_ref.rollout.n_high=12 actor_rollout_ref.rollout.n_update=2 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=True actor_rollout_ref.rollout.enable_annealing=True actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_e3_2/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-26 14:01:54,584	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=2492879)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 14:02:16,391:Waiting for register center actor mLXjL1_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2496465)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=2496465)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=2496465)[0m [rank0]:[W1126 14:02:34.434112045 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=2496465)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2496465)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2496692)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m [rank2]:[W1126 14:02:35.797533481 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2496693)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2496465)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2496692)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(WorkerDict pid=2496691)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:   0%|          | 1/480 [02:03<16:24:18, 123.29s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   0%|          | 2/480 [04:03<16:09:46, 121.73s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   1%|          | 3/480 [06:10<16:24:44, 123.87s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   1%|          | 4/480 [08:08<16:05:06, 121.65s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   1%|          | 5/480 [10:08<15:58:30, 121.08s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   1%|â–         | 6/480 [12:12<16:02:55, 121.89s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   1%|â–         | 7/480 [14:13<16:00:43, 121.87s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 14:20:48,337:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:   2%|â–         | 8/480 [16:19<16:07:09, 122.94s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   2%|â–         | 9/480 [18:17<15:54:54, 121.64s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 14:24:55,600:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:   2%|â–         | 10/480 [21:45<19:20:41, 148.17s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   2%|â–         | 11/480 [23:44<18:07:51, 139.17s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   2%|â–Ž         | 12/480 [25:42<17:15:21, 132.74s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   3%|â–Ž         | 13/480 [27:41<16:41:47, 128.71s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   3%|â–Ž         | 14/480 [29:41<16:18:12, 125.95s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   3%|â–Ž         | 15/480 [31:35<15:49:33, 122.52s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   3%|â–Ž         | 16/480 [33:32<15:33:01, 120.65s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   4%|â–Ž         | 17/480 [35:29<15:23:12, 119.64s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   4%|â–         | 18/480 [37:24<15:10:03, 118.19s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   4%|â–         | 19/480 [39:23<15:10:22, 118.49s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   4%|â–         | 20/480 [42:42<18:14:19, 142.74s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   4%|â–         | 21/480 [44:43<17:21:17, 136.12s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   5%|â–         | 22/480 [46:43<16:42:47, 131.37s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   5%|â–         | 23/480 [48:41<16:10:06, 127.37s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   5%|â–Œ         | 24/480 [50:35<15:36:43, 123.25s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   5%|â–Œ         | 25/480 [52:26<15:06:14, 119.50s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   5%|â–Œ         | 26/480 [54:21<14:54:13, 118.18s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   6%|â–Œ         | 27/480 [56:21<14:55:45, 118.64s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   6%|â–Œ         | 28/480 [58:12<14:38:08, 116.57s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:09<14:35:52, 116.52s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:17<17:16:27, 138.20s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:04<16:02:10, 128.58s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   7%|â–‹         | 32/480 [1:06:50<15:09:34, 121.82s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   7%|â–‹         | 33/480 [1:08:46<14:55:33, 120.21s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:39<14:36:35, 117.93s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:29<14:17:21, 115.60s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:16<13:57:32, 113.18s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:06<13:47:34, 112.09s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:03<13:56:00, 113.49s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   8%|â–Š         | 39/480 [1:19:50<13:41:20, 111.75s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:01<16:33:49, 135.52s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   9%|â–Š         | 41/480 [1:24:50<15:32:13, 127.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   9%|â–‰         | 42/480 [1:26:43<14:59:17, 123.19s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   9%|â–‰         | 43/480 [1:28:31<14:23:22, 118.54s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:22<14:04:20, 116.19s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:05<13:35:23, 112.47s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  10%|â–‰         | 46/480 [1:33:56<13:29:52, 111.96s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  10%|â–‰         | 47/480 [1:35:47<13:24:34, 111.49s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:37:38<13:21:48, 111.36s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:39:31<13:24:54, 112.05s/it]
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(TaskRunner pid=2492879)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:42:54<16:37:41, 139.21s/it]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:44:42<15:28:03, 129.80s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:27<14:33:48, 122.50s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:11<13:52:59, 117.05s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:03<13:39:50, 115.47s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:51:49<13:17:50, 112.64s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:53:37<13:05:52, 111.21s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:27<13:01:15, 110.82s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:10<12:43:16, 108.52s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 16:03:33,270:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:58:57<12:37:25, 107.95s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:01:53<14:58:08, 128.31s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:03:38<14:06:59, 121.29s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:23<13:32:54, 116.69s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:07:08<13:05:23, 113.01s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:09:02<13:06:36, 113.45s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:10:43<12:37:19, 109.49s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:12:36<12:44:21, 110.78s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:14:21<12:28:58, 108.81s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:16:04<12:16:20, 107.23s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:17:52<12:15:02, 107.31s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:20:55<14:48:16, 129.99s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:22:37<13:50:29, 121.83s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:24:21<13:10:15, 116.21s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:26:05<12:43:43, 112.59s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 16:32:31,629:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:27:59<12:44:55, 113.04s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:29:46<12:30:24, 111.17s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:31:35<12:25:14, 110.68s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:33:24<12:18:52, 110.01s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:35:09<12:07:17, 108.55s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:36:57<12:05:20, 108.53s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:39:56<14:24:57, 129.74s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:41:43<13:37:30, 122.93s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:43:27<12:57:23, 117.20s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:45:15<12:36:20, 114.31s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:47:01<12:18:52, 111.95s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:48:48<12:07:24, 110.49s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:50:36<12:00:19, 109.69s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:52:23<11:52:57, 108.85s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:54:10<11:46:47, 108.18s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:55:52<11:34:23, 106.56s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:58:52<13:55:49, 128.59s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:00:34<13:01:27, 120.53s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:02:14<12:19:49, 114.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:03:59<11:58:33, 111.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:05:45<11:46:34, 109.83s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:07:27<11:30:27, 107.60s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:09:16<11:30:37, 107.91s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:10:59<11:20:17, 106.57s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:12:35<10:58:23, 103.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:14:27<11:12:12, 105.86s/it]
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(WorkerDict pid=2496465)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2496465)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=2492879)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:17:45<14:05:31, 133.50s/it]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:19:25<12:59:49, 123.46s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 17:25:57,227:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:21:22<12:45:37, 121.53s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:23:02<12:03:42, 115.18s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:24:44<11:36:47, 111.19s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:26:30<11:25:37, 109.70s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:28:25<11:32:54, 111.16s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:30:14<11:26:21, 110.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:31:52<11:02:54, 106.92s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:33:46<11:13:12, 108.88s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:37:00<13:48:56, 134.42s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:38:45<12:52:30, 125.61s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:40:31<12:15:09, 119.86s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:42:27<12:05:20, 118.58s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:44:14<11:42:34, 115.18s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:45:50<11:05:01, 109.32s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:47:43<11:10:55, 110.59s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:49:54<11:44:25, 116.43s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:51:59<11:58:54, 119.16s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:53:42<11:27:44, 114.31s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 18:00:13,742:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 18:00:21,103:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:57:30<14:50:27, 148.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:59:16<13:31:55, 135.70s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [4:01:04<12:40:14, 127.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:02:46<11:52:05, 119.68s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:05:23<12:56:55, 130.94s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:07:03<12:00:04, 121.70s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:08:45<11:23:12, 115.80s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:10:24<10:51:20, 110.71s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:12:14<10:48:50, 110.60s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:13:56<10:31:51, 108.01s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:16:54<12:32:22, 128.98s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:18:41<11:52:14, 122.45s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:20:19<11:06:34, 114.93s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:22:03<10:45:47, 111.66s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:23:46<10:29:31, 109.17s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:25:29<10:16:50, 107.28s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:27:18<10:18:34, 107.89s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:28:58<10:02:45, 105.44s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:30:43<10:00:26, 105.34s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:32:25<9:52:22, 104.23s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:35:23<11:57:06, 126.55s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:37:07<11:16:09, 119.67s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:38:46<10:38:25, 113.33s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:40:29<10:20:02, 110.39s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:42:09<9:59:58, 107.14s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:43:55<9:56:01, 106.75s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:45:32<9:39:01, 104.02s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:47:13<9:31:41, 103.01s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:48:55<9:27:42, 102.60s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:50:44<9:36:51, 104.57s/it]
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(TaskRunner pid=2492879)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:54:19<12:38:06, 137.84s/it]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:56:17<12:03:17, 131.91s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:58:03<11:18:47, 124.17s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:59:43<10:36:02, 116.71s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [5:01:27<10:13:44, 112.96s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [5:03:12<9:59:26, 110.67s/it] 
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 19:09:35,360:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:04:56<9:46:25, 108.60s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:06:37<9:31:44, 106.21s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:08:23<9:30:15, 106.26s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:10:11<9:30:45, 106.68s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:13:15<11:33:54, 130.11s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:15:09<11:05:25, 125.16s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:16:55<10:32:45, 119.39s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:18:43<10:13:33, 116.13s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:20:32<9:59:59, 113.92s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:22:18<9:45:36, 111.55s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 19:28:43,413:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 19:28:49,937:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:24:16<9:53:28, 113.40s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:25:58<9:33:39, 109.97s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:27:45<9:27:02, 109.05s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:29:31<9:20:34, 108.15s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:32:32<11:11:59, 130.06s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:34:23<10:40:59, 124.47s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:36:07<10:06:52, 118.22s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:37:55<9:49:07, 115.14s/it] 
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 19:44:18,523:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:39:42<9:34:12, 112.59s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:41:28<9:23:20, 110.82s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:43:16<9:17:21, 110.00s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:45:02<9:08:28, 108.61s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:46:49<9:03:45, 108.03s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:48:33<8:56:14, 106.89s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:51:43<10:58:56, 131.79s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 19:58:18,867:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 19:58:25,621:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 19:58:30,640:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:53:55<10:56:58, 131.84s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:55:40<10:16:05, 124.05s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:57:30<9:51:56, 119.59s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:59:12<9:24:45, 114.48s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [6:00:59<9:12:04, 112.29s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [6:02:46<9:01:22, 110.48s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [6:04:30<8:50:17, 108.59s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [6:06:18<8:48:25, 108.58s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:08:08<8:47:33, 108.78s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:11:07<10:28:05, 129.95s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:12:50<9:47:19, 121.94s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:14:30<9:14:05, 115.43s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:16:15<8:56:45, 112.22s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:18:04<8:50:42, 111.34s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:19:47<8:36:48, 108.80s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:21:39<8:38:55, 109.63s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:23:21<8:26:55, 107.48s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:25:07<8:22:45, 106.97s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:26:48<8:11:53, 105.03s/it]
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(TaskRunner pid=2492879)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:30:09<10:25:38, 134.07s/it]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:31:54<9:42:51, 125.35s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:33:38<9:11:04, 118.94s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:35:22<8:47:21, 114.23s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:37:07<8:32:52, 111.49s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:38:52<8:21:54, 109.51s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:40:37<8:13:52, 108.15s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:42:27<8:14:38, 108.71s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:44:03<7:56:10, 105.04s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:45:47<7:52:24, 104.59s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:48:51<9:38:13, 128.50s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:50:36<9:03:59, 121.33s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:52:21<8:40:48, 116.60s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:54:09<8:27:16, 114.00s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:56:00<8:21:32, 113.13s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:57:43<8:06:20, 110.12s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:59:30<7:59:41, 109.02s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [7:01:16<7:54:10, 108.18s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [7:02:53<7:38:27, 104.99s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [7:04:45<7:45:03, 106.91s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 21:12:44,689:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [7:07:48<9:21:44, 129.63s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [7:09:29<8:43:34, 121.29s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:11:19<8:26:26, 117.78s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:12:56<7:57:51, 111.56s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:14:40<7:46:36, 109.36s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:16:25<7:39:15, 108.06s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:18:06<7:28:35, 105.97s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:19:53<7:27:11, 106.05s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:21:34<7:19:22, 104.61s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:23:21<7:21:24, 105.52s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:26:20<8:51:03, 127.45s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:27:59<8:13:36, 118.94s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:29:42<7:51:36, 114.10s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:31:27<7:38:48, 111.45s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:33:08<7:23:31, 108.18s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:34:49<7:12:51, 106.01s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:36:30<7:05:04, 104.53s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:38:09<6:57:07, 103.00s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:39:53<6:56:27, 103.26s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:41:35<6:52:54, 102.80s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:44:30<8:18:22, 124.59s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:46:21<7:59:32, 120.39s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:48:07<7:40:42, 116.15s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:49:54<7:27:23, 113.27s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:51:37<7:14:26, 110.45s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:53:21<7:04:43, 108.44s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:55:03<6:54:54, 106.39s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:56:43<6:45:23, 104.39s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:58:27<6:44:09, 104.53s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [8:00:07<6:36:31, 102.99s/it]
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(TaskRunner pid=2492879)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [8:03:24<8:23:19, 131.30s/it]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [8:05:29<8:13:16, 129.24s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [8:07:10<7:38:47, 120.73s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [8:08:48<7:11:27, 114.04s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [8:10:25<6:49:59, 108.85s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 22:16:46,180:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [8:12:08<6:41:43, 107.13s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:13:49<6:33:48, 105.49s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:15:26<6:21:38, 102.68s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:17:13<6:24:48, 104.00s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 22:23:32,802:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 22:23:38,610:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:18:59<6:26:09, 104.84s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:21:46<7:32:19, 123.36s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:23:24<7:02:46, 115.83s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 22:29:40,438:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 22:29:51,035:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:25:13<6:52:54, 113.64s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:26:52<6:35:04, 109.24s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:28:34<6:25:14, 107.01s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:30:08<6:10:03, 103.27s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:31:45<6:01:19, 101.31s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:33:23<5:56:40, 100.47s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:34:59<5:49:35, 98.94s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:36:35<5:45:04, 98.13s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 22:42:53,542:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 22:43:00,209:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:39:33<7:07:15, 122.07s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:41:10<6:38:54, 114.52s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:42:42<6:14:13, 107.95s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:44:15<5:56:53, 103.45s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:45:57<5:53:14, 102.89s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:47:30<5:41:01, 99.81s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:49:12<5:42:18, 100.68s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:50:49<5:36:51, 99.56s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:52:23<5:29:20, 97.82s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:54:03<5:30:05, 98.53s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:56:49<6:35:58, 118.79s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:58:23<6:08:39, 111.16s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:59:58<5:51:00, 106.36s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [9:01:33<5:37:54, 102.91s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 23:07:57,075:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [9:03:20<5:40:17, 104.17s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [9:04:59<5:33:49, 102.71s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [9:06:36<5:26:24, 100.95s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [9:08:17<5:24:22, 100.84s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [9:09:48<5:13:52, 98.09s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [9:11:24<5:10:17, 97.47s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:14:21<6:23:50, 121.22s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:15:53<5:54:48, 112.64s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:17:29<5:37:08, 107.60s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:19:03<5:22:01, 103.32s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:20:35<5:09:54, 99.97s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:22:09<5:03:17, 98.36s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:23:49<5:02:19, 98.58s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:25:20<4:54:12, 96.46s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:26:54<4:50:14, 95.68s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:28:26<4:45:39, 94.69s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-26 23:34:44,358:Timeout during comparison
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(TaskRunner pid=2492879)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:31:36<6:09:37, 123.21s/it]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:33:12<5:42:57, 114.96s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:34:46<5:22:12, 108.61s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:36:26<5:13:25, 106.25s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:38:02<5:02:50, 103.24s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:39:37<4:53:39, 100.68s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:41:12<4:47:06, 99.00s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:42:43<4:37:54, 96.38s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:44:20<4:37:09, 96.68s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:45:59<4:37:25, 97.34s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:48:53<5:41:25, 120.50s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:50:33<5:21:36, 114.18s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:52:09<5:04:54, 108.90s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:53:43<4:50:36, 104.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:55:23<4:44:40, 102.90s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:57:03<4:40:32, 102.01s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:58:44<4:38:16, 101.81s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 00:05:00,063:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [10:00:21<4:32:41, 100.38s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [10:01:58<4:28:19, 99.38s/it] 
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 00:08:14,162:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [10:03:40<4:29:06, 100.29s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [10:06:29<5:22:13, 120.83s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [10:08:12<5:06:01, 115.48s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 00:14:31,452:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 00:14:36,459:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 00:14:42,187:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 00:14:47,260:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [10:10:10<5:06:15, 116.30s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:11:53<4:53:14, 112.07s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:13:37<4:45:02, 109.63s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:15:19<4:37:32, 107.44s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:17:01<4:31:34, 105.81s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:18:44<4:27:28, 104.89s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:20:24<4:21:56, 103.40s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:22:00<4:14:48, 101.25s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:24:57<5:09:57, 123.99s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:26:39<4:51:25, 117.35s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:28:15<4:34:06, 111.12s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:29:58<4:26:24, 108.74s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:31:40<4:19:16, 106.55s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:33:20<4:13:08, 104.75s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:34:59<4:07:05, 102.96s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:36:39<4:02:55, 101.92s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:38:22<4:01:56, 102.23s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:40:02<3:58:40, 101.56s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:42:56<4:47:44, 123.32s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:44:36<4:29:31, 116.34s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:46:18<4:17:39, 112.03s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:47:57<4:06:55, 108.14s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:49:34<3:57:43, 104.88s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:51:16<3:53:53, 103.96s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:53:08<3:57:36, 106.39s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:54:55<3:55:54, 106.42s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:56:39<3:53:04, 105.94s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:58:15<3:44:50, 102.98s/it]
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(TaskRunner pid=2492879)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [11:01:25<4:39:06, 128.82s/it]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [11:03:06<4:19:24, 120.65s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [11:04:47<4:04:52, 114.79s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [11:06:31<3:56:04, 111.53s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [11:08:20<3:52:20, 110.64s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [11:10:03<3:45:51, 108.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [11:11:43<3:39:09, 106.04s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [11:13:23<3:33:38, 104.22s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:15:05<3:30:33, 103.55s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:16:51<3:29:53, 104.08s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:19:38<4:06:09, 123.08s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:21:22<3:52:49, 117.39s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:23:07<3:43:27, 113.63s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:24:48<3:34:10, 109.83s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:26:27<3:26:05, 106.60s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 01:32:46,717:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:28:07<3:20:35, 104.66s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:29:46<3:15:32, 102.92s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:31:24<3:11:01, 101.43s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:33:02<3:07:11, 100.28s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:34:34<3:01:09, 97.92s/it] 
[36m(TaskRunner pid=2492879)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:37:32<3:43:23, 121.85s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:39:11<3:29:12, 115.16s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:40:53<3:19:53, 111.05s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:42:39<3:15:24, 109.58s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:44:13<3:05:22, 104.93s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:45:52<3:00:21, 103.06s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:47:29<2:55:51, 101.46s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:49:06<2:51:43, 100.03s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:50:47<2:50:19, 100.20s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:52:33<2:51:48, 102.06s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:55:34<3:29:35, 125.75s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:57:15<3:15:07, 118.25s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 02:03:34,119:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 02:03:41,252:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 02:03:46,257:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:59:10<3:11:34, 117.30s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [12:00:53<3:02:38, 112.97s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 02:07:16,964:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [12:02:43<2:59:35, 112.24s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [12:04:22<2:51:03, 108.04s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [12:05:59<2:44:10, 104.80s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [12:07:54<2:47:03, 107.78s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [12:09:34<2:41:54, 105.59s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [12:11:16<2:38:18, 104.38s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [12:14:09<3:07:27, 124.97s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:15:50<2:54:39, 117.75s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:17:34<2:46:49, 113.75s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:19:10<2:37:15, 108.46s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:20:48<2:30:53, 105.28s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:22:36<2:30:20, 106.12s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:24:16<2:25:58, 104.26s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:25:56<2:22:20, 102.90s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:27:36<2:19:43, 102.23s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:29:17<2:17:21, 101.74s/it]
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(TaskRunner pid=2492879)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:32:26<2:50:43, 128.04s/it]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:34:09<2:38:36, 120.47s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:35:49<2:28:28, 114.22s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:37:35<2:23:29, 111.81s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:39:21<2:19:21, 110.02s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:40:59<2:13:09, 106.53s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:42:40<2:09:22, 104.90s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:44:27<2:08:24, 105.54s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:46:13<2:06:41, 105.58s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:47:56<2:03:52, 104.68s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:50:56<2:28:39, 127.43s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:52:52<2:22:28, 123.89s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:54:43<2:16:06, 120.10s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:56:29<2:09:26, 115.92s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:58:14<2:03:57, 112.68s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:59:53<1:57:38, 108.59s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [13:01:37<1:54:21, 107.21s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [13:03:22<1:51:45, 106.43s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [13:05:04<1:48:34, 105.07s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [13:06:48<1:46:31, 104.77s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [13:09:50<2:08:03, 128.05s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [13:11:36<1:59:27, 121.49s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [13:13:30<1:55:07, 119.09s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [13:15:12<1:48:18, 114.01s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [13:17:01<1:44:55, 112.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:18:48<1:41:37, 110.86s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:20:40<1:39:58, 111.08s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:22:32<1:38:29, 111.50s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:24:28<1:37:51, 112.90s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:26:19<1:35:25, 112.26s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 03:32:44,143:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:29:26<1:52:08, 134.58s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:31:11<1:42:39, 125.71s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:32:55<1:35:25, 119.28s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:34:45<1:31:21, 116.63s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:36:28<1:26:12, 112.44s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:38:16<1:23:24, 111.21s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:40:02<1:20:16, 109.46s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:41:49<1:17:57, 108.79s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:43:32<1:14:52, 106.97s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:45:15<1:12:21, 105.89s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:48:08<1:24:02, 126.05s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:49:50<1:17:09, 118.70s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:51:33<1:12:12, 114.01s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:53:20<1:09:04, 112.03s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:55:03<1:05:28, 109.12s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:56:46<1:02:44, 107.56s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 04:03:03,230:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:58:27<59:45, 105.45s/it]  
[36m(TaskRunner pid=2492879)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [14:00:08<57:12, 104.02s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [14:01:48<54:54, 102.96s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [14:03:31<53:14, 103.04s/it]
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(TaskRunner pid=2492879)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [14:06:38<1:04:04, 128.14s/it]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2492879)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [14:08:21<58:12, 120.43s/it]  
[36m(TaskRunner pid=2492879)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [14:10:00<53:13, 114.07s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [14:11:42<49:40, 110.38s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [14:13:22<46:28, 107.26s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [14:15:03<43:57, 105.52s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [14:16:41<41:19, 103.31s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [14:18:28<40:03, 104.48s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [14:20:09<37:54, 103.38s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:21:49<35:47, 102.28s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:24:42<41:12, 123.62s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:26:27<37:20, 117.94s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:28:07<33:43, 112.44s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:29:49<31:01, 109.49s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:31:27<28:16, 106.04s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:33:12<26:27, 105.81s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 04:39:35,799:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:34:59<24:43, 106.00s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 04:41:18,931:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:36:45<22:59, 106.08s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:38:26<20:52, 104.40s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:40:07<18:57, 103.41s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:43:08<21:06, 126.65s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:44:52<17:58, 119.89s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:46:38<15:27, 115.88s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 04:52:57,326:Timeout during comparison
[36m(TaskRunner pid=2492879)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:48:24<13:09, 112.72s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:50:03<10:52, 108.77s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:51:45<08:52, 106.58s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:53:27<07:01, 105.36s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:55:06<05:09, 103.29s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:56:51<03:27, 103.99s/it]
[36m(TaskRunner pid=2492879)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:58:39<01:45, 105.09s/it]
[36m(TaskRunner pid=2492879)[0m WARNING:2025-11-27 05:06:33,963:Timeout during comparison
[36m(WorkerDict pid=2496465)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2496465)[0m   warnings.warn(
[36m(TaskRunner pid=2492879)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [15:01:57<01:52, 112.98s/it]
[36m(WorkerDict pid=2496692)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2496692)[0m   warnings.warn([32m [repeated 3x across cluster][0m
