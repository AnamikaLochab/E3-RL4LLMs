
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) gcc/14.1.0 => gcc/11.4.1

+ NUM_EPISODES=3
+ n_samples_per_prompt=8
+ n_rollout_max=12
+ n_rollout_min=4
+ LR_ACTOR=5e-6
+ entropy_coeff=0
+ n_rollout_update=2
+ enable_temperature_scheduler=True
+ enable_annealing=True
+ TRAIN_DATADIR=./dataset/train_data_10k.parquet
+ VAL_DATADIR=./dataset/valid_data.parquet
+ MODELDIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ PRETRAIN_DIR=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
+ SAVE_DIR=../checkpoint/e3_1_5b_e3_3/
+ TENSORBOARD_PATH=../checkpoint/e3_1_5b_e3_3//tensorboard
+ export TENSORBOARD_DIR=../checkpoint/e3_1_5b_e3_3//tensorboard
+ TENSORBOARD_DIR=../checkpoint/e3_1_5b_e3_3//tensorboard
+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ python3 -m e3.main_e3 algorithm.adv_estimator=grpo data.train_files=./dataset/train_data_10k.parquet data.val_files=./dataset/valid_data.parquet data.train_batch_size=64 data.max_prompt_length=2048 data.max_response_length=6144 data.filter_overlong_prompts=True data.truncation=error actor_rollout_ref.model.path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B actor_rollout_ref.actor.optim.lr=5e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=512 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.entropy_coeff=0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=8 actor_rollout_ref.rollout.n_low=4 actor_rollout_ref.rollout.n_high=12 actor_rollout_ref.rollout.n_update=2 actor_rollout_ref.rollout.temperature=1 actor_rollout_ref.rollout.enable_temperature_scheduler=True actor_rollout_ref.rollout.enable_annealing=True actor_rollout_ref.rollout.max_steps=4 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=[console,tensorboard]' trainer.project_name=GRPO trainer.experiment_name=Qwen trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.default_local_dir=../checkpoint/e3_1_5b_e3_3/ trainer.save_freq=50 trainer.test_freq=10 trainer.total_epochs=3
2025-11-27 14:16:00,155	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(TaskRunner pid=2371994)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 14:16:21,058:Waiting for register center actor DyPQJm_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2375788)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=2375582)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=2375582)[0m [rank0]:[W1127 14:16:39.844964491 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[36m(WorkerDict pid=2375582)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2375582)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2375582)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn(  # warn only once[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m [rank3]:[W1127 14:16:39.176087232 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2375582)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2375788)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. [32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2375788)[0m   warnings.warn(  # warn only once[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2375788)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(WorkerDict pid=2375790)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=2371994)[0m Training Progress:   0%|          | 0/480 [00:00<?, ?it/s]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2371994)[0m Training Progress:   0%|          | 1/480 [02:00<15:58:48, 120.10s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   0%|          | 2/480 [03:59<15:53:00, 119.63s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   1%|          | 3/480 [06:03<16:05:46, 121.48s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   1%|          | 4/480 [07:59<15:46:20, 119.29s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   1%|          | 5/480 [10:01<15:53:20, 120.42s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   1%|â–         | 6/480 [12:04<15:58:02, 121.27s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   1%|â–         | 7/480 [14:05<15:56:05, 121.28s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   2%|â–         | 8/480 [16:04<15:46:51, 120.36s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   2%|â–         | 9/480 [18:04<15:45:24, 120.44s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   2%|â–         | 10/480 [21:27<19:03:07, 145.93s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   2%|â–         | 11/480 [23:24<17:49:54, 136.88s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   2%|â–Ž         | 12/480 [25:20<16:59:49, 130.75s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   3%|â–Ž         | 13/480 [27:19<16:29:58, 127.19s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   3%|â–Ž         | 14/480 [29:19<16:10:57, 125.02s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   3%|â–Ž         | 15/480 [31:14<15:45:38, 122.02s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   3%|â–Ž         | 16/480 [33:12<15:34:25, 120.83s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   4%|â–Ž         | 17/480 [35:14<15:34:15, 121.07s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   4%|â–         | 18/480 [37:12<15:24:36, 120.08s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   4%|â–         | 19/480 [39:13<15:24:28, 120.32s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   4%|â–         | 20/480 [42:34<18:29:12, 144.68s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   4%|â–         | 21/480 [44:35<17:31:00, 137.39s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   5%|â–         | 22/480 [46:35<16:49:19, 132.23s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   5%|â–         | 23/480 [48:32<16:13:56, 127.87s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   5%|â–Œ         | 24/480 [50:28<15:43:44, 124.18s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   5%|â–Œ         | 25/480 [52:22<15:19:06, 121.20s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 15:12:34,528:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:   5%|â–Œ         | 26/480 [54:22<15:14:36, 120.87s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   6%|â–Œ         | 27/480 [56:24<15:14:32, 121.13s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   6%|â–Œ         | 28/480 [58:16<14:50:42, 118.23s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   6%|â–Œ         | 29/480 [1:00:11<14:43:26, 117.53s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   6%|â–‹         | 30/480 [1:03:20<17:20:58, 138.80s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 15:23:27,272:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 15:23:34,477:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:   6%|â–‹         | 31/480 [1:05:18<16:31:47, 132.53s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   7%|â–‹         | 32/480 [1:07:04<15:29:52, 124.54s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   7%|â–‹         | 33/480 [1:09:01<15:10:53, 122.27s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   7%|â–‹         | 34/480 [1:10:55<14:51:49, 119.98s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   7%|â–‹         | 35/480 [1:12:47<14:31:09, 117.46s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   8%|â–Š         | 36/480 [1:14:38<14:14:52, 115.52s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   8%|â–Š         | 37/480 [1:16:30<14:05:20, 114.49s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   8%|â–Š         | 38/480 [1:18:27<14:08:47, 115.22s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   8%|â–Š         | 39/480 [1:20:16<13:53:09, 113.35s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   8%|â–Š         | 40/480 [1:23:27<16:42:09, 136.66s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   9%|â–Š         | 41/480 [1:25:17<15:40:38, 128.56s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   9%|â–‰         | 42/480 [1:27:12<15:10:12, 124.69s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   9%|â–‰         | 43/480 [1:29:01<14:32:50, 119.84s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   9%|â–‰         | 44/480 [1:30:51<14:10:44, 117.07s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:   9%|â–‰         | 45/480 [1:32:36<13:42:17, 113.42s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  10%|â–‰         | 46/480 [1:34:27<13:35:14, 112.71s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  10%|â–‰         | 47/480 [1:36:16<13:23:45, 111.38s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  10%|â–ˆ         | 48/480 [1:38:06<13:20:09, 111.13s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  10%|â–ˆ         | 49/480 [1:40:01<13:26:49, 112.32s/it]
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(TaskRunner pid=2371994)[0m Training Progress:  10%|â–ˆ         | 50/480 [1:43:19<16:29:36, 138.08s/it]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2371994)[0m Training Progress:  11%|â–ˆ         | 51/480 [1:45:08<15:24:01, 129.23s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  11%|â–ˆ         | 52/480 [1:46:55<14:33:40, 122.48s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  11%|â–ˆ         | 53/480 [1:48:39<13:52:09, 116.93s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  11%|â–ˆâ–        | 54/480 [1:50:27<13:32:26, 114.43s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  11%|â–ˆâ–        | 55/480 [1:52:13<13:12:35, 111.90s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  12%|â–ˆâ–        | 56/480 [1:54:02<13:03:01, 110.81s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  12%|â–ˆâ–        | 57/480 [1:55:51<12:58:43, 110.46s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  12%|â–ˆâ–        | 58/480 [1:57:35<12:42:36, 108.43s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  12%|â–ˆâ–        | 59/480 [1:59:17<12:27:12, 106.49s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  12%|â–ˆâ–Ž        | 60/480 [2:02:14<14:53:43, 127.68s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  13%|â–ˆâ–Ž        | 61/480 [2:04:05<14:17:15, 122.76s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  13%|â–ˆâ–Ž        | 62/480 [2:05:52<13:41:43, 117.95s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  13%|â–ˆâ–Ž        | 63/480 [2:07:38<13:15:09, 114.41s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  13%|â–ˆâ–Ž        | 64/480 [2:09:30<13:08:02, 113.66s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  14%|â–ˆâ–Ž        | 65/480 [2:11:12<12:41:53, 110.15s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  14%|â–ˆâ–        | 66/480 [2:13:01<12:38:02, 109.86s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  14%|â–ˆâ–        | 67/480 [2:14:48<12:28:57, 108.81s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  14%|â–ˆâ–        | 68/480 [2:16:32<12:17:17, 107.37s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  14%|â–ˆâ–        | 69/480 [2:18:19<12:16:17, 107.49s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  15%|â–ˆâ–        | 70/480 [2:21:23<14:50:29, 130.31s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  15%|â–ˆâ–        | 71/480 [2:23:10<13:59:55, 123.22s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  15%|â–ˆâ–Œ        | 72/480 [2:24:54<13:18:54, 117.49s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  15%|â–ˆâ–Œ        | 73/480 [2:26:40<12:53:24, 114.02s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  15%|â–ˆâ–Œ        | 74/480 [2:28:28<12:40:59, 112.46s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  16%|â–ˆâ–Œ        | 75/480 [2:30:13<12:22:47, 110.04s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  16%|â–ˆâ–Œ        | 76/480 [2:32:03<12:21:19, 110.10s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  16%|â–ˆâ–Œ        | 77/480 [2:33:51<12:15:13, 109.46s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  16%|â–ˆâ–‹        | 78/480 [2:35:37<12:06:19, 108.41s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  16%|â–ˆâ–‹        | 79/480 [2:37:25<12:04:43, 108.44s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  17%|â–ˆâ–‹        | 80/480 [2:40:23<14:21:24, 129.21s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  17%|â–ˆâ–‹        | 81/480 [2:42:09<13:32:27, 122.17s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  17%|â–ˆâ–‹        | 82/480 [2:43:54<12:56:58, 117.13s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  17%|â–ˆâ–‹        | 83/480 [2:45:43<12:38:15, 114.60s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  18%|â–ˆâ–Š        | 84/480 [2:47:29<12:19:15, 112.01s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  18%|â–ˆâ–Š        | 85/480 [2:49:15<12:04:47, 110.10s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  18%|â–ˆâ–Š        | 86/480 [2:51:00<11:53:36, 108.67s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  18%|â–ˆâ–Š        | 87/480 [2:52:50<11:53:51, 108.98s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  18%|â–ˆâ–Š        | 88/480 [2:54:38<11:50:42, 108.78s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  19%|â–ˆâ–Š        | 89/480 [2:56:22<11:39:57, 107.41s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  19%|â–ˆâ–‰        | 90/480 [2:59:22<14:00:08, 129.25s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  19%|â–ˆâ–‰        | 91/480 [3:01:06<13:07:28, 121.46s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  19%|â–ˆâ–‰        | 92/480 [3:02:50<12:32:10, 116.32s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  19%|â–ˆâ–‰        | 93/480 [3:04:34<12:07:21, 112.77s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  20%|â–ˆâ–‰        | 94/480 [3:06:25<12:00:16, 111.96s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  20%|â–ˆâ–‰        | 95/480 [3:08:09<11:44:53, 109.85s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  20%|â–ˆâ–ˆ        | 96/480 [3:09:58<11:40:39, 109.48s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  20%|â–ˆâ–ˆ        | 97/480 [3:11:41<11:26:37, 107.57s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  20%|â–ˆâ–ˆ        | 98/480 [3:13:20<11:07:53, 104.90s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  21%|â–ˆâ–ˆ        | 99/480 [3:15:11<11:18:52, 106.91s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 17:35:16,302:Timeout during comparison
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(WorkerDict pid=2375582)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=2375582)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is bfloat16. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(TaskRunner pid=2371994)[0m Training Progress:  21%|â–ˆâ–ˆ        | 100/480 [3:18:32<14:15:15, 135.04s/it]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2371994)[0m Training Progress:  21%|â–ˆâ–ˆ        | 101/480 [3:20:14<13:09:28, 124.98s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 17:40:18,365:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 102/480 [3:22:04<12:39:00, 120.48s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 103/480 [3:23:43<11:58:11, 114.30s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 104/480 [3:25:26<11:33:52, 110.72s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 105/480 [3:27:11<11:21:24, 109.02s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 106/480 [3:28:50<11:00:43, 106.00s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 107/480 [3:30:38<11:02:04, 106.50s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  22%|â–ˆâ–ˆâ–Ž       | 108/480 [3:32:16<10:46:16, 104.24s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 109/480 [3:34:10<11:01:03, 106.91s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 110/480 [3:37:12<13:19:21, 129.63s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 111/480 [3:38:57<12:30:27, 122.03s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [3:40:34<11:43:56, 114.77s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  24%|â–ˆâ–ˆâ–Ž       | 113/480 [3:42:20<11:25:32, 112.08s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 114/480 [3:44:07<11:13:35, 110.42s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 115/480 [3:45:43<10:45:06, 106.05s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 116/480 [3:47:23<10:33:02, 104.35s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 117/480 [3:49:06<10:28:52, 103.95s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 118/480 [3:50:50<10:26:52, 103.90s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 18:10:52,308:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 119/480 [3:52:34<10:26:27, 104.12s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 18:12:44,788:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 18:12:49,799:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 120/480 [3:55:46<13:02:10, 130.36s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 121/480 [3:57:23<11:59:46, 120.30s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 122/480 [3:59:10<11:34:43, 116.43s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 18:19:16,947:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 123/480 [4:00:59<11:19:21, 114.18s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 124/480 [4:02:52<11:15:32, 113.86s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 125/480 [4:04:31<10:47:32, 109.44s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 126/480 [4:06:15<10:35:00, 107.63s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  26%|â–ˆâ–ˆâ–‹       | 127/480 [4:07:53<10:16:03, 104.71s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 128/480 [4:09:34<10:09:05, 103.82s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 129/480 [4:11:15<10:01:18, 102.79s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 130/480 [4:14:11<12:08:42, 124.92s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 131/480 [4:15:55<11:28:57, 118.45s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 132/480 [4:17:30<10:46:47, 111.52s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 133/480 [4:19:14<10:31:39, 109.22s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 134/480 [4:20:57<10:19:19, 107.40s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 135/480 [4:22:40<10:10:05, 106.10s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 136/480 [4:24:23<10:03:22, 105.24s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 137/480 [4:26:02<9:50:36, 103.31s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 138/480 [4:27:46<9:48:58, 103.33s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 139/480 [4:29:27<9:44:09, 102.78s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 140/480 [4:32:20<11:40:50, 123.68s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 141/480 [4:33:59<10:58:19, 116.52s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 142/480 [4:35:38<10:25:34, 111.05s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  30%|â–ˆâ–ˆâ–‰       | 143/480 [4:37:17<10:03:55, 107.52s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [4:38:55<9:45:48, 104.61s/it] 
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 18:58:57,148:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 145/480 [4:40:37<9:39:23, 103.77s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 146/480 [4:42:10<9:19:45, 100.55s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 147/480 [4:43:44<9:08:21, 98.80s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 148/480 [4:45:22<9:04:14, 98.36s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 149/480 [4:47:05<9:11:23, 99.95s/it]
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(TaskRunner pid=2371994)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 150/480 [4:50:12<11:33:22, 126.07s/it]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2371994)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 151/480 [4:51:55<10:53:18, 119.14s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 152/480 [4:53:35<10:19:35, 113.34s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 153/480 [4:55:12<9:51:34, 108.54s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 154/480 [4:56:58<9:44:50, 107.64s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 155/480 [4:58:37<9:28:41, 104.99s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 156/480 [5:00:13<9:11:58, 102.22s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 157/480 [5:01:50<9:02:49, 100.83s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 158/480 [5:03:32<9:03:19, 101.24s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159/480 [5:05:12<8:59:23, 100.82s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [5:08:03<10:49:39, 121.81s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 161/480 [5:09:52<10:27:32, 118.03s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 162/480 [5:11:35<10:02:04, 113.60s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 163/480 [5:13:16<9:38:58, 109.59s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 164/480 [5:14:55<9:21:24, 106.60s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 165/480 [5:16:38<9:13:40, 105.46s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 166/480 [5:18:21<9:07:23, 104.60s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 167/480 [5:20:00<8:56:47, 102.90s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 168/480 [5:21:43<8:55:40, 103.01s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 169/480 [5:23:24<8:51:31, 102.55s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170/480 [5:26:18<10:40:09, 123.90s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 171/480 [5:28:03<10:08:35, 118.17s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 172/480 [5:29:43<9:39:03, 112.80s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 173/480 [5:31:26<9:21:23, 109.72s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 174/480 [5:33:02<8:59:47, 105.84s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 175/480 [5:34:46<8:53:45, 105.00s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [5:36:29<8:49:50, 104.57s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 177/480 [5:38:17<8:53:21, 105.61s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 178/480 [5:40:00<8:48:00, 104.90s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 179/480 [5:41:43<8:42:29, 104.15s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 180/480 [5:44:40<10:30:08, 126.03s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 20:04:44,060:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 20:04:49,885:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 20:04:55,615:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 181/480 [5:46:39<10:17:10, 123.85s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 182/480 [5:48:20<9:40:57, 116.97s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 183/480 [5:50:03<9:18:45, 112.88s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 184/480 [5:51:41<8:54:57, 108.44s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 185/480 [5:53:31<8:54:50, 108.78s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 186/480 [5:55:11<8:41:31, 106.44s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 187/480 [5:56:55<8:35:29, 105.56s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 188/480 [5:58:39<8:31:13, 105.05s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 189/480 [6:00:25<8:30:31, 105.26s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 190/480 [6:03:16<10:04:37, 125.10s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 191/480 [6:04:54<9:23:39, 117.02s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [6:06:33<8:55:20, 111.53s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 193/480 [6:08:14<8:37:59, 108.29s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194/480 [6:09:56<8:27:57, 106.56s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 195/480 [6:11:35<8:15:39, 104.35s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 196/480 [6:13:17<8:09:54, 103.50s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 197/480 [6:14:55<8:00:20, 101.84s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 198/480 [6:16:36<7:57:38, 101.62s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/480 [6:18:14<7:50:29, 100.46s/it]
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(TaskRunner pid=2371994)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 200/480 [6:21:24<9:54:36, 127.42s/it]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 20:41:27,221:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201/480 [6:23:10<9:22:24, 120.95s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 202/480 [6:24:49<8:50:21, 114.47s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 203/480 [6:26:26<8:23:27, 109.05s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 204/480 [6:28:03<8:06:12, 105.70s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205/480 [6:29:41<7:53:34, 103.33s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 206/480 [6:31:23<7:49:19, 102.77s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/480 [6:33:07<7:49:05, 103.10s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [6:34:40<7:34:31, 100.26s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209/480 [6:36:18<7:28:51, 99.38s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/480 [6:39:11<9:06:41, 121.49s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/480 [6:40:50<8:35:32, 114.99s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/480 [6:42:31<8:13:48, 110.55s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/480 [6:44:14<8:01:45, 108.26s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/480 [6:45:53<7:48:46, 105.74s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/480 [6:47:30<7:34:59, 103.02s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 216/480 [6:49:07<7:25:40, 101.29s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 217/480 [6:50:45<7:19:45, 100.33s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 218/480 [6:52:19<7:09:23, 98.33s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 219/480 [6:54:04<7:16:14, 100.28s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220/480 [6:56:52<8:42:11, 120.50s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 221/480 [6:58:30<8:11:43, 113.91s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 222/480 [7:00:10<7:52:10, 109.81s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223/480 [7:01:44<7:29:02, 104.83s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [7:03:25<7:23:22, 103.92s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 225/480 [7:05:02<7:12:27, 101.75s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 226/480 [7:06:39<7:04:57, 100.38s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227/480 [7:08:21<7:04:34, 100.69s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 228/480 [7:10:03<7:05:07, 101.22s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 229/480 [7:11:46<7:05:55, 101.81s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 230/480 [7:14:34<8:26:16, 121.50s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231/480 [7:16:10<7:52:34, 113.87s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 232/480 [7:17:48<7:31:00, 109.11s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 233/480 [7:19:26<7:15:20, 105.75s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 234/480 [7:21:01<7:01:11, 102.73s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 235/480 [7:22:37<6:50:34, 100.55s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 236/480 [7:24:13<6:43:23, 99.20s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 237/480 [7:25:49<6:37:28, 98.14s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238/480 [7:27:31<6:40:41, 99.35s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 239/480 [7:29:10<6:38:41, 99.26s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [7:32:01<8:03:38, 120.91s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241/480 [7:33:47<7:43:23, 116.33s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242/480 [7:35:26<7:20:58, 111.17s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 243/480 [7:37:06<7:05:28, 107.72s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 244/480 [7:38:45<6:54:00, 105.26s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 245/480 [7:40:28<6:49:23, 104.52s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 246/480 [7:42:05<6:38:54, 102.28s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 247/480 [7:43:45<6:34:29, 101.59s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 248/480 [7:45:28<6:34:41, 102.08s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249/480 [7:47:09<6:31:02, 101.57s/it]
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(TaskRunner pid=2371994)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 250/480 [7:50:13<8:04:21, 126.35s/it]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2371994)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 251/480 [7:51:49<7:28:07, 117.41s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 252/480 [7:53:29<7:06:05, 112.13s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253/480 [7:55:10<6:51:16, 108.71s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 22:15:10,956:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 254/480 [7:56:53<6:43:16, 107.07s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 255/480 [7:58:30<6:30:19, 104.09s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [8:00:11<6:24:37, 103.02s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 257/480 [8:01:48<6:16:44, 101.36s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/480 [8:03:32<6:17:01, 101.90s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 22:23:32,004:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/480 [8:05:13<6:14:21, 101.64s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/480 [8:07:58<7:23:05, 120.84s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/480 [8:09:38<6:58:17, 114.60s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/480 [8:11:23<6:45:22, 111.57s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/480 [8:13:06<6:34:04, 108.96s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 22:33:10,241:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264/480 [8:14:55<6:32:42, 109.09s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 265/480 [8:16:33<6:18:27, 105.62s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 266/480 [8:18:13<6:11:04, 104.04s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267/480 [8:19:52<6:04:35, 102.70s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 268/480 [8:21:25<5:51:47, 99.56s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 269/480 [8:23:05<5:50:34, 99.69s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 22:43:10,924:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/480 [8:26:06<7:14:39, 124.19s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271/480 [8:27:52<6:53:29, 118.71s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [8:29:31<6:31:08, 112.83s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 273/480 [8:31:09<6:13:50, 108.36s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 274/480 [8:32:49<6:03:54, 105.99s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275/480 [8:34:25<5:51:56, 103.01s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 276/480 [8:36:09<5:51:11, 103.29s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 22:56:11,457:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 277/480 [8:37:58<5:54:21, 104.74s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278/480 [8:39:33<5:43:13, 101.95s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 279/480 [8:41:10<5:36:41, 100.51s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 280/480 [8:43:58<6:42:09, 120.65s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 281/480 [8:45:28<6:09:57, 111.54s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 282/480 [8:47:06<5:55:02, 107.59s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 283/480 [8:48:44<5:42:58, 104.46s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 284/480 [8:50:26<5:39:33, 103.95s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285/480 [8:52:09<5:36:37, 103.58s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 286/480 [8:53:46<5:28:07, 101.48s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 287/480 [8:55:26<5:24:59, 101.03s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [8:57:04<5:20:42, 100.22s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289/480 [8:58:40<5:15:27, 99.10s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 290/480 [9:01:40<6:29:58, 123.15s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 291/480 [9:03:17<6:03:47, 115.49s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 292/480 [9:04:55<5:45:21, 110.22s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293/480 [9:06:33<5:31:33, 106.38s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 294/480 [9:08:10<5:21:15, 103.63s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 295/480 [9:09:49<5:15:06, 102.20s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 296/480 [9:11:30<5:12:40, 101.96s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297/480 [9:13:04<5:03:55, 99.65s/it] 
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-27 23:33:05,754:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 298/480 [9:14:48<5:06:02, 100.89s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 299/480 [9:16:24<4:59:45, 99.37s/it] 
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(TaskRunner pid=2371994)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 300/480 [9:19:26<6:12:32, 124.18s/it]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2371994)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 301/480 [9:21:04<5:47:10, 116.37s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/480 [9:22:42<5:28:32, 110.74s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 303/480 [9:24:24<5:19:13, 108.21s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [9:26:04<5:10:10, 105.74s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 305/480 [9:27:37<4:57:18, 101.93s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 306/480 [9:29:15<4:52:06, 100.73s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/480 [9:30:50<4:45:25, 98.99s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/480 [9:32:25<4:40:10, 97.74s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/480 [9:34:04<4:39:52, 98.20s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/480 [9:36:54<5:39:15, 119.74s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/480 [9:38:36<5:21:55, 114.29s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 312/480 [9:40:13<5:05:53, 109.25s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 313/480 [9:41:48<4:52:25, 105.06s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 314/480 [9:43:27<4:45:28, 103.19s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315/480 [9:45:08<4:41:35, 102.40s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 316/480 [9:46:49<4:38:51, 102.02s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 00:06:46,950:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 317/480 [9:48:26<4:33:08, 100.54s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 318/480 [9:50:04<4:29:32, 99.83s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 319/480 [9:51:44<4:28:08, 99.93s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [9:54:36<5:23:26, 121.29s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 321/480 [9:56:18<5:06:48, 115.78s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 00:16:22,139:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 00:16:27,156:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 00:16:33,560:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 00:16:43,435:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 00:16:48,453:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322/480 [9:58:33<5:19:58, 121.51s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 323/480 [10:00:09<4:57:49, 113.82s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 324/480 [10:01:51<4:46:34, 110.22s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 325/480 [10:03:30<4:36:11, 106.91s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326/480 [10:05:11<4:29:45, 105.10s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 327/480 [10:06:51<4:23:51, 103.48s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 328/480 [10:08:29<4:18:06, 101.89s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329/480 [10:10:02<4:09:46, 99.25s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 330/480 [10:12:48<4:57:57, 119.18s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 331/480 [10:14:22<4:37:03, 111.57s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 332/480 [10:15:56<4:22:51, 106.56s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333/480 [10:17:36<4:16:03, 104.51s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 334/480 [10:19:12<4:08:18, 102.04s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 335/480 [10:20:48<4:01:49, 100.07s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [10:22:23<3:56:38, 98.60s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 337/480 [10:23:59<3:53:03, 97.78s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 338/480 [10:25:35<3:50:04, 97.22s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 339/480 [10:27:10<3:47:00, 96.60s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340/480 [10:29:54<4:32:36, 116.83s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 341/480 [10:31:30<4:16:05, 110.54s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 342/480 [10:33:09<4:06:11, 107.04s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 343/480 [10:34:45<3:57:01, 103.81s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344/480 [10:36:21<3:49:44, 101.35s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 345/480 [10:38:01<3:47:08, 100.95s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 346/480 [10:39:40<3:44:32, 100.54s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 347/480 [10:41:17<3:40:26, 99.45s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 348/480 [10:42:55<3:37:55, 99.06s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349/480 [10:44:31<3:33:56, 97.99s/it]
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(TaskRunner pid=2371994)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 350/480 [10:47:36<4:29:16, 124.28s/it]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2371994)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351/480 [10:49:16<4:11:30, 116.98s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [10:50:56<3:58:26, 111.77s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 353/480 [10:52:38<3:50:26, 108.87s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/480 [10:54:20<3:44:24, 106.86s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/480 [10:56:01<3:38:54, 105.08s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/480 [10:57:39<3:32:30, 102.83s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/480 [10:59:19<3:29:10, 102.04s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/480 [11:00:58<3:25:33, 101.10s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/480 [11:02:42<3:25:52, 102.08s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 360/480 [11:05:25<4:00:43, 120.36s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 361/480 [11:07:05<3:46:41, 114.30s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 362/480 [11:08:45<3:36:18, 109.99s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363/480 [11:10:22<3:26:31, 105.91s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 364/480 [11:11:57<3:18:39, 102.75s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 01:31:54,959:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 01:32:00,729:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 01:32:06,444:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 365/480 [11:13:45<3:19:42, 104.19s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 366/480 [11:15:21<3:13:25, 101.80s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 367/480 [11:16:56<3:07:53, 99.76s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [11:18:34<3:05:15, 99.24s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 369/480 [11:20:08<3:00:30, 97.57s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370/480 [11:22:58<3:39:06, 119.51s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 371/480 [11:24:37<3:25:39, 113.21s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 372/480 [11:26:14<3:14:54, 108.28s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373/480 [11:28:00<3:11:57, 107.64s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 374/480 [11:29:32<3:02:13, 103.15s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 375/480 [11:31:09<2:57:14, 101.28s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 376/480 [11:32:46<2:52:58, 99.79s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377/480 [11:34:22<2:49:29, 98.73s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 378/480 [11:36:02<2:48:39, 99.21s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 379/480 [11:37:39<2:45:39, 98.42s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380/480 [11:40:27<3:18:51, 119.32s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 381/480 [11:42:07<3:07:07, 113.41s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 02:02:09,242:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 02:02:14,259:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 382/480 [11:43:55<3:02:57, 112.02s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 383/480 [11:45:36<2:55:27, 108.54s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [11:47:24<2:53:23, 108.37s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 385/480 [11:49:01<2:46:30, 105.16s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 386/480 [11:50:38<2:40:53, 102.69s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 387/480 [11:52:20<2:38:55, 102.53s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388/480 [11:53:57<2:34:25, 100.71s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 389/480 [11:55:38<2:32:50, 100.77s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 390/480 [11:58:30<3:03:14, 122.16s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391/480 [12:00:12<2:52:21, 116.20s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 392/480 [12:01:51<2:42:58, 111.12s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 393/480 [12:03:28<2:34:34, 106.61s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 394/480 [12:05:06<2:29:11, 104.09s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395/480 [12:06:48<2:26:33, 103.45s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 396/480 [12:08:24<2:21:55, 101.38s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 397/480 [12:10:02<2:18:45, 100.31s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 398/480 [12:11:42<2:16:54, 100.18s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399/480 [12:13:19<2:14:02, 99.29s/it] 
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(TaskRunner pid=2371994)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [12:16:26<2:47:15, 125.44s/it]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2371994)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 401/480 [12:18:09<2:36:32, 118.90s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/480 [12:19:52<2:28:20, 114.11s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/480 [12:21:32<2:20:58, 109.85s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/480 [12:23:13<2:15:52, 107.27s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/480 [12:24:48<2:09:25, 103.53s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406/480 [12:26:26<2:05:30, 101.76s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/480 [12:28:08<2:03:57, 101.88s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 02:48:07,371:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 408/480 [12:29:52<2:03:05, 102.58s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 409/480 [12:31:31<2:00:03, 101.46s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 410/480 [12:34:27<2:24:21, 123.73s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411/480 [12:36:08<2:14:40, 117.10s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 412/480 [12:37:51<2:07:43, 112.70s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 413/480 [12:39:31<2:01:48, 109.08s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 414/480 [12:41:11<1:56:47, 106.18s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 415/480 [12:42:43<1:50:37, 102.12s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [12:44:22<1:47:42, 100.98s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 417/480 [12:46:03<1:46:08, 101.09s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418/480 [12:47:42<1:43:37, 100.28s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 419/480 [12:49:20<1:41:16, 99.61s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 420/480 [12:52:13<2:01:43, 121.72s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 421/480 [12:53:52<1:52:59, 114.91s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422/480 [12:55:39<1:48:40, 112.43s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 423/480 [12:57:16<1:42:28, 107.86s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 424/480 [12:58:58<1:39:14, 106.32s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425/480 [13:00:40<1:36:16, 105.03s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 426/480 [13:02:22<1:33:27, 103.84s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427/480 [13:04:04<1:31:14, 103.29s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 428/480 [13:05:48<1:29:42, 103.50s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429/480 [13:07:32<1:28:06, 103.65s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 430/480 [13:10:23<1:43:21, 124.04s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 431/480 [13:12:02<1:35:10, 116.54s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [13:13:39<1:28:29, 110.62s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 433/480 [13:15:23<1:25:11, 108.76s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 434/480 [13:17:01<1:20:54, 105.53s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 435/480 [13:18:38<1:17:10, 102.91s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 436/480 [13:20:18<1:14:46, 101.96s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437/480 [13:22:01<1:13:19, 102.32s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 438/480 [13:23:41<1:11:10, 101.68s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 439/480 [13:25:21<1:09:10, 101.23s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 440/480 [13:28:10<1:21:02, 121.56s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 03:48:10,875:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441/480 [13:29:56<1:15:51, 116.69s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442/480 [13:31:39<1:11:16, 112.53s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 443/480 [13:33:18<1:06:56, 108.54s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 444/480 [13:35:00<1:03:54, 106.51s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 445/480 [13:36:42<1:01:27, 105.35s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 03:56:43,701:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 446/480 [13:38:24<59:05, 104.29s/it]  
[36m(TaskRunner pid=2371994)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 447/480 [13:40:04<56:34, 102.85s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [13:41:43<54:20, 101.89s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449/480 [13:43:25<52:35, 101.79s/it]
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(TaskRunner pid=2371994)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/480 [13:46:30<1:03:23, 126.77s/it]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=2371994)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/480 [13:48:10<57:27, 118.89s/it]  
[36m(TaskRunner pid=2371994)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/480 [13:49:48<52:32, 112.57s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/480 [13:51:27<48:47, 108.44s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/480 [13:53:07<45:56, 106.01s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/480 [13:54:44<42:59, 103.20s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 456/480 [13:56:20<40:26, 101.12s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 457/480 [13:58:04<39:04, 101.96s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 458/480 [13:59:42<36:58, 100.84s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 459/480 [14:01:20<34:57, 99.89s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460/480 [14:04:13<40:33, 121.66s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 461/480 [14:05:55<36:44, 116.02s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 462/480 [14:07:33<33:09, 110.54s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 04:27:36,287:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 463/480 [14:09:17<30:47, 108.69s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [14:10:52<27:53, 104.57s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 465/480 [14:12:35<25:58, 103.87s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 466/480 [14:14:15<23:59, 102.83s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467/480 [14:15:54<22:02, 101.74s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 468/480 [14:17:32<20:04, 100.41s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 469/480 [14:19:11<18:22, 100.19s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 470/480 [14:22:07<20:28, 122.84s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471/480 [14:23:46<17:21, 115.71s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 472/480 [14:25:27<14:49, 111.20s/it]
[36m(TaskRunner pid=2371994)[0m WARNING:2025-11-28 04:45:28,934:Timeout during comparison
[36m(TaskRunner pid=2371994)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 473/480 [14:27:10<12:41, 108.79s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 474/480 [14:28:47<10:31, 105.22s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 475/480 [14:30:24<08:34, 102.84s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 476/480 [14:32:02<06:45, 101.47s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 477/480 [14:33:36<04:57, 99.22s/it] 
[36m(TaskRunner pid=2371994)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 478/480 [14:35:19<03:20, 100.21s/it]
[36m(TaskRunner pid=2371994)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:37:02<01:41, 101.09s/it]
[36m(WorkerDict pid=2375582)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=2375582)[0m   warnings.warn(
[36m(TaskRunner pid=2371994)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479/480 [14:40:08<01:50, 110.25s/it]
[36m(WorkerDict pid=2375790)[0m /scratch/gautschi/alochab/conda_envs/e3/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=2375790)[0m   warnings.warn([32m [repeated 3x across cluster][0m
